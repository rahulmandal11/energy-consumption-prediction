{"version":3,"file":"3197.5568597e6f9e0b194a18.js?v=5568597e6f9e0b194a18","mappings":";;;;;;;;;;;;;;AAAO;AACP;AACA;AACO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;;AClCgC;AACzB;AACP,aAAa,EAAE,OAAO,KAAK,EAAE,OAAO;AACpC;AACA;AACO,uBAAuB,EAAE;AAChC,aAAa,EAAE,OAAO,KAAK,EAAE,OAAO;AACpC;AACA;AACA,aAAa,EAAE,OAAO,KAAK,EAAE,OAAO;AACpC;AACA;AACA;AACO;AACP,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN,IAAI,EAAE;AACN;AACA;;ACzC4G;AAClB;AAC1F;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,oCAAoC;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,aAAa;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uBAAuB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,aAAa;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,aAAa;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,aAAa;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uBAAuB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,EAAE,QAAQ,EAAE,QAAQ,EAAE,YAAY,EAAE;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,eAAe;AACrC;AACA;AACA,sBAAsB,eAAe;AACrC;AACA;AACA;AACA,sBAAsB,eAAe;AACrC;AACA;AACA,sBAAsB,eAAe;AACrC;AACA;AACA;AACA,sBAAsB,aAAa;AACnC;AACA;AACA,sBAAsB,aAAa;AACnC;AACA;AACA;AACA;AACA,YAAY,aAAa;AACzB,qBAAqB;AACrB;AACA;AACA,eAAe,uBAAuB;AACtC;AACA;AACA;AACA;AACA;AACA,6BAA6B,EAAE;AAC/B;AACA;AACA,6BAA6B,EAAE;AAC/B;AACA;AACA,6BAA6B,EAAE;AAC/B;AACA;AACA,6BAA6B,EAAE;AAC/B;AACA;AACA,6BAA6B,EAAE;AAC/B;AACA;AACA;AACA,YAAY,aAAa;AACzB,qBAAqB;AACrB;AACA;AACA,eAAe,uBAAuB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,iBAAiB,0BAA0B,EAAE;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,0BAA0B,EAAE;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,0BAA0B,EAAE;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,WAAW;AAC3B;AACA;AACA;AACA;AACA,oBAAoB,WAAW;AAC/B;AACA;AACA;AACA,+BAA+B,gCAAgC;AAC/D;AACA;AACA;AACA,oBAAoB,WAAW;AAC/B,6BAA6B,EAAE;AAC/B,oBAAoB,WAAW;AAC/B;AACA;AACA;AACA,gBAAgB,WAAW;AAC3B;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,0BAA0B,EAAE;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,0BAA0B,EAAE;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,aAAa;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;;ACvuBO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7FkD;AACW;AAC7D;;;;;;;;;;;;;;;;ACI8B;;AAE9B;AAMiB;;AAEjB;AACA,yCAAyC,sFAA2B;AACpE;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,kCAAkC,qEAAM;AACxC,oCAAoC,qEAAM,WAAW,+EAAoB;AACzE;AACA;AACA,0CAA0C,6DAAe;AACzD,iBAAiB,yDAAM;AACvB,IAAI,+EAA6B;AACjC,IAAI,uFAA4B;AAChC;AACA,mBAAmB,yDAAM;AACzB,IAAI,yEAAuB,GAAG,QAAQ;AACtC,IAAI,yFAA8B;AAClC;AACA;AACA;AACA,WAAW;AACX;AACA,qEAAM;;AAKJ;;;;;;;;;;;;;;;;;AC7C4B;;AAE9B;AAMiB;;AAEjB;AACA,wCAAwC,sFAA2B;AACnE;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA;;AAEA;AACA,4DAA4D,MAAM;AAClE,0CAA0C,wFAA6B;AACvE;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA,MAAM;AACN;AACA,MAAM;AACN;AACA,MAAM;AACN;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qEAAM;AACN;AACA;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA,SAAS;AACT,QAAQ;AACR;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,kCAAkC,qEAAM;AACxC,oCAAoC,qEAAM;AAC1C,GAAG;AACH;AACA,sCAAsC,qEAAM;AAC5C;AACA;AACA,yCAAyC,6DAAe;AACxD,iBAAiB,yDAAM;AACvB,IAAI,+EAA6B;AACjC,IAAI,uFAA4B;AAChC;AACA,kBAAkB,yDAAM;AACxB,IAAI,yEAAuB,GAAG,QAAQ;AACtC,IAAI,wFAA6B;AACjC;AACA;AACA;AACA;AACA,WAAW;AACX;AACA,qEAAM;;AAKJ;;;;;;;;;;;;;;;;;AC9H4B;;AAE9B;AAMiB;;AAEjB;AACA,qCAAqC,sFAA2B;AAChE;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,kCAAkC,qEAAM;AACxC,oCAAoC,qEAAM,WAAW,+EAAoB;AACzE;AACA;AACA,sCAAsC,6DAAe;AACrD,iBAAiB,yDAAM;AACvB,IAAI,+EAA6B;AACjC,IAAI,uFAA4B;AAChC;AACA,eAAe,yDAAM;AACrB,IAAI,yEAAuB,GAAG,QAAQ;AACtC,IAAI,qFAA0B;AAC9B;AACA;AACA;AACA,WAAW;AACX;AACA,qEAAM;;AAKJ;;;;;;;;;;;;;;;;;AC7C4B;;AAE9B;AAMiB;;AAEjB;AACA,oCAAoC,sFAA2B;AAC/D;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA;;AAEA;AACA,sCAAsC,wFAA6B;AACnE;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,kCAAkC,qEAAM;AACxC,oCAAoC,qEAAM;AAC1C;AACA;AACA,qCAAqC,6DAAe;AACpD,iBAAiB,yDAAM;AACvB,IAAI,+EAA6B;AACjC,IAAI,uFAA4B;AAChC;AACA,cAAc,yDAAM;AACpB,IAAI,yEAAuB,GAAG,QAAQ;AACtC,IAAI,oFAAyB;AAC7B;AACA;AACA;AACA,WAAW;AACX;AACA,qEAAM;;AAKJ;;;;;;;;;;;;;;;;;AC1D4B;;AAE9B;AAMiB;;AAEjB;AACA,uCAAuC,sFAA2B;AAClE;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,kCAAkC,qEAAM;AACxC,oCAAoC,qEAAM,WAAW,+EAAoB;AACzE;AACA;AACA,wCAAwC,6DAAe;AACvD,iBAAiB,yDAAM;AACvB,IAAI,+EAA6B;AACjC,IAAI,uFAA4B;AAChC;AACA,iBAAiB,yDAAM;AACvB,IAAI,yEAAuB,GAAG,QAAQ;AACtC,IAAI,uFAA4B;AAChC;AACA;AACA;AACA,WAAW;AACX;AACA,qEAAM;;AAKJ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACnDF;AACA;AACA;AACA;AACA;AAC8F;AAC1C;AACC;AACkB;AAClC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,6BAA6B,uCAA+B;AAC5D;AACA;AACA,mBAAmB,uCAAM,CAAC,uDAA6B,CAAC,2CAAe;AACvE,oBAAoB,uCAAM,CAAC,iDAAuB,GAAG,QAAQ;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,wEAAwE,cAAG,kBAAkB,0BAA0B;AACvH;AACA;AACA;;;;;;ACrCA;AACA,4DAA4D,2BAA2B;;AAEvF;AACmC;AACnC;AACA;AACA;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA,uEAAuE,IAAI,IAAI;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,SAAS;AAClC;AACA;AACA;AACA;AACA,CAAC,kDAAkD;AACnD;AACA;AACA;AACA,uEAAuE,IAAI,IAAI;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,SAAS;AAClC;AACA;AACA;AACA,CAAC,0CAA0C;AAC3C;AACA;AACA;AACA,uEAAuE,IAAI,IAAI;AAC/E;AACA;AACA;AACA;AACA;AACA,yBAAyB,SAAS;AAClC;AACA;AACA,CAAC,kCAAkC;AACnC;AACA;AACA;AACA,uEAAuE,IAAI,IAAI;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,SAAS;AAClC;AACA;AACA,CAAC,sCAAsC;AACvC;AACA;AACA;AACA;AACA,uEAAuE,IAAI,IAAI;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,SAAS;AAClC;AACA;AACA,CAAC,gCAAgC;AACjC;AACA;AACA;AACA;AACA;AACA,uEAAuE,IAAI,IAAI;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,SAAS;AAClC;AACA;AACA,CAAC,oCAAoC;AACrC;AACA;AACA;AACA,uEAAuE,IAAI,IAAI;AAC/E;AACA;AACA;AACA,6DAA6D,aAAa;AAC1E;AACA;AACA;AACA,wBAAwB,GAAG;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,yCAA6B;AACt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sBAAsB;AACtB;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,WAAW;AACX;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAC8C;AAC9C;AACA,sIAAsI,mBAAmB,GAAG,wFAAwF,sEAAsE,6BAA6B,2BAA2B,oBAAoB,kCAAkC,EAAE,8CAA8C,EAAE,oCAAoC,2BAA2B,oBAAoB,gBAAgB,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,2BAA2B,mBAAmB,gBAAgB,oBAAoB,EAAE,kCAAkC,EAAE,sEAAsE,oCAAoC,oEAAoE,2BAA2B,mBAAmB,iBAAiB,EAAE,sEAAsE,2BAA2B,mBAAmB,iBAAiB,EAAE,uEAAuE,2BAA2B,mBAAmB,iBAAiB,EAAE,mEAAmE,2BAA2B,mBAAmB,iBAAiB,EAAE,+BAA+B,EAAE,qEAAqE,6BAA6B,8BAA8B,EAAE,mEAAmE,2BAA2B,mBAAmB,iBAAiB,EAAE,+BAA+B,EAAE,sEAAsE,6BAA6B,mEAAmE,2BAA2B,mBAAmB,iBAAiB,EAAE,8BAA8B,EAAE,+BAA+B,EAAE,kEAAkE,6BAA6B,2BAA2B,mBAAmB,gBAAgB,EAAE,qEAAqE,2BAA2B,oBAAoB,gBAAgB,mBAAmB,EAAE,oCAAoC,+BAA+B,EAAE,6BAA6B,8BAA8B,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,8BAA8B,EAAE,EAAE,EAAE,qEAAqE,2BAA2B,oBAAoB,gBAAgB,mBAAmB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,+BAA+B,EAAE,kDAAkD,6BAA6B,kCAAkC,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,EAAE,iEAAiE,2BAA2B,oBAAoB,gBAAgB,mBAAmB,EAAE,kEAAkE,2BAA2B,oBAAoB,gBAAgB,mBAAmB,EAAE,6BAA6B,+BAA+B,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,gDAAgD,EAAE,oDAAoD,6BAA6B,oCAAoC,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,EAAE,oCAAoC,qEAAqE,2BAA2B,oBAAoB,iBAAiB,EAAE,iEAAiE,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,kEAAkE,2BAA2B,oBAAoB,gBAAgB,mBAAmB,EAAE,6BAA6B,+BAA+B,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,gDAAgD,EAAE,qDAAqD,6BAA6B,qCAAqC,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,EAAE,6BAA6B,+BAA+B,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,gDAAgD,EAAE,iDAAiD,6BAA6B,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,sEAAsE,2BAA2B,oBAAoB,gBAAgB,mBAAmB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,sEAAsE,2BAA2B,oBAAoB,gBAAgB,mBAAmB,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,gDAAgD,EAAE,8DAA8D,4CAA4C,4CAA4C,4CAA4C,iCAAiC,8BAA8B,uBAAuB,EAAE,iCAAiC,8BAA8B,uBAAuB,wBAAwB,EAAE,iCAAiC,8BAA8B,uBAAuB,wBAAwB,EAAE,iCAAiC,8BAA8B,uBAAuB,wBAAwB,iCAAiC,EAAE,0DAA0D,oCAAoC,UAAU,yBAAyB,iCAAiC,EAAE,yDAAyD,2DAA2D,iCAAiC,EAAE,oEAAoE,oCAAoC,2BAA2B,oBAAoB,kCAAkC,EAAE,oBAAoB,EAAE,gDAAgD,EAAE,oFAAoF,6BAA6B,oCAAoC,qEAAqE,2BAA2B,oBAAoB,iBAAiB,EAAE,qEAAqE,2BAA2B,oBAAoB,iBAAiB,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,2BAA2B,oBAAoB,gBAAgB,oBAAoB,+BAA+B,EAAE,gDAAgD,sCAAsC,eAAe,4CAA4C,iCAAiC,iCAAiC,uBAAuB,EAAE,iCAAiC,kCAAkC,uBAAuB,wBAAwB,iCAAiC,EAAE,wDAAwD,2GAA2G,IAAI,IAAI,0BAA0B,iCAAiC,EAAE,wDAAwD,2HAA2H,iCAAiC,EAAE,oDAAoD,+HAA+H,iCAAiC,EAAE,8CAA8C,qCAAqC,eAAe,kFAAkF,iCAAiC,EAAE,4CAA4C,qCAAqC,eAAe,8EAA8E,iCAAiC,EAAE,+CAA+C,qCAAqC,eAAe,4CAA4C,mCAAmC,oBAAoB,uBAAuB,EAAE,mCAAmC,oBAAoB,uBAAuB,wBAAwB,iCAAiC,EAAE,+CAA+C,qCAAqC,eAAe,qHAAqH,iCAAiC,EAAE,2CAA2C,qCAAqC,eAAe,gFAAgF,iCAAiC,EAAE,sDAAsD,mEAAmE,iCAAiC,EAAE,uEAAuE,iEAAiE,kBAAkB,EAAE,iEAAiE,yIAAyI,kBAAkB,EAAE,sEAAsE,2CAA2C,eAAe,oDAAoD,kBAAkB,EAAE,gFAAgF,iFAAiF,kBAAkB,EAAE,wDAAwD,4EAA4E,iCAAiC,EAAE,yDAAyD,2EAA2E,iCAAiC,6BAA6B;AACl5W;AACA,0HAA0H,mBAAmB,GAAG,oFAAoF,kEAAkE,6BAA6B,2BAA2B,oBAAoB,kCAAkC,EAAE,oCAAoC,qCAAqC,EAAE,6BAA6B,qCAAqC,EAAE,8BAA8B,EAAE,EAAE,sCAAsC,EAAE,6BAA6B,qCAAqC,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,8BAA8B,EAAE,EAAE,EAAE,oCAAoC,2BAA2B,oBAAoB,gBAAgB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,wEAAwE,2BAA2B,mBAAmB,iBAAiB,oBAAoB,EAAE,kCAAkC,EAAE,sDAAsD,oCAAoC,2BAA2B,mBAAmB,gBAAgB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,gDAAgD,EAAE,sDAAsD,gEAAgE,oCAAoC,+BAA+B,EAAE,+BAA+B,EAAE,+BAA+B,GAAG,gDAAgD,EAAE,mDAAmD,6BAA6B,mCAAmC,EAAE,oCAAoC,6BAA6B,gCAAgC,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,mDAAmD,EAAE,oEAAoE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,iCAAiC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,kCAAkC,EAAE,iEAAiE,oCAAoC,mCAAmC,EAAE,oCAAoC,EAAE,sCAAsC,GAAG,EAAE,oBAAoB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,gDAAgD,EAAE,mDAAmD,6BAA6B,mCAAmC,EAAE,iEAAiE,oCAAoC,2BAA2B,oBAAoB,gBAAgB,EAAE,2BAA2B,oBAAoB,gBAAgB,GAAG,EAAE,6BAA6B,mCAAmC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,gDAAgD,EAAE,kDAAkD,6BAA6B,kCAAkC,EAAE,mEAAmE,oCAAoC,2BAA2B,oBAAoB,gBAAgB,EAAE,2BAA2B,oBAAoB,gBAAgB,GAAG,EAAE,oCAAoC,6BAA6B,gCAAgC,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,iCAAiC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,kCAAkC,EAAE,iEAAiE,oCAAoC,mCAAmC,EAAE,oCAAoC,EAAE,sCAAsC,GAAG,EAAE,oBAAoB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,gDAAgD,EAAE,qDAAqD,6BAA6B,oCAAoC,qCAAqC,EAAE,mCAAmC,EAAE,EAAE,mEAAmE,oCAAoC,2BAA2B,oBAAoB,gBAAgB,EAAE,2BAA2B,oBAAoB,gBAAgB,GAAG,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,gDAAgD,EAAE,0DAA0D,6BAA6B,wCAAwC,EAAE,oCAAoC,6BAA6B,gCAAgC,EAAE,+DAA+D,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,iCAAiC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,oCAAoC,EAAE,mEAAmE,2BAA2B,oBAAoB,iBAAiB,EAAE,oBAAoB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,gDAAgD,EAAE,oEAAoE,oCAAoC,2BAA2B,oBAAoB,kCAAkC,EAAE,oBAAoB,EAAE,gDAAgD,EAAE,oFAAoF,6BAA6B,oCAAoC,qEAAqE,2BAA2B,oBAAoB,iBAAiB,EAAE,qEAAqE,2BAA2B,oBAAoB,iBAAiB,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,2BAA2B,mBAAmB,gBAAgB,oBAAoB,+BAA+B,EAAE,gDAAgD,sCAAsC,eAAe,4CAA4C,iCAAiC,iCAAiC,uBAAuB,EAAE,iCAAiC,kCAAkC,uBAAuB,wBAAwB,iCAAiC,EAAE,wDAAwD,2GAA2G,IAAI,IAAI,0BAA0B,iCAAiC,EAAE,wDAAwD,2HAA2H,iCAAiC,EAAE,oDAAoD,+HAA+H,iCAAiC,EAAE,8CAA8C,qCAAqC,eAAe,kFAAkF,iCAAiC,EAAE,4CAA4C,qCAAqC,eAAe,8EAA8E,iCAAiC,EAAE,+CAA+C,qCAAqC,eAAe,4CAA4C,mCAAmC,oBAAoB,uBAAuB,EAAE,mCAAmC,oBAAoB,uBAAuB,wBAAwB,iCAAiC,EAAE,+CAA+C,qCAAqC,eAAe,qHAAqH,iCAAiC,EAAE,2CAA2C,qCAAqC,eAAe,gFAAgF,iCAAiC,EAAE,sDAAsD,mEAAmE,iCAAiC,EAAE,uEAAuE,iEAAiE,kBAAkB,EAAE,iEAAiE,yIAAyI,kBAAkB,EAAE,sEAAsE,2CAA2C,eAAe,oDAAoD,kBAAkB,EAAE,gFAAgF,iFAAiF,kBAAkB,EAAE,kDAAkD,qCAAqC,eAAe,uFAAuF,iCAAiC,6BAA6B;AAChjV;AACA,8GAA8G,mBAAmB,GAAG,gFAAgF,8DAA8D,6BAA6B,2BAA2B,oBAAoB,kCAAkC,EAAE,iCAAiC,EAAE,2BAA2B,oBAAoB,kCAAkC,EAAE,6BAA6B,qCAAqC,EAAE,2BAA2B,oBAAoB,kCAAkC,oBAAoB,EAAE,2BAA2B,mBAAmB,kCAAkC,EAAE,kCAAkC,EAAE,oEAAoE,oCAAoC,2BAA2B,oBAAoB,kCAAkC,EAAE,oBAAoB,EAAE,gDAAgD,EAAE,oFAAoF,6BAA6B,oCAAoC,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,kEAAkE,2BAA2B,mBAAmB,iBAAiB,EAAE,EAAE,2BAA2B,mBAAmB,gBAAgB,oBAAoB,+BAA+B,EAAE,gDAAgD,sCAAsC,eAAe,4CAA4C,iCAAiC,iCAAiC,uBAAuB,EAAE,iCAAiC,kCAAkC,uBAAuB,wBAAwB,iCAAiC,EAAE,wDAAwD,2GAA2G,IAAI,IAAI,0BAA0B,iCAAiC,EAAE,wDAAwD,2HAA2H,iCAAiC,EAAE,oDAAoD,+HAA+H,iCAAiC,EAAE,8CAA8C,qCAAqC,eAAe,kFAAkF,iCAAiC,EAAE,4CAA4C,qCAAqC,eAAe,8EAA8E,iCAAiC,EAAE,+CAA+C,qCAAqC,eAAe,4CAA4C,mCAAmC,mBAAmB,uBAAuB,EAAE,mCAAmC,mBAAmB,uBAAuB,wBAAwB,iCAAiC,EAAE,+CAA+C,qCAAqC,eAAe,qHAAqH,iCAAiC,EAAE,2CAA2C,qCAAqC,eAAe,gFAAgF,iCAAiC,EAAE,sDAAsD,mEAAmE,iCAAiC,EAAE,uEAAuE,iEAAiE,kBAAkB,EAAE,iEAAiE,yIAAyI,kBAAkB,EAAE,sEAAsE,2CAA2C,eAAe,oDAAoD,kBAAkB,EAAE,gFAAgF,iFAAiF,kBAAkB,6BAA6B;AACn1J;AACA,oHAAoH,mBAAmB,GAAG,kFAAkF,gEAAgE,6BAA6B,2BAA2B,oBAAoB,kCAAkC,EAAE,oCAAoC,mCAAmC,EAAE,wCAAwC,EAAE,EAAE,oCAAoC,2BAA2B,mBAAmB,gBAAgB,EAAE,oEAAoE,2BAA2B,mBAAmB,iBAAiB,EAAE,2BAA2B,oBAAoB,gBAAgB,oBAAoB,EAAE,kCAAkC,EAAE,wDAAwD,6BAA6B,oCAAoC,6BAA6B,kEAAkE,2BAA2B,mBAAmB,iBAAiB,EAAE,6BAA6B,8BAA8B,EAAE,gEAAgE,2BAA2B,mBAAmB,iBAAiB,oBAAoB,EAAE,EAAE,6BAA6B,8BAA8B,EAAE,iEAAiE,2BAA2B,mBAAmB,iBAAiB,EAAE,EAAE,EAAE,8BAA8B,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,gDAAgD,EAAE,oEAAoE,oCAAoC,2BAA2B,oBAAoB,kCAAkC,EAAE,oBAAoB,EAAE,gDAAgD,EAAE,oFAAoF,6BAA6B,oCAAoC,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,kEAAkE,2BAA2B,mBAAmB,iBAAiB,EAAE,EAAE,2BAA2B,mBAAmB,gBAAgB,oBAAoB,+BAA+B,EAAE,gDAAgD,sCAAsC,eAAe,4CAA4C,iCAAiC,iCAAiC,uBAAuB,EAAE,iCAAiC,kCAAkC,uBAAuB,wBAAwB,iCAAiC,EAAE,wDAAwD,2GAA2G,IAAI,IAAI,0BAA0B,iCAAiC,EAAE,wDAAwD,2HAA2H,iCAAiC,EAAE,oDAAoD,+HAA+H,iCAAiC,EAAE,8CAA8C,qCAAqC,eAAe,kFAAkF,iCAAiC,EAAE,4CAA4C,qCAAqC,eAAe,8EAA8E,iCAAiC,EAAE,+CAA+C,qCAAqC,eAAe,4CAA4C,mCAAmC,mBAAmB,uBAAuB,EAAE,mCAAmC,mBAAmB,uBAAuB,wBAAwB,iCAAiC,EAAE,+CAA+C,qCAAqC,eAAe,qHAAqH,iCAAiC,EAAE,2CAA2C,qCAAqC,eAAe,gFAAgF,iCAAiC,EAAE,sDAAsD,mEAAmE,iCAAiC,EAAE,uEAAuE,iEAAiE,kBAAkB,EAAE,iEAAiE,yIAAyI,kBAAkB,EAAE,sEAAsE,2CAA2C,eAAe,oDAAoD,kBAAkB,EAAE,gFAAgF,iFAAiF,kBAAkB,6BAA6B;AACn2L;AACA,2GAA2G,mBAAmB,GAAG,+EAA+E,6DAA6D,6BAA6B,2BAA2B,oBAAoB,kCAAkC,EAAE,gCAAgC,EAAE,sEAAsE,qCAAqC,mBAAmB,EAAE,oCAAoC,2BAA2B,mBAAmB,gBAAgB,EAAE,sEAAsE,2BAA2B,mBAAmB,iBAAiB,EAAE,2BAA2B,oBAAoB,gBAAgB,oBAAoB,EAAE,kCAAkC,EAAE,uDAAuD,6BAA6B,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,8BAA8B,EAAE,kEAAkE,2BAA2B,mBAAmB,iBAAiB,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,gDAAgD,EAAE,kDAAkD,qCAAqC,eAAe,oFAAoF,iCAAiC,EAAE,gDAAgD,qCAAqC,eAAe,kFAAkF,iCAAiC,EAAE,mDAAmD,qCAAqC,eAAe,4CAA4C,mCAAmC,mBAAmB,uBAAuB,EAAE,mCAAmC,mBAAmB,uBAAuB,wBAAwB,iCAAiC,EAAE,oEAAoE,oCAAoC,2BAA2B,oBAAoB,kCAAkC,EAAE,oBAAoB,EAAE,gDAAgD,EAAE,oFAAoF,6BAA6B,oCAAoC,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,2BAA2B,mBAAmB,gBAAgB,oBAAoB,+BAA+B,EAAE,gDAAgD,sCAAsC,eAAe,4CAA4C,iCAAiC,iCAAiC,uBAAuB,EAAE,iCAAiC,kCAAkC,uBAAuB,wBAAwB,iCAAiC,EAAE,wDAAwD,2GAA2G,IAAI,IAAI,0BAA0B,iCAAiC,EAAE,wDAAwD,2HAA2H,iCAAiC,EAAE,oDAAoD,+HAA+H,iCAAiC,EAAE,8CAA8C,qCAAqC,eAAe,kFAAkF,iCAAiC,EAAE,4CAA4C,qCAAqC,eAAe,8EAA8E,iCAAiC,EAAE,+CAA+C,qCAAqC,eAAe,4CAA4C,mCAAmC,oBAAoB,uBAAuB,EAAE,mCAAmC,oBAAoB,uBAAuB,wBAAwB,iCAAiC,EAAE,+CAA+C,qCAAqC,eAAe,qHAAqH,iCAAiC,EAAE,2CAA2C,qCAAqC,eAAe,gFAAgF,iCAAiC,EAAE,sDAAsD,mEAAmE,iCAAiC,EAAE,uEAAuE,iEAAiE,kBAAkB,EAAE,iEAAiE,yIAAyI,kBAAkB,EAAE,sEAAsE,2CAA2C,eAAe,oDAAoD,kBAAkB,EAAE,gFAAgF,iFAAiF,kBAAkB,6BAA6B;AAC7sM;AACA,iHAAiH,mBAAmB,GAAG,iFAAiF,+DAA+D,6BAA6B,2BAA2B,oBAAoB,kCAAkC,EAAE,oCAAoC,uCAAuC,EAAE,wCAAwC,EAAE,6BAA6B,uCAAuC,EAAE,8BAA8B,EAAE,EAAE,EAAE,2BAA2B,oBAAoB,kCAAkC,EAAE,oCAAoC,2BAA2B,oBAAoB,gBAAgB,EAAE,6BAA6B,iCAAiC,EAAE,kEAAkE,2BAA2B,mBAAmB,iBAAiB,EAAE,6BAA6B,8BAA8B,EAAE,kEAAkE,2BAA2B,mBAAmB,iBAAiB,oBAAoB,EAAE,EAAE,6BAA6B,kCAAkC,EAAE,oEAAoE,2BAA2B,mBAAmB,iBAAiB,EAAE,6BAA6B,8BAA8B,EAAE,oEAAoE,2BAA2B,mBAAmB,iBAAiB,oBAAoB,EAAE,EAAE,6BAA6B,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,6BAA6B,8BAA8B,EAAE,qEAAqE,2BAA2B,mBAAmB,iBAAiB,oBAAoB,EAAE,EAAE,2BAA2B,oBAAoB,gBAAgB,oBAAoB,EAAE,kCAAkC,EAAE,kEAAkE,6BAA6B,8BAA8B,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,8BAA8B,EAAE,+BAA+B,EAAE,iDAAiD,6BAA6B,iEAAiE,2BAA2B,oBAAoB,iBAAiB,EAAE,2BAA2B,mBAAmB,kCAAkC,EAAE,gDAAgD,EAAE,kDAAkD,6BAA6B,iEAAiE,2BAA2B,oBAAoB,iBAAiB,EAAE,2BAA2B,mBAAmB,kCAAkC,EAAE,4BAA4B,EAAE,EAAE,2BAA2B,mBAAmB,gBAAgB,EAAE,4BAA4B,EAAE,EAAE,gDAAgD,EAAE,oEAAoE,oCAAoC,6BAA6B,2BAA2B,oBAAoB,kCAAkC,EAAE,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,6BAA6B,8BAA8B,EAAE,2BAA2B,oBAAoB,kCAAkC,EAAE,qEAAqE,2BAA2B,mBAAmB,iBAAiB,oBAAoB,EAAE,2BAA2B,oBAAoB,kCAAkC,EAAE,EAAE,6BAA6B,2BAA2B,oBAAoB,kCAAkC,EAAE,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,6BAA6B,8BAA8B,EAAE,2BAA2B,oBAAoB,kCAAkC,EAAE,qEAAqE,2BAA2B,mBAAmB,iBAAiB,oBAAoB,EAAE,2BAA2B,oBAAoB,kCAAkC,EAAE,EAAE,+BAA+B,EAAE,0DAA0D,wBAAwB,eAAe,6BAA6B,iEAAiE,iCAAiC,mBAAmB,aAAa,2BAA2B,oBAAoB,gBAAgB,2CAA2C,EAAE,gDAAgD,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,gDAAgD,EAAE,wDAAwD,wBAAwB,eAAe,kEAAkE,2BAA2B,oBAAoB,iBAAiB,gDAAgD,EAAE,mDAAmD,oCAAoC,6BAA6B,iEAAiE,wCAAwC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,iEAAiE,mCAAmC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,iEAAiE,iCAAiC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,iEAAiE,iCAAiC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,6BAA6B,iEAAiE,uCAAuC,EAAE,kEAAkE,2BAA2B,mBAAmB,iBAAiB,EAAE,EAAE,gDAAgD,EAAE,kDAAkD,qCAAqC,eAAe,4CAA4C,iCAAiC,mCAAmC,uBAAuB,EAAE,iCAAiC,oCAAoC,uBAAuB,wBAAwB,iCAAiC,EAAE,oEAAoE,oCAAoC,2BAA2B,oBAAoB,kCAAkC,EAAE,oBAAoB,EAAE,gDAAgD,EAAE,oFAAoF,6BAA6B,oCAAoC,qEAAqE,2BAA2B,oBAAoB,iBAAiB,EAAE,qEAAqE,2BAA2B,oBAAoB,iBAAiB,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,EAAE,2BAA2B,mBAAmB,gBAAgB,oBAAoB,+BAA+B,EAAE,gDAAgD,sCAAsC,eAAe,4CAA4C,iCAAiC,iCAAiC,uBAAuB,EAAE,iCAAiC,kCAAkC,uBAAuB,wBAAwB,iCAAiC,EAAE,wDAAwD,2GAA2G,IAAI,IAAI,0BAA0B,iCAAiC,EAAE,wDAAwD,2HAA2H,iCAAiC,EAAE,oDAAoD,+HAA+H,iCAAiC,EAAE,8CAA8C,qCAAqC,eAAe,kFAAkF,iCAAiC,EAAE,4CAA4C,qCAAqC,eAAe,8EAA8E,iCAAiC,EAAE,+CAA+C,qCAAqC,eAAe,4CAA4C,mCAAmC,oBAAoB,uBAAuB,EAAE,mCAAmC,oBAAoB,uBAAuB,wBAAwB,iCAAiC,EAAE,+CAA+C,qCAAqC,eAAe,qHAAqH,iCAAiC,EAAE,2CAA2C,qCAAqC,eAAe,gFAAgF,iCAAiC,EAAE,sDAAsD,mEAAmE,iCAAiC,EAAE,uEAAuE,iEAAiE,kBAAkB,EAAE,iEAAiE,yIAAyI,kBAAkB,EAAE,sEAAsE,2CAA2C,eAAe,oDAAoD,kBAAkB,EAAE,gFAAgF,iFAAiF,kBAAkB,iBAAiB,kDAAkD,gEAAgE,yCAAyC,gCAAgC,oBAAoB,kBAAkB,EAAE,+CAA+C,8CAA8C,oBAAoB,kBAAkB,aAAa;AAC3nX;AACA,uHAAuH,mBAAmB,GAAG,sEAAsE,oFAAoF,oCAAoC,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,qEAAqE,2BAA2B,mBAAmB,iBAAiB,EAAE,kEAAkE,2BAA2B,mBAAmB,iBAAiB,oBAAoB,+BAA+B,EAAE,gDAAgD,sCAAsC,eAAe,4CAA4C,iCAAiC,iCAAiC,uBAAuB,EAAE,iCAAiC,kCAAkC,uBAAuB,wBAAwB,iCAAiC,EAAE,wDAAwD,2GAA2G,IAAI,IAAI,0BAA0B,iCAAiC,EAAE,wDAAwD,2HAA2H,iCAAiC,EAAE,oDAAoD,+HAA+H,iCAAiC,EAAE,iEAAiE,wBAAwB,eAAe,6BAA6B,2BAA2B,mBAAmB,gBAAgB,EAAE,oCAAoC,2BAA2B,mBAAmB,gBAAgB,EAAE,yEAAyE,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,kCAAkC,EAAE,8DAA8D,4CAA4C,iCAAiC,yCAAyC,uBAAuB,EAAE,iCAAiC,oCAAoC,uBAAuB,wBAAwB,iCAAiC,EAAE,wDAAwD,kFAAkF,mBAAmB,2BAA2B,iCAAiC,EAAE,8DAA8D,iCAAiC,gCAAgC,uBAAuB,iCAAiC,EAAE,wDAAwD,iCAAiC,8BAA8B,uBAAuB,iCAAiC,EAAE,oDAAoD,iCAAiC,8BAA8B,uBAAuB,iCAAiC,EAAE,0DAA0D,wCAAwC,GAAG,yBAAyB,iCAAiC,EAAE,+DAA+D,iEAAiE,kBAAkB,EAAE,uEAAuE,2EAA2E,kBAAkB,EAAE,+DAA+D,mEAAmE,kBAAkB,EAAE,uDAAuD,6BAA6B,mEAAmE,2BAA2B,oBAAoB,gBAAgB,mBAAmB,EAAE,oCAAoC,iEAAiE,2BAA2B,oBAAoB,iBAAiB,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,EAAE,gDAAgD,EAAE,yEAAyE,2BAA2B,mBAAmB,gBAAgB,gDAAgD,EAAE,iDAAiD,wBAAwB,eAAe,oCAAoC,2BAA2B,oBAAoB,gBAAgB,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,gDAAgD,EAAE,oDAAoD,wBAAwB,eAAe,6BAA6B,iEAAiE,2BAA2B,oBAAoB,iBAAiB,EAAE,6BAA6B,2BAA2B,mBAAmB,gBAAgB,EAAE,0EAA0E,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,gDAAgD,EAAE,iDAAiD,wBAAwB,eAAe,6BAA6B,iEAAiE,2BAA2B,oBAAoB,iBAAiB,EAAE,2BAA2B,oBAAoB,kCAAkC,EAAE,oCAAoC,2BAA2B,mBAAmB,gBAAgB,EAAE,2BAA2B,oBAAoB,gBAAgB,EAAE,EAAE,2BAA2B,oBAAoB,kCAAkC,EAAE,kEAAkE,2BAA2B,oBAAoB,iBAAiB,EAAE,6BAA6B,2BAA2B,mBAAmB,gBAAgB,EAAE,0EAA0E,2BAA2B,oBAAoB,iBAAiB,oBAAoB,EAAE,gDAAgD,EAAE,kDAAkD,8EAA8E,iCAAiC,EAAE,sDAAsD,yEAAyE,iCAAiC,EAAE,yEAAyE,2BAA2B,oBAAoB,gBAAgB,gDAAgD,EAAE,sDAAsD,6EAA6E,iCAAiC,iBAAiB,iDAAiD,8CAA8C,8CAA8C,oBAAoB,EAAE,yEAAyE,+CAA+C,kBAAkB,EAAE,oDAAoD,wBAAwB,kBAAkB,EAAE,iDAAiD,wBAAwB,iBAAiB,+CAA+C,8CAA8C,oBAAoB,EAAE,EAAE,8DAA8D,mDAAmD,8CAA8C,oBAAoB,EAAE,mDAAmD,8CAA8C,oBAAoB,kBAAkB,EAAE,oDAAoD,qDAAqD,mCAAmC,gCAAgC,sBAAsB,oBAAoB,EAAE,iEAAiE,+CAA+C,EAAE,oEAAoE,+CAA+C,EAAE,oEAAoE,+CAA+C,kBAAkB,6TAA6T;;AAEx7R;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACgD;;AAEhD;AACA,gEAAgE,IAAI,IAAI;AACxE;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,4CAAqB;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,GAAG;AAC/C;AACA;AACA,iFAAiF,GAAG,0BAA0B,GAAG;AACjH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AAC8C;AAC9C,gDAAgD,wCAAmB;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAwCE;;;;;;;;;;;;;;;;;ACljC4B;;AAE9B;AAMiB;;AAEjB;AACA,sCAAsC,sFAA2B;AACjE;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,kCAAkC,qEAAM;AACxC,oCAAoC,qEAAM,WAAW,+EAAoB;AACzE;AACA;AACA,uCAAuC,6DAAe;AACtD,iBAAiB,yDAAM;AACvB,IAAI,+EAA6B;AACjC,IAAI,uFAA4B;AAChC;AACA,gBAAgB,yDAAM;AACtB,IAAI,yEAAuB,GAAG,QAAQ;AACtC,IAAI,sFAA2B;AAC/B;AACA;AACA;AACA,WAAW;AACX;AACA,qEAAM;;AAKJ;;;;;;;;;;;;;;;;;AC7C4B;;AAE9B;AAMiB;;AAEjB;AACA,6CAA6C,sFAA2B;AACxE;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA;;AAEA;AACA,+CAA+C,wFAA6B;AAC5E;AACA,IAAI,qEAAM;AACV;AACA;AACA;AACA;AACA,MAAM;AACN;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,kCAAkC,qEAAM;AACxC,oCAAoC,qEAAM;AAC1C;AACA;AACA,8CAA8C,6DAAe;AAC7D,iBAAiB,yDAAM;AACvB,IAAI,+EAA6B;AACjC,IAAI,uFAA4B;AAChC;AACA,uBAAuB,yDAAM;AAC7B,IAAI,yEAAuB,GAAG,QAAQ;AACtC,IAAI,6FAAkC;AACtC;AACA;AACA;AACA,WAAW;AACX;AACA,qEAAM;;AAKJ;;;;;;;;;;;;;;;;;;;;;ACjEuD;AAIA;AAIA;AAIA;AAIA;AAIA;AAIA;AAuCA;;AAEzD;AACA;AACA;AACA,wBAAwB,gGAAM;AAC9B,YAAY,0CAA0C,QAAQ,qGAAwD;AACtH;AACA;AACA,GAAG;AACH,0BAA0B,gGAAM;AAChC,YAAY,8CAA8C,QAAQ,kGAA0D;AAC5H;AACA;AACA,GAAG;AACH,uBAAuB,gGAAM;AAC7B,YAAY,wCAAwC,QAAQ,qGAAuD;AACnH;AACA;AACA,GAAG;AACH,gCAAgC,gGAAM;AACtC,YAAY,0DAA0D,QAAQ,qGAAgE;AAC9I;AACA;AACA,GAAG;AACH,4BAA4B,gGAAM;AAClC,YAAY,kDAAkD,QAAQ,qGAA4D;AAClI;AACA;AACA,GAAG;AACH,yBAAyB,gGAAM;AAC/B,YAAY,4CAA4C,QAAQ,qGAAyD;AACzH;AACA;AACA,GAAG;AACH,2BAA2B,gGAAM;AACjC,YAAY,gDAAgD,QAAQ,qGAA2D;AAC/H;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,6CAA6C,YAAY;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gGAAM;AACN;AACA;AACA;AACA;AACA,6BAA6B,aAAa,EAAE,aAAa;AACzD;AACA;AACA;AACA,IAAI,gGAAM;AACV;AACA;AAsDE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC3LF;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,IAAC;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvBA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,aAAa,OAAO;AACpB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,iDAAe,SAAS,EAAC;;;;;AC9Be;AACD;;AAEvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,QAAQ;AACnB,YAAY,QAAQ;AACpB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,4BAAS;AAChD,SAAS,UAAS;AAClB;;AAEA,qDAAe,IAAI,EAAC;;;;;;;;;;;;;;;;;ACrCwB;AACF;AACQ;AACP;AACC;AACf;;AAE7B;AACA;;AAEA;AACA,IAAI,qBAAc;;AAElB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,WAAW;AACtB,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,QAAQ;AACtB,WAAW;AACX;AACA,IAAI,aAAM,GAAG,kCAAc;AAC3B,MAAM,+BAAW,YAAY,8BAAW;AACxC,IAAI,8BAAU,SAAS,uBAAI;AAC3B;AACA;AACA;AACA,QAAQ,qBAAc;AACtB,MAAM,+BAAW;AACjB;AACA;AACA,CAAC;;AAED,uDAAe,aAAM,EAAC;;;;;;;;;;;ACzDgB;AACQ;AACJ;AACI;;AAE9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,UAAU;AACrB,aAAa,QAAQ;AACrB;AACA;AACA,kBAAkB;AAClB;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA,cAAc,4BAAQ,CAAC,gCAAY;AACnC;AACA,GAAG;AACH,cAAc,gCAAY;AAC1B,SAAS,8BAAU;AACnB;AACA,GAAG;AACH;;AAEA,uDAAe,MAAM,EAAC;;;;;;;ACpCoB;AACG;;AAE7C;AACA;;AAEA;AACA;AACA;AACA;AACA,WAAW,GAAG;AACd,aAAa,SAAS;AACtB;AACA;AACA,SAAS,+BAAY,WAAW,8BAAU;AAC1C;;AAEA,oDAAe,YAAY,EAAC;;;;;;;ACjBkB;AACN;AACF;;AAEtC;AACA,mBAAmB,wBAAQ,IAAI,wBAAQ;;AAEvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,GAAG;AACd,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,6BAAS,iBAAiB,aAAY;;AAEpE,yDAAe,QAAQ,EAAC;;;AC1BqD;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,2BAAQ;AACnB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0BAAO;AACf;AACA,SAAS;AACT;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACO;AACP;AACA;AACA,QAAQ,gBAAM,OAAO,gBAAM;AAC3B;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,sBAAG;AACd;AACO;AACP;AACA,eAAe,sBAAG;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,2BAAQ;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,8BAA8B;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,8BAA8B;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,2BAAQ;AACpB;AACA;AACA;AACA;AACA,yCAAyC,kBAAQ;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChO0C;AAC8I;AACxL;AACA;AACA;AACO;AACP;AACA,QAAQ,0BAAO;AACf,6BAA6B,cAAI;AACjC;AACA,mCAAmC,WAAW;AAC9C;AACA;AACA,wCAAwC,QAAQ;AAChD;AACA;AACA,wCAAwC,WAAW;AACnD;AACA;AACA,wCAAwC,MAAM;AAC9C;AACA;AACA,wCAAwC,mBAAmB;AAC3D;AACA;AACA,wCAAwC,gCAAgC;AACxE;AACA;AACA,wCAAwC,uBAAuB;AAC/D;AACA;AACA,wCAAwC,UAAU;AAClD;AACA;AACA,wCAAwC,WAAW;AACnD;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,MAAM,GAAG,uCAAuC;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,MAAM,GAAG,iCAAiC;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0BAAO;AACf;AACA;AACA;AACA,oCAAoC,WAAW,GAAG,mBAAmB;AACrE;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,YAAY,MAAM;AAClB;AACA,oBAAoB,QAAQ,GAAG,oCAAoC;AACnE;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;;;;ACtGsC;;AAEtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,4BAAQ;AAC3C;;AAEA,qDAAe,IAAI,EAAC;;;;;;;;;ACxBkB;;AAEtC;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,aAAa,SAAS;AACtB;AACA;AACA;AACA;;AAEA,EAAE,4BAAQ;AACV;AACA;AACA,GAAG;AACH;AACA;;AAEA,gDAAe,QAAQ,EAAC;;;;;;;ACrBgB;AACM;AACR;AACH;AACe;;AAElD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,YAAY,QAAQ;AACpB,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,kCAAkC;AACzC,OAAO;AACP;AACA;AACA;AACA,mBAAmB,mCAAmC;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,0BAAO,eAAe,yBAAS,GAAG,SAAQ;AACvD,eAAe,kCAAc;AAC7B;AACA;AACA,0BAA0B,gCAAY;AACtC;;AAEA,qDAAe,IAAI,EAAC;;;;;AClDwB;AACD;AACN;AACE;AACN;;AAEjC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,qBAAqB;AAChC,WAAW,GAAG;AACd,WAAW,QAAQ;AACnB,YAAY,QAAQ;AACpB,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,gBAAgB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,8BAAW,4BAA4B,yBAAM;AAC5D,sCAAsC,4BAAS;;AAE/C;AACA;AACA;AACA;AACA,SAAS,2BAAQ;AACjB;AACA,mBAAmB,+BAAW;AAC9B;;AAEA,yDAAe,QAAQ,EAAC;;;ACpDxB;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,UAAU;AACrB,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,kDAAe,UAAU,EAAC;;;ACtBY;;AAEtC;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA,EAAE,4BAAQ;AACV;AACA;AACA,GAAG;AACH;AACA;;AAEA,iDAAe,SAAS,EAAC;;;ACpBiB;AACF;AACM;AACX;AACe;;AAElD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,YAAY,QAAQ;AACpB,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,8CAA8C;AACrD,OAAO;AACP;AACA;AACA;AACA,oBAAoB,mCAAmC;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,0BAAO,eAAe,WAAU,GAAG,UAAS;AACzD,eAAe,kCAAc;AAC7B;AACA;AACA,0BAA0B,gCAAY;AACtC;;AAEA,sDAAe,KAAK,EAAC;;;ACvD6B;AAC0J;AACrM;AACP,4BAA4B,WAAW;AACvC,wBAAwB,MAAM;AAC9B,wBAAwB,UAAU;AAClC,wBAAwB,mBAAmB;AAC3C,wBAAwB,gCAAgC;AACxD,wBAAwB,uBAAuB;AAC/C,wBAAwB,QAAQ;AAChC,wBAAwB,IAAI;AAC5B;AACO;AACP,+CAA+C,MAAM;AACrD,wBAAwB,UAAU;AAClC,wBAAwB,uBAAuB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,WAAW;AACnC;AACA,eAAe,cAAI;AACnB;AACA,SAAS;AACT;AACA,6BAA6B,WAAW,IAAI,kBAAQ;AACpD;AACA;AACA;AACA,6BAA6B,kBAAkB;AAC/C,4BAA4B,WAAW;AACvC;AACA;AACA,eAAe,eAAK;AACpB;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACO;AACP,2BAA2B,WAAW;AACtC;AACO;AACP;AACA,wBAAwB,WAAW;AACnC;AACA;AACA,6BAA6B,MAAM;AACnC;AACA;AACA,6BAA6B,WAAW;AACxC;AACA;AACA,6BAA6B,mBAAmB;AAChD;AACA;AACA,6BAA6B,gCAAgC;AAC7D;AACA;AACA,6BAA6B,uBAAuB;AACpD;AACA;AACA,6BAA6B,UAAU;AACvC;AACA;AACA,6BAA6B,QAAQ;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9E+C;AAC4D;AACpG;AACP;AACA,wBAAwB,WAAW;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,QAAQ;AACrC;AACA;AACA,aAAa,cAAc;AAC3B;AACA;AACA,aAAa,eAAe;AAC5B;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,cAAc;AAChD;AACA;AACA;AACA;AACA,WAAW,cAAI;AACf;AACO;AACP,kCAAkC,sBAAG;AACrC;AACA,KAAK;AACL,WAAW,cAAI,CAAC,0BAAO;AACvB;AACO;AACP;AACA;AACA;;ACvDA;AACO,MAAM,YAAE;AACf;;ACFuC;AACJ;AACS;AACP;AACU;AAC/C;AACA;AACO,kCAAkC,UAAU;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,WAAW,GAAG,sBAAsB;AACjE,qCAAqC,KAAK;AAC1C;AACA;AACA;AACO;AACP;AACA,IAAI,0BAAO;AACX;AACA,QAAQ,gBAAM;AACd,KAAK;AACL;AACA;AACO;AACP,4CAA4C,YAAE;AAC9C;AACO;AACP;AACA;AACA;AACA;;;;;;;;;;;;AC5CA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,UAAU;AACrB,aAAa,UAAU;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,uDAAe,MAAM,EAAC;;;ACvCsB;AACF;AACI;AACX;AACF;;AAEjC;AACA,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA,OAAO,8CAA8C;AACrD,OAAO;AACP;AACA;AACA,iCAAiC,mBAAmB;AACpD;AACA;AACA;AACA,qBAAqB,2BAA2B;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,0BAAO,eAAe,2BAAW,GAAG,0BAAU;AAC3D,0BAA0B,gBAAM,CAAC,gCAAY;AAC7C;;AAEA,uDAAe,MAAM,EAAC;;;;;AC7CsB;AACL;;AAEvC;AACA,IAAI,iBAAS;;AAEb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,GAAG;AACd,WAAW,QAAQ;AACnB,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,4BAAS;AAC/C;AACA,YAAY,iBAAS;AACrB;AACA,SAAS,+BAAW;AACpB;;AAEA,wDAAe,OAAO,EAAC;;;;;;;;;;;;;;;ACzCe;AACU;AACQ;AAClB;AACE;AACF;;AAEtC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,OAAO;AAClB,WAAW,UAAU;AACrB,WAAW,UAAU;AACrB,aAAa,OAAO;AACpB;AACA;AACA;AACA,iBAAiB,6BAAa;AAC9B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,aAAa,4BAAQ,SAAS,6BAAS;AACvC;AACA;AACA,eAAe,iCAAiB;AAChC;AACA;AACA;AACA,eAAe,wBAAQ;AACvB;AACA,iBAAiB,wBAAQ;AACzB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sDAAe,cAAc,EAAC;;;;;;;;;AClEoB;AACN;AACN;AACiB;;AAEvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,UAAU;AACrB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,4BAAQ;AACzB,SAAS,oCAAiB;AAC1B,MAAM,eAAc,QAAQ,+BAAW,YAAY,gCAAiB;AACpE;AACA,CAAC;;AAED,2DAAe,UAAU,EAAC;;;AChC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wDAAe,OAAO,EAAC;;;AC9BvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,aAAa,GAAG;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,qDAAe,IAAI,EAAC;;;;;ACtBb;AACP;AACA;AACA,gCAAgC,IAAI;AACpC;AACA;AACO;AACP;AACA;AACA;AACA,iCAAiC,IAAI;AACrC;AACA;AACA;;ACb0D;AAC1D;AACA,yBAAyB,uBAAY;AAC9B;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;ACjB+D;AACa;AACb;AACZ;AACuB;AAC1E;AACO;AACA;AACP;AACA,oBAAoB,YAAY;AAChC,kEAAkE;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,aAAa,IAAI,4BAA4B;AAC7D,+CAA+C,mBAAmB;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,WAAW,IAAI,4BAA4B;AACvD,uCAAuC,mBAAmB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,4BAA4B,sBAAsB;AAClD;AACA;AACA;AACA;AACA;AACA,4BAA4B,kBAAkB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,0BAAO;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qEAAqE,uBAAuB;AAC5F;AACA;AACA;AACA;AACA;AACA;AACA,qEAAqE,qCAAqC,kBAAkB,EAAE;AAC9H;AACA;AACA;AACA,oDAAoD,kBAAkB;AACtE,0EAA0E,kBAAkB;AAC5F;AACA,8CAA8C,kBAAkB;AAChE;AACA,0DAA0D,wBAAwB;AAClF,0DAA0D,wBAAwB;AAClF,yEAAyE,yBAAyB;AAClG;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,yBAAM;AACjB;AACA;AACA,6BAA6B,wBAAwB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,wBAAwB;AACzD;AACA;AACA;AACA;AACA;AACA,qCAAqC,wBAAwB;AAC7D;AACA;AACA;AACA;AACA;AACA,WAAW,uBAAI;AACf;AACA,mBAAmB,kBAAQ;AAC3B;AACA;AACA;AACA;AACA,oBAAoB,uBAAI;AACxB;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,0BAAO;AAClB,UAAU,eAAK;AACf;AACA;AACA,6BAA6B,4BAAiB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,kBAAQ;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,oBAAoB,YAAY;AAChC;AACA;AACA;AACA;AACA;AACA,gBAAgB,uBAAI;AACpB,mBAAmB,kBAAQ;AAC3B,SAAS;AACT;AACA;AACA;;ACvP8D;AACO;AACuJ;AAC5K;AAC6D;AAC1D;AACnD;AACO;AACA;AACA;AACA;AACP;AACA;AACO;AACP;AACA;AACO;AACP,cAAc,2BAAQ;AACtB;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,4BAA4B,gBAAM;AAClC,yCAAyC,KAAK;AAC9C,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA,iCAAiC,sBAAG;AACpC;AACA;AACA,gBAAgB,kBAAQ;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,kBAAQ;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,6BAAU;AAC/B;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qFAAqF;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,sBAAG;AAC9B,4BAA4B,sBAAG;AAC/B;AACA;AACA,8BAA8B,KAAK;AACnC;AACA;AACA,qBAAqB,2BAAQ;AAC7B;AACA;AACA,qBAAqB,8BAAW;AAChC;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,sCAAsC,sBAAG;AACzC;AACA;AACA,wCAAwC,0BAAO;AAC/C,sBAAsB,sBAAG,0BAA0B,iBAAO;AAC1D,uBAAuB,iBAAO;AAC9B;AACA;AACA,SAAS;AACT,+BAA+B,sBAAG;AAClC,8BAA8B,sBAAG,+BAA+B,sBAAG;AACnE,KAAK;AACL;AACA;AACA;AACA,wCAAwC,sBAAG;AAC3C;AACA,4CAA4C,sBAAG;AAC/C,oBAAoB,sBAAG;AACvB;AACA;AACA;AACA;AACA,wBAAwB,gBAAgB;AACxC;AACA,aAAa;AACb;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,+BAA+B,sBAAG;AAClC,4BAA4B,sBAAG;AAC/B,sBAAsB,yBAAM;AAC5B;AACA,gBAAgB,2BAAQ,+BAA+B,KAAK;AAC5D;AACA;AACA;AACA,SAAS,IAAI;AACb,6BAA6B,sBAAG;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA,2CAA2C,yBAAM;AACjD;AACA;AACA;AACA;AACA;AACA,yBAAyB,0BAAO;AAChC;AACA,oBAAoB,0BAAO;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,yBAAyB,kBAAQ;AACjC;AACA;AACA;AACA,4BAA4B,WAAW,IAAI,2BAA2B,CAAC;AACvE,yDAAyD,gCAAgC;AACzF;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,6BAA6B;AAC5E;AACA;AACA;AACA,4BAA4B,0BAAO;AACnC;AACA;AACA;AACA;AACA;AACA,wBAAwB,0BAAO;AAC/B;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA,wBAAwB,WAAW,IAAI,2BAA2B,CAAC;AACnE,6CAA6C,iBAAiB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,yBAAM,8BAA8B,kBAAQ;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,yCAAyC,yBAAM;AAC/C,gBAAgB,sBAAG;AACnB,KAAK;AACL,mBAAmB,sBAAG;AACtB;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL,kBAAkB,oBAAU;AAC5B,aAAa;AACb;AACO;AACP,yCAAyC,yBAAM;AAC/C;AACA,iBAAiB,kBAAQ;AACzB,aAAa,6BAAU;AACvB,aAAa,sBAAG;AAChB,aAAa,2BAAQ;AACrB,KAAK;AACL,mBAAmB,sBAAG;AACtB;AACA;AACA;AACA;AACA,yCAAyC,0BAA0B,gCAAgC,gBAAgB;AACnH,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL,kBAAkB,oBAAU;AAC5B,aAAa;AACb;AACA;AACO;AACP,kCAAkC,4BAAiB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,yBAAM;AAC/B;AACA;AACA,8BAA8B,YAAY;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,mBAAmB,sBAAG;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL;AACA;AACO;AACP,+BAA+B,yBAAM;AACrC;AACA;AACA,KAAK;AACL,mBAAmB,sBAAG;AACtB;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL;AACA;AACA;AACO;AACP,oCAAoC,4BAAiB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,yBAAM;AAC/B;AACA;AACA,8BAA8B,YAAY;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,mBAAmB,sBAAG;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL;AACA;AACO;AACP,yBAAyB,yBAAM;AAC/B;AACA;AACA,KAAK;AACL,mBAAmB,sBAAG;AACtB;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL;AACA;AACA;AACO;AACP;AACA,4BAA4B,sBAAG;AAC/B,eAAe,yBAAM;AACrB;AACA,iBAAiB,kBAAQ;AACzB,sCAAsC,KAAK;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL,wBAAwB,iBAAO;AAC/B,8BAA8B,yBAAM;AACpC;AACA,KAAK;AACL,mBAAmB,sBAAG;AACtB,+BAA+B,sBAAG;AAClC;AACA,SAAS;AACT,8BAA8B,cAAK;AACnC;AACA,kDAAkD,cAAc;AAChE,sEAAsE,2BAA2B;AACjG,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL;AACA;AACO;AACP,yBAAyB,yBAAM;AAC/B,aAAa,sBAAG;AAChB;AACA;AACA;AACA,yBAAyB,KAAK,sBAAsB,KAAK,QAAQ,2BAAQ;AACzE,KAAK;AACL,mBAAmB,sBAAG;AACtB;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL;AACA;AACO;AACP,yBAAyB,yBAAM;AAC/B,kDAAkD,kBAAQ;AAC1D,KAAK;AACL,mBAAmB,sBAAG;AACtB,qCAAqC,aAAa,6DAA6D,kBAAkB;AACjI;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA,KAAK;AACL;AACA;AACO;AACP;AACA,wBAAwB,yBAAM;AAC9B;AACA,wBAAwB,KAAK;AAC7B;AACA;AACA;AACA;AACA,YAAY,2BAAQ;AACpB,0BAA0B,uCAAuC;AACjE;AACA,iBAAiB,kBAAQ;AACzB,0BAA0B,8CAA8C;AACxE;AACA;AACA,KAAK;AACL,IAAI,0BAAO;AACX,QAAQ,0BAAO,iBAAiB,2CAA2C;AAC3E;AACA,wCAAwC,cAAc;AACtD,iEAAiE,cAAc;AAC/E;AACA;AACA;AACA;AACA,0BAA0B,wBAAwB;AAClD;AACA,iBAAiB;AACjB;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA,QAAQ,kBAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,6BAAU;AACvB;AACA,qCAAqC;AACrC;AACA,aAAa,sBAAG;AAChB;AACA,0CAA0C;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA,YAAY,uBAAI;AAChB;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,6BAA6B,eAAe;AAC5C;AACO;AACP;AACA;AACA;AACA,yBAAyB,eAAe;AACxC;AACO;AACP;AACA;AACA,SAAS,sBAAG;AACZ;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C,SAAS;AACT;AACA,SAAS,sBAAG;AACZ;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C,SAAS;AACT;AACA,QAAQ,sBAAG;AACX,QAAQ,sBAAG;AACX,SAAS,sBAAG;AACZ;AACA,uEAAuE,aAAa,KAAK,4BAA4B;AACrH;AACA,kBAAkB,wBAAwB;AAC1C,SAAS;AACT;AACA,QAAQ,sBAAG;AACX,QAAQ,0BAAO;AACf,YAAY,0BAAO;AACnB,oBAAoB,8BAAW;AAC/B;AACA;AACA,gCAAgC,aAAa,eAAe,QAAQ;AACpE,8BAA8B,wBAAwB;AACtD,qBAAqB;AACrB;AACA,yBAAyB,sBAAG;AAC5B,sCAAsC,0BAAO;AAC7C;AACA;AACA,oBAAoB,0BAAO;AAC3B,6BAA6B,8BAAW;AACxC,6BAA6B,kBAAQ;AACrC;AACA,uGAAuG,mBAAmB,cAAc,iBAAiB,qBAAqB,aAAa;AAC3L,sCAAsC,wBAAwB;AAC9D,6BAA6B;AAC7B;AACA,qBAAqB;AACrB;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACO;AACP;AACA;AACA,0BAA0B,iBAAO,CAAC,0BAAO,CAAC,yBAAM;AAChD,+BAA+B,gBAAM,oDAAoD,KAAK;AAC9F;AACA;AACA,QAAQ,0BAAO;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sBAAG;AACvB;AACA;AACA;AACA;AACA;AACA,wBAAwB,gBAAgB;AACxC;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,wBAAwB;AAC1C,SAAS;AACT;AACA;AACA;AACO;AACP;AACA,sBAAsB,uBAAI;AAC1B,IAAI,0BAAO;AACX;AACA;AACA,YAAY,0BAAO;AACnB;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACO;AACP;AACA;AACA,QAAQ,kBAAQ;AAChB;AACA;AACA,aAAa,6BAAU;AACvB;AACA;AACA;AACA,aAAa,sBAAG;AAChB;AACA;AACA;AACA,aAAa,2BAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACO;AACP,QAAQ,2BAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,qCAAqC,SAAS;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,kBAAQ;AACpB;AACA;AACA,gBAAgB,gBAAgB;AAChC;AACA;AACA;AACA;AACA,2BAA2B,wBAAwB;AACnD;AACA;AACA;AACA;AACA;AACA,iBAAiB,2BAAQ;AACzB;AACA;AACA;AACA;AACA;AACA,qBAAqB,OAAO,wBAAwB;AACpD;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,0BAA0B,wBAAwB;AAClD;AACA,wCAAwC,aAAa;AACrD,8BAA8B,eAAe;AAC7C;AACA;AACA,+BAA+B,wBAAwB;AACvD;AACA,wCAAwC,aAAa;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,sBAAG;AACzB,YAAY,2BAAQ;AACpB;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0BAAO;AACf;AACA,wBAAwB,WAAW;AACnC;AACA;AACA;AACA;AACA;;;;;;;;ACn3BO;AACP;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;;ACPgH;AACzG;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACA;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,0BAAO;AACX;AACA,KAAK;AACL;AACO;AACP,iBAAiB,kCAAK;AACtB;AACA;AACA;AACA,qBAAqB,iBAAO,CAAC,0BAAO,CAAC,sBAAG;AACxC,8BAA8B,oBAAU;AACxC;AACA,YAAY,0BAAO;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,IAAI,0BAAO;AACX;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,0BAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACO;AACP,IAAI,0BAAO;AACX;AACA;AACA,QAAQ,0BAAO;AACf;AACA,SAAS;AACT,KAAK;AACL;AACO;AACP,IAAI,0BAAO;AACX;AACA,KAAK;AACL;AACO;AACP,IAAI,0BAAO;AACX;AACA,KAAK;AACL,IAAI,0BAAO;AACX;AACA;AACA,aAAa,kBAAQ;AACrB;AACA;AACA,KAAK;AACL;AACO;AACP,WAAW,sBAAG;AACd;AACO;AACP,WAAW,sBAAG;AACd;AACO;AACP,WAAW,sBAAG;AACd;AACO;AACP,WAAW,sBAAG;AACd;AACO;AACP,WAAW,sBAAG;AACd;AACA;;ACjHO;AACP;AACA,sEAAsE,YAAY;AAClF,KAAK;AACL;AACA,2CAA2C,6BAA6B,gBAAgB,YAAY,iBAAiB,QAAQ;AAC7H,KAAK;AACL;AACA;;ACR8N;AAC1F;AACzD;AAC3B;AACqB;AACR;AACtD;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4DAA4D;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,yBAAyB;AACnD;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,OAAO,OAAO,UAAU;AAC3D;AACA,wBAAwB,cAAc,EAAE,KAAK;AAC7C;AACA;AACA;AACA,mCAAmC,OAAO,OAAO,UAAU,UAAU,KAAK;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,gBAAM,GAAG;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,6BAA6B;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,0BAAO;AAC3B;AACA,iCAAiC,aAAa,kCAAK,mBAAmB;AACtE,qCAAqC,YAAY;AACjD;AACA;AACA;AACA;AACA;AACA,uCAAuC,kCAAK;AAC5C;AACA,aAAa;AACb;AACA;AACA,mFAAmF,oBAAoB;AACvG,iBAAiB;AACjB;AACA,qFAAqF,2BAA2B;AAChH,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0BAAO;AACnB,uDAAuD,gBAAM,iCAAiC,8BAAW;AACzG,aAAa;AACb,iCAAiC,uBAAI;AACrC,YAAY,0BAAO;AACnB,0CAA0C,YAAY;AACtD;AACA;AACA;AACA,2FAA2F,gBAAgB;AAC3G,yBAAyB;AACzB;AACA;AACA;AACA;AACA,wBAAwB,0BAAO;AAC/B,wBAAwB,iBAAiB;AACzC;AACA;AACA,gDAAgD,iBAAiB;AACjE;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B,yBAAyB;AACzB;AACA;AACA;AACA;AACA,2CAA2C,gBAAM,GAAG;AACpD;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA,iBAAiB,0BAAO;AACxB;AACA,uCAAuC,sBAAG;AAC1C;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,YAAY,0BAAO;AACnB,gBAAgB,aAAa;AAC7B,aAAa;AACb;AACA;AACA;AACA;AACA,oBAAoB,cAAc;AAClC,qCAAqC,uBAAQ;AAC7C;AACA;AACA;AACA,2CAA2C,mBAAI;AAC/C;AACA;AACA;AACA,uCAAuC,mBAAI;AAC3C;AACA;AACA,4CAA4C,uBAAQ;AACpD;AACA;AACA,4DAA4D,mBAAI;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8EAA8E,6BAA6B;AAC3G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,yCAAyC,yBAAM;AAC/C;AACA;AACA;AACA;AACA,iBAAiB;AACjB,mDAAmD,0BAAO;AAC1D,kDAAkD,6BAA6B;AAC/E;AACA;AACA;AACA,aAAa;AACb;AACA,gBAAgB,sBAAsB;AACtC,aAAa;AACb;AACA,gBAAgB,gBAAgB;AAChC,aAAa;AACb,SAAS;AACT;AACA;AACA,aAAa,0BAAO;AACpB,mCAAmC,sBAAG;AACtC;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,gBAAgB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,wBAAwB;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,gCAAgC,uBAAI;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,0BAA0B;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,qBAAqB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,4BAA4B;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sJAAsJ,uBAAI;AAC1J;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACroBuD;AACb;AAC8B;AACjE,SAAS,wBAAU;AAC1B,QAAQ,2BAAa;AACrB;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO,SAAS,2BAAa;AAC7B,WAAW,2BAAQ;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,8BAAW;AACpB;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA;AACA,IAAI,iBAAiB;AACrB,QAAQ,sBAAG;AACX;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA;AACA;AACO,0BAA0B,sBAAsB,KAAK,KAAK;AACjE,iBAAiB;AACV;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,sBAAsB;AACjC;AACA;;ACtFqE;AACtB;AACuC;AAC/E;AACP,gCAAgC,sCAAsC;AACtE,yBAAyB,2BAAa;AACtC;AACA,qBAAqB,wBAAU,YAAY;AAC3C,mCAAmC,eAAe;AAClD,iCAAiC,aAAa,iBAAiB,aAAa;AAC5E;AACA,KAAK;AACL,oCAAoC,0BAA0B;AAC9D;AACA,KAAK;AACL,8BAA8B,yEAAyE;AACvG;AACA;AACA,2BAA2B,cAAK;AAChC;AACA;AACA;AACA;AACA;AACA,sCAAsC,yBAAM;AAC5C,4CAA4C,sBAAG,sCAAsC,sBAAG,8BAA8B,wBAAU,4BAA4B;AAC5J,2CAA2C,sBAAG,iDAAiD,QAAQ,IAAI,QAAQ;AACnH,qFAAqF,kCAAkC;AACvH;AACA;AACA,KAAK;AACL,4BAA4B,kEAAkE;AAC9F;AACA;AACA,2BAA2B,cAAK;AAChC;AACA;AACA;AACA;AACA;AACA,4CAA4C,sBAAG,2CAA2C,sBAAG,8BAA8B,wBAAU,2BAA2B;AAChK;AACA,oBAAoB,mCAAmC;AACvD;AACA;AACA,KAAK;AACL;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACO;AACP;AACA;AACA,gCAAgC,QAAQ;AACxC;AACA;AACA,qCAAqC,WAAW;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,cAAK;AACnC;AACA,wBAAwB,oBAAoB;AAC5C;AACA;AACA,uBAAuB,QAAQ,EAAE,8BAA8B,KAAK,oCAAoC,cAAc;AACtH,4CAA4C,uBAAuB,kCAAkC,aAAa;AAClH;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,uFAAuF,UAAU;AACjG;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,wBAAwB,sBAAG,kCAAkC,wBAAU;AACvE;AACA,mDAAmD,oCAAoC;AACvF,qBAAqB,WAAW,YAAY,0BAA0B;AACtE,gBAAgB,QAAQ;AACxB;AACA;AACA;AACA,KAAK;AACL;AACA,wBAAwB,sBAAG,kCAAkC,wBAAU;AACvE;AACA,+DAA+D,oCAAoC,UAAU,WAAW;AACxH,wBAAwB,0BAA0B;AAClD,gBAAgB,QAAQ;AACxB;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,sBAAsB,oBAAoB;AAC1C;AACA;AACA;AACA,0CAA0C,QAAQ,iBAAiB,0BAA0B;AAC7F;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,wDAAwD,2BAA2B;AACnF,sBAAsB,wBAAwB,YAAY,0BAA0B;AACpF;AACA;AACA,KAAK;AACL;AACA;AACA,kBAAkB,wBAAwB,YAAY,0BAA0B,gBAAgB,2CAA2C;AAC3I;AACA,KAAK;AACL;AACA;AACA,0BAA0B,sBAAG;AAC7B,qCAAqC,UAAU,MAAM;AACrD;AACA,2BAA2B;AAC3B;AACA,sBAAsB,SAAS;AAC/B,sFAAsF,kBAAkB;AACxG;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,4CAA4C,IAAI;AAChD;AACA;AACA;AACA;AACA;AACA,wDAAwD,SAAS,0CAA0C,oBAAoB;AAC/H;AACA,KAAK;AACL;AACA;;AC9KwL;AACjL;AACP;AACA;AACA;AACA,iBAAiB,WAAW;AAC5B;AACA,iBAAiB,WAAW;AAC5B;AACA,iBAAiB,MAAM;AACvB;AACA,iBAAiB,mBAAmB;AACpC;AACA,iBAAiB,gCAAgC;AACjD;AACA,iBAAiB,uBAAuB;AACxC;AACA,iBAAiB,UAAU;AAC3B;AACA,iBAAiB,WAAW;AAC5B;AACA,iBAAiB,QAAQ;AACzB;AACA,iBAAiB,IAAI;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnDiE;AACrB;AACG;AACxC;AACP;AACA;AACA;AACA;AACO,qCAAqC,WAAW;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0BAAO,CAAC,yBAAM;AACtB;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,yBAAyB;AAC/C;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;ACrCA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,UAAU;AACrB,WAAW,UAAU;AACrB,WAAW,QAAQ;AACnB,aAAa,UAAU;AACvB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,uDAAe,eAAe,EAAC;;;ACrBO;;AAEtC;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,WAAW,UAAU;AACrB,WAAW,QAAQ;AACnB,aAAa,UAAU;AACvB;AACA;AACA,EAAE,4BAAQ;AACV;AACA,GAAG;AACH;AACA;;AAEA,sDAAe,cAAc,EAAC;;;ACpBsB;AACF;AACJ;AACX;;AAEnC;AACA;AACA;AACA;AACA,WAAW,UAAU;AACrB,WAAW,UAAU;AACrB,aAAa,UAAU;AACvB;AACA;AACA;AACA,eAAe,0BAAO,eAAe,gBAAe,GAAG,eAAc;AACrE;;AAEA,oCAAoC,gCAAY;AAChD;AACA;;AAEA,wDAAe,gBAAgB,EAAC;;;ACtBoB;AACE;;AAEtD;AACA,IAAI,mBAAW;;AAEf;AACA,IAAI,sBAAc,GAAG,mBAAW;;AAEhC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,aAAa,QAAQ;AACrB;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA,cAAc,iBAAgB;AAC9B,MAAM,sBAAc;AACpB;AACA,IAAI;AACJ,IAAI,mCAAe;AACnB;AACA,CAAC;;AAED,wDAAe,OAAO,EAAC;;;ACxCiB;AACD;;AAEvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,QAAQ;AACnB,YAAY,QAAQ;AACpB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,4BAAS;AAChD;AACA,SAAS,UAAS;AAClB;;AAEA,0DAAe,SAAS,EAAC;;;ACtCoE;AAC1D;AACI;AACuJ;AACvL,+CAA+C,UAAU;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,kCAAK,iCAAiC;AAC/D,+BAA+B,kCAAK,uCAAuC;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0BAAO;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,WAAW,GAAG,sBAAsB;AACrE,oCAAoC,KAAK;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,wDAAwD,UAAU;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,mCAAmC,cAAM;AACzC;AACA,0CAA0C,QAAQ;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,sCAAsC,cAAM;AAC5C;AACA,6CAA6C,QAAQ;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,yCAAyC,cAAM;AAC/C;AACA,gDAAgD,QAAQ;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,sDAAsD,cAAM;AAC5D;AACA,6DAA6D,QAAQ;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,eAAe,kCAAK;AACpB;AACA;AACA;AACA;AACA,8BAA8B,cAAI;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,WAAW;AACvC;AACA;AACA,iCAAiC,WAAW;AAC5C;AACA;AACA,iCAAiC,MAAM;AACvC;AACA;AACA,iCAAiC,mBAAmB;AACpD;AACA,oBAAoB,UAAU;AAC9B;AACA,iBAAiB;AACjB;AACA;AACA;AACA,iCAAiC,gCAAgC;AACjE;AACA,oBAAoB,WAAW,GAAG,6BAA6B;AAC/D,oBAAoB,UAAU;AAC9B,qCAAqC,QAAQ,GAAG,8BAA8B;AAC9E,iBAAiB;AACjB;AACA;AACA;AACA,iCAAiC,uBAAuB;AACxD;AACA,oBAAoB,UAAU;AAC9B,qCAAqC,QAAQ,GAAG,8BAA8B;AAC9E,iBAAiB;AACjB;AACA;AACA;AACA,iCAAiC,UAAU;AAC3C;AACA,oBAAoB,UAAU;AAC9B;AACA,iBAAiB;AACjB;AACA;AACA;AACA,iCAAiC,WAAW;AAC5C,YAAY,0BAAO;AACnB;AACA;AACA;AACA,oBAAoB,0BAAO;AAC3B;AACA;AACA,aAAa;AACb;AACA;AACA,iCAAiC,QAAQ;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,cAAI;AACvB,KAAK;AACL;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,YAAY,0BAAO;AACnB;AACA;AACA;AACA;AACA,gBAAgB,uBAAI;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0BAAO;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,cAAI;AACzB,2BAA2B,mBAAS;AACpC,iCAAiC,mBAAS;AAC1C;AACA;AACA;AACA,iCAAiC,QAAQ;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,cAAI;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,WAAW;AAC5C,iCAAiC,kCAAK;AACtC;AACA,uCAAuC,kCAAK;AAC5C;AACA;AACA;AACA,mEAAmE,cAAI;AACvE;AACA;AACA;AACA;AACA;AACA,iCAAiC,MAAM;AACvC;AACA;AACA;AACA,qBAAqB,cAAI;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,cAAI;AAChD;AACA;AACA;AACA;AACA;AACA,iCAAiC,mBAAmB;AACpD;AACA,wCAAwC,UAAU;AAClD;AACA;AACA,aAAa;AACb,sEAAsE,cAAI;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,gCAAgC;AACjE;AACA,sCAAsC,QAAQ;AAC9C;AACA,aAAa;AACb,wCAAwC,UAAU;AAClD;AACA;AACA,aAAa;AACb,sEAAsE,cAAI;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,uBAAuB;AACxD;AACA;AACA;AACA,qBAAqB,cAAI;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,QAAQ;AAC9C;AACA,aAAa;AACb,sCAAsC,UAAU;AAChD;AACA;AACA,aAAa;AACb,oEAAoE,cAAI;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,UAAU;AAC3C;AACA;AACA;AACA,qBAAqB,cAAI;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,UAAU;AAChD;AACA;AACA,aAAa;AACb,oEAAoE,cAAI;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,WAAW;AAC5C;AACA,qDAAqD,QAAQ;AAC7D;AACA;AACA;AACA,mDAAmD,cAAI;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,WAAW;AAC5C;AACA;AACA,4CAA4C,cAAI;AAChD;AACA;AACA,aAAa;AACb;AACA,iCAAiC,IAAI;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,kCAAK;AAC9B;AACA,mCAAmC,kCAAK;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3e+E;AAC1B;AACd;AAC4D;AAC8F;AAC1L;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AACxB;AACP;AACA,wBAAwB,MAAM;AAC9B;AACA;AACA,6BAA6B,UAAU;AACvC;AACA;AACA,6BAA6B,mBAAmB;AAChD;AACA;AACA;AACA,6BAA6B,gCAAgC;AAC7D;AACA;AACA;AACA,6BAA6B,uBAAuB;AACpD;AACA;AACA;AACA,6BAA6B,WAAW;AACxC;AACA;AACA;AACA;AACA;AACA;AACO;AACP,YAAY,2CAA2C;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,UAAU,kCAAkC;AAC5C,UAAU,sBAAsB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,UAAU,kCAAkC;AAC5C,UAAU,sBAAsB;AAChC;AACA;AACO;AACP;AACA,oCAAoC,eAAK;AACzC,eAAe,eAAK;AACpB;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA,qBAAqB,QAAQ;AAC7B;AACA;AACA;AACA;AACA;AACA,+BAA+B,sBAAG;AAClC,4BAA4B,eAAe;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,oBAAoB;AAC9D;AACA;AACA,oCAAoC,oBAAoB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,sBAAG;AACnC,mBAAmB,0BAAO;AAC1B,SAAS;AACT,4BAA4B,yBAAM;AAClC,YAAY,0BAAO;AACnB,qBAAqB,sBAAG;AACxB;AACA;AACA,gBAAgB,0BAAO;AACvB,yBAAyB,sBAAG;AAC5B;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA,SAAS,IAAI;AACb;AACA,qBAAqB,QAAQ;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,QAAQ;AAC7B;AACA;AACA,4BAA4B,eAAe;AAC3C;AACA;AACA,0CAA0C,oBAAoB;AAC9D;AACA;AACA,oCAAoC,oBAAoB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,oCAAoC,eAAK;AACzC;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,kCAAkC,0BAAO;AACzC;AACA,YAAY,0BAAO;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,yBAAM;AACtC;AACA,gBAAgB,0BAAO;AACvB;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,gBAAgB;AACtD;AACA;AACA,gCAAgC,oBAAoB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,UAAU;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,WAAW;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,UAAU;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,iBAAiB;AACrC;AACA;AACA,wBAAwB,iBAAiB;AACzC;AACA;AACA,4BAA4B,oCAAoC;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,uCAAuC;AACpE;AACA;AACA;AACA;AACA;AACA,gCAAgC,mCAAmC;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,wBAAwB,sBAAG,wBAAwB,iBAAiB;AACpE;AACA,uBAAuB,sBAAG;AAC1B;AACA,QAAQ,0BAAO;AACf;AACA,YAAY,0BAAO;AACnB;AACA,aAAa;AACb,SAAS;AACT;AACA,KAAK;AACL;AACA;AACA,6BAA6B,iBAAiB;AAC9C;AACA;AACA;AACA,6BAA6B,6BAA6B;AAC1D;AACA;AACA,sCAAsC,8CAA8C;AACpF;AACA;AACA;AACA;AACA;AACA,gCAAgC,0BAAO;AACvC;AACA;AACA;AACA;AACA;AACA,wCAAwC,uBAAuB;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,iBAAiB;AACxE;AACA;AACA,oBAAoB,0BAAO;AAC3B;AACA,wBAAwB,0BAAO;AAC/B;AACA,yBAAyB;AACzB,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,2BAA2B,WAAe,GAAG,uBAAuB;AACpE,0BAA0B,WAAe,GAAG,sBAAsB;AAClE;AACA;AACO;AACP,sCAAsC,wBAAwB;AAC9D;AACA;AACA;AACA;AACA,wBAAwB,sBAAsB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,QAAQ,eAAK;AACb;AACA;AACA;AACA,SAAS;AACT;AACO;AACP,WAAW,eAAK,qCAAqC,eAAK,iCAAiC,eAAK,wBAAwB,0BAAO;AAC/H;AACA;;ACtdoL;AACnH;AAC6L;AAClH;AACjF;AACG;AACvD;AACP;AACA;AACA;AACA;AACA,KAAK;AACL,WAAW,sBAAG,sEAAsE,MAAM,yBAAyB,8BAA8B;AACjJ;AACO;AACP,4BAA4B,0BAAO;AACnC;AACA,8BAA8B,0BAAO;AACrC,gCAAgC,0BAAO;AACvC;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,iBAAO;AACpC,uBAAuB,gBAAM;AAC7B;AACA,KAAK;AACL,mBAAmB,sBAAG,CAAC,yBAAM;AAC7B,0BAA0B,cAAK;AAC/B;AACA,wBAAwB,oBAAoB;AAC5C;AACA;AACA,kBAAkB,yBAAyB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACO;AACP,cAAc,oBAAoB,OAAO,KAAK,SAAS,KAAK,iCAAiC;AAC7F;AACA;AACA,wBAAwB,QAAQ;AAChC;AACA;AACA,6BAA6B,WAAW;AACxC;AACA;AACA;AACA;AACA;AACA;AACO,4CAA4C,WAAW;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,wBAAwB,yBAAM;AAC9B;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,kBAAkB,yBAAyB;AAC3C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,SAAS,kBAAQ;AACjB;AACA,8CAA8C,SAAS,4CAA4C,UAAU;AAC7G;AACA;AACA;AACA,kBAAkB,yBAAyB;AAC3C;AACA,SAAS;AACT;AACA;AACA;AACO;AACP;AACA;AACA,QAAQ,0BAAO;AACf;AACA;AACA;AACA;AACA,mCAAmC,kBAAQ;AAC3C;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,sBAAsB,yBAAyB;AAC/C;AACA,aAAa;AACb;AACA;AACA;AACA,+BAA+B,oBAAU;AACzC,oCAAoC,0BAAO;AAC3C,4BAA4B,kCAAK;AACjC;AACA;AACA,SAAS;AACT;AACA;AACA;AACO;AACP;AACA,QAAQ,0BAAO;AACf;AACA;AACA,sBAAsB,cAAK;AAC3B;AACA,6BAA6B,WAAW;AACxC;AACA;AACA,kCAAkC,WAAe;AACjD,6BAA6B,MAAM;AACnC,6BAA6B,mBAAmB;AAChD,6BAA6B,gCAAgC;AAC7D,6BAA6B,uBAAuB;AACpD,6BAA6B,UAAU;AACvC;AACA;AACA,kCAAkC,WAAW;AAC7C;AACA,iBAAiB,0BAAO,CAAC,sBAAG;AAC5B;AACA,kCAAkC,QAAQ;AAC1C;AACA;AACA;AACA;AACA;AACA,4BAA4B,cAAc;AAC1C;AACA;AACA,qBAAqB,cAAI;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,WAAW;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mBAAmB,0BAAO;AAC1B,2BAA2B,mBAAS;AACpC,eAAe,0BAAO;AACtB,uCAAuC,uBAAuB,wBAAwB,sBAAsB;AAC5G,gBAAgB,0BAAO;AACvB;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB,8BAA8B,yBAAyB;AACvD;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,UAAU,gBAAM;AAChB,mBAAmB,0BAAO;AAC1B;AACA;AACA,6BAA6B,sBAAsB;AACnD;AACA;AACA;AACA,KAAK;AACL;AACA;AACO,kCAAkC,WAAW;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mBAAmB,0BAAO;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,0BAA0B,yBAAyB;AACnD;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACO;AACP;AACA,IAAI,0BAAO;AACX;AACA;AACA;AACA,QAAQ,0BAAO;AACf,6BAA6B,WAAW;AACxC;AACA;AACA,0BAA0B,gCAAgC;AAC1D;AACA,gBAAgB,0BAAO,CAAC,0BAAO;AAC/B;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,0BAA0B,yBAAyB;AACnD;AACA,iBAAiB;AACjB;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA,iCAAiC,yBAAM;AACvC;AACA;AACA;AACA;AACA,QAAQ,0BAAO;AACf;AACA,YAAY,0BAAO;AACnB;AACA,oBAAoB,YAAY;AAChC;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,iBAAiB,YAAY;AAC7B;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,SAAS;AACT;AACA,KAAK;AACL,uBAAuB,sBAAG;AAC1B,4BAA4B,sBAAG;AAC/B;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,kBAAkB,yBAAyB;AAC3C;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACO;AACP;AACA,4BAA4B,yBAAM;AAClC,gCAAgC,sBAAG;AACnC,qBAAqB;AACrB,SAAS;AACT;AACA,KAAK;AACL,mBAAmB,iBAAO,CAAC,0BAAO;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,yBAAM;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,oBAAoB;AACpC,SAAS;AACT,qCAAqC,sBAAG;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,sBAAsB,yBAAyB;AAC/C;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,uBAAuB,sBAAG;AAC1B,IAAI,0BAAO;AACX;AACA,YAAY,kBAAQ;AACpB;AACA;AACA;AACA,sBAAsB,yBAAyB;AAC/C;AACA,aAAa;AACb;AACA,KAAK;AACL;AACA;AACA;;AClb8C;AACuB;AACA;AAC+C;AAC7G,SAAS,mCAAc;AAC9B,0BAA0B,2BAAQ;AAClC,wBAAwB,mCAAmC;AAC3D,KAAK;AACL;AACA,IAAI,0BAAO;AACX;AACA,KAAK;AACL,WAAW,cAAiB;AAC5B;AACO,SAAS,oCAAe;AAC/B,cAAc,2BAAQ;AACtB,wBAAwB,oCAAoC;AAC5D,KAAK;AACL,WAAW,eAAkB;AAC7B;AACA;;ACpBqC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,WAAW,kBAAQ;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;;ACzDyF;AACC;AACpB;AAC9B;AACa;AAC9C;AACA;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,+BAA+B,sBAAG;AAClC;AACA,cAAc,qBAAqB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,mBAAmB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,8BAA8B,wBAAwB;AACtD;AACA,mCAAmC,mBAAS;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0BAAO;AACnB;AACA;AACA;AACA,yCAAyC,uBAAI;AAC7C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,kBAAQ;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,uBAAI;AACnC,iCAAiC,YAAY;AAC7C;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,sBAAG;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,4BAA4B,sBAAG;AAC/B;AACA,SAAS;AACT,eAAe,0BAAO;AACtB;AACA;AACA;AACA,oBAAoB,GAAG;AACvB;AACA,6EAA6E,YAAE;AAC/E;AACA;AACA;AACA;AACA;AACA,sCAAsC,GAAG;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,mBAAS;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,kCAAK;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,sBAAG;AAClB;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,GAAG;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjSA;AACA;AACA;AACA;AACA;AACA;AACO;AACA;AACA;AACP;AACO;AACP;AACA;AACA;AACO;AACA;AACA;AACA;AACA;AACA;AACP;AACO;AACP;AACA;AACA;AACA;;ACzB6C;AAC8B;AACf;AACoG;AACmB;AAC5K;AACP;AACA;AACA;AACA,2HAA2H,qBAAqB;AAChJ;AACA;AACA;AACA,YAAY,0BAAO;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,0BAAO,yBAAyB,uBAAuB,2BAA2B,oCAAoC;AACrI;AACA;AACA,eAAe,0BAAO,yBAAyB,0BAA0B,cAAc,oCAAoC;AAC3H;AACA;AACA,eAAe,0BAAO,yBAAyB,wCAAwC,4BAA4B,oCAAoC;AACvJ;AACA;AACA,eAAe,iCAAiC,sBAAsB,oCAAoC;AAC1G;AACA;AACA,eAAe,uBAAuB,kHAAkH,8BAA8B;AACtL;AACA;AACA,eAAe,iCAAiC,2FAA2F,WAAW,oBAAoB,uCAAuC;AACjN;AACA;AACA;;AC9CyC;AACY;AACoG;AACnF;AACA;AACtE;AACA;AACA;AACO;AACP;AACA,oCAAoC,sBAAG;AACvC;AACA,cAAc,qBAAqB;AACnC,4BAA4B,sBAAG;AAC/B;AACA,cAAc,qBAAqB;AACnC,iCAAiC,sBAAG;AACpC;AACA,kBAAkB,oBAAoB,GAAG,iCAAiC;AAC1E;AACA;AACA;AACA,QAAQ,0BAAO;AACf,+BAA+B,eAAe;AAC9C,wBAAwB,mHAAmH;AAC3I,gBAAgB,0BAAO;AACvB;AACA,uCAAuC,oBAAoB,WAAW,EAAE,QAAQ;AAChF;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB,oCAAoC,2BAA2B,0CAA0C,MAAM;AAC/G;AACA,qBAAqB;AACrB,iBAAiB;AACjB,gBAAgB,0BAAO;AACvB,sEAAsE,QAAQ,uCAAuC,oBAAoB;AACzI,iBAAiB;AACjB,gBAAgB,0BAAO;AACvB,sEAAsE,UAAU,mCAAmC,oBAAoB;AACvI,iBAAiB;AACjB,gBAAgB,0BAAO;AACvB,sEAAsE,gBAAgB,gDAAgD,oBAAoB;AAC1J,iBAAiB;AACjB,gBAAgB,0BAAO;AACvB,sEAAsE,oBAAoB,6DAA6D,oBAAoB;AAC3K,iBAAiB;AACjB,gBAAgB,0BAAO;AACvB,sEAAsE,YAAY,oDAAoD,oBAAoB;AAC1J,iBAAiB;AACjB,aAAa;AACb,SAAS;AACT;AACA;AACA,2BAA2B,cAAc,EAAE,2CAA2C;AACtF;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,wBAAwB,2BAA2B;AACnD;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,eAAe,2BAA2B;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,WAAW;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrIA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtEA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;ACT4G;AAC7C;AACxD;AACP,0BAA0B,uBAAI;AAC9B;AACA,oBAAoB,yBAAyB;AAC7C;AACA;AACA;AACA,wBAAwB,0BAA0B;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,IAAI,cAAc;AAClB;AACA;AACA;AACA,gBAAgB,0BAAO;AACvB;AACA;AACA;AACA;AACA;AACA,gBAAgB,8BAAW;AAC3B;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,iBAAiB,0BAAO;AACxB,sCAAsC,sBAAG;AACzC,+DAA+D,sBAAsB;AACrF,uBAAuB,kDAAkD;AACzE;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,IAAI,cAAc;AAClB;AACA,IAAI,0BAAO;AACX;AACA,KAAK;AACL;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,CAAC,8DAA8D;AACxD;AACP;AACA;AACA;AACO;AACP,6BAA6B,yBAAM;AACnC,eAAe,6BAAU;AACzB,KAAK;AACL,mBAAmB,sBAAG;AACtB;AACA,6CAA6C,aAAa,OAAO,oCAAoC;AACrG;AACA;AACA;AACA,KAAK;AACL,WAAW,iBAAO;AAClB;AACA;;ACzF2H;AAClE;AACkE;AACtE;AACrD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,oCAAoC,sBAAG;AACvC;AACA,cAAc,qBAAqB;AACnC;AACA,4CAA4C,mBAAI;AAChD,yCAAyC,mBAAI;AAC7C,mCAAmC,mBAAI;AACvC,sCAAsC,mBAAI;AAC1C,+BAA+B,mBAAI;AACnC;AACA;AACA;AACA;AACA,oDAAoD,mBAAmB;AACvE,mDAAmD,mBAAmB;AACtE,uCAAuC,mBAAI;AAC3C;AACA;AACA;AACA,oDAAoD,mBAAI;AACxD,mDAAmD,mBAAI;AACvD;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,yBAAyB;AAC7E,mDAAmD,yBAAyB;AAC5E,uCAAuC,mBAAI;AAC3C;AACA;AACA;AACA;AACA,oDAAoD,mBAAI;AACxD,mDAAmD,mBAAI;AACvD;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,mBAAI;AACpD,+CAA+C,mBAAI;AACnD,mCAAmC,mBAAI;AACvC,8CAA8C,mBAAI;AAClD;AACA;AACA,8EAA8E,4BAA4B;AAC1G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,gBAAgB;AACxB;AACA;AACA;AACA;AACA;AACA,QAAQ,oBAAoB;AAC5B;AACA;AACA;AACA;AACA,YAAY,8BAAW;AACvB,iDAAiD,oCAAoC,iBAAiB,uBAAI;AAC1G;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,8BAAW;AACvB,mCAAmC,wCAAwC,iBAAiB,uBAAI;AAChG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9L2C;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,WAAW;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,WAAW;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrE6C;AACuB;AACU;AACA;AACX;AACf;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,mBAAmB;AAC3D,YAAY,kBAAQ;AACpB,2BAA2B,oCAAoC;AAC/D;AACA;AACA,aAAa;AACb;AACA;AACA,sBAAsB,yBAAyB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,mBAAmB;AAC1D,2BAA2B,wBAAwB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sBAAsB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,gBAAgB,CAAC,yBAAM;AACtC;AACA;AACA;;;;AC7U0G;AACiE;AAChD;AACpE;AAC8H;AAClI;AACW;AACT;AACiF;AACtI;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,kCAAkC;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sBAAG;AACf;AACA;AACA;AACA;AACA,YAAY,0BAAO;AACnB;AACA;AACA;AACA,gBAAgB,0BAAO;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0BAAO;AACnB,6BAA6B,yBAAM;AACnC;AACA;AACA,aAAa,IAAI;AACjB;AACA,iBAAiB,sBAAG;AACpB,YAAY,eAAK,CAAC,0BAAO,CAAC,yBAAM,0BAA0B,WAAW;AACrE,kCAAkC,0BAAO,CAAC,yBAAM;AAChD,iCAAiC,cAAI;AACrC,6BAA6B,yBAAM;AACnC;AACA;AACA,aAAa,IAAI;AACjB;AACA,iBAAiB,2BAAQ;AACzB,6BAA6B,kCAAK;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,GAAG;AACnC,8BAA8B,sBAAG;AACjC,cAAc,0BAAO,CAAC,yBAAM;AAC5B,cAAc,yBAAM;AACpB,sCAAsC,eAAK,sCAAsC,0BAAO;AACxF;AACA,cAAc,kCAAkC;AAChD,cAAc,sBAAsB;AACpC;AACA;AACA;AACA,QAAQ,iBAAiB,CAAC,yBAAM;AAChC;AACA;AACA;AACA,yCAAyC,SAAS;AAClD;AACA;AACA,8BAA8B,sBAAG;AACjC;AACA,cAAc,mBAAmB;AACjC,kCAAkC,sBAAG;AACrC;AACA,cAAc,mBAAmB;AACjC;AACA;AACA,oDAAoD,oBAAoB,GAAG,uBAAuB;AAClG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sEAAsE,uCAAuC;AAC7G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sBAAsB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,UAAU;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,gBAAgB;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,SAAS;AACxE;AACA;AACA;AACA;AACA;AACA,sHAAsH,gBAAgB,kBAAkB,iCAAiC;AACzL;AACA;AACA,uDAAuD,oBAAoB;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,oCAAoC;AACpD,uCAAuC,oBAAoB,kBAAkB,oCAAoC;AACjH;AACA;AACA,+DAA+D,SAAS;AACxE;AACA;AACA;AACA,uDAAuD,QAAQ;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oHAAoH,QAAQ,kBAAkB,2BAA2B;AACzK;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,YAAY;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,8BAA8B;AAC9C,uCAAuC,YAAY,kBAAkB,8BAA8B;AACnG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,oBAAoB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,MAAM;AAC7D,qBAAqB,0BAAO;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,gCAAgC,0BAA0B;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sBAAsB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,kCAAkC,wBAAwB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,0BAA0B;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,kCAAK;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,GAAG;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7hB+G;AACxE;AACgE;AAClD;AACrD;AACA;AACA;AACO;AACP;AACA;AACA,oCAAoC,sBAAG;AACvC;AACA,cAAc,qBAAqB;AACnC;AACA;AACA,YAAY,sBAAsB;AAClC;AACA;AACA,qCAAqC,kCAAK;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,kCAAK;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,gCAAgC;AAC7E;AACA;AACA,wBAAwB,wBAAwB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,kCAAkC,kBAAkB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,sBAAsB;AACnE;AACA,wBAAwB,wBAAwB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,kCAAkC,oBAAoB;AACtD;AACA;AACA;;ACzE8F;AAC/C;AACxC;AACP;AACA;AACA;AACA,YAAY,8BAAW;AACvB,kCAAkC,cAAc;AAChD;AACA,eAAe,uBAAuB;AACtC;AACA;AACA;AACA;AACA,4BAA4B,cAAK;AACjC;AACA;AACA,2CAA2C,oBAAoB;AAC/D;AACA;AACA;AACA;;ACrBmF;AAC2G;AACxI;AAC4B;AACC;AACxC;AACqB;AAChE;AACA;AACA;AACA;AACA;AACA,mCAAmC,uBAAuB;AAC1D,YAAY,WAAW,GAAG,wCAAwC,KAAK,KAAK;AAC5E,iBAAiB;AACjB,8BAA8B,mBAAmB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,QAAQ;AACpC;AACA,+BAA+B,IAAI;AACnC;AACA;AACA,+BAA+B,IAAI;AACnC;AACA;AACA,8BAA8B,IAAI;AAClC;AACA;AACA,0BAA0B,IAAI;AAC9B;AACA;AACA,4BAA4B,IAAI;AAChC;AACA;AACA,gCAAgC,IAAI;AACpC;AACA;AACA,oCAAoC,IAAI;AACxC;AACA;AACA,wCAAwC,IAAI;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,QAAQ;AACpC;AACA,sCAAsC,IAAI;AAC1C,sCAAsC,IAAI;AAC1C,qCAAqC,IAAI;AACzC,iCAAiC,IAAI;AACrC,mCAAmC,IAAI;AACvC,uCAAuC,IAAI;AAC3C,2CAA2C,IAAI;AAC/C,+CAA+C,IAAI;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,WAAW;AAC1B;AACA;AACA;AACA,wCAAwC,IAAI,GAAG,4BAA4B;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,MAAM;AAC3C;AACA;AACA,8BAA8B,mBAAmB;AACjD;AACA;AACA,8BAA8B,gCAAgC;AAC9D;AACA;AACA,8BAA8B,UAAU;AACxC;AACA;AACA,8BAA8B,uBAAuB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,sBAAG;AAC9B,+CAA+C,yBAAyB;AACxE,kEAAkE,2BAA2B;AAC7F,8CAA8C,gCAAgC;AAC9E;AACA;AACA;AACA,yBAAyB,uBAAI;AAC7B;AACA,oCAAoC,WAAW;AAC/C;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,mBAAmB;AAChC,+CAA+C,yBAAyB;AACxE,8DAA8D,wBAAwB;AACtF,8CAA8C,gCAAgC;AAC9E;AACA;AACA;AACA,yBAAyB,uBAAI;AAC7B,oCAAoC,QAAQ;AAC5C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,uBAAI;AACzB,0BAA0B,6BAAU;AACpC,0CAA0C,iCAAiC;AAC3E;AACA;AACA;AACA,QAAQ,sBAAG;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,uBAAI;AACzB;AACA,uBAAuB,0BAAO;AAC9B;AACA,0BAA0B,WAAW;AACrC;AACA;AACA;AACA,KAAK;AACL,QAAQ,sBAAG;AACX;AACA;AACA,0BAA0B,cAAI,oBAAoB,6BAAU;AAC5D;AACA;AACA,IAAI,0BAAO;AACX,gCAAgC,WAAW,GAAG,gBAAgB;AAC9D;AACA,YAAY,sBAAG;AACf,wEAAwE;AACxE;AACA;AACA,iBAAiB,sBAAG;AACpB;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,+BAA+B,IAAI;AACnC;AACA;AACA;AACA;AACA;AACA,0CAA0C,IAAI;AAC9C,oEAAoE,mBAAmB;AACvF;AACA;AACA;AACA;AACA;;ACtSgC;AACU;AACW;AACrD;AACA;AACA;AACO;AACP;AACA,YAAY,sBAAG;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC;AACrC;AACA;AACA;AACA,iCAAiC,qBAAqB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,OAAO,OAAO,UAAU;AACvD;AACA,oBAAoB,cAAc,EAAE,KAAK;AACzC;AACA;AACA;AACA,+BAA+B,OAAO,OAAO,UAAU,UAAU,KAAK;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/CO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;;ACnBsE;AACjB;AACS;AACS;AACiC;AACb;AACrC;AACF;AACG;AACE;AACE;AACM;AACR;AACE;AACF;AACG;AACN;AACG;AAClD,oBAAoB,mBAAmB,CAAC,GAAG;AAClD;AACO;AACP;AACA;AACA;AACA;AACA,0BAA0B,0BAA0B;AACpD;AACA;AACA;AACA,CAAC;AACM;AACP;AACA;AACA,CAAC;AACM;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8DAA8D;AACxD;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,gBAAgB;AAChC,aAAa;AACb;AACA;AACA;AACA;AACA,oBAAoB,0BAAO;AAC3B;AACA;AACA;AACA,2CAA2C,cAAc;AACzD;AACA,yBAAyB;AACzB;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,iCAAiC,mCAAc;AAC/C,2BAA2B,yBAAM;AACjC,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA,oBAAoB,0BAAO;AAC3B,6CAA6C,oCAAe;AAC5D,+BAA+B,yBAAM;AACrC,oCAAoC,yBAAM;AAC1C,wCAAwC,oCAAoC;AAC5E;AACA,qBAAqB;AACrB,sDAAsD,iBAAiB;AACvE;AACA,+BAA+B,yBAAM;AACrC,oCAAoC,yBAAM;AAC1C;AACA,qBAAqB;AACrB;AACA;AACA,aAAa;AACb;AACA,gBAAgB,0BAAO;AACvB;AACA;AACA;AACA,2CAA2C,sBAAsB,CAAC,yBAAM;AACxE;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,+BAA+B,yBAAM;AACrC,qBAAqB;AACrB,sDAAsD,yBAAM;AAC5D,iBAAiB;AACjB;AACA;AACA,iBAAiB,0BAAO;AACxB,gCAAgC,sBAAG;AACnC,wEAAwE,0DAA0D;AAClI;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sBAAG;AACf;AACA;AACA;AACA;AACA;AACA,+BAA+B,sBAAG;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,IAAI,WAAW;AACf,IAAI,UAAU;AACd,IAAI,WAAW;AACf,IAAI,YAAY;AAChB,IAAI,gBAAgB;AACpB,IAAI,aAAa;AACjB,IAAI,YAAY;AAChB,IAAI,aAAa;AACjB,IAAI,YAAY;AAChB,IAAI,iBAAiB;AACrB;AACO,wBAAwB,sDAAM;AACrC;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,4BAA4B,kCAAK;AACjC;AACA;AACA;AACA;AACA;;ACxMwC;AACD;AACvC;AACA;AACA;AACA;AACO;AACP,2DAA2D;AAC3D;AACA;AACA;AACA;;ACXA;AACA;AACuC;AAC4E;AAC1C;AACzE;AACsH;AACtH;AACiE;AACO;AACxE;AACsE;AACiG;AAC7F;AAC1E;AAC8L;AAC9L;AACuF;AAC9B;AACzD;AACO;AACP;AACA;AACA;AACA;AACuE;AAChE,MAAM,UAAM;AACnB;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AAC0D;AACmB;AACf;AACV;AACpD;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,YAAY,8BAAc,UAAU,2CAAiB,UAAU,2CAAkB,CAAC,uCAAa;AAC/F;AACA;AACA;AACA;AACA;AACA,oBAAoB,mCAAiB;AACrC;AACA;AACA;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACmC;AACM;AAC2H;AAC7J;AACP,cAAc,UAAU,GAAG,KAAK,GAAG,WAAW;AAC9C;AACO;AACA;AACA;AACA;AACA;AACP;AACO;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,gBAAgB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,gBAAgB;AACpC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,oBAAQ;AACtC;AACA;AACA,mCAAmC,uBAAW;AAC9C;AACA;AACA,mCAAmC,uBAAW;AAC9C;AACA;AACA,mCAAmC,kBAAM;AACzC,eAAe,UAAM;AACrB;AACA,mCAAmC,sBAAU;AAC7C;AACA;AACA,mCAAmC,mCAAuB;AAC1D;AACA;AACA,mCAAmC,+BAAmB;AACtD;AACA;AACA,mCAAmC,4CAAgC;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,iBAAiB,sBAAG;AACpB;AACA;AACA;AACA,SAAS,UAAM;AACf;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,oBAAoB,yBAAM,CAAC,sBAAG;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA,iCAAiC;AACjC,4BAA4B;AAC5B;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,2BAA2B;AAC3B,6BAA6B;AAC7B,wBAAwB;AACxB;AACA,gCAAgC;AAChC;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,uBAAW;AACzC;AACA;AACA,mCAAmC,kBAAM;AACzC;AACA;AACA,mCAAmC,sBAAU;AAC7C;AACA;AACA,mCAAmC,mCAAuB;AAC1D;AACA;AACA,mCAAmC,+BAAmB;AACtD;AACA;AACA,mCAAmC,4CAAgC;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,oBAAoB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B,mIAAmI;AACnI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnZA;AACA;AACA;AACA;AACA;AACmC;AAC5B;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,sBAAG;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,cAAc,UAAU,WAAW,OAAO,GAAG,yBAAyB,GAAG,4DAA4D;AACrI;AACA;;;;;;;;;;AC7C8C;AACR;;AAEtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,UAAU;AACrB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ,IAAI,QAAQ,IAAI,QAAQ;AAC/C,YAAY,QAAQ,IAAI,QAAQ;AAChC;AACA;AACA,mCAAmC,4BAAQ,QAAQ,gCAAY;AAC/D;;AAEA,uDAAe,MAAM,EAAC;;;;;;;;;;;AC9BtB;AACA;AACA;AACA;AACA;AACuO;AACnH;AAChD;AACjC;AACQ;AACF;AACN;AACQ;AACA;AACA;AACF;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,UAAU;AAClC;AACA;AACA;AACA;AACA;AACA;AACO,sCAAsC,gCAAoB;AACjE;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,SAAS;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,4DAA4D;AAC5E;AACA;AACA,oBAAoB,WAAW;AAC/B;AACA;AACA,4BAA4B,sBAAG,CAAC,iCAAiB;AACjD;AACA;AACA;AACA;AACA,SAAS,gBAAgB,sBAAG;AAC5B;AACA,gCAAgC,yBAAM;AACtC,gBAAgB,0BAAO;AACvB;AACA;AACA,wBAAwB,0BAAO;AAC/B;AACA,yBAAyB;AACzB;AACA,iBAAiB;AACjB;AACA,aAAa,IAAI;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,YAAY;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,uDAAuD;AACvE;AACA;AACA,oBAAoB,WAAW;AAC/B;AACA;AACA,qBAAqB,sBAAG,CAAC,iCAAiB;AAC1C;AACA;AACA;AACA;AACA,SAAS;AACT,mBAAmB,sBAAG;AACtB,SAAS;AACT;AACA;AACA,sCAAsC,0BAAO;AAC7C;AACA,gBAAgB,0BAAO;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,yBAAM;AAC1C;AACA;AACA,wBAAwB,0BAAO;AAC/B;AACA,yBAAyB;AACzB;AACA;AACA,iBAAiB,IAAI;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,oBAAoB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,SAAS;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,SAAS;AACnD,eAAe,SAAS;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,sBAAG;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,gBAAgB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,oBAAoB,sBAAG,kCAAkC,0BAAU;AACnE;AACA,2DAA2D,oCAAoC,QAAQ,yCAAyC,EAAE,WAAW;AAC7J,oBAAoB,0BAA0B;AAC9C,YAAY,QAAQ;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,uBAAW;AACnC;AACA;AACA,6BAA6B,kBAAM;AACnC;AACA;AACA,6BAA6B,uBAAW;AACxC;AACA;AACA,6BAA6B,+BAAmB;AAChD;AACA;AACA,6BAA6B,4CAAgC;AAC7D;AACA;AACA,6BAA6B,mCAAuB;AACpD;AACA;AACA,6BAA6B,sBAAU;AACvC;AACA;AACA,6BAA6B,oBAAQ;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,0BAAO;AACnC,2BAA2B,gBAAM;AACjC,oCAAoC,cAAc;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,YAAY;AACzC;AACA;AACA;AACA;AACA;AACA,6BAA6B,aAAa;AAC1C;AACA;AACA;AACA;AACA,wBAAwB,sBAAsB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,YAAY;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,cAAc;AAC5C,QAAQ,4BAAY;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,SAAS;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,YAAY;AACpC;AACA,oBAAoB,yBAAyB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,aAAa;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sBAAsB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,iBAAiB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,cAAc;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,aAAa;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,aAAa;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,eAAe;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3iBA;AACA;AACA;AACA;AACA;AACkE;AAClE;;;;;;ACNA;AACA;AACA;AACA;AACA;AACuD;AACF;AAC9C;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oFAAoF,kCAAY;AAChG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wFAAwF,kCAAY;AACpG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,oBAAoB;AAC5C,wBAAwB,mBAAmB;AAC3C,qCAAqC;AACrC;AACA;AACA;AACA;AACA,qBAAqB,OAAO,aAAQ,oBAAoB,aAAQ;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,QAAQ;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC9NA;AACA;AACA;AACA;AACA;AACA;AAC4D;AACyC;AACxC;AAC2C;AAChC;AACsC;AACvD;AAChD;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,+BAA+B,cAAc;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,2BAAW;AACvB;AACA;AACA;AACA;AACA;AACA,YAAY,4BAAY;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,uCAAuC;AAC/D;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,YAAY,2BAAW;AACvB,mBAAmB,qCAAW;AAC9B;AACA;AACA;AACA;AACA,iBAAiB,wCAAc;AAC/B;AACA;AACA;AACA,mBAAmB,qCAAW;AAC9B;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA,uEAAuE,aAAa;AACpF;AACA;AACA;AACA;AACA;AACA,QAAQ,4CAAsB,WAAW,YAAY;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,yBAAyB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,uBAAuB;AAC3C;AACA;AACA,uCAAuC,yBAAS;AAChD;AACA;AACA;AACA;AACA,qBAAqB,yBAAS;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,uBAAuB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,+CAAyB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,sBAAsB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,wCAAkB,UAAU,wBAAY;AACvE;AACA;AACA,wCAAwC,gCAAgB;AACxD,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,eAAe,sCAA0B;AACzC;AACA;AACA,eAAe,sCAA0B;AACzC;AACA;AACA,eAAe,sCAA0B;AACzC;AACA;AACA,eAAe,sCAA0B;AACzC;AACA;AACO;AACP,gCAAgC,kBAAkB;AAClD;AACA;AACA;AACA,8BAA8B,qDAAqD;AACnF,oCAAoC,cAAc;AAClD,4BAA4B,aAAa,cAAc,aAAa;AACpE;AACA,oCAAoC,gBAAgB;AACpD,oDAAoD,qBAAqB;AACzE;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,iBAAiB;AACrE;AACA;AACA,2CAA2C;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,iCAAqB;AACrD;AACA;AACA;AACA;AACA;AACA,sBAAsB,gCAAoB,GAAG,mCAAmC;AAChF,sBAAsB,uBAAuB;AAC7C;AACA,gEAAgE;AAChE,iBAAiB;AACjB;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;ACvpBA;AACA;AACA;AACA;AACA;AAC4C;AAC+Q;AACjP;AAC9B;AACsD;AAC3F;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,8CAAoB;AAC1C,wBAAwB,+BAAM,uBAAuB,wBAAY;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,+BAAM,uBAAuB,uBAAW;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,8BAAc;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,QAAQ,yBAAS;AACjB;AACA;AACA,aAAa,wBAAQ;AACrB;AACA;AACA,aAAa,4BAAY;AACzB;AACA;AACA,aAAa,gCAAgB;AAC7B;AACA;AACA,aAAa,0BAAU;AACvB;AACA;AACA,aAAa,8BAAc;AAC3B;AACA;AACA,aAAa,gCAAgB;AAC7B;AACA;AACA,aAAa,uBAAO;AACpB;AACA;AACA,aAAa,2BAAW;AACxB;AACA,+CAA+C,eAAG;AAClD;AACA;AACA,kBAAkB,gCAAiB,+CAA+C,cAAc;AAChG;AACA;AACA;AACA;AACA,uBAAuB,qCAAW;AAClC;AACA;AACA;AACA;AACA,QAAQ,oCAAoB;AAC5B;AACA,yBAAyB,4BAAY;AACrC,sHAAsH;AACtH;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,8BAAc;AAC3B;AACA;AACA;AACA;AACA;AACA,kBAAkB,gCAAiB,uCAAuC,uBAAuB;AACjG;AACA;AACA,QAAQ,oCAAiB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,yBAAyB,2BAA2B;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,uBAAuB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,6BAAa;AACrB;AACA;AACA;AACA;AACA,aAAa,6BAAa;AAC1B;AACA;AACA;AACA;AACA,aAAa,0BAAU;AACvB;AACA;AACA;AACA,aAAa,oCAAoB;AACjC;AACA;AACA;AACA,aAAa,+BAAgB;AAC7B;AACA;AACA;AACA,IAAI,oCAAiB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,SAAS,GAAG,QAAQ;AAC7C;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,uBAAO;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,4CAAkB;AAC7C;AACA;AACA,0EAA0E,qCAAW;AACrF;AACA;AACA;AACA,aAAa,0BAAU,cAAc,4BAAY;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,0BAAU,cAAc,8BAAc;AACnD;AACA;AACA;AACA;AACA,aAAa,yBAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,yBAAyB,yBAAS;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,iBAAiB;AACjB;AACA,yBAAyB,yBAAS;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,QAAQ,oCAAiB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,KAAK;AACtC;AACA;AACA;AACA,QAAQ,oCAAoB;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,4BAAY;AAC5B,gBAAgB,uBAAO,YAAY,8BAAc,YAAY,gCAAgB;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,KAAK;AACvC;AACA;AACA;;ACzdA;AACA;AACA;AACA;AACA;AAC8D;AACN;AACjD;AACP;AACA;AACA,uBAAuB,uBAAuB;AAC9C,IAAI,YAAY;AAChB;AACA;AACA;AACA;;ACfA;AACA;AACA;AACA;AACA;AACoD;AACI;AACxD;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,uBAAuB,aAAa;AACpC,WAAW,YAAY;AACvB;AACA;;;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACsF;AACtF;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,eAAe,oCAAuB;AACtC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO,MAAM,gCAAkB;AAC/B;AACA;AACA;AACA;AACO;AACP,mBAAmB,gCAAkB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,kBAAkB,8BAAiB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,gCAAkB;AAChC;AACA;AACA;AACA;AACA;AACA;AACO,MAAM,sBAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AClGA;AACA;AACA;AACA;AACa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE,SAAS;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA,oGAAoG,SAAS;AAC7G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oCAAoC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,iBAAiB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;;;;;;ACvQA;AACA;AACA;AACA;AACA;AACwC;AACzB;AACR;AACP;AACA,wBAAwB,gBAAK;AAC7B,uBAAuB,gBAAK;AAC5B,uBAAuB,gBAAK;AAC5B,wBAAwB,gBAAK;AAC7B,2BAA2B,gBAAK;AAChC,6BAA6B,OAAO,iBAAiB,OAAO;AAC5D;AACA;AACA;AACA;AACA;AACA,oDAAoD,cAAG;AACvD,gDAAgD,cAAG;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C;AAC5C;AACA;AACA;AACA,eAAe,sBAAsB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,cAAG;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACO;AACP;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,cAAG;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,cAAG;AACtC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACkE;AACpB;AACe;AACjB;AACS;AACrD;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC;AAChC;AACP;AACA;AACA;AACA;AACA;AACA,2CAA2C,8BAAiB;AAC5D;AACA;AACA;AACA;AACA,qBAAqB,cAAG;AACxB,YAAY,8BAAiB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,8BAAiB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,eAAe;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,cAAc;AAC/C;AACA,6CAA6C,aAAa;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,YAAY;AACrD;AACA;AACA;AACO;AACP;AACA,gCAAgC,OAAO;AACvC;AACA;AACA;AACA;AACA;AACA,eAAe,+BAAM;AACrB;AACA;AACA;AACA;AACA,wDAAwD,UAAU;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrRA;AACA;AACA;AACA;AACA;AAC6D;AACuB;AACF;AACpB;AACJ;AACnD;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,8BAAiB;AACxD;AACA;AACA;AACA;AACA,mCAAmC,+BAAS;AAC5C,0BAA0B,iBAAiB;AAC3C,oBAAoB,sCAAgB;AACpC,wCAAwC,WAAW,GAAG,aAAa;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,+BAAS;AACxC,sBAAsB,iBAAiB;AACvC,gBAAgB,sCAAgB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sCAAc;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iFAAiF,aAAa;AAC9F;AACA;AACA;AACA,gFAAgF,aAAa,KAAK,aAAa;AAC/G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sCAAc;AAClC;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,gDAAgD;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gFAAgF,aAAa,KAAK,IAAI;AACtG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+FAA+F,iBAAiB,GAAG,UAAU;AAC7H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,iCAAS;AAC7B;AACA;AACA;AACA,yBAAyB,4CAAoB;AAC7C;AACA;AACA;AACA,oDAAoD,sCAAsC;AAC1F;AACA;AACA;AACA;AACA,qCAAqC,kCAAY;AACjD,2DAA2D,sCAAsC;AACjG,sEAAsE,aAAa;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,iCAAS;AAChC,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA,uBAAuB,sCAAc;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,kCAAY;AACjD;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,wBAAwB,sCAAc;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,gDAAgD;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6EAA6E,sCAAsC;AACnH;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE,yCAAyC,GAAG,UAAU,WAAW,QAAQ;AAC1I;AACA;AACA;AACA;AACA,gBAAgB,sCAAc;AAC9B,yBAAyB;AACzB;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6EAA6E,2BAA2B;AACxG;AACA;AACA;AACA;AACA,gFAAgF,2BAA2B,KAAK,aAAa;AAC7H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,kCAAY;AACrC,yCAAyC,aAAa;AACtD,yGAAyG,aAAa;AACtH;AACA;AACA;AACA;AACA,uDAAuD,eAAe,SAAS,2BAA2B;AAC1G;AACA;AACA;AACA;AACA;;AC5RA;AACA;AACA;AACA;AACA;AACgE;AACzD;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,6CAAmB;AAClC;AACA;AACA;;ACpBA;AACA;AACA;AACA;AACA;AAC2D;AACO;AACkC;AAC7B;AAC3B;AACK;AACgB;AAC1D;AACP;AACA;AACA;AACA;AACA;AACA,iCAAiC,+BAAS,gCAAgC,gCAAgB;AAC1F;AACA;AACA;AACA,+BAA+B,wCAAc;AAC7C;AACA;AACA;AACA,oBAAoB,mCAAW,eAAe,wCAAgB;AAC9D,2BAA2B,uCAAiB;AAC5C;AACA;AACA;AACA,6BAA6B,mCAAW,SAAS,wCAAgB;AACjE;AACA;AACA,mCAAmC,uCAAiB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,iCAAW;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,sCAAgB;AAClD,wBAAwB,wCAAgB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,QAAQ;AACpE;AACA;AACA,eAAe,+BAAM;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,iCAAW;AACvC;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,uCAAiB;AAC9C;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;;ACnIA;AACA;AACA;AACA;AACA;AAC8D;AAC9D;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,8BAAS,KAAK,+BAAM;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,oBAAoB;AAC5B;AACA;AACA;AACA,wBAAwB,+BAAM,WAAW,iCAAY;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,+BAAM;AACrB;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,+BAAM;AACrB;AACA;AACA;AACA;AACA;AACA,eAAe,+BAAM;AACrB;AACA;AACA;AACA;AACA;AACA,eAAe,+BAAM;AACrB;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClMA;AACA;AACA;AACA;AACA;AAC0E;AACb;AACV;AACW;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,yDAAyD,8BAAiB;AAC1E;AACA;AACA;AACA,gBAAgB,8CAA8C,eAAe,0BAA0B;AACvG,sFAAsF,eAAe;AACrG,+CAA+C,kBAAkB;AACjE;AACA,qEAAqE,0BAA0B;AAC/F;AACA,+CAA+C,kBAAkB,qCAAqC,gBAAgB,2FAA2F,iBAAiB;AAClO;AACA;AACA,2BAA2B,8CAA8C;AACzE;AACA,yEAAyE,gCAAc,gBAAgB,8BAAiB;AACxH;AACA;AACA;AACA,kBAAkB,iBAAiB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,8BAAiB;AACvE;AACA,4BAA4B,QAAQ;AACpC;AACA,2BAA2B,uCAAiB;AAC5C,kBAAkB,iBAAiB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtFA;AACA;AACA;AACA;AACA;AACmD;AACO;AAC1D;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,4BAA4B,QAAQ;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,+BAAM;AACzB;AACA;AACA,mBAAmB,+BAAM;AACzB;AACA;AACA;AACA,4BAA4B,+BAAM;AAClC;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,KAAK;AACL;AACA,eAAe,iCAAY;AAC3B,KAAK;AACL;AACA,eAAe,iCAAY;AAC3B;AACA;AACA;;ACrJA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,4BAA4B,4DAAY;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,6CAA6C;AAC7C;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,yDAAyD;AACzD;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,0CAA0C;AAC1C;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;;ACzLA;AACA;AACA;AACA;AACA;AACwD;AACJ;AACR;AACS;AAC9C;AACP;AACA;AACA;AACA;AACA;AACA,oCAAoC,cAAc;AAClD;AACA;AACA;AACA;AACA,6BAA6B,iCAAW;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA,wCAAwC,QAAQ;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,WAAW,CAAC,+BAAM;AACrC;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,+BAAM;AACxB;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,mBAAmB,WAAW;AAC9B;AACA;AACA;AACA;AACA;AACA,kEAAkE,aAAa;AAC/E;AACA;AACA;;AC/DA;AACA;AACA;AACA;AACA;AACiC;AAC4C;AACzB;AACa;AAC1D;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,iCAAW;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,0DAA0D;AACrF;AACA;AACA;AACA,iBAAiB,mCAAW;AAC5B;AACA;AACA;AACA,uCAAuC,iCAAW;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,UAAU,GAAG,WAAW;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,wCAAgB;AACjC;AACA;AACA;AACA;AACA,uCAAuC,iCAAW;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,UAAU,GAAG,WAAW;AACtD;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,iCAAS;AAC1B;AACA;AACA,mEAAmE,UAAU;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,UAAU;AAClD;AACA;AACA;AACA,wCAAwC,UAAU;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,4CAA4C,8CAAoB;AAChE;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,qBAAqB;AACzD;AACA;AACA;AACA;AACA,6BAA6B,iCAAS;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,iCAAS;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,iCAAS;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,iCAAS;AAC7B,gCAAgC,cAAc;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,cAAG;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA,+FAA+F,cAAG;AAClG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzQA;AACA;AACA;AACA;AACA;AACgD;AAChD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,KAAK,wDAAwD,gBAAgB;AAChI;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,MAAM,wDAAwD,gBAAgB;AAChI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,QAAQ;AAC5B,qBAAqB,QAAQ;AAC7B;AACA;AACA;AACA,gGAAgG,IAAI,kBAAkB,WAAW;AACjI;AACA;AACA,gGAAgG,IAAI;AACpG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7EA;AACA;AACA;AACA;AACA;AACgD;AACG;AACc;AACrB;AAC5C;AACA;AACA;AACO;AACP,aAAa;AACb;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gDAAgD;AACjD;AACA;AACA;AACO;AACP;AACA,2BAA2B,QAAQ;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,oCAAiB;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,oBAAoB;AACpC;AACA;AACA,6BAA6B,eAAe;AAC5C;AACA;AACA;AACA;AACA,+BAA+B,eAAe,IAAI,eAAe,KAAK,MAAM;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,+BAAM;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClKA;AACA;AACA;AACA;AACA;AAC6D;AACuB;AAClC;AACG;AAC+B;AAC1B;AACnD;AACP;AACA;AACA,CAAC;AACM;AACP;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,gBAAgB,8BAAiB;AAClF;AACA;AACA,cAAc,iBAAiB;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,oBAAoB;AACpC;AACA;AACA;AACA;AACA,cAAc,iBAAiB;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C;AAC3C,kCAAkC;AAClC;AACA;AACA;AACA;AACA,2CAA2C;AAC3C,kCAAkC;AAClC;AACA;AACA;AACA;AACA,wBAAwB,kCAAY;AACpC;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,cAAc;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,8BAAiB;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,8BAAiB;AACxF;AACA;AACA,kBAAkB,iBAAiB;AACnC;AACA;AACA;AACA,sEAAsE,8BAAiB;AACvF;AACA;AACA;AACA;AACA,8BAA8B,+BAAS;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,+BAAS;AACnC;AACA,sBAAsB,iBAAiB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sEAAsE,8BAAiB;AACvF;AACA;AACA,kBAAkB,iBAAiB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,kBAAkB,6CAAmB;AACrC;AACA;AACA,kBAAkB,4CAAkB;AACpC;AACA;AACA;AACA;AACA,qBAAqB,uBAAuB;AAC5C,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA,gDAAgD,gCAAgC;AAChF;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,mBAAmB,cAAc;AACjC;AACA,mBAAmB,cAAc;AACjC;AACA,mBAAmB,cAAc;AACjC;AACA,mBAAmB,cAAc;AACjC;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AAC/C;;AC/RA;AACA;AACA;AACA;AACA;AAC6D;AACK;AACe;AACvB;AACI;AACb;AAC1C;AACP;AACA;AACA;AACA;AACA;AACA,gCAAgC,iCAAW;AAC3C;AACA;AACA;AACA,4CAA4C,MAAM;AAClD;AACA;AACA,8EAA8E,uCAAiB;AAC/F;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,8BAA8B,uCAAiB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,qDAAqD,8BAAiB;AACtE;AACA;AACA,8BAA8B,+BAAS;AACvC,kBAAkB,iBAAiB;AACnC,YAAY,sCAAgB;AAC5B;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,mCAAW;AACvB;AACA;AACA,iBAAiB,wCAAgB;AACjC;AACA;AACA,0BAA0B,iCAAW;AACrC;AACA;AACA,wBAAwB,uCAAiB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,QAAQ;AAC/B,aAAa;AACb;AACA;AACA;AACA;AACA;;ACpFA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,qCAAqC;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;;;AC7CA;AACA;AACA;AACA;AACA;AAC4C;AACS;AACrD;AACA;AACA;AACO;AACP;AACA,0BAA0B,sBAAQ;AAClC,uDAAuD,cAAO;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,wBAAwB;AACpF,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,WAAW;AAC7B;AACA;AACA;AACA;AACA;AACA;;;;ACzFA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AACjC;;ACdA;AACA;AACA;AACA;AACA;AAC8E;AACjB;AACT;AACD;AACqD;AAC5D;AACK;AACF;AACxC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,QAAQ;AAC/C,0CAA0C,QAAQ;AAClD;AACA;AACA,4BAA4B,aAAa;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,gBAAgB,8BAAiB;AACxE;AACA;AACA,mCAAmC,aAAa;AAChD;AACA;AACA,gDAAgD,aAAa;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA,yBAAyB;AACzB;AACA,yCAAyC,aAAa;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,aAAa;AACzC;AACA;AACA;AACA,iDAAiD,8BAAiB;AAClE,4BAA4B,aAAa;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0EAA0E,kBAAkB;AAC5F,wCAAwC,aAAa,UAAU;AAC/D;AACA;AACA,+CAA+C,aAAa;AAC5D;AACA;AACA,+BAA+B,+BAAM;AACrC;AACA;AACA,mDAAmD,aAAa;AAChE;AACA;AACA;AACA,cAAc,iBAAiB;AAC/B;AACA;AACA;AACA;AACA,oBAAoB,aAAa;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,+BAAM;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,UAAU;AACzB;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,iBAAiB,aAAa;AAC9B;AACA;AACA,iBAAiB,aAAa;AAC9B;AACA;AACA,iBAAiB,aAAa;AAC9B;AACA;AACA,iBAAiB,aAAa;AAC9B;AACA;AACA;AACA;AACA,iBAAiB,aAAa;AAC9B;AACA;AACA,iBAAiB,aAAa;AAC9B;AACA;AACA;AACA,iBAAiB,aAAa;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,aAAa;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,oBAAoB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,aAAa;AACzD;AACA,4CAA4C,aAAa;AACzD;AACA,4CAA4C,aAAa;AACzD;AACA;AACA,SAAS;AACT;AACA;AACA,6CAA6C,aAAa;AAC1D;AACA;AACA,SAAS;AACT;AACA,6CAA6C,aAAa;AAC1D;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA,2CAA2C;AAC3C;AACA;AACA,SAAS;AACT,gDAAgD,aAAa;AAC7D;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE,0BAA0B;AAC1F;AACA;AACA,2BAA2B,oBAAoB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uFAAuF,oBAAoB;AAC3G;AACA;AACA,sCAAsC,qBAAqB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,iBAAiB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,UAAU;AACzB;AACA,SAAS;AACT;AACA;AACA;AACA,eAAe,UAAU;AACzB;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,8BAAiB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,0BAAa,CAAC,0BAAa,gDAAgD,eAAe;AAChI;AACA;AACA;AACA;AACA;AACA,kCAAkC,gCAAkB;AACpD;AACA;AACA;AACA;AACA;AACA,sCAAsC,0BAAa,CAAC,0BAAa,qCAAqC,gBAAgB,KAAK,aAAa,iBAAiB,cAAc,aAAa,QAAQ,mCAAmC,aAAa,oBAAoB;AAChQ;AACA;AACA;AACA,oBAAoB,QAAQ;AAC5B;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,uBAAuB,gCAAkB;AACzC,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,gCAAkB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,uBAAuB,gCAAkB;AACzC,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,iBAAiB;AACvC;AACA;AACA;AACA;AACA;AACA,qBAAqB,oBAAoB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,iBAAiB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6EAA6E,wBAAwB;AACrG,gGAAgG;AAChG;AACA;AACA,uDAAuD;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C;AAC9C;AACA,gDAAgD,+BAAM;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtfA;AACA;AACA;AACA;AACA;AACoD;AACD;AACU;AACjB;AACK;AAC1C;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,YAAY;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,iCAAW;AACxC;AACA;AACA;AACA,oBAAoB,QAAQ;AAC5B;AACA;AACA,aAAa;AACb,SAAS;AACT,eAAe,+BAAM;AACrB;AACA;AACA,2BAA2B,+BAAM;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,8BAAiB;AACjE;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,8BAAiB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChGA;AACA;AACA;AACA;AACA;AAC6D;AACW;AAClB;AACV;AACrC;AACP;AACA;AACA,0BAA0B,sBAAQ;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,8BAAiB;AACtE;AACA;AACA;AACA,cAAc,iBAAiB;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,+BAAM;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,cAAG;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,QAAQ;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACtIA;AACA;AACA;AACA;AACA;AACiF;AAC1E;AACP;AACA,eAAe,qCAAyB;AACxC;AACA;AACA,eAAe,qCAAyB;AACxC;AACA;AACO,mCAAmC;AACnC;AACP;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,mCAAmC,iBAAe;AAClD;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;ACtEA;AACA;AACA;AACA;AACA;AAC8D;AACU;AAC5B;AACrC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,aAAQ;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,mCAAc;AAC9C;AACA;AACA,4BAA4B,EAAE,KAAK,EAAE,GAAG,EAAE;AAC1C,0BAA0B,MAAM,EAAE,KAAK,EAAE,GAAG,EAAE,gBAAgB,MAAM;AACpE;AACA;AACA;AACA;AACA,oBAAoB,0BAA0B;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,aAAQ;AACzC;AACA;AACA;AACA,2BAA2B,UAAK;AAChC,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,aAAQ;AACtC,4BAA4B,aAAQ;AACpC;AACA;AACA;AACA,2BAA2B,UAAK;AAChC,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,aAAQ;AAC9B,oBAAoB,aAAQ;AAC5B;AACA;AACA;AACA,mBAAmB,UAAK;AACxB,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,UAAK,QAAQ,aAAQ,gDAAgD,aAAQ;AACxG,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,UAAK,QAAQ,aAAQ,yDAAyD,aAAQ;AAC7G,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,UAAK,QAAQ,aAAQ,yDAAyD,aAAQ;AACjH,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,2BAA2B,UAAK,QAAQ,aAAQ,yDAAyD,aAAQ;AACjH,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,UAAK,QAAQ,aAAQ,gDAAgD,aAAQ;AACpG,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,aAAQ;AAClC;AACA,wCAAwC,UAAK;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,UAAK;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,UAAK;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+FAA+F,UAAK;AACpG;AACA;AACA;AACA,2DAA2D,UAAK;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,YAAY,mBAAmB;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,qCAAY;AACjE;AACA,sCAAsC,QAAQ;AAC9C;AACA;AACA,qCAAqC,QAAQ;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,UAAU;AACjC;AACA;AACA,sBAAsB,MAAM,EAAE,QAAQ;AACtC;AACA;AACA,sBAAsB,KAAK,IAAI,QAAQ;AACvC;AACA;AACA;AACA,qBAAqB,EAAE,MAAM;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8EAA8E;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,OAAO,GAAG,UAAU,EAAE,OAAO;AACnD;AACA,sBAAsB,MAAM,IAAI,QAAQ;AACxC;AACA;AACA,sBAAsB,KAAK,IAAI,QAAQ;AACvC;AACA;AACA;AACA,qBAAqB,EAAE,MAAM;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,QAAQ;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,cAAG;AACX,mBAAmB,QAAQ,IAAI,QAAQ;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,yBAAyB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,yBAAyB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvfA;AACA;AACA;AACA;AACA;AACoD;AACH;AAC1C;AACP;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,OAAO;AAC9B,gCAAgC,UAAU;AAC1C;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,cAAc,KAAK,GAAG,UAAU,GAAG;AAC1F,uBAAuB,QAAQ,IAAI,eAAe;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,iCAAW;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjEA;AACA;AACA;AACA;AACA;AACwE;AAChB;AACjD;AACP;AACA;AACA;AACA;AACA,YAAY,oBAAoB;AAChC;AACA;AACA,eAAe,qCAAe;AAC9B;AACA;AACA;;AClBA;AACA;AACA;AACA;AACA;AACyE;AAC7B;AAC5C;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpJA;AACA;AACA;AACA;AACA;AACsF;AACe;AAC9F;AACP;AACA,uCAAuC,oCAAuB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,wBAAwB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,8BAAiB;AAChE,6BAA6B,sBAAQ;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,qCAAqC;AACpF;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,oBAAoB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1EA;AACA;AACA;AACA;AACA;AACuG;AACrC;AAC2C;AAC3D;AACF;AACE;AAC3C;AACP;AACA,uCAAuC,KAAK;AAC5C,kCAAkC,KAAK;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,0BAA0B;AACpF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,+BAAS;AACvC,oCAAoC;AACpC;AACA;AACA,kCAAkC,+BAAS;AAC3C,wCAAwC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,iCAAS;AACjC;AACA;AACA,6BAA6B,mCAAW;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,iCAAS;AAC9B;AACA;AACA,qBAAqB,mCAAW;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,qCAAa;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0CAAkB;AAC9B;AACA;AACA,iBAAiB,qCAAa;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,+BAAS;AACvC,oCAAoC;AACpC;AACA;AACA;AACA,kCAAkC,+BAAS;AAC3C;AACA;AACA,8BAA8B,eAAe;AAC7C;AACA;AACA;AACA,8BAA8B,oBAAoB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,iCAAS;AACjC;AACA;AACA,6BAA6B,mCAAW;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,iCAAS;AAC9B;AACA;AACA,qBAAqB,mCAAW;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0CAAkB;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,eAAe;AACxC;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,+BAAS;AACvC,gBAAgB,iCAAiB;AACjC;AACA;AACA;AACA;AACA;AACA;;AClRA;AACA;AACA;AACA;AACA;AACoE;AACW;AACN;AACT;AACI;AACb;AACa;AACL;AACa;AACN;AACE;AACT;AACe;AACL;AACgD;AACjD;AACI;AACH;AACyB;AAC/B;AACQ;AACQ;AACI;AACV;AACE;AACjB;AACO;AACV;AAC3D;AACA;AACA;AACA;AACO;AACP;AACA;AACA,+CAA+C,sBAAsB;AACrE,qDAAqD,0BAA0B;AAC/E,SAAS;AACT;AACA,2CAA2C,kBAAkB;AAC7D,yCAAyC,mBAAmB;AAC5D,yCAAyC,mBAAmB;AAC5D,4CAA4C,sBAAsB;AAClE,sCAAsC,4CAAqB;AAC3D,oCAAoC,wCAAmB;AACvD,qCAAqC,YAAY;AACjD,kDAAkD,iCAAiC;AACnF,iDAAiD,gCAAgC;AACjF,SAAS;AACT;AACA,sCAAsC,qBAAqB;AAC3D,0DAA0D,iCAAiC;AAC3F,4DAA4D,mCAAmC;AAC/F,SAAS;AACT;AACA,sCAAsC,aAAa;AACnD,oCAAoC,mBAAmB;AACvD,6CAA6C,oBAAoB;AACjE,gDAAgD,uBAAuB;AACvE,0CAA0C,iBAAiB;AAC3D,SAAS;AACT;AACA,wCAAwC,eAAe;AACvD,8CAA8C,qBAAqB;AACnE,SAAS;AACT;AACA,iDAAiD,wBAAwB;AACzE,kDAAkD,kBAAkB;AACpE,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,2CAA2C,sBAAsB;AACjE;AACA,gDAAgD,uBAAuB;AACvE,sDAAsD,6BAA6B;AACnF,+CAA+C,sBAAsB;AACrE,4CAA4C,mBAAmB;AAC/D,gDAAgD,uBAAuB;AACvE;AACA,qCAAqC,oBAAoB;AACzD,qDAAqD,4BAA4B;AACjF,SAAS;AACT;AACA;AACA;AACA;;;;;;;;;;;;ACjGA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C;AAC/C,CAAC,wBAAwB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,sHAAsH;AACtH;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACnKA;AACA;AACA;AACA;AACA;AACgD;AACzC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO,0CAA0C,4EAA6B;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA,8BAA8B;AAC9B;AACA,aAAa;AACb;AACA;AACA,8BAA8B;AAC9B;AACA,aAAa;AACb;AACA;AACA,8BAA8B;AAC9B;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA,8BAA8B;AAC9B;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA,8BAA8B;AAC9B;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA,8BAA8B;AAC9B;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACO;AACP;;;;;;;;;;;;;;;;;ACzqCA;AACA;AACA;AACA;AACA;AACmC;AAC6D;AACtC;AACsB;AACM;AAC1C;AACrC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,kEAAM,CAAC,uFAAoB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,iFAAc;AAC1C;AACA;AACA;AACA,sBAAsB,gFAAa;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,8EAAY,UAAU,uDAAK;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,uFAAoB;AACxC,6BAA6B,gFAAiB,cAAc,4EAAS;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,8EAAY;AACnC;AACA;AACA;AACA;AACA;AACA,mCAAmC,gFAAc;AACjD;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;;;;;;;;;;;;;ACjHA;AACA;AACA;AACA;AACA;AAC6E;AACM;AAC5E;AACP;AACA;AACA,YAAY,uFAAgB;AAC5B,sBAAsB,4FAAyB;AAC/C;AACA,YAAY,iFAAU;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,8EAAW;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,wBAAwB,sBAAsB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC;;;;;;;;;;;;;;;;;;;ACjGA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,sCAAsC,qBAAqB;AAC3D;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,wCAAwC;AAC5E;AACA;AACA;AACA,wCAAwC,iCAAiC,UAAU,yBAAyB;AAC5G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;AC5GA;AACA;AACA;AACA;AACA;AAC6E;AACP;AAC7B;AACzC;AACA;AACA;AACA;AACO,kDAAkD;AACzD;AACA;AACA;AACA;AACA,wBAAwB,oEAAS;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,qBAAqB,oEAAS;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,QAAQ,sEAAW;AACnB;AACA;AACA,aAAa,2EAAgB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,eAAe,2DAAU;AACzB;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,oBAAoB,oEAAS;AAC7B;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,oEAAS;AACrC,qCAAqC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,6DAAW;AAC1B,KAAK;AACL;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,eAAe,gEAAc;AAC7B;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,mBAAmB,gEAAc;AACjC;AACA,eAAe,gEAAc,gDAAgD,mBAAmB;AAChG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,gEAAO;AAClB;AACA;AACA;AACA;AACA;AACO;AACP,eAAe,2DAAU;AACzB;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,oBAAoB,sEAAW,WAAW,2EAAgB;AAC1D;AACA,6BAA6B,sBAAsB;AACnD;AACA;AACA;AACA;AACA;AACA,4BAA4B,sEAAW,aAAa,2EAAgB;AACpE,qCAAqC,sBAAsB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,6DAAW;AAC1B,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,YAAY;AAC/C;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACtRA;AACA;AACA;AACA;AACA;AACqF;AACxC;AACO;AACS;AAC7D;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,eAAe,gEAAc;AAC7B,YAAY,6EAAkB;AAC9B;AACA;AACA;AACA;AACA;AACA,KAAK,IAAI,mBAAmB;AAC5B;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,YAAY,qBAAqB;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0CAA0C;AACpC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,UAAU,GAAG;AACb;AACO,kCAAkC,EAAE;AAC3C;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,YAAY,wEAAa;AACzB;AACA;AACA;AACA,uCAAuC,QAAQ;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,WAAW,wEAAa;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,4CAA4C;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACjVA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,wBAAwB,SAAS,KAAK,sBAAsB,GAAG,2BAA2B;AAC1F;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACuD;AACF;AACE;AACgB;AAC5B;AACoB;AAC/D;AACA;AACA;AACA;AACO;AACP,mCAAmC,+EAAgB;AACnD;AACA;AACA;AACA;AACO;AACP,qCAAqC,iFAAkB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,iFAAkB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,0EAAiB;AACrB,YAAY,6EAAc,2BAA2B,qFAAsB;AAC3E;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,mCAAmC,wEAAY;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,2EAAkB,qBAAqB,+EAAgB;AACnF;AACA;AACA;AACA;AACA,QAAQ,6EAAkB;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,4EAAa;AACrB;AACA;AACA,yBAAyB,kEAAS;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,4EAAa;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,2BAA2B,2EAAkB,wBAAwB,+EAAgB;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,QAAQ,iFAAkB;AAC1B;AACA,YAAY,2EAAY;AACxB;AACA;AACA;AACA,iBAAiB,uFAAwB;AACzC;AACA;AACA;AACA;AACA,YAAY,6EAAiB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,2EAAkB,OAAO,+EAAgB;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,0EAAiB;AACxC,YAAY,+EAAgB;AAC5B;AACA;AACA;AACA,iBAAiB,6EAAc,UAAU,+EAAgB;AACzD;AACA;AACA,iBAAiB,+EAAgB;AACjC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,gCAAgC,QAAQ;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,0EAAiB;AACxC,YAAY,6EAAc;AAC1B;AACA;AACA;AACA;AACA,gBAAgB,+EAAgB;AAChC;AACA;AACA,gBAAgB,8EAAe;AAC/B;AACA;AACA;AACA,iBAAiB,+EAAgB;AACjC;AACA;AACA,iBAAiB,2EAAY;AAC7B;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,QAAQ,iFAAkB;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,QAAQ,uFAAwB;AAChC,eAAe,+EAAgB;AAC/B;AACA,aAAa,8EAAe,UAAU,yEAAU,UAAU,+EAAgB;AAC1E;AACA;AACA,aAAa,2EAAY;AACzB;AACA;AACA;AACA;AACA;AACA,aAAa,iFAAkB;AAC/B;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA,0CAA0C;AAC1C;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C;AAC1C;AACA;AACA;AACO;AACP,QAAQ,iFAAkB;AAC1B;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,yFAA0B;AAClC;AACA;AACA,aAAa,kFAAmB;AAChC;AACA;AACA,aAAa,mFAAoB;AACjC;AACA;AACA,aAAa,qFAAsB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,aAAa,iFAAkB;AAC/B;AACA;AACA,aAAa,+EAAgB;AAC7B;AACA;AACA,aAAa,+EAAgB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,aAAa,6EAAc;AAC3B;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,qDAAqD,eAAe,IAAI,wBAAwB;AAChG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,8BAA8B,SAAS,IAAI,uCAAuC;AAClF;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,iCAAiC,wCAAwC,GAAG,SAAS;AACrF;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,mCAAmC,2BAA2B,GAAG,4BAA4B;AAC7F;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,WAAW,wEAAY;AACvB;AACA;AACA;AACA;AACA,oBAAoB,YAAY,EAAE,MAAM;AACxC;AACA;AACA,kBAAkB,MAAM,EAAE,oBAAoB;AAC9C;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC7lBA;AACA;AACA;AACA;AACA;AAC4E;AACrE;AACP,yBAAyB,4EAAY;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,iFAAiB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,qBAAqB,OAAO;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACO;AACP;AACA;AACA;AACO;AACP,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD;AACxD,oEAAoE;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB,6BAA6B,UAAU;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACrSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,6EAA6E;AACpH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,cAAc;AAClC;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,sBAAsB;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,cAAc;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA,cAAc;AACd;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,wBAAwB;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,cAAc;AACtC;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA,cAAc;AACd;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,eAAe;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,uCAAuC,gCAAgC;AACvE;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,uCAAuC,+CAA+C;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACO,oCAAoC,8BAA8B;AACzE;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,UAAU;AACrD;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,uCAAuC,2BAA2B;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AAC/B;;;;;;;;;;;;AC7fA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;;;;;;;;;;;ACxCqC;;AAErC;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,UAAU;AACrB,WAAW,UAAU;AACrB,aAAa,GAAG;AAChB;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,qCAAqC,iEAAQ;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,iEAAe,YAAY,EAAC;;;;;;;;;;;;AC/B5B;AACA;AACA;AACA;AACA,WAAW,GAAG;AACd,WAAW,GAAG;AACd,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;;AAEA,iEAAe,MAAM,EAAC;;;;;;;;;;;;;;ACbgB;AACK;;AAE3C;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,aAAa,OAAO;AACpB;AACA;AACA;AACA,eAAe,oEAAW;;AAE1B,EAAE,iEAAQ;AACV;AACA,GAAG;AACH;AACA;;AAEA,iEAAe,OAAO,EAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrBqB;AACN;AACF;AACC;AACL;;AAEhC;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,cAAc;AACzB,WAAW,GAAG;AACd,WAAW,UAAU;AACrB,aAAa,QAAQ;AACrB;AACA;AACA,OAAO,2BAAQ;AACf;AACA;AACA,SAAS,4BAAQ;;AAEjB;AACA;AACA;AACA;;AAEA;AACA,cAAc,yBAAK;AACnB;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,mBAAmB,2BAAQ;AAC3B;AACA,aAAa,2BAAO,2BAA2B;AAC/C;AACA;AACA,IAAI,+BAAW;AACf;AACA;AACA;AACA;;AAEA,+CAAe,OAAO,EAAC;;;AClDa;AACA;AACE;;AAEtC;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,UAAU;AACrB,WAAW,UAAU;AACrB,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,gBAAgB,2BAAO;;AAEvB;AACA,MAAM,QAAO,SAAS,4BAAQ;AAC9B;AACA;AACA;AACA;;AAEA,kDAAe,UAAU,EAAC;;;;;;;;;;;;;AC7Bc;;AAExC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,GAAG;AACd,aAAa,GAAG;AAChB;AACA;AACA;AACA,oBAAoB,QAAQ,IAAI,QAAQ;AACxC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,kEAAS;AAClB;;AAEA,iEAAe,KAAK,EAAC;;;;;;;;;;;;;;;;ACnCiB;AACb;AACyB;AACjB;;AAEjC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,WAAW;AACtB,aAAa,QAAQ;AACrB;AACA;AACA;AACA,gBAAgB,QAAQ,IAAI,QAAQ,IAAI,QAAQ;AAChD,WAAW;AACX;AACA,eAAe,iEAAQ;AACvB;;AAEA;AACA;AACA;;AAEA,eAAe,uEAAc;AAC7B;AACA;;AAEA;AACA;AACA,gBAAgB,+DAAM;AACtB;AACA;;AAEA;AACA;AACA;;AAEA;AACA,WAAW,2DAAE;AACb;AACA;AACA;AACA;;AAEA;AACA,CAAC;;AAED,iEAAe,QAAQ,EAAC;;;;;;;;;;;;;;;;;;;;;;AC/DsB;AACH;AACd;;AAE7B;AACA;AACA;AACA;AACA,WAAW,UAAU;AACrB,aAAa,UAAU;AACvB;AACA;AACA;AACA;AACA,SAAS,8BAAW;AACpB,qBAAqB,gCAAY;AACjC,mBAAmB,uBAAI;AACvB,kCAAkC;AAClC;AACA;AACA;AACA;AACA;;AAEA,kDAAe,UAAU,EAAC;;;;;;;ACxBsB;AACF;AACP;;AAEvC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,WAAW,UAAU;AACrB,WAAW,QAAQ;AACnB,aAAa,QAAQ;AACrB;AACA;AACA;AACA,OAAO,oCAAoC;AAC3C,OAAO,oCAAoC;AAC3C,OAAO;AACP;AACA;AACA,oCAAoC,4BAA4B;AAChE;AACA;AACA;AACA,wBAAwB,iCAAiC;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,4BAAS;AAC/C;AACA;AACA;AACA,SAAS,iCAAa,QAAQ,gCAAY;AAC1C;;AAEA,0DAAe,SAAS,EAAC;;;ACtDiB;AACH;;AAEvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,WAAW,QAAQ;AACnB,aAAa,GAAG;AAChB;AACA;AACA;AACA,OAAO,8CAA8C;AACrD,OAAO,+CAA+C;AACtD,OAAO;AACP;AACA;AACA,+BAA+B,oBAAoB;AACnD;AACA;AACA;AACA,mBAAmB,0BAA0B;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,WAAU,CAAC,mBAAS;;AAE/B,qDAAe,IAAI,EAAC;;;;;;;;;;;;;;ACzCwB;AACjB;;AAE3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,oEAAW,CAAC,4DAAG;AACxB;;AAEA,iEAAe,OAAO,EAAC;;;;;;;;;;;;;AC5BqB;;AAE5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,oEAAW;AAC7B;;AAEA,iEAAe,OAAO,EAAC;;;;;;;;;;;;;;;;ACrBvB;AACA;;AAEA;AACA,IAAI,uBAAc;;AAElB;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,cAAc;AACzB,aAAa,SAAS;AACtB;AACA;AACA,2BAA2B,uBAAc;AACzC;;AAEA,+CAAe,OAAO,EAAC;;;;;AClBa;AACA;;AAEpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,cAAc;AACzB,aAAa,SAAS;AACtB;AACA;AACA,kBAAkB,OAAO;AACzB,0BAA0B,gBAAgB,QAAQ,GAAG;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,2BAAO,eAAe,QAAO;AACxD;;AAEA,oDAAe,GAAG,EAAC;;;;;;;;;;;;;;;AClCuB;AACP;AACU;;AAE7C;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,GAAG;AACd,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,gEAAO,WAAW,qEAAY,WAAW,mEAAU;AACzD;;AAEA,iEAAe,QAAQ,EAAC;;;;;;;;;;;;AC7BxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,aAAa,GAAG;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,iEAAe,IAAI,EAAC;;;;;;;;;;;;;;;;ACnBkB;AACQ;AACV;AACD;;AAEnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,UAAU;AACrB,aAAa,OAAO;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,gBAAgB;AAC3B;AACA;AACA;AACA,OAAO,kBAAkB;AACzB,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,gEAAO,eAAe,6DAAQ,GAAG,4DAAO;AACrD,0BAA0B,qEAAY;AACtC;;AAEA,iEAAe,GAAG,EAAC;;;;;;;;;;;;;;;ACpD2B;AACZ;AACG;;AAErC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,OAAO;AAClB,aAAa,GAAG;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,qEAAY,QAAQ,6DAAQ,EAAE,2DAAM;AAC1C;AACA;;AAEA,iEAAe,GAAG,EAAC;;;;;;;;;;;;;;;;AC5BnB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,aAAa,QAAQ;AACrB;AACA;AACA;;AAEA;AACA;AACA;;AAEA,uDAAe,eAAe,EAAC;;;AClBqB;;AAEpD;AACA;;AAEA;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,aAAa,QAAQ;AACrB;AACA;AACA;AACA,sBAAsB,gBAAe;AACrC;AACA;;AAEA,gDAAe,QAAQ,EAAC;;;;;;;AClBc;AACD;AACA;;AAErC;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,GAAG;AACd,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,2BAAQ;AACd;AACA;AACA,MAAM,2BAAQ;AACd;AACA,YAAY,2BAAQ;AACpB;AACA;AACA;AACA;AACA,UAAU,SAAQ;AAClB;AACA;AACA;AACA;AACA;;AAEA,yDAAe,QAAQ,EAAC;;;AC/Da;;AAErC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,GAAG;AACd,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,kBAAQ;AAClB;AACA;AACA;AACA;AACA;AACA;;AAEA,yDAAe,QAAQ,EAAC;;;;;;;;;;;;;ACzCa;;AAErC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,GAAG;AACd,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,iEAAQ;AACvB;;AAEA;AACA;;AAEA,iEAAe,SAAS,EAAC;;;;;;;;ACnCzB;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA,MAAM;AACN;AACA;AACA,EAAE;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;;;;AAIA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,wBAAwB,sBAAsB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,sCAAsC;;AAEtC;AACA;AACA;;AAEA,4BAA4B;AAC5B;AACA;AACA;AACA,6BAA6B;;;;;;;;;ACvL7B;AACA;AACA;AACA;AACa;;AAEb,2CAA8C;;;;;;;;ACNjC;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,oCAAoC;AACnD;AACA;AACA,CAAC;AACD;AACA;AACA,CAAC;AACD;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,gCAAgC;AAChC,kBAAkB,mBAAO,CAAC,KAAwB;AAClD,aAAa,mBAAO,CAAC,KAAwB;AAC7C,aAAa,mBAAO,CAAC,KAAe;AACpC;AACA;AACA;AACA,gCAAgC;;;;;;;;;AC3BnB;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,oCAAoC;AACnD;AACA;AACA,CAAC;AACD;AACA;AACA,CAAC;AACD;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,qBAAqB,GAAG,gCAAgC;AACxD,aAAa,mBAAO,CAAC,KAAgB;AACrC,aAAa,mBAAO,CAAC,KAA6B;AAClD,aAAa,mBAAO,CAAC,IAAY;AACjC,aAAa,mBAAO,CAAC,KAAY;AACjC,mBAAmB,mBAAO,CAAC,KAAc;AACzC,4DAA2D,EAAE,qCAAqC,iDAAiD,EAAC;AACpJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oBAAoB,qBAAqB,qBAAqB;;;;;;;;;AC5ElD;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,gCAAgC;AAChC,yBAAyB,mBAAO,CAAC,KAAgB;AACjD;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA,gCAAgC;;;;;;;;;ACdnB;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,gCAAgC,GAAG,iCAAiC,GAAG,2BAA2B,GAAG,4BAA4B,GAAG,wBAAwB,GAAG,wBAAwB;AACvL,yBAAyB,mBAAO,CAAC,KAAgB;AACjD;AACA;AACA;AACA;AACA;AACA,CAAC,uBAAuB,wBAAwB,wBAAwB;AACxE;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA,gCAAgC;;;;;;;;;AC3CnB;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,yCAAyC,GAAG,yCAAyC,GAAG,mCAAmC;AAC3H,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,kCAAkC,mCAAmC,mCAAmC;AACzG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC,yCAAyC,yCAAyC;AAC3H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC,yCAAyC,yCAAyC;;;;;;;;;ACzC9G;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,gCAAgC,GAAG,4BAA4B;AAC/D,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA,yBAAyB,2BAA2B;AACpD,wBAAwB,2CAA2C;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,2BAA2B,4BAA4B,4BAA4B;AACpF;AACA;AACA,yBAAyB,+BAA+B;AACxD,wBAAwB,2CAA2C;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,+BAA+B,gCAAgC,gCAAgC;;;;;;;;;AC/BnF;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,4BAA4B;AAC5B,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,2BAA2B,4BAA4B,4BAA4B;;;;;;;;;ACvBvE;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,0BAA0B;AAC1B,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA;AACA;AACA,0DAA0D;AAC1D,4BAA4B,mBAAmB,qBAAqB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,yBAAyB,0BAA0B,0BAA0B;;;;;;;;;ACrBjE;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,gCAAgC,GAAG,kCAAkC,GAAG,iCAAiC,GAAG,oCAAoC,GAAG,wCAAwC;AAC3L,yBAAyB,mBAAO,CAAC,KAAgB;AACjD,WAAW,mBAAO,CAAC,KAAY;AAC/B,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,uCAAuC,wCAAwC,wCAAwC;AACxH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,mCAAmC,oCAAoC,oCAAoC;AAC5G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC,iCAAiC,iCAAiC;AACnG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,iCAAiC,kCAAkC,kCAAkC;AACtG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,+BAA+B,gCAAgC,gCAAgC;;;;;;;;;ACzEnF;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,8BAA8B,GAAG,kCAAkC,GAAG,kCAAkC,GAAG,8BAA8B,GAAG,kCAAkC,GAAG,8BAA8B,GAAG,gCAAgC;AAClP,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,+BAA+B,gCAAgC,gCAAgC;AAChG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,6BAA6B,8BAA8B,8BAA8B;AAC1F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,iCAAiC,kCAAkC,kCAAkC;AACtG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,6BAA6B,8BAA8B,8BAA8B;AAC1F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,iCAAiC,kCAAkC,kCAAkC;AACtG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,iCAAiC,kCAAkC,kCAAkC;AACtG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,6BAA6B,8BAA8B,8BAA8B;;;;;;;;;ACpG7E;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,kCAAkC,GAAG,2BAA2B;AAChE,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA,yBAAyB,yBAAyB;AAClD,wBAAwB,wBAAwB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0BAA0B,2BAA2B,2BAA2B;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,iCAAiC,kCAAkC,kCAAkC;;;;;;;;;AC7BzF;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,6BAA6B;AAC7B,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA;AACA;AACA,0DAA0D;AAC1D,4BAA4B,kBAAkB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B,6BAA6B,6BAA6B;;;;;;;;;ACpB1E;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,+BAA+B,GAAG,+BAA+B,GAAG,wBAAwB;AAC5F,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA,SAAS,uBAAuB;AAChC,IAAI,6BAA6B;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,uBAAuB,wBAAwB,wBAAwB;AACxE;AACA;AACA,uCAAuC,gBAAgB;AACvD,YAAY,iBAAiB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B,+BAA+B,+BAA+B;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B,+BAA+B,+BAA+B;;;;;;;;;AC1ChF;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,+BAA+B;AAC/B,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA,SAAS,6BAA6B;AACtC,IAAI,2CAA2C;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B,+BAA+B,+BAA+B;;;;;;;;;ACrBhF;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,iCAAiC,GAAG,0BAA0B;AAC9D,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA,SAAS,wBAAwB;AACjC,IAAI,iCAAiC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,yBAAyB,0BAA0B,0BAA0B;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC,iCAAiC,iCAAiC;;;;;;;;;AC7BtF;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,8BAA8B,GAAG,gCAAgC,GAAG,yBAAyB,GAAG,6BAA6B,GAAG,gCAAgC,GAAG,yBAAyB,GAAG,yBAAyB,GAAG,4BAA4B,GAAG,gCAAgC,GAAG,oBAAoB,GAAG,gCAAgC,GAAG,yBAAyB,GAAG,6BAA6B,GAAG,sCAAsC,GAAG,iBAAiB,GAAG,uBAAuB,GAAG,sBAAsB,GAAG,yCAAyC,GAAG,4CAA4C,GAAG,wCAAwC,GAAG,8BAA8B,GAAG,uCAAuC,GAAG,wCAAwC,GAAG,yCAAyC,GAAG,sCAAsC,GAAG,uCAAuC,GAAG,4BAA4B,GAAG,kCAAkC,GAAG,8BAA8B,GAAG,0BAA0B,GAAG,+BAA+B,GAAG,mBAAmB,GAAG,0CAA0C,GAAG,wBAAwB,GAAG,uBAAuB,GAAG,+BAA+B,GAAG,4BAA4B,GAAG,yBAAyB,GAAG,+BAA+B,GAAG,uCAAuC,GAAG,iCAAiC,GAAG,4BAA4B,GAAG,2BAA2B,GAAG,6BAA6B,GAAG,6BAA6B,GAAG,2BAA2B,GAAG,wBAAwB,GAAG,sCAAsC,GAAG,8BAA8B,GAAG,0BAA0B;AACjoD,sBAAsB,GAAG,mBAAmB,GAAG,uBAAuB,GAAG,8BAA8B,GAAG,kCAAkC,GAAG,8BAA8B,GAAG,kCAAkC,GAAG,8BAA8B,GAAG,kCAAkC,GAAG,gCAAgC,GAAG,iCAAiC,GAAG,2BAA2B,GAAG,sCAAsC,GAAG,oCAAoC,GAAG,kCAAkC,GAAG,kCAAkC,GAAG,6BAA6B,GAAG,mBAAmB,GAAG,mCAAmC,GAAG,yCAAyC,GAAG,yCAAyC,GAAG,0CAA0C,GAAG,qCAAqC,GAAG,wBAAwB,GAAG,6BAA6B,GAAG,0BAA0B,GAAG,kCAAkC,GAAG,2BAA2B,GAAG,gCAAgC,GAAG,4BAA4B,GAAG,4BAA4B,GAAG,6CAA6C,GAAG,+BAA+B,GAAG,6BAA6B,GAAG,6BAA6B,GAAG,iCAAiC,GAAG,6BAA6B,GAAG,4BAA4B,GAAG,qBAAqB,GAAG,qCAAqC,GAAG,uCAAuC,GAAG,uCAAuC,GAAG,sCAAsC,GAAG,iCAAiC,GAAG,kCAAkC,GAAG,2BAA2B,GAAG,8BAA8B,GAAG,8BAA8B,GAAG,uBAAuB,GAAG,qCAAqC;AACzrD,+BAA+B,GAAG,4CAA4C,GAAG,2CAA2C,GAAG,6CAA6C,GAAG,+BAA+B,GAAG,2CAA2C,GAAG,4CAA4C,GAAG,wBAAwB,GAAG,oBAAoB,GAAG,wBAAwB,GAAG,wBAAwB,GAAG,gCAAgC,GAAG,kCAAkC,GAAG,iCAAiC,GAAG,oCAAoC,GAAG,wCAAwC,GAAG,+BAA+B,GAAG,+BAA+B,GAAG,wBAAwB,GAAG,iCAAiC,GAAG,0BAA0B,GAAG,sCAAsC,GAAG,oCAAoC,GAAG,mCAAmC;AACv2B,mBAAmB,mBAAO,CAAC,IAAY;AACvC,sCAAsC,mBAAO,CAAC,KAA6B;AAC3E,WAAW,mBAAO,CAAC,KAAY;AAC/B,kCAAkC,mBAAO,CAAC,KAA2B;AACrE,yDAAwD,EAAE,qCAAqC,2DAA2D,EAAC;AAC3J,kCAAkC,mBAAO,CAAC,KAA2B;AACrE,yDAAwD,EAAE,qCAAqC,2DAA2D,EAAC;AAC3J,mCAAmC,mBAAO,CAAC,KAA4B;AACvE,2DAA0D,EAAE,qCAAqC,8DAA8D,EAAC;AAChK,yEAAwE,EAAE,qCAAqC,4EAA4E,EAAC;AAC5L,iCAAiC,mBAAO,CAAC,KAA0B;AACnE,wDAAuD,EAAE,qCAAqC,yDAAyD,EAAC;AACxJ,iCAAiC,mBAAO,CAAC,KAA0B;AACnE,wDAAuD,EAAE,qCAAqC,yDAAyD,EAAC;AACxJ,4DAA2D,EAAE,qCAAqC,6DAA6D,EAAC;AAChK,gCAAgC,mBAAO,CAAC,KAAyB;AACjE,uDAAsD,EAAE,qCAAqC,uDAAuD,EAAC;AACrJ,8DAA6D,EAAE,qCAAqC,8DAA8D,EAAC;AACnK,+BAA+B,mBAAO,CAAC,KAAwB;AAC/D,sDAAqD,EAAE,qCAAqC,qDAAqD,EAAC;AAClJ,kCAAkC,mBAAO,CAAC,IAA2B;AACrE,yDAAwD,EAAE,qCAAqC,2DAA2D,EAAC;AAC3J,4BAA4B,mBAAO,CAAC,KAAqB;AACzD,oDAAmD,EAAE,qCAAqC,gDAAgD,EAAC;AAC3I,iEAAgE,EAAE,qCAAqC,6DAA6D,EAAC;AACrK,sEAAqE,EAAE,qCAAqC,kEAAkE,EAAC;AAC/K,iCAAiC,mBAAO,CAAC,IAA0B;AACnE,qEAAoE,EAAE,qCAAqC,sEAAsE,EAAC;AAClL,qEAAoE,EAAE,qCAAqC,sEAAsE,EAAC;AAClL,+DAA8D,EAAE,qCAAqC,gEAAgE,EAAC;AACtK,kCAAkC,mBAAO,CAAC,KAA2B;AACrE,+CAA8C,EAAE,qCAAqC,iDAAiD,EAAC;AACvI,yDAAwD,EAAE,qCAAqC,2DAA2D,EAAC;AAC3J,8DAA6D,EAAE,qCAAqC,gEAAgE,EAAC;AACrK,8DAA6D,EAAE,qCAAqC,gEAAgE,EAAC;AACrK,gEAA+D,EAAE,qCAAqC,kEAAkE,EAAC;AACzK,kEAAiE,EAAE,qCAAqC,oEAAoE,EAAC;AAC7K,gCAAgC,mBAAO,CAAC,KAAyB;AACjE,uDAAsD,EAAE,qCAAqC,uDAAuD,EAAC;AACrJ,sCAAsC,mBAAO,CAAC,KAA+B;AAC7E,6DAA4D,EAAE,qCAAqC,mEAAmE,EAAC;AACvK,kCAAkC,mBAAO,CAAC,KAA2B;AACrE,4DAA2D,EAAE,qCAAqC,8DAA8D,EAAC;AACjK,8DAA6D,EAAE,qCAAqC,gEAAgE,EAAC;AACrK,0DAAyD,EAAE,qCAAqC,4DAA4D,EAAC;AAC7J,8DAA6D,EAAE,qCAAqC,gEAAgE,EAAC;AACrK,0DAAyD,EAAE,qCAAqC,4DAA4D,EAAC;AAC7J,8DAA6D,EAAE,qCAAqC,gEAAgE,EAAC;AACrK,0DAAyD,EAAE,qCAAqC,4DAA4D,EAAC;AAC7J,2BAA2B,mBAAO,CAAC,KAAoB;AACvD,mDAAkD,EAAE,qCAAqC,8CAA8C,EAAC;AACxI,+CAA8C,EAAE,qCAAqC,0CAA0C,EAAC;AAChI,kDAAiD,EAAE,qCAAqC,6CAA6C,EAAC;AACtI,iCAAiC,mBAAO,CAAC,IAA0B;AACnE,+DAA8D,EAAE,qCAAqC,gEAAgE,EAAC;AACtK,gEAA+D,EAAE,qCAAqC,iEAAiE,EAAC;AACxK,kEAAiE,EAAE,qCAAqC,mEAAmE,EAAC;AAC5K,+BAA+B,mBAAO,CAAC,KAAwB;AAC/D,sDAAqD,EAAE,qCAAqC,qDAAqD,EAAC;AAClJ,6DAA4D,EAAE,qCAAqC,4DAA4D,EAAC;AAChK,6BAA6B,mBAAO,CAAC,KAAsB;AAC3D,oDAAmD,EAAE,qCAAqC,iDAAiD,EAAC;AAC5I,2DAA0D,EAAE,qCAAqC,wDAAwD,EAAC;AAC1J,2DAA0D,EAAE,qCAAqC,wDAAwD,EAAC;AAC1J,8BAA8B,mBAAO,CAAC,KAAuB;AAC7D,oEAAmE,EAAE,qCAAqC,kEAAkE,EAAC;AAC7K,gEAA+D,EAAE,qCAAqC,8DAA8D,EAAC;AACrK,6DAA4D,EAAE,qCAAqC,2DAA2D,EAAC;AAC/J,8DAA6D,EAAE,qCAAqC,4DAA4D,EAAC;AACjK,4DAA2D,EAAE,qCAAqC,0DAA0D,EAAC;AAC7J,4BAA4B,mBAAO,CAAC,KAAqB;AACzD,oDAAmD,EAAE,qCAAqC,gDAAgD,EAAC;AAC3I,oDAAmD,EAAE,qCAAqC,gDAAgD,EAAC;AAC3I,gDAA+C,EAAE,qCAAqC,4CAA4C,EAAC;AACnI,oDAAmD,EAAE,qCAAqC,gDAAgD,EAAC;AAC3I,wEAAuE,EAAE,qCAAqC,oEAAoE,EAAC;AACnL,uEAAsE,EAAE,qCAAqC,mEAAmE,EAAC;AACjL,2DAA0D,EAAE,qCAAqC,uDAAuD,EAAC;AACzJ,yEAAwE,EAAE,qCAAqC,qEAAqE,EAAC;AACrL,uEAAsE,EAAE,qCAAqC,mEAAmE,EAAC;AACjL,wEAAuE,EAAE,qCAAqC,oEAAoE,EAAC;AACnL,oCAAoC,mBAAO,CAAC,KAA6B;AACzE,2DAA0D,EAAE,qCAAqC,+DAA+D,EAAC;AACjK;AACA;AACA;AACA;AACA,IAAI,0BAA0B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,yBAAyB,0BAA0B,0BAA0B;AAC9E;AACA;AACA,IAAI,8BAA8B;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,6BAA6B,8BAA8B,8BAA8B;AAC1F;AACA;AACA,IAAI,sCAAsC;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,qCAAqC,sCAAsC,sCAAsC;AAClH;AACA;AACA,IAAI,uBAAuB;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,uBAAuB,wBAAwB,wBAAwB;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0BAA0B,2BAA2B,2BAA2B;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B,6BAA6B,6BAA6B;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B,6BAA6B,6BAA6B;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0BAA0B,2BAA2B,2BAA2B;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,2BAA2B,4BAA4B,4BAA4B;AACpF;AACA;AACA,IAAI,iCAAiC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC,iCAAiC,iCAAiC;AACnG;AACA;AACA,IAAI,uCAAuC;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC,uCAAuC,uCAAuC;AACrH;AACA;AACA,IAAI,+BAA+B;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B,+BAA+B,+BAA+B;AAC7F;AACA;AACA;AACA,sCAAsC;AACtC,4BAA4B,wBAAwB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wBAAwB,yBAAyB,yBAAyB;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,2BAA2B,4BAA4B,4BAA4B;AACpF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B,+BAA+B,+BAA+B;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sBAAsB,uBAAuB,uBAAuB;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,uBAAuB,wBAAwB,wBAAwB;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,yCAAyC,0CAA0C,0CAA0C;AAC9H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,kBAAkB,mBAAmB,mBAAmB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B,+BAA+B,+BAA+B;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,yBAAyB,0BAA0B,0BAA0B;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,6BAA6B,8BAA8B,8BAA8B;AAC1F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,iCAAiC,kCAAkC,kCAAkC;AACtG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,2BAA2B,4BAA4B,4BAA4B;AACpF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC,uCAAuC,uCAAuC;AACrH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,qCAAqC,sCAAsC,sCAAsC;AAClH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC,yCAAyC,yCAAyC;AAC3H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,uCAAuC,wCAAwC,wCAAwC;AACxH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC,uCAAuC,uCAAuC;AACrH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,6BAA6B,8BAA8B,8BAA8B;AAC1F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,uCAAuC,wCAAwC,wCAAwC;AACxH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,2CAA2C,4CAA4C,4CAA4C;AACpI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC,yCAAyC,yCAAyC;AAC3H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,qBAAqB,sBAAsB,sBAAsB;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sBAAsB,uBAAuB,uBAAuB;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gBAAgB,iBAAiB,iBAAiB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,qCAAqC,sCAAsC,sCAAsC;AAClH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B,6BAA6B,6BAA6B;AACvF;AACA;AACA,yBAAyB,4BAA4B;AACrD,eAAe,uCAAuC,IAAI;AAC1D;AACA;AACA,iDAAiD;AACjD,QAAQ,oDAAoD;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wBAAwB,yBAAyB,yBAAyB;AAC3E;AACA;AACA,yBAAyB,sBAAsB;AAC/C,eAAe,sBAAsB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,+BAA+B,gCAAgC,gCAAgC;AAChG;AACA;AACA,yBAAyB,4BAA4B;AACrD,SAAS,aAAa;AACtB;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,mBAAmB,oBAAoB,oBAAoB;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,+BAA+B,gCAAgC,gCAAgC;AAChG;AACA;AACA;AACA;AACA;AACA,CAAC,2BAA2B,4BAA4B,4BAA4B;AACpF;AACA;AACA,0DAA0D;AAC1D,mCAAmC,kBAAkB;AACrD,IAAI,sBAAsB;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wBAAwB,yBAAyB,yBAAyB;AAC3E;AACA;AACA;AACA,SAAS,uBAAuB;AAChC,IAAI,2BAA2B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wBAAwB,yBAAyB,yBAAyB;AAC3E;AACA,yBAAyB,yBAAyB;AAClD,+DAA+D;AAC/D,6CAA6C;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,+BAA+B,gCAAgC,gCAAgC;AAChG;AACA;AACA,yBAAyB,8BAA8B;AACvD,wBAAwB,6CAA6C;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B,6BAA6B,6BAA6B;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wBAAwB,yBAAyB,yBAAyB;AAC3E;AACA;AACA,yBAAyB,kBAAkB;AAC3C,eAAe,kBAAkB;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,+BAA+B,gCAAgC,gCAAgC;AAChG;AACA;AACA,WAAW,4BAA4B;AACvC,YAAY,6CAA6C;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,6BAA6B,8BAA8B,8BAA8B;AAC1F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oCAAoC,qCAAqC,qCAAqC;AAC/G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sBAAsB,uBAAuB,uBAAuB;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,6BAA6B,8BAA8B,8BAA8B;AAC1F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,6BAA6B,8BAA8B,8BAA8B;AAC1F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0BAA0B,2BAA2B,2BAA2B;AACjF;AACA;AACA,yBAAyB,oBAAoB;AAC7C,eAAe,oBAAoB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,iCAAiC,kCAAkC,kCAAkC;AACtG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC,iCAAiC,iCAAiC;AACnG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,qCAAqC,sCAAsC,sCAAsC;AAClH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC,uCAAuC,uCAAuC;AACrH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC,uCAAuC,uCAAuC;AACrH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oCAAoC,qCAAqC,qCAAqC;AAC/G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oBAAoB,qBAAqB,qBAAqB;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,2BAA2B,4BAA4B,4BAA4B;AACpF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B,6BAA6B,6BAA6B;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC,iCAAiC,iCAAiC;;;;;;;;;AC96BtF;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,iCAAiC;AACjC,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC,iCAAiC,iCAAiC;;;;;;;;;AClBtF;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,sBAAsB,GAAG,mBAAmB,GAAG,uBAAuB;AACtE,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sBAAsB,uBAAuB,uBAAuB;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,kBAAkB,mBAAmB,mBAAmB;AACzD;AACA;AACA,qCAAqC,iCAAiC;AACtE,4BAA4B,yBAAyB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,qBAAqB,sBAAsB,sBAAsB;;;;;;;;;ACnErD;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,4CAA4C,GAAG,2CAA2C,GAAG,6CAA6C,GAAG,+BAA+B,GAAG,2CAA2C,GAAG,4CAA4C,GAAG,wBAAwB,GAAG,oBAAoB,GAAG,wBAAwB,GAAG,wBAAwB;AACjX,sCAAsC,mBAAO,CAAC,KAA6B;AAC3E,WAAW,mBAAO,CAAC,KAAY;AAC/B,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,uBAAuB,wBAAwB,wBAAwB;AACxE;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,uBAAuB,wBAAwB,wBAAwB;AACxE;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,gBAAgB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,oBAAoB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,mBAAmB,oBAAoB,oBAAoB;AAC5D;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,uBAAuB,wBAAwB,wBAAwB;AACxE;AACA;AACA;AACA;AACA;AACA,CAAC,2CAA2C,4CAA4C,4CAA4C;AACpI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0CAA0C,2CAA2C,2CAA2C;AACjI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B,+BAA+B,+BAA+B;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4CAA4C,6CAA6C,6CAA6C;AACvI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0CAA0C,2CAA2C,2CAA2C;AACjI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,2CAA2C,4CAA4C,4CAA4C;;;;;;;;;ACrNvH;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,0CAA0C,GAAG,qCAAqC,GAAG,wBAAwB;AAC7G,yBAAyB,mBAAO,CAAC,KAAgB;AACjD,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,uBAAuB,wBAAwB,wBAAwB;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oCAAoC,qCAAqC,qCAAqC;AAC/G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,yCAAyC,0CAA0C,0CAA0C;;;;;;;;;ACpCjH;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,6BAA6B;AAC7B,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA,yBAAyB,2BAA2B;AACpD,wBAAwB,uCAAuC;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B,6BAA6B,6BAA6B;;;;;;;;;ACnB1E;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,oCAAoC,GAAG,kCAAkC,GAAG,kCAAkC,GAAG,6BAA6B,GAAG,sCAAsC,GAAG,mBAAmB;AAC7M,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA;AACA;AACA,CAAC,kBAAkB,mBAAmB,mBAAmB;AACzD;AACA;AACA;AACA;AACA,CAAC,qCAAqC,sCAAsC,sCAAsC;AAClH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B,6BAA6B,6BAA6B;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,iCAAiC,kCAAkC,kCAAkC;AACtG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,iCAAiC,kCAAkC,kCAAkC;AACtG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,mCAAmC,oCAAoC,oCAAoC;;;;;;;;;ACxD/F;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,2BAA2B;AAC3B,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0BAA0B,2BAA2B,2BAA2B;;;;;;;;;ACrBpE;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,6BAA6B;AAC7B,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA;AACA;AACA,0DAA0D;AAC1D,4BAA4B,kBAAkB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B,6BAA6B,6BAA6B;;;;;;;;;ACpB1E;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,oCAAoC,GAAG,sCAAsC,GAAG,mCAAmC;AACnH,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,kCAAkC,mCAAmC,mCAAmC;AACzG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,qCAAqC,sCAAsC,sCAAsC;AAClH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,mCAAmC,oCAAoC,oCAAoC;;;;;;;;;ACzC/F;AACb;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,6CAA6C,GAAG,+BAA+B;AAC/E,mBAAmB,mBAAO,CAAC,IAAY;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B,+BAA+B,+BAA+B;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4CAA4C,6CAA6C,6CAA6C;;;;;;;;;AC1BvI;AACA;AACA;AACA;AACa;AACb,8CAA6C,EAAE,aAAa,EAAC;AAC7D,qBAAqB,GAAG,kBAAkB,GAAG,mBAAmB,GAAG,aAAa,GAAG,YAAY,GAAG,aAAa,GAAG,cAAc,GAAG,cAAc,GAAG,eAAe;AACnK;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7CrB;AACA;AACA;AACA;AACa;AACN;AACP;AACA;AACA;AACA;AACA;AACA,CAAC,kCAAkC;AAC5B;AACP;AACA;AACA;AACA;AACA;AACA,CAAC,kBAAkB;AACZ;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0BAA0B;AACpB;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B;AAC7B;AACA;AACA,IAAI,gBAAgB;AACpB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,gBAAgB;AACzE;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B;AAC7B;AACA;AACA,IAAI,aAAa;AACjB;AACO;AACP;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA,0EAA0E,IAAI,IAAI,IAAI,IAAI,MAAM,IAAI,KAAK;AACzG;AACA;AACA;AACA;AACA,yDAAyD,aAAa;AACtE;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sBAAsB;AACvB;AACA;AACA,IAAI,gBAAgB;AACpB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,gBAAgB;AACzE;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B;AAC7B;AACA;AACA,IAAI,oBAAoB;AACxB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,oBAAoB;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oCAAoC;AACrC;AACA;AACA,IAAI,aAAa;AACjB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,aAAa;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sBAAsB;AACvB;AACA;AACA,IAAI,wBAAwB;AAC5B;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,wBAAwB;AACjF;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4CAA4C;AAC7C;AACA;AACA,IAAI,yBAAyB;AAC7B;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,wBAAwB;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AAC/C;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4CAA4C;AAC7C;AACA;AACA,IAAI,oBAAoB;AACxB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,oBAAoB;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oCAAoC;AACrC;AACA;AACA,IAAI,oCAAoC;AACxC;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,oCAAoC;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oEAAoE;AACrE;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gDAAgD;AACjD;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC;AACvC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0CAA0C;AAC3C;AACA;AACA,IAAI,kBAAkB;AACtB;AACO;AACP;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,kBAAkB;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AACjC;AACA;AACA,IAAI,eAAe;AACnB;AACO;AACP;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,eAAe;AACxE;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0BAA0B;AAC3B;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,SAAS,gCAAgC;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B;AACtB;AACP;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4CAA4C;AACtC;AACP;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gEAAgE;AAC1D;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,SAAS,gCAAgC;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AAC/C;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4CAA4C;AACtC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AAC1B;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AAC1B;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AAC1B;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,CAAC,sCAAsC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,IAAI;AACtC;AACA;AACA,6DAA6D,GAAG;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,qBAAqB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,8BAA8B;AAClC;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,8BAA8B;AACvF;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wDAAwD;AACzD;AACA;AACA,IAAI,uCAAuC;AAC3C;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,uCAAuC;AAChG;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0EAA0E;AAC3E;AACA;AACA,IAAI,+CAA+C;AACnD;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,+CAA+C;AACxG;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0FAA0F;AAC3F;AACA;AACA,IAAI,wBAAwB;AAC5B;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,wBAAwB;AACjF;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4CAA4C;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,kBAAkB;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AAC1B;AACP;AACA;AACA,uDAAuD,qBAAqB;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC;AACvC;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gDAAgD;AACjD;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,MAAM;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4CAA4C;AAC7C;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AAC/C;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,yBAAyB;AAClF;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AAC/C;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AAClC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gEAAgE;AACjE;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,CAAC,wCAAwC;AACzC;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,CAAC,wCAAwC;AAClC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,yBAAyB;AACnE;AACA;AACA;AACA,uDAAuD,oBAAoB;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oCAAoC;AAC9B;AACP;AACA;AACA,uDAAuD,aAAa;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sBAAsB;AACvB;AACA;AACA,IAAI,4BAA4B;AAChC;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,uBAAuB,IAAI;AAC5D;AACA;AACA,CAAC,oDAAoD;AACrD;AACA;AACA,IAAI,4BAA4B;AAChC;AACO;AACP;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oDAAoD;AACrD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sDAAsD;AACvD;AACA;AACA,IAAI,yBAAyB;AAC7B;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AAC/C;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AACjC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AACxB;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AACxC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,wBAAwB;AACxC,gBAAgB,wBAAwB;AACxC;AACA;AACA,CAAC,0CAA0C;AACpC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,sBAAsB;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sDAAsD;AACvD;AACA;AACA,IAAI,yBAAyB;AAC7B;AACO;AACP;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,yBAAyB;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AACxC;AACP;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AACjC;AACA;AACA,IAAI,gBAAgB;AACpB;AACO;AACP;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,gBAAgB;AACzE;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B;AAC7B;AACA;AACA,IAAI,yBAAyB;AAC7B;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,yBAAyB;AAClF;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AAC/C;AACA;AACA,IAAI,oBAAoB;AACxB;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,oBAAoB;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oCAAoC;AACrC;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gDAAgD;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wDAAwD;AACzD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0CAA0C;AAC3C;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8DAA8D;AAC/D;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4EAA4E;AAC7E;AACA;AACA,IAAI,0BAA0B;AAC9B;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,yDAAyD,0BAA0B;AACnF;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gDAAgD;AACjD;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC;AAChC;AACP;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gDAAgD;AAC1C;AACP;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AACxB;AACP;AACA;AACA,iBAAiB;AACjB;AACA;AACA,CAAC,kCAAkC;AAC5B;AACP;AACA;AACA,iBAAiB;AACjB;AACA;AACA,CAAC,oDAAoD;AAC9C;AACP;AACA;AACA,iBAAiB;AACjB;AACA;AACA,CAAC,oDAAoD;AACrD;AACA,qBAAqB,+DAA+D;AACpF;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,kEAAkE;AAC5D;AACP;AACA;AACA,iBAAiB;AACjB;AACA;AACA,CAAC,wDAAwD;AAClD;AACP;AACA;AACA,iBAAiB;AACjB;AACA;AACA,CAAC,0DAA0D;AACpD;AACP;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0CAA0C;AACpC;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,qBAAqB;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,6CAA6C,QAAQ;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oCAAoC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,iBAAiB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gBAAgB;;;;;;;;;;;;;;AC7qEjB,QAAQ,MAAM,aAAa,OAAO,QAAQ,cAAc,gGAAgG,gBAAgB,gCAAgC,YAAY,KAAK,gCAAgC,KAAK,gBAAgB,KAAK,WAAW,mBAAmB,wBAAwB,kGAAkG,yBAAyB,mBAAmB,yEAAyE,UAAU,oCAAoC,iBAAiB,SAAS,oCAAoC,+DAA+D,QAAQ,6BAA6B,SAAS,OAAO,mBAAmB,yCAAyC,UAAU,KAAK,MAAM,oCAAoC,OAAO,mEAAmE,yDAAyD,uBAAuB,+BAA+B,2DAA2D,4EAA4E,wBAAwB,6CAA6C,iBAAiB,kCAAkC,cAAc,mBAAmB,KAAK,mBAAmB,2CAA2C,qCAAqC,wBAAwB,4BAA4B,gDAAgD,YAAY,iCAAiC,KAAK,6BAA6B,iCAAiC,KAAK,wCAAwC,KAAK,KAAK,UAAU,QAAQ,gDAAgD,6BAA6B,oDAAoD,MAAM,wBAAwB,+BAA+B,cAAc,SAAS,YAAY,KAAK,iEAAiE,6EAA6E,uBAAuB,SAAS,qBAAqB,+BAA+B,0DAA0D,KAAK,iCAAiC,OAAO,IAAI,OAAO,UAAU,kDAAkD,wBAAwB,yFAAyF,KAAK,oBAAoB,+CAA+C,uCAAuC,sBAAsB,iBAAiB,KAAK,KAAK,sBAAsB,WAAW,OAAO,MAAM,OAAO,+EAA+E,mDAAmD,iBAAiB,KAAK,6BAA6B,OAAO,MAAM,OAAO,yBAAyB,6BAA6B,qBAAqB,KAAK,4CAA4C,KAAK,KAAK,sBAAsB,6EAA6E,YAAY,MAAM,OAAO,qEAAqE,oBAAoB,iIAAiI,qBAAqB,uDAAuD,kCAAkC,MAAM,mBAAmB,KAAK,OAAO,uCAAuC,yBAAyB,iCAAiC,uBAAuB,4CAA4C,KAAK,mGAAmG,YAAY,MAAM,MAAM,4QAA4Q,8CAA8C,uBAAuB,MAAM,cAAc,WAAW,+BAA+B,YAAY,YAAY,qCAAqC,YAAY,+DAA+D,uBAAuB,EAAE,8DAA8D,4FAA4F,eAAe,wCAAwC,SAAS,GAAG,SAAS,MAAM,iBAAiB,sBAAsB,mBAAmB,OAAO,aAAa,OAAO,UAAU,oCAAoC,0BAA0B,0BAA0B,2CAA2C,gBAAgB,iEAAiE,0BAA0B,YAAY,YAAY,OAAO,aAAa,QAAQ,gBAAgB,WAAW,EAAE,GAAG,kGAAkG,0BAA0B,+KAA+K,oKAAoK,kFAAkF,QAAQ,gBAAgB,yPAAyP,OAAO,UAAU,KAAK,MAAM,SAAS,4BAA4B,4KAA4K,qBAAqB,kDAAkD,UAAU,0DAA0D,SAAS,iEAAiE,aAAa,kBAAkB,QAAQ,kBAAkB,IAAI,+CAA+C,GAAG,kUAAkU,qBAAqB,kBAAkB,uFAAuF,eAAe,QAAQ,iDAAiD,uBAAuB,uEAAuE,6BAA6B,eAAe,8DAA8D,iBAAiB,eAAe,iBAAiB,SAAS,YAAY,iBAAiB,MAAM,4BAA4B,iBAAiB,qEAAqE,UAAU,mBAAmB,kBAAkB,gBAAgB,aAAa,aAAa,4DAA4D,eAAe,oFAAoF,SAAS,SAAS,QAAQ,iSAAiS,SAAS,4KAA4K,kBAAkB,WAAW,YAAY,WAAW,KAAK,wBAAwB,8MAA8M,KAAK,8BAA8B,aAAa,wFAAwF,qEAAqE,cAAc,MAAM,YAAY,WAAW,KAAK,wBAAwB,6EAA6E,sBAAsB,gBAAgB,MAAM,8DAA8D,YAAY,EAAE,OAAO,oQAAoQ,gBAAgB,cAAc,UAAU,+CAA+C,GAAG,oDAAoD,qBAAqB,WAAW,sBAAsB,8HAA8H,uGAAuG,MAAM,4DAA4D,wBAAwB,qBAAqB,0BAA0B,GAAG,YAAY,GAAG,2CAA2C,wBAAwB,oBAAoB,0BAA0B,GAAG,YAAY,GAAG,cAAc,iEAAiE,cAAc,IAAI,6BAA6B,MAAM,kDAAkD,sCAAsC,cAAc,2CAA2C,aAAa,yBAAyB,MAAM,aAAa,4BAA4B,eAAe,yBAAyB,EAAE,gCAAgC,kBAAkB,uBAAuB,wBAAwB,6DAA6D,OAAO,EAAE,uBAAuB,0CAA0C,wBAAwB,0DAA0D,OAAO,EAAE,wBAAwB,0BAA0B,uBAAuB,0BAA0B,SAAS,SAAS,IAAW,MAAM,UAAU;AACp8U","sources":["webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/regexp-to-ast/lib/src/utils.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/regexp-to-ast/lib/src/character-classes.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/regexp-to-ast/lib/src/regexp-parser.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/regexp-to-ast/lib/src/base-regexp-visitor.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/regexp-to-ast/lib/src/api.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-4F5CHEZ2.mjs","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-B2363JML.mjs","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-FRFDVMJY.mjs","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-PL6DKKU2.mjs","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-SJTYNZTY.mjs","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/grammar-loader.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-TCCFYFTB.mjs","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-TQ3KTPDO.mjs","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-UMXZTB3W.mjs","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@mermaid-js/parser/dist/mermaid-parser.core.mjs","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/utils/lib/src/to-fast-properties.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseSlice.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/drop.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/assign.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/pickBy.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseIsRegExp.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/isRegExp.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/gast/lib/src/model.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/rest.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/uniq.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseSome.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/some.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/includes.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_arrayEvery.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseEvery.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/every.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/gast/lib/src/helpers.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/first.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/constants.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/follow.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/negate.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/reject.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/indexOf.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseDifference.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/difference.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/compact.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/head.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/utils/lib/src/print.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/scan/reg_exp_parser.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/scan/reg_exp.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/scan/lexer.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/utils/lib/src/timer.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/scan/tokens.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/scan/lexer_errors_public.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/scan/lexer_public.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/scan/tokens_public.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/errors_public.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/gast/lib/src/visitor.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/resolver.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_arrayAggregator.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseAggregator.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_createAggregator.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/groupBy.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/dropRight.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/interpreter.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/lookahead.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/checks.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/gast/gast_resolver_public.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/exceptions_public.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/recoverable.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/keys.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/grammar/llk_lookahead.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/looksahead.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/cst/cst.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/lang/lang_extensions.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/cst/cst_visitor.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/tree_builder.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/lexer_adapter.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/recognizer_api.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/recognizer_engine.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/error_handler.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/context_assist.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/gast_recorder.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/traits/perf_tracer.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/utils/apply_mixins.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/parse/parser/parser.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/@chevrotain/cst-dts-gen/lib/src/api.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain/lib/src/api.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/languages/grammar-config.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain-allstar/lib/atn.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain-allstar/lib/dfa.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/uniqBy.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain-allstar/lib/all-star-lookahead.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/chevrotain-allstar/lib/index.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/cst-node-builder.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/langium-parser.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/parser-builder-base.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/completion-parser-builder.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/langium-parser-builder.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/promise-utils.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-textdocument/lib/esm/main.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/uri-utils.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/documents.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/references/linker.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/references/name-provider.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/references/references.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/collections.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/references/scope-computation.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/references/scope.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/caching.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/references/scope-provider.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/serializer/json-serializer.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/service-registry.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/validation/validation-registry.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/validation/document-validator.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/ast-descriptions.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/ast-node-locator.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/configuration.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/disposable.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/document-builder.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/index-manager.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/workspace-manager.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/lexer.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/documentation/jsdoc.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/documentation/documentation-provider.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/documentation/comment-provider.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/async-parser.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/workspace-lock.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/serializer/hydrator.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/default-module.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/dependency-injection.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/languages/generated/ast.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/token-builder.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/parser/value-converter.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/syntax-tree.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/ast-utils.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/cst-utils.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/errors.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/grammar-utils.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/regexp-utils.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/utils/stream.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/langium/lib/workspace/file-system-provider.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseExtremum.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseLt.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseMap.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseSet.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_basePickBy.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/clone.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/defaults.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_createFind.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/findIndex.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/find.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/flatMap.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/flatten.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseHas.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/has.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/isString.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/last.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/map.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/min.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_trimmedEndIndex.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/_baseTrim.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/toNumber.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/toFinite.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/lodash-es/toInteger.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/process/browser.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-jsonrpc/browser.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/browser/main.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/api.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/connection.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/messages.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.callHierarchy.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.colorProvider.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.configuration.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.declaration.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.diagnostic.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.fileOperations.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.foldingRange.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.implementation.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.inlayHint.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.inlineCompletion.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.inlineValue.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.linkedEditingRange.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.moniker.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.notebook.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.progress.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.selectionRange.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.semanticTokens.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.showDocument.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.typeDefinition.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.typeHierarchy.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/protocol.workspaceFolder.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-protocol/lib/common/utils/is.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-languageserver-types/lib/esm/main.js","webpack://_JUPYTERLAB.CORE_OUTPUT/../node_modules/vscode-uri/lib/esm/index.mjs"],"sourcesContent":["export function cc(char) {\n    return char.charCodeAt(0);\n}\nexport function insertToSet(item, set) {\n    if (Array.isArray(item)) {\n        item.forEach(function (subItem) {\n            set.push(subItem);\n        });\n    }\n    else {\n        set.push(item);\n    }\n}\nexport function addFlag(flagObj, flagKey) {\n    if (flagObj[flagKey] === true) {\n        throw \"duplicate flag \" + flagKey;\n    }\n    const x = flagObj[flagKey];\n    flagObj[flagKey] = true;\n}\nexport function ASSERT_EXISTS(obj) {\n    // istanbul ignore next\n    if (obj === undefined) {\n        throw Error(\"Internal Error - Should never get here!\");\n    }\n    return true;\n}\n// istanbul ignore next\nexport function ASSERT_NEVER_REACH_HERE() {\n    throw Error(\"Internal Error - Should never get here!\");\n}\nexport function isCharacter(obj) {\n    return obj[\"type\"] === \"Character\";\n}\n//# sourceMappingURL=utils.js.map","import { cc } from \"./utils.js\";\nexport const digitsCharCodes = [];\nfor (let i = cc(\"0\"); i <= cc(\"9\"); i++) {\n    digitsCharCodes.push(i);\n}\nexport const wordCharCodes = [cc(\"_\")].concat(digitsCharCodes);\nfor (let i = cc(\"a\"); i <= cc(\"z\"); i++) {\n    wordCharCodes.push(i);\n}\nfor (let i = cc(\"A\"); i <= cc(\"Z\"); i++) {\n    wordCharCodes.push(i);\n}\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp#character-classes\nexport const whitespaceCodes = [\n    cc(\" \"),\n    cc(\"\\f\"),\n    cc(\"\\n\"),\n    cc(\"\\r\"),\n    cc(\"\\t\"),\n    cc(\"\\v\"),\n    cc(\"\\t\"),\n    cc(\"\\u00a0\"),\n    cc(\"\\u1680\"),\n    cc(\"\\u2000\"),\n    cc(\"\\u2001\"),\n    cc(\"\\u2002\"),\n    cc(\"\\u2003\"),\n    cc(\"\\u2004\"),\n    cc(\"\\u2005\"),\n    cc(\"\\u2006\"),\n    cc(\"\\u2007\"),\n    cc(\"\\u2008\"),\n    cc(\"\\u2009\"),\n    cc(\"\\u200a\"),\n    cc(\"\\u2028\"),\n    cc(\"\\u2029\"),\n    cc(\"\\u202f\"),\n    cc(\"\\u205f\"),\n    cc(\"\\u3000\"),\n    cc(\"\\ufeff\"),\n];\n//# sourceMappingURL=character-classes.js.map","import { addFlag, ASSERT_EXISTS, ASSERT_NEVER_REACH_HERE, cc, insertToSet, isCharacter, } from \"./utils.js\";\nimport { digitsCharCodes, whitespaceCodes, wordCharCodes, } from \"./character-classes.js\";\n// consts and utilities\nconst hexDigitPattern = /[0-9a-fA-F]/;\nconst decimalPattern = /[0-9]/;\nconst decimalPatternNoZero = /[1-9]/;\n// https://hackernoon.com/the-madness-of-parsing-real-world-javascript-regexps-d9ee336df983\n// https://www.ecma-international.org/ecma-262/8.0/index.html#prod-Pattern\nexport class RegExpParser {\n    constructor() {\n        this.idx = 0;\n        this.input = \"\";\n        this.groupIdx = 0;\n    }\n    saveState() {\n        return {\n            idx: this.idx,\n            input: this.input,\n            groupIdx: this.groupIdx,\n        };\n    }\n    restoreState(newState) {\n        this.idx = newState.idx;\n        this.input = newState.input;\n        this.groupIdx = newState.groupIdx;\n    }\n    pattern(input) {\n        // parser state\n        this.idx = 0;\n        this.input = input;\n        this.groupIdx = 0;\n        this.consumeChar(\"/\");\n        const value = this.disjunction();\n        this.consumeChar(\"/\");\n        const flags = {\n            type: \"Flags\",\n            loc: { begin: this.idx, end: input.length },\n            global: false,\n            ignoreCase: false,\n            multiLine: false,\n            unicode: false,\n            sticky: false,\n        };\n        while (this.isRegExpFlag()) {\n            switch (this.popChar()) {\n                case \"g\":\n                    addFlag(flags, \"global\");\n                    break;\n                case \"i\":\n                    addFlag(flags, \"ignoreCase\");\n                    break;\n                case \"m\":\n                    addFlag(flags, \"multiLine\");\n                    break;\n                case \"u\":\n                    addFlag(flags, \"unicode\");\n                    break;\n                case \"y\":\n                    addFlag(flags, \"sticky\");\n                    break;\n            }\n        }\n        if (this.idx !== this.input.length) {\n            throw Error(\"Redundant input: \" + this.input.substring(this.idx));\n        }\n        return {\n            type: \"Pattern\",\n            flags: flags,\n            value: value,\n            loc: this.loc(0),\n        };\n    }\n    disjunction() {\n        const alts = [];\n        const begin = this.idx;\n        alts.push(this.alternative());\n        while (this.peekChar() === \"|\") {\n            this.consumeChar(\"|\");\n            alts.push(this.alternative());\n        }\n        return { type: \"Disjunction\", value: alts, loc: this.loc(begin) };\n    }\n    alternative() {\n        const terms = [];\n        const begin = this.idx;\n        while (this.isTerm()) {\n            terms.push(this.term());\n        }\n        return { type: \"Alternative\", value: terms, loc: this.loc(begin) };\n    }\n    term() {\n        if (this.isAssertion()) {\n            return this.assertion();\n        }\n        else {\n            return this.atom();\n        }\n    }\n    assertion() {\n        const begin = this.idx;\n        switch (this.popChar()) {\n            case \"^\":\n                return {\n                    type: \"StartAnchor\",\n                    loc: this.loc(begin),\n                };\n            case \"$\":\n                return { type: \"EndAnchor\", loc: this.loc(begin) };\n            // '\\b' or '\\B'\n            case \"\\\\\":\n                switch (this.popChar()) {\n                    case \"b\":\n                        return {\n                            type: \"WordBoundary\",\n                            loc: this.loc(begin),\n                        };\n                    case \"B\":\n                        return {\n                            type: \"NonWordBoundary\",\n                            loc: this.loc(begin),\n                        };\n                }\n                /* c8 ignore next */\n                throw Error(\"Invalid Assertion Escape\");\n            // '(?=' or '(?!'\n            case \"(\":\n                this.consumeChar(\"?\");\n                let type;\n                switch (this.popChar()) {\n                    case \"=\":\n                        type = \"Lookahead\";\n                        break;\n                    case \"!\":\n                        type = \"NegativeLookahead\";\n                        break;\n                    case \"<\": {\n                        switch (this.popChar()) {\n                            case \"=\":\n                                type = \"Lookbehind\";\n                                break;\n                            case \"!\":\n                                type = \"NegativeLookbehind\";\n                        }\n                        break;\n                    }\n                }\n                ASSERT_EXISTS(type);\n                const disjunction = this.disjunction();\n                this.consumeChar(\")\");\n                return {\n                    type: type,\n                    value: disjunction,\n                    loc: this.loc(begin),\n                };\n        }\n        // istanbul ignore next\n        return ASSERT_NEVER_REACH_HERE();\n    }\n    quantifier(isBacktracking = false) {\n        let range = undefined;\n        const begin = this.idx;\n        switch (this.popChar()) {\n            case \"*\":\n                range = {\n                    atLeast: 0,\n                    atMost: Infinity,\n                };\n                break;\n            case \"+\":\n                range = {\n                    atLeast: 1,\n                    atMost: Infinity,\n                };\n                break;\n            case \"?\":\n                range = {\n                    atLeast: 0,\n                    atMost: 1,\n                };\n                break;\n            case \"{\":\n                const atLeast = this.integerIncludingZero();\n                switch (this.popChar()) {\n                    case \"}\":\n                        range = {\n                            atLeast: atLeast,\n                            atMost: atLeast,\n                        };\n                        break;\n                    case \",\":\n                        let atMost;\n                        if (this.isDigit()) {\n                            atMost = this.integerIncludingZero();\n                            range = {\n                                atLeast: atLeast,\n                                atMost: atMost,\n                            };\n                        }\n                        else {\n                            range = {\n                                atLeast: atLeast,\n                                atMost: Infinity,\n                            };\n                        }\n                        this.consumeChar(\"}\");\n                        break;\n                }\n                // throwing exceptions from \"ASSERT_EXISTS\" during backtracking\n                // causes severe performance degradations\n                if (isBacktracking === true && range === undefined) {\n                    return undefined;\n                }\n                ASSERT_EXISTS(range);\n                break;\n        }\n        // throwing exceptions from \"ASSERT_EXISTS\" during backtracking\n        // causes severe performance degradations\n        if (isBacktracking === true && range === undefined) {\n            return undefined;\n        }\n        // istanbul ignore else\n        if (ASSERT_EXISTS(range)) {\n            if (this.peekChar(0) === \"?\") {\n                this.consumeChar(\"?\");\n                range.greedy = false;\n            }\n            else {\n                range.greedy = true;\n            }\n            range.type = \"Quantifier\";\n            range.loc = this.loc(begin);\n            return range;\n        }\n    }\n    atom() {\n        let atom;\n        const begin = this.idx;\n        switch (this.peekChar()) {\n            case \".\":\n                atom = this.dotAll();\n                break;\n            case \"\\\\\":\n                atom = this.atomEscape();\n                break;\n            case \"[\":\n                atom = this.characterClass();\n                break;\n            case \"(\":\n                atom = this.group();\n                break;\n        }\n        if (atom === undefined && this.isPatternCharacter()) {\n            atom = this.patternCharacter();\n        }\n        // istanbul ignore else\n        if (ASSERT_EXISTS(atom)) {\n            atom.loc = this.loc(begin);\n            if (this.isQuantifier()) {\n                atom.quantifier = this.quantifier();\n            }\n            return atom;\n        }\n        // istanbul ignore next\n        return ASSERT_NEVER_REACH_HERE();\n    }\n    dotAll() {\n        this.consumeChar(\".\");\n        return {\n            type: \"Set\",\n            complement: true,\n            value: [cc(\"\\n\"), cc(\"\\r\"), cc(\"\\u2028\"), cc(\"\\u2029\")],\n        };\n    }\n    atomEscape() {\n        this.consumeChar(\"\\\\\");\n        switch (this.peekChar()) {\n            case \"1\":\n            case \"2\":\n            case \"3\":\n            case \"4\":\n            case \"5\":\n            case \"6\":\n            case \"7\":\n            case \"8\":\n            case \"9\":\n                return this.decimalEscapeAtom();\n            case \"d\":\n            case \"D\":\n            case \"s\":\n            case \"S\":\n            case \"w\":\n            case \"W\":\n                return this.characterClassEscape();\n            case \"f\":\n            case \"n\":\n            case \"r\":\n            case \"t\":\n            case \"v\":\n                return this.controlEscapeAtom();\n            case \"c\":\n                return this.controlLetterEscapeAtom();\n            case \"0\":\n                return this.nulCharacterAtom();\n            case \"x\":\n                return this.hexEscapeSequenceAtom();\n            case \"u\":\n                return this.regExpUnicodeEscapeSequenceAtom();\n            default:\n                return this.identityEscapeAtom();\n        }\n    }\n    decimalEscapeAtom() {\n        const value = this.positiveInteger();\n        return { type: \"GroupBackReference\", value: value };\n    }\n    characterClassEscape() {\n        let set;\n        let complement = false;\n        switch (this.popChar()) {\n            case \"d\":\n                set = digitsCharCodes;\n                break;\n            case \"D\":\n                set = digitsCharCodes;\n                complement = true;\n                break;\n            case \"s\":\n                set = whitespaceCodes;\n                break;\n            case \"S\":\n                set = whitespaceCodes;\n                complement = true;\n                break;\n            case \"w\":\n                set = wordCharCodes;\n                break;\n            case \"W\":\n                set = wordCharCodes;\n                complement = true;\n                break;\n        }\n        // istanbul ignore else\n        if (ASSERT_EXISTS(set)) {\n            return { type: \"Set\", value: set, complement: complement };\n        }\n        // istanbul ignore next\n        return ASSERT_NEVER_REACH_HERE();\n    }\n    controlEscapeAtom() {\n        let escapeCode;\n        switch (this.popChar()) {\n            case \"f\":\n                escapeCode = cc(\"\\f\");\n                break;\n            case \"n\":\n                escapeCode = cc(\"\\n\");\n                break;\n            case \"r\":\n                escapeCode = cc(\"\\r\");\n                break;\n            case \"t\":\n                escapeCode = cc(\"\\t\");\n                break;\n            case \"v\":\n                escapeCode = cc(\"\\v\");\n                break;\n        }\n        // istanbul ignore else\n        if (ASSERT_EXISTS(escapeCode)) {\n            return { type: \"Character\", value: escapeCode };\n        }\n        // istanbul ignore next\n        return ASSERT_NEVER_REACH_HERE();\n    }\n    controlLetterEscapeAtom() {\n        this.consumeChar(\"c\");\n        const letter = this.popChar();\n        if (/[a-zA-Z]/.test(letter) === false) {\n            throw Error(\"Invalid \");\n        }\n        const letterCode = letter.toUpperCase().charCodeAt(0) - 64;\n        return { type: \"Character\", value: letterCode };\n    }\n    nulCharacterAtom() {\n        // TODO implement '[lookahead  DecimalDigit]'\n        // TODO: for the deprecated octal escape sequence\n        this.consumeChar(\"0\");\n        return { type: \"Character\", value: cc(\"\\0\") };\n    }\n    hexEscapeSequenceAtom() {\n        this.consumeChar(\"x\");\n        return this.parseHexDigits(2);\n    }\n    regExpUnicodeEscapeSequenceAtom() {\n        this.consumeChar(\"u\");\n        return this.parseHexDigits(4);\n    }\n    identityEscapeAtom() {\n        // TODO: implement \"SourceCharacter but not UnicodeIDContinue\"\n        // // http://unicode.org/reports/tr31/#Specific_Character_Adjustments\n        const escapedChar = this.popChar();\n        return { type: \"Character\", value: cc(escapedChar) };\n    }\n    classPatternCharacterAtom() {\n        switch (this.peekChar()) {\n            // istanbul ignore next\n            case \"\\n\":\n            // istanbul ignore next\n            case \"\\r\":\n            // istanbul ignore next\n            case \"\\u2028\":\n            // istanbul ignore next\n            case \"\\u2029\":\n            // istanbul ignore next\n            case \"\\\\\":\n            // istanbul ignore next\n            case \"]\":\n                throw Error(\"TBD\");\n            default:\n                const nextChar = this.popChar();\n                return { type: \"Character\", value: cc(nextChar) };\n        }\n    }\n    characterClass() {\n        const set = [];\n        let complement = false;\n        this.consumeChar(\"[\");\n        if (this.peekChar(0) === \"^\") {\n            this.consumeChar(\"^\");\n            complement = true;\n        }\n        while (this.isClassAtom()) {\n            const from = this.classAtom();\n            const isFromSingleChar = from.type === \"Character\";\n            if (isCharacter(from) && this.isRangeDash()) {\n                this.consumeChar(\"-\");\n                const to = this.classAtom();\n                const isToSingleChar = to.type === \"Character\";\n                // a range can only be used when both sides are single characters\n                if (isCharacter(to)) {\n                    if (to.value < from.value) {\n                        throw Error(\"Range out of order in character class\");\n                    }\n                    set.push({ from: from.value, to: to.value });\n                }\n                else {\n                    // literal dash\n                    insertToSet(from.value, set);\n                    set.push(cc(\"-\"));\n                    insertToSet(to.value, set);\n                }\n            }\n            else {\n                insertToSet(from.value, set);\n            }\n        }\n        this.consumeChar(\"]\");\n        return { type: \"Set\", complement: complement, value: set };\n    }\n    classAtom() {\n        switch (this.peekChar()) {\n            // istanbul ignore next\n            case \"]\":\n            // istanbul ignore next\n            case \"\\n\":\n            // istanbul ignore next\n            case \"\\r\":\n            // istanbul ignore next\n            case \"\\u2028\":\n            // istanbul ignore next\n            case \"\\u2029\":\n                throw Error(\"TBD\");\n            case \"\\\\\":\n                return this.classEscape();\n            default:\n                return this.classPatternCharacterAtom();\n        }\n    }\n    classEscape() {\n        this.consumeChar(\"\\\\\");\n        switch (this.peekChar()) {\n            // Matches a backspace.\n            // (Not to be confused with \\b word boundary outside characterClass)\n            case \"b\":\n                this.consumeChar(\"b\");\n                return { type: \"Character\", value: cc(\"\\u0008\") };\n            case \"d\":\n            case \"D\":\n            case \"s\":\n            case \"S\":\n            case \"w\":\n            case \"W\":\n                return this.characterClassEscape();\n            case \"f\":\n            case \"n\":\n            case \"r\":\n            case \"t\":\n            case \"v\":\n                return this.controlEscapeAtom();\n            case \"c\":\n                return this.controlLetterEscapeAtom();\n            case \"0\":\n                return this.nulCharacterAtom();\n            case \"x\":\n                return this.hexEscapeSequenceAtom();\n            case \"u\":\n                return this.regExpUnicodeEscapeSequenceAtom();\n            default:\n                return this.identityEscapeAtom();\n        }\n    }\n    group() {\n        let capturing = true;\n        this.consumeChar(\"(\");\n        switch (this.peekChar(0)) {\n            case \"?\":\n                this.consumeChar(\"?\");\n                this.consumeChar(\":\");\n                capturing = false;\n                break;\n            default:\n                this.groupIdx++;\n                break;\n        }\n        const value = this.disjunction();\n        this.consumeChar(\")\");\n        const groupAst = {\n            type: \"Group\",\n            capturing: capturing,\n            value: value,\n        };\n        if (capturing) {\n            groupAst[\"idx\"] = this.groupIdx;\n        }\n        return groupAst;\n    }\n    positiveInteger() {\n        let number = this.popChar();\n        // istanbul ignore next - can't ever get here due to previous lookahead checks\n        // still implementing this error checking in case this ever changes.\n        if (decimalPatternNoZero.test(number) === false) {\n            throw Error(\"Expecting a positive integer\");\n        }\n        while (decimalPattern.test(this.peekChar(0))) {\n            number += this.popChar();\n        }\n        return parseInt(number, 10);\n    }\n    integerIncludingZero() {\n        let number = this.popChar();\n        if (decimalPattern.test(number) === false) {\n            throw Error(\"Expecting an integer\");\n        }\n        while (decimalPattern.test(this.peekChar(0))) {\n            number += this.popChar();\n        }\n        return parseInt(number, 10);\n    }\n    patternCharacter() {\n        const nextChar = this.popChar();\n        switch (nextChar) {\n            // istanbul ignore next\n            case \"\\n\":\n            // istanbul ignore next\n            case \"\\r\":\n            // istanbul ignore next\n            case \"\\u2028\":\n            // istanbul ignore next\n            case \"\\u2029\":\n            // istanbul ignore next\n            case \"^\":\n            // istanbul ignore next\n            case \"$\":\n            // istanbul ignore next\n            case \"\\\\\":\n            // istanbul ignore next\n            case \".\":\n            // istanbul ignore next\n            case \"*\":\n            // istanbul ignore next\n            case \"+\":\n            // istanbul ignore next\n            case \"?\":\n            // istanbul ignore next\n            case \"(\":\n            // istanbul ignore next\n            case \")\":\n            // istanbul ignore next\n            case \"[\":\n            // istanbul ignore next\n            case \"|\":\n                // istanbul ignore next\n                throw Error(\"TBD\");\n            default:\n                return { type: \"Character\", value: cc(nextChar) };\n        }\n    }\n    isRegExpFlag() {\n        switch (this.peekChar(0)) {\n            case \"g\":\n            case \"i\":\n            case \"m\":\n            case \"u\":\n            case \"y\":\n                return true;\n            default:\n                return false;\n        }\n    }\n    isRangeDash() {\n        return this.peekChar() === \"-\" && this.isClassAtom(1);\n    }\n    isDigit() {\n        return decimalPattern.test(this.peekChar(0));\n    }\n    isClassAtom(howMuch = 0) {\n        switch (this.peekChar(howMuch)) {\n            case \"]\":\n            case \"\\n\":\n            case \"\\r\":\n            case \"\\u2028\":\n            case \"\\u2029\":\n                return false;\n            default:\n                return true;\n        }\n    }\n    isTerm() {\n        return this.isAtom() || this.isAssertion();\n    }\n    isAtom() {\n        if (this.isPatternCharacter()) {\n            return true;\n        }\n        switch (this.peekChar(0)) {\n            case \".\":\n            case \"\\\\\": // atomEscape\n            case \"[\": // characterClass\n            // TODO: isAtom must be called before isAssertion - disambiguate\n            case \"(\": // group\n                return true;\n            default:\n                return false;\n        }\n    }\n    isAssertion() {\n        switch (this.peekChar(0)) {\n            case \"^\":\n            case \"$\":\n                return true;\n            // '\\b' or '\\B'\n            case \"\\\\\":\n                switch (this.peekChar(1)) {\n                    case \"b\":\n                    case \"B\":\n                        return true;\n                    default:\n                        return false;\n                }\n            // '(?=' or '(?!' or `(?<=` or `(?<!`\n            case \"(\":\n                return (this.peekChar(1) === \"?\" &&\n                    (this.peekChar(2) === \"=\" ||\n                        this.peekChar(2) === \"!\" ||\n                        (this.peekChar(2) === \"<\" &&\n                            (this.peekChar(3) === \"=\" || this.peekChar(3) === \"!\"))));\n            default:\n                return false;\n        }\n    }\n    isQuantifier() {\n        const prevState = this.saveState();\n        try {\n            return this.quantifier(true) !== undefined;\n        }\n        catch (e) {\n            return false;\n        }\n        finally {\n            this.restoreState(prevState);\n        }\n    }\n    isPatternCharacter() {\n        switch (this.peekChar()) {\n            case \"^\":\n            case \"$\":\n            case \"\\\\\":\n            case \".\":\n            case \"*\":\n            case \"+\":\n            case \"?\":\n            case \"(\":\n            case \")\":\n            case \"[\":\n            case \"|\":\n            case \"/\":\n            case \"\\n\":\n            case \"\\r\":\n            case \"\\u2028\":\n            case \"\\u2029\":\n                return false;\n            default:\n                return true;\n        }\n    }\n    parseHexDigits(howMany) {\n        let hexString = \"\";\n        for (let i = 0; i < howMany; i++) {\n            const hexChar = this.popChar();\n            if (hexDigitPattern.test(hexChar) === false) {\n                throw Error(\"Expecting a HexDecimal digits\");\n            }\n            hexString += hexChar;\n        }\n        const charCode = parseInt(hexString, 16);\n        return { type: \"Character\", value: charCode };\n    }\n    peekChar(howMuch = 0) {\n        return this.input[this.idx + howMuch];\n    }\n    popChar() {\n        const nextChar = this.peekChar(0);\n        this.consumeChar(undefined);\n        return nextChar;\n    }\n    consumeChar(char) {\n        if (char !== undefined && this.input[this.idx] !== char) {\n            throw Error(\"Expected: '\" +\n                char +\n                \"' but found: '\" +\n                this.input[this.idx] +\n                \"' at offset: \" +\n                this.idx);\n        }\n        if (this.idx >= this.input.length) {\n            throw Error(\"Unexpected end of input\");\n        }\n        this.idx++;\n    }\n    loc(begin) {\n        return { begin: begin, end: this.idx };\n    }\n}\n//# sourceMappingURL=regexp-parser.js.map","export class BaseRegExpVisitor {\n    visitChildren(node) {\n        for (const key in node) {\n            const child = node[key];\n            /* istanbul ignore else */\n            if (node.hasOwnProperty(key)) {\n                if (child.type !== undefined) {\n                    this.visit(child);\n                }\n                else if (Array.isArray(child)) {\n                    child.forEach((subChild) => {\n                        this.visit(subChild);\n                    }, this);\n                }\n            }\n        }\n    }\n    visit(node) {\n        switch (node.type) {\n            case \"Pattern\":\n                this.visitPattern(node);\n                break;\n            case \"Flags\":\n                this.visitFlags(node);\n                break;\n            case \"Disjunction\":\n                this.visitDisjunction(node);\n                break;\n            case \"Alternative\":\n                this.visitAlternative(node);\n                break;\n            case \"StartAnchor\":\n                this.visitStartAnchor(node);\n                break;\n            case \"EndAnchor\":\n                this.visitEndAnchor(node);\n                break;\n            case \"WordBoundary\":\n                this.visitWordBoundary(node);\n                break;\n            case \"NonWordBoundary\":\n                this.visitNonWordBoundary(node);\n                break;\n            case \"Lookahead\":\n                this.visitLookahead(node);\n                break;\n            case \"NegativeLookahead\":\n                this.visitNegativeLookahead(node);\n                break;\n            case \"Lookbehind\":\n                this.visitLookbehind(node);\n                break;\n            case \"NegativeLookbehind\":\n                this.visitNegativeLookbehind(node);\n                break;\n            case \"Character\":\n                this.visitCharacter(node);\n                break;\n            case \"Set\":\n                this.visitSet(node);\n                break;\n            case \"Group\":\n                this.visitGroup(node);\n                break;\n            case \"GroupBackReference\":\n                this.visitGroupBackReference(node);\n                break;\n            case \"Quantifier\":\n                this.visitQuantifier(node);\n                break;\n        }\n        this.visitChildren(node);\n    }\n    visitPattern(node) { }\n    visitFlags(node) { }\n    visitDisjunction(node) { }\n    visitAlternative(node) { }\n    // Assertion\n    visitStartAnchor(node) { }\n    visitEndAnchor(node) { }\n    visitWordBoundary(node) { }\n    visitNonWordBoundary(node) { }\n    visitLookahead(node) { }\n    visitNegativeLookahead(node) { }\n    visitLookbehind(node) { }\n    visitNegativeLookbehind(node) { }\n    // atoms\n    visitCharacter(node) { }\n    visitSet(node) { }\n    visitGroup(node) { }\n    visitGroupBackReference(node) { }\n    visitQuantifier(node) { }\n}\n//# sourceMappingURL=base-regexp-visitor.js.map","export { RegExpParser } from \"./regexp-parser.js\";\nexport { BaseRegExpVisitor } from \"./base-regexp-visitor.js\";\n//# sourceMappingURL=api.js.map","import {\n  AbstractMermaidTokenBuilder,\n  CommonValueConverter,\n  GitGraphGrammarGeneratedModule,\n  MermaidGeneratedSharedModule,\n  __name\n} from \"./chunk-TCCFYFTB.mjs\";\n\n// src/language/gitGraph/module.ts\nimport {\n  inject,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  EmptyFileSystem\n} from \"langium\";\n\n// src/language/gitGraph/tokenBuilder.ts\nvar GitGraphTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"GitGraphTokenBuilder\");\n  }\n  constructor() {\n    super([\"gitGraph\"]);\n  }\n};\n\n// src/language/gitGraph/module.ts\nvar GitGraphModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new GitGraphTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new CommonValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createGitGraphServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const GitGraph = inject(\n    createDefaultCoreModule({ shared }),\n    GitGraphGrammarGeneratedModule,\n    GitGraphModule\n  );\n  shared.ServiceRegistry.register(GitGraph);\n  return { shared, GitGraph };\n}\n__name(createGitGraphServices, \"createGitGraphServices\");\n\nexport {\n  GitGraphModule,\n  createGitGraphServices\n};\n","import {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  MermaidGeneratedSharedModule,\n  TreemapGrammarGeneratedModule,\n  __name\n} from \"./chunk-TCCFYFTB.mjs\";\n\n// src/language/treemap/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/treemap/tokenBuilder.ts\nvar TreemapTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"TreemapTokenBuilder\");\n  }\n  constructor() {\n    super([\"treemap\"]);\n  }\n};\n\n// src/language/treemap/valueConverter.ts\nvar classDefRegex = /classDef\\s+([A-Z_a-z]\\w+)(?:\\s+([^\\n\\r;]*))?;?/;\nvar TreemapValueConverter = class extends AbstractMermaidValueConverter {\n  static {\n    __name(this, \"TreemapValueConverter\");\n  }\n  runCustomConverter(rule, input, _cstNode) {\n    if (rule.name === \"NUMBER2\") {\n      return parseFloat(input.replace(/,/g, \"\"));\n    } else if (rule.name === \"SEPARATOR\") {\n      return input.substring(1, input.length - 1);\n    } else if (rule.name === \"STRING2\") {\n      return input.substring(1, input.length - 1);\n    } else if (rule.name === \"INDENTATION\") {\n      return input.length;\n    } else if (rule.name === \"ClassDef\") {\n      if (typeof input !== \"string\") {\n        return input;\n      }\n      const match = classDefRegex.exec(input);\n      if (match) {\n        return {\n          $type: \"ClassDefStatement\",\n          className: match[1],\n          styleText: match[2] || void 0\n        };\n      }\n    }\n    return void 0;\n  }\n};\n\n// src/language/treemap/treemap-validator.ts\nfunction registerValidationChecks(services) {\n  const validator = services.validation.TreemapValidator;\n  const registry = services.validation.ValidationRegistry;\n  if (registry) {\n    const checks = {\n      Treemap: validator.checkSingleRoot.bind(validator)\n      // Remove unused validation for TreemapRow\n    };\n    registry.register(checks, validator);\n  }\n}\n__name(registerValidationChecks, \"registerValidationChecks\");\nvar TreemapValidator = class {\n  static {\n    __name(this, \"TreemapValidator\");\n  }\n  /**\n   * Validates that a treemap has only one root node.\n   * A root node is defined as a node that has no indentation.\n   */\n  checkSingleRoot(doc, accept) {\n    let rootNodeIndentation;\n    for (const row of doc.TreemapRows) {\n      if (!row.item) {\n        continue;\n      }\n      if (rootNodeIndentation === void 0 && // Check if this is a root node (no indentation)\n      row.indent === void 0) {\n        rootNodeIndentation = 0;\n      } else if (row.indent === void 0) {\n        accept(\"error\", \"Multiple root nodes are not allowed in a treemap.\", {\n          node: row,\n          property: \"item\"\n        });\n      } else if (rootNodeIndentation !== void 0 && rootNodeIndentation >= parseInt(row.indent, 10)) {\n        accept(\"error\", \"Multiple root nodes are not allowed in a treemap.\", {\n          node: row,\n          property: \"item\"\n        });\n      }\n    }\n  }\n};\n\n// src/language/treemap/module.ts\nvar TreemapModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new TreemapTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new TreemapValueConverter(), \"ValueConverter\")\n  },\n  validation: {\n    TreemapValidator: /* @__PURE__ */ __name(() => new TreemapValidator(), \"TreemapValidator\")\n  }\n};\nfunction createTreemapServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Treemap = inject(\n    createDefaultCoreModule({ shared }),\n    TreemapGrammarGeneratedModule,\n    TreemapModule\n  );\n  shared.ServiceRegistry.register(Treemap);\n  registerValidationChecks(Treemap);\n  return { shared, Treemap };\n}\n__name(createTreemapServices, \"createTreemapServices\");\n\nexport {\n  TreemapModule,\n  createTreemapServices\n};\n","import {\n  AbstractMermaidTokenBuilder,\n  CommonValueConverter,\n  InfoGrammarGeneratedModule,\n  MermaidGeneratedSharedModule,\n  __name\n} from \"./chunk-TCCFYFTB.mjs\";\n\n// src/language/info/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/info/tokenBuilder.ts\nvar InfoTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"InfoTokenBuilder\");\n  }\n  constructor() {\n    super([\"info\", \"showInfo\"]);\n  }\n};\n\n// src/language/info/module.ts\nvar InfoModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new InfoTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new CommonValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createInfoServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Info = inject(\n    createDefaultCoreModule({ shared }),\n    InfoGrammarGeneratedModule,\n    InfoModule\n  );\n  shared.ServiceRegistry.register(Info);\n  return { shared, Info };\n}\n__name(createInfoServices, \"createInfoServices\");\n\nexport {\n  InfoModule,\n  createInfoServices\n};\n","import {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  MermaidGeneratedSharedModule,\n  PieGrammarGeneratedModule,\n  __name\n} from \"./chunk-TCCFYFTB.mjs\";\n\n// src/language/pie/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/pie/tokenBuilder.ts\nvar PieTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"PieTokenBuilder\");\n  }\n  constructor() {\n    super([\"pie\", \"showData\"]);\n  }\n};\n\n// src/language/pie/valueConverter.ts\nvar PieValueConverter = class extends AbstractMermaidValueConverter {\n  static {\n    __name(this, \"PieValueConverter\");\n  }\n  runCustomConverter(rule, input, _cstNode) {\n    if (rule.name !== \"PIE_SECTION_LABEL\") {\n      return void 0;\n    }\n    return input.replace(/\"/g, \"\").trim();\n  }\n};\n\n// src/language/pie/module.ts\nvar PieModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new PieTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new PieValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createPieServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Pie = inject(\n    createDefaultCoreModule({ shared }),\n    PieGrammarGeneratedModule,\n    PieModule\n  );\n  shared.ServiceRegistry.register(Pie);\n  return { shared, Pie };\n}\n__name(createPieServices, \"createPieServices\");\n\nexport {\n  PieModule,\n  createPieServices\n};\n","import {\n  AbstractMermaidTokenBuilder,\n  CommonValueConverter,\n  MermaidGeneratedSharedModule,\n  PacketGrammarGeneratedModule,\n  __name\n} from \"./chunk-TCCFYFTB.mjs\";\n\n// src/language/packet/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/packet/tokenBuilder.ts\nvar PacketTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"PacketTokenBuilder\");\n  }\n  constructor() {\n    super([\"packet\"]);\n  }\n};\n\n// src/language/packet/module.ts\nvar PacketModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new PacketTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new CommonValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createPacketServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Packet = inject(\n    createDefaultCoreModule({ shared }),\n    PacketGrammarGeneratedModule,\n    PacketModule\n  );\n  shared.ServiceRegistry.register(Packet);\n  return { shared, Packet };\n}\n__name(createPacketServices, \"createPacketServices\");\n\nexport {\n  PacketModule,\n  createPacketServices\n};\n","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { createDefaultCoreModule, createDefaultSharedCoreModule } from '../default-module.js';\nimport { inject } from '../dependency-injection.js';\nimport * as ast from '../languages/generated/ast.js';\nimport { EmptyFileSystem } from '../workspace/file-system-provider.js';\nimport { URI } from './uri-utils.js';\nconst minimalGrammarModule = {\n    Grammar: () => undefined,\n    LanguageMetaData: () => ({\n        caseInsensitive: false,\n        fileExtensions: ['.langium'],\n        languageId: 'langium'\n    })\n};\nconst minimalSharedGrammarModule = {\n    AstReflection: () => new ast.LangiumGrammarAstReflection()\n};\nfunction createMinimalGrammarServices() {\n    const shared = inject(createDefaultSharedCoreModule(EmptyFileSystem), minimalSharedGrammarModule);\n    const grammar = inject(createDefaultCoreModule({ shared }), minimalGrammarModule);\n    shared.ServiceRegistry.register(grammar);\n    return grammar;\n}\n/**\n * Load a Langium grammar for your language from a JSON string. This is used by several services,\n * most notably the parser builder which interprets the grammar to create a parser.\n */\nexport function loadGrammarFromJson(json) {\n    const services = createMinimalGrammarServices();\n    const astNode = services.serializer.JsonSerializer.deserialize(json);\n    services.shared.workspace.LangiumDocumentFactory.fromModel(astNode, URI.parse(`memory:/${astNode.name ?? 'grammar'}.langium`));\n    return astNode;\n}\n//# sourceMappingURL=grammar-loader.js.map","var __defProp = Object.defineProperty;\nvar __name = (target, value) => __defProp(target, \"name\", { value, configurable: true });\n\n// src/language/generated/ast.ts\nimport * as langium from \"langium\";\nvar ArchitectureGrammar;\n((ArchitectureGrammar2) => {\n  ArchitectureGrammar2.Terminals = {\n    ARROW_DIRECTION: /L|R|T|B/,\n    ARROW_GROUP: /\\{group\\}/,\n    ARROW_INTO: /<|>/,\n    ACC_DESCR: /[\\t ]*accDescr(?:[\\t ]*:([^\\n\\r]*?(?=%%)|[^\\n\\r]*)|\\s*{([^}]*)})/,\n    ACC_TITLE: /[\\t ]*accTitle[\\t ]*:(?:[^\\n\\r]*?(?=%%)|[^\\n\\r]*)/,\n    TITLE: /[\\t ]*title(?:[\\t ][^\\n\\r]*?(?=%%)|[\\t ][^\\n\\r]*|)/,\n    STRING: /\"([^\"\\\\]|\\\\.)*\"|'([^'\\\\]|\\\\.)*'/,\n    ID: /[\\w]([-\\w]*\\w)?/,\n    NEWLINE: /\\r?\\n/,\n    WHITESPACE: /[\\t ]+/,\n    YAML: /---[\\t ]*\\r?\\n(?:[\\S\\s]*?\\r?\\n)?---(?:\\r?\\n|(?!\\S))/,\n    DIRECTIVE: /[\\t ]*%%{[\\S\\s]*?}%%(?:\\r?\\n|(?!\\S))/,\n    SINGLE_LINE_COMMENT: /[\\t ]*%%[^\\n\\r]*/,\n    ARCH_ICON: /\\([\\w-:]+\\)/,\n    ARCH_TITLE: /\\[[\\w ]+\\]/\n  };\n})(ArchitectureGrammar || (ArchitectureGrammar = {}));\nvar GitGraphGrammar;\n((GitGraphGrammar2) => {\n  GitGraphGrammar2.Terminals = {\n    ACC_DESCR: /[\\t ]*accDescr(?:[\\t ]*:([^\\n\\r]*?(?=%%)|[^\\n\\r]*)|\\s*{([^}]*)})/,\n    ACC_TITLE: /[\\t ]*accTitle[\\t ]*:(?:[^\\n\\r]*?(?=%%)|[^\\n\\r]*)/,\n    TITLE: /[\\t ]*title(?:[\\t ][^\\n\\r]*?(?=%%)|[\\t ][^\\n\\r]*|)/,\n    INT: /0|[1-9][0-9]*(?!\\.)/,\n    STRING: /\"([^\"\\\\]|\\\\.)*\"|'([^'\\\\]|\\\\.)*'/,\n    NEWLINE: /\\r?\\n/,\n    WHITESPACE: /[\\t ]+/,\n    YAML: /---[\\t ]*\\r?\\n(?:[\\S\\s]*?\\r?\\n)?---(?:\\r?\\n|(?!\\S))/,\n    DIRECTIVE: /[\\t ]*%%{[\\S\\s]*?}%%(?:\\r?\\n|(?!\\S))/,\n    SINGLE_LINE_COMMENT: /[\\t ]*%%[^\\n\\r]*/,\n    REFERENCE: /\\w([-\\./\\w]*[-\\w])?/\n  };\n})(GitGraphGrammar || (GitGraphGrammar = {}));\nvar InfoGrammar;\n((InfoGrammar2) => {\n  InfoGrammar2.Terminals = {\n    ACC_DESCR: /[\\t ]*accDescr(?:[\\t ]*:([^\\n\\r]*?(?=%%)|[^\\n\\r]*)|\\s*{([^}]*)})/,\n    ACC_TITLE: /[\\t ]*accTitle[\\t ]*:(?:[^\\n\\r]*?(?=%%)|[^\\n\\r]*)/,\n    TITLE: /[\\t ]*title(?:[\\t ][^\\n\\r]*?(?=%%)|[\\t ][^\\n\\r]*|)/,\n    NEWLINE: /\\r?\\n/,\n    WHITESPACE: /[\\t ]+/,\n    YAML: /---[\\t ]*\\r?\\n(?:[\\S\\s]*?\\r?\\n)?---(?:\\r?\\n|(?!\\S))/,\n    DIRECTIVE: /[\\t ]*%%{[\\S\\s]*?}%%(?:\\r?\\n|(?!\\S))/,\n    SINGLE_LINE_COMMENT: /[\\t ]*%%[^\\n\\r]*/\n  };\n})(InfoGrammar || (InfoGrammar = {}));\nvar PacketGrammar;\n((PacketGrammar2) => {\n  PacketGrammar2.Terminals = {\n    ACC_DESCR: /[\\t ]*accDescr(?:[\\t ]*:([^\\n\\r]*?(?=%%)|[^\\n\\r]*)|\\s*{([^}]*)})/,\n    ACC_TITLE: /[\\t ]*accTitle[\\t ]*:(?:[^\\n\\r]*?(?=%%)|[^\\n\\r]*)/,\n    TITLE: /[\\t ]*title(?:[\\t ][^\\n\\r]*?(?=%%)|[\\t ][^\\n\\r]*|)/,\n    INT: /0|[1-9][0-9]*(?!\\.)/,\n    STRING: /\"([^\"\\\\]|\\\\.)*\"|'([^'\\\\]|\\\\.)*'/,\n    NEWLINE: /\\r?\\n/,\n    WHITESPACE: /[\\t ]+/,\n    YAML: /---[\\t ]*\\r?\\n(?:[\\S\\s]*?\\r?\\n)?---(?:\\r?\\n|(?!\\S))/,\n    DIRECTIVE: /[\\t ]*%%{[\\S\\s]*?}%%(?:\\r?\\n|(?!\\S))/,\n    SINGLE_LINE_COMMENT: /[\\t ]*%%[^\\n\\r]*/\n  };\n})(PacketGrammar || (PacketGrammar = {}));\nvar PieGrammar;\n((PieGrammar2) => {\n  PieGrammar2.Terminals = {\n    NUMBER_PIE: /(?:-?[0-9]+\\.[0-9]+(?!\\.))|(?:-?(0|[1-9][0-9]*)(?!\\.))/,\n    ACC_DESCR: /[\\t ]*accDescr(?:[\\t ]*:([^\\n\\r]*?(?=%%)|[^\\n\\r]*)|\\s*{([^}]*)})/,\n    ACC_TITLE: /[\\t ]*accTitle[\\t ]*:(?:[^\\n\\r]*?(?=%%)|[^\\n\\r]*)/,\n    TITLE: /[\\t ]*title(?:[\\t ][^\\n\\r]*?(?=%%)|[\\t ][^\\n\\r]*|)/,\n    STRING: /\"([^\"\\\\]|\\\\.)*\"|'([^'\\\\]|\\\\.)*'/,\n    NEWLINE: /\\r?\\n/,\n    WHITESPACE: /[\\t ]+/,\n    YAML: /---[\\t ]*\\r?\\n(?:[\\S\\s]*?\\r?\\n)?---(?:\\r?\\n|(?!\\S))/,\n    DIRECTIVE: /[\\t ]*%%{[\\S\\s]*?}%%(?:\\r?\\n|(?!\\S))/,\n    SINGLE_LINE_COMMENT: /[\\t ]*%%[^\\n\\r]*/\n  };\n})(PieGrammar || (PieGrammar = {}));\nvar RadarGrammar;\n((RadarGrammar2) => {\n  RadarGrammar2.Terminals = {\n    GRATICULE: /circle|polygon/,\n    BOOLEAN: /true|false/,\n    ACC_DESCR: /[\\t ]*accDescr(?:[\\t ]*:([^\\n\\r]*?(?=%%)|[^\\n\\r]*)|\\s*{([^}]*)})/,\n    ACC_TITLE: /[\\t ]*accTitle[\\t ]*:(?:[^\\n\\r]*?(?=%%)|[^\\n\\r]*)/,\n    TITLE: /[\\t ]*title(?:[\\t ][^\\n\\r]*?(?=%%)|[\\t ][^\\n\\r]*|)/,\n    NUMBER: /(?:[0-9]+\\.[0-9]+(?!\\.))|(?:0|[1-9][0-9]*(?!\\.))/,\n    STRING: /\"([^\"\\\\]|\\\\.)*\"|'([^'\\\\]|\\\\.)*'/,\n    ID: /[\\w]([-\\w]*\\w)?/,\n    NEWLINE: /\\r?\\n/,\n    WHITESPACE: /[\\t ]+/,\n    YAML: /---[\\t ]*\\r?\\n(?:[\\S\\s]*?\\r?\\n)?---(?:\\r?\\n|(?!\\S))/,\n    DIRECTIVE: /[\\t ]*%%{[\\S\\s]*?}%%(?:\\r?\\n|(?!\\S))/,\n    SINGLE_LINE_COMMENT: /[\\t ]*%%[^\\n\\r]*/\n  };\n})(RadarGrammar || (RadarGrammar = {}));\nvar TreemapGrammar;\n((TreemapGrammar2) => {\n  TreemapGrammar2.Terminals = {\n    ACC_DESCR: /[\\t ]*accDescr(?:[\\t ]*:([^\\n\\r]*?(?=%%)|[^\\n\\r]*)|\\s*{([^}]*)})/,\n    ACC_TITLE: /[\\t ]*accTitle[\\t ]*:(?:[^\\n\\r]*?(?=%%)|[^\\n\\r]*)/,\n    TITLE: /[\\t ]*title(?:[\\t ][^\\n\\r]*?(?=%%)|[\\t ][^\\n\\r]*|)/,\n    TREEMAP_KEYWORD: /treemap-beta|treemap/,\n    CLASS_DEF: /classDef\\s+([a-zA-Z_][a-zA-Z0-9_]+)(?:\\s+([^;\\r\\n]*))?(?:;)?/,\n    STYLE_SEPARATOR: /:::/,\n    SEPARATOR: /:/,\n    COMMA: /,/,\n    INDENTATION: /[ \\t]{1,}/,\n    WS: /[ \\t]+/,\n    ML_COMMENT: /\\%\\%[^\\n]*/,\n    NL: /\\r?\\n/,\n    ID2: /[a-zA-Z_][a-zA-Z0-9_]*/,\n    NUMBER2: /[0-9_\\.\\,]+/,\n    STRING2: /\"[^\"]*\"|'[^']*'/\n  };\n})(TreemapGrammar || (TreemapGrammar = {}));\nvar MermaidTerminals = {\n  ...ArchitectureGrammar.Terminals,\n  ...GitGraphGrammar.Terminals,\n  ...InfoGrammar.Terminals,\n  ...PacketGrammar.Terminals,\n  ...PieGrammar.Terminals,\n  ...RadarGrammar.Terminals,\n  ...TreemapGrammar.Terminals\n};\nvar Architecture = {\n  $type: \"Architecture\",\n  accDescr: \"accDescr\",\n  accTitle: \"accTitle\",\n  edges: \"edges\",\n  groups: \"groups\",\n  junctions: \"junctions\",\n  services: \"services\",\n  title: \"title\"\n};\nfunction isArchitecture(item) {\n  return reflection.isInstance(item, Architecture.$type);\n}\n__name(isArchitecture, \"isArchitecture\");\nvar Axis = {\n  $type: \"Axis\",\n  label: \"label\",\n  name: \"name\"\n};\nvar Branch = {\n  $type: \"Branch\",\n  name: \"name\",\n  order: \"order\"\n};\nfunction isBranch(item) {\n  return reflection.isInstance(item, Branch.$type);\n}\n__name(isBranch, \"isBranch\");\nvar Checkout = {\n  $type: \"Checkout\",\n  branch: \"branch\"\n};\nvar CherryPicking = {\n  $type: \"CherryPicking\",\n  id: \"id\",\n  parent: \"parent\",\n  tags: \"tags\"\n};\nvar ClassDefStatement = {\n  $type: \"ClassDefStatement\",\n  className: \"className\",\n  styleText: \"styleText\"\n};\nvar Commit = {\n  $type: \"Commit\",\n  id: \"id\",\n  message: \"message\",\n  tags: \"tags\",\n  type: \"type\"\n};\nfunction isCommit(item) {\n  return reflection.isInstance(item, Commit.$type);\n}\n__name(isCommit, \"isCommit\");\nvar Curve = {\n  $type: \"Curve\",\n  entries: \"entries\",\n  label: \"label\",\n  name: \"name\"\n};\nvar Direction = {\n  $type: \"Direction\",\n  accDescr: \"accDescr\",\n  accTitle: \"accTitle\",\n  dir: \"dir\",\n  statements: \"statements\",\n  title: \"title\"\n};\nvar Edge = {\n  $type: \"Edge\",\n  lhsDir: \"lhsDir\",\n  lhsGroup: \"lhsGroup\",\n  lhsId: \"lhsId\",\n  lhsInto: \"lhsInto\",\n  rhsDir: \"rhsDir\",\n  rhsGroup: \"rhsGroup\",\n  rhsId: \"rhsId\",\n  rhsInto: \"rhsInto\",\n  title: \"title\"\n};\nvar Entry = {\n  $type: \"Entry\",\n  axis: \"axis\",\n  value: \"value\"\n};\nvar GitGraph = {\n  $type: \"GitGraph\",\n  accDescr: \"accDescr\",\n  accTitle: \"accTitle\",\n  statements: \"statements\",\n  title: \"title\"\n};\nfunction isGitGraph(item) {\n  return reflection.isInstance(item, GitGraph.$type);\n}\n__name(isGitGraph, \"isGitGraph\");\nvar Group = {\n  $type: \"Group\",\n  icon: \"icon\",\n  id: \"id\",\n  in: \"in\",\n  title: \"title\"\n};\nvar Info = {\n  $type: \"Info\",\n  accDescr: \"accDescr\",\n  accTitle: \"accTitle\",\n  title: \"title\"\n};\nfunction isInfo(item) {\n  return reflection.isInstance(item, Info.$type);\n}\n__name(isInfo, \"isInfo\");\nvar Item = {\n  $type: \"Item\",\n  classSelector: \"classSelector\",\n  name: \"name\"\n};\nvar Junction = {\n  $type: \"Junction\",\n  id: \"id\",\n  in: \"in\"\n};\nvar Leaf = {\n  $type: \"Leaf\",\n  classSelector: \"classSelector\",\n  name: \"name\",\n  value: \"value\"\n};\nvar Merge = {\n  $type: \"Merge\",\n  branch: \"branch\",\n  id: \"id\",\n  tags: \"tags\",\n  type: \"type\"\n};\nfunction isMerge(item) {\n  return reflection.isInstance(item, Merge.$type);\n}\n__name(isMerge, \"isMerge\");\nvar Option = {\n  $type: \"Option\",\n  name: \"name\",\n  value: \"value\"\n};\nvar Packet = {\n  $type: \"Packet\",\n  accDescr: \"accDescr\",\n  accTitle: \"accTitle\",\n  blocks: \"blocks\",\n  title: \"title\"\n};\nfunction isPacket(item) {\n  return reflection.isInstance(item, Packet.$type);\n}\n__name(isPacket, \"isPacket\");\nvar PacketBlock = {\n  $type: \"PacketBlock\",\n  bits: \"bits\",\n  end: \"end\",\n  label: \"label\",\n  start: \"start\"\n};\nfunction isPacketBlock(item) {\n  return reflection.isInstance(item, PacketBlock.$type);\n}\n__name(isPacketBlock, \"isPacketBlock\");\nvar Pie = {\n  $type: \"Pie\",\n  accDescr: \"accDescr\",\n  accTitle: \"accTitle\",\n  sections: \"sections\",\n  showData: \"showData\",\n  title: \"title\"\n};\nfunction isPie(item) {\n  return reflection.isInstance(item, Pie.$type);\n}\n__name(isPie, \"isPie\");\nvar PieSection = {\n  $type: \"PieSection\",\n  label: \"label\",\n  value: \"value\"\n};\nfunction isPieSection(item) {\n  return reflection.isInstance(item, PieSection.$type);\n}\n__name(isPieSection, \"isPieSection\");\nvar Radar = {\n  $type: \"Radar\",\n  accDescr: \"accDescr\",\n  accTitle: \"accTitle\",\n  axes: \"axes\",\n  curves: \"curves\",\n  options: \"options\",\n  title: \"title\"\n};\nvar Section = {\n  $type: \"Section\",\n  classSelector: \"classSelector\",\n  name: \"name\"\n};\nvar Service = {\n  $type: \"Service\",\n  icon: \"icon\",\n  iconText: \"iconText\",\n  id: \"id\",\n  in: \"in\",\n  title: \"title\"\n};\nvar Statement = {\n  $type: \"Statement\"\n};\nvar Treemap = {\n  $type: \"Treemap\",\n  accDescr: \"accDescr\",\n  accTitle: \"accTitle\",\n  title: \"title\",\n  TreemapRows: \"TreemapRows\"\n};\nfunction isTreemap(item) {\n  return reflection.isInstance(item, Treemap.$type);\n}\n__name(isTreemap, \"isTreemap\");\nvar TreemapRow = {\n  $type: \"TreemapRow\",\n  indent: \"indent\",\n  item: \"item\"\n};\nvar MermaidAstReflection = class extends langium.AbstractAstReflection {\n  constructor() {\n    super(...arguments);\n    this.types = {\n      Architecture: {\n        name: Architecture.$type,\n        properties: {\n          accDescr: {\n            name: Architecture.accDescr\n          },\n          accTitle: {\n            name: Architecture.accTitle\n          },\n          edges: {\n            name: Architecture.edges,\n            defaultValue: []\n          },\n          groups: {\n            name: Architecture.groups,\n            defaultValue: []\n          },\n          junctions: {\n            name: Architecture.junctions,\n            defaultValue: []\n          },\n          services: {\n            name: Architecture.services,\n            defaultValue: []\n          },\n          title: {\n            name: Architecture.title\n          }\n        },\n        superTypes: []\n      },\n      Axis: {\n        name: Axis.$type,\n        properties: {\n          label: {\n            name: Axis.label\n          },\n          name: {\n            name: Axis.name\n          }\n        },\n        superTypes: []\n      },\n      Branch: {\n        name: Branch.$type,\n        properties: {\n          name: {\n            name: Branch.name\n          },\n          order: {\n            name: Branch.order\n          }\n        },\n        superTypes: [Statement.$type]\n      },\n      Checkout: {\n        name: Checkout.$type,\n        properties: {\n          branch: {\n            name: Checkout.branch\n          }\n        },\n        superTypes: [Statement.$type]\n      },\n      CherryPicking: {\n        name: CherryPicking.$type,\n        properties: {\n          id: {\n            name: CherryPicking.id\n          },\n          parent: {\n            name: CherryPicking.parent\n          },\n          tags: {\n            name: CherryPicking.tags,\n            defaultValue: []\n          }\n        },\n        superTypes: [Statement.$type]\n      },\n      ClassDefStatement: {\n        name: ClassDefStatement.$type,\n        properties: {\n          className: {\n            name: ClassDefStatement.className\n          },\n          styleText: {\n            name: ClassDefStatement.styleText\n          }\n        },\n        superTypes: []\n      },\n      Commit: {\n        name: Commit.$type,\n        properties: {\n          id: {\n            name: Commit.id\n          },\n          message: {\n            name: Commit.message\n          },\n          tags: {\n            name: Commit.tags,\n            defaultValue: []\n          },\n          type: {\n            name: Commit.type\n          }\n        },\n        superTypes: [Statement.$type]\n      },\n      Curve: {\n        name: Curve.$type,\n        properties: {\n          entries: {\n            name: Curve.entries,\n            defaultValue: []\n          },\n          label: {\n            name: Curve.label\n          },\n          name: {\n            name: Curve.name\n          }\n        },\n        superTypes: []\n      },\n      Direction: {\n        name: Direction.$type,\n        properties: {\n          accDescr: {\n            name: Direction.accDescr\n          },\n          accTitle: {\n            name: Direction.accTitle\n          },\n          dir: {\n            name: Direction.dir\n          },\n          statements: {\n            name: Direction.statements,\n            defaultValue: []\n          },\n          title: {\n            name: Direction.title\n          }\n        },\n        superTypes: [GitGraph.$type]\n      },\n      Edge: {\n        name: Edge.$type,\n        properties: {\n          lhsDir: {\n            name: Edge.lhsDir\n          },\n          lhsGroup: {\n            name: Edge.lhsGroup,\n            defaultValue: false\n          },\n          lhsId: {\n            name: Edge.lhsId\n          },\n          lhsInto: {\n            name: Edge.lhsInto,\n            defaultValue: false\n          },\n          rhsDir: {\n            name: Edge.rhsDir\n          },\n          rhsGroup: {\n            name: Edge.rhsGroup,\n            defaultValue: false\n          },\n          rhsId: {\n            name: Edge.rhsId\n          },\n          rhsInto: {\n            name: Edge.rhsInto,\n            defaultValue: false\n          },\n          title: {\n            name: Edge.title\n          }\n        },\n        superTypes: []\n      },\n      Entry: {\n        name: Entry.$type,\n        properties: {\n          axis: {\n            name: Entry.axis,\n            referenceType: Axis.$type\n          },\n          value: {\n            name: Entry.value\n          }\n        },\n        superTypes: []\n      },\n      GitGraph: {\n        name: GitGraph.$type,\n        properties: {\n          accDescr: {\n            name: GitGraph.accDescr\n          },\n          accTitle: {\n            name: GitGraph.accTitle\n          },\n          statements: {\n            name: GitGraph.statements,\n            defaultValue: []\n          },\n          title: {\n            name: GitGraph.title\n          }\n        },\n        superTypes: []\n      },\n      Group: {\n        name: Group.$type,\n        properties: {\n          icon: {\n            name: Group.icon\n          },\n          id: {\n            name: Group.id\n          },\n          in: {\n            name: Group.in\n          },\n          title: {\n            name: Group.title\n          }\n        },\n        superTypes: []\n      },\n      Info: {\n        name: Info.$type,\n        properties: {\n          accDescr: {\n            name: Info.accDescr\n          },\n          accTitle: {\n            name: Info.accTitle\n          },\n          title: {\n            name: Info.title\n          }\n        },\n        superTypes: []\n      },\n      Item: {\n        name: Item.$type,\n        properties: {\n          classSelector: {\n            name: Item.classSelector\n          },\n          name: {\n            name: Item.name\n          }\n        },\n        superTypes: []\n      },\n      Junction: {\n        name: Junction.$type,\n        properties: {\n          id: {\n            name: Junction.id\n          },\n          in: {\n            name: Junction.in\n          }\n        },\n        superTypes: []\n      },\n      Leaf: {\n        name: Leaf.$type,\n        properties: {\n          classSelector: {\n            name: Leaf.classSelector\n          },\n          name: {\n            name: Leaf.name\n          },\n          value: {\n            name: Leaf.value\n          }\n        },\n        superTypes: [Item.$type]\n      },\n      Merge: {\n        name: Merge.$type,\n        properties: {\n          branch: {\n            name: Merge.branch\n          },\n          id: {\n            name: Merge.id\n          },\n          tags: {\n            name: Merge.tags,\n            defaultValue: []\n          },\n          type: {\n            name: Merge.type\n          }\n        },\n        superTypes: [Statement.$type]\n      },\n      Option: {\n        name: Option.$type,\n        properties: {\n          name: {\n            name: Option.name\n          },\n          value: {\n            name: Option.value,\n            defaultValue: false\n          }\n        },\n        superTypes: []\n      },\n      Packet: {\n        name: Packet.$type,\n        properties: {\n          accDescr: {\n            name: Packet.accDescr\n          },\n          accTitle: {\n            name: Packet.accTitle\n          },\n          blocks: {\n            name: Packet.blocks,\n            defaultValue: []\n          },\n          title: {\n            name: Packet.title\n          }\n        },\n        superTypes: []\n      },\n      PacketBlock: {\n        name: PacketBlock.$type,\n        properties: {\n          bits: {\n            name: PacketBlock.bits\n          },\n          end: {\n            name: PacketBlock.end\n          },\n          label: {\n            name: PacketBlock.label\n          },\n          start: {\n            name: PacketBlock.start\n          }\n        },\n        superTypes: []\n      },\n      Pie: {\n        name: Pie.$type,\n        properties: {\n          accDescr: {\n            name: Pie.accDescr\n          },\n          accTitle: {\n            name: Pie.accTitle\n          },\n          sections: {\n            name: Pie.sections,\n            defaultValue: []\n          },\n          showData: {\n            name: Pie.showData,\n            defaultValue: false\n          },\n          title: {\n            name: Pie.title\n          }\n        },\n        superTypes: []\n      },\n      PieSection: {\n        name: PieSection.$type,\n        properties: {\n          label: {\n            name: PieSection.label\n          },\n          value: {\n            name: PieSection.value\n          }\n        },\n        superTypes: []\n      },\n      Radar: {\n        name: Radar.$type,\n        properties: {\n          accDescr: {\n            name: Radar.accDescr\n          },\n          accTitle: {\n            name: Radar.accTitle\n          },\n          axes: {\n            name: Radar.axes,\n            defaultValue: []\n          },\n          curves: {\n            name: Radar.curves,\n            defaultValue: []\n          },\n          options: {\n            name: Radar.options,\n            defaultValue: []\n          },\n          title: {\n            name: Radar.title\n          }\n        },\n        superTypes: []\n      },\n      Section: {\n        name: Section.$type,\n        properties: {\n          classSelector: {\n            name: Section.classSelector\n          },\n          name: {\n            name: Section.name\n          }\n        },\n        superTypes: [Item.$type]\n      },\n      Service: {\n        name: Service.$type,\n        properties: {\n          icon: {\n            name: Service.icon\n          },\n          iconText: {\n            name: Service.iconText\n          },\n          id: {\n            name: Service.id\n          },\n          in: {\n            name: Service.in\n          },\n          title: {\n            name: Service.title\n          }\n        },\n        superTypes: []\n      },\n      Statement: {\n        name: Statement.$type,\n        properties: {},\n        superTypes: []\n      },\n      Treemap: {\n        name: Treemap.$type,\n        properties: {\n          accDescr: {\n            name: Treemap.accDescr\n          },\n          accTitle: {\n            name: Treemap.accTitle\n          },\n          title: {\n            name: Treemap.title\n          },\n          TreemapRows: {\n            name: Treemap.TreemapRows,\n            defaultValue: []\n          }\n        },\n        superTypes: []\n      },\n      TreemapRow: {\n        name: TreemapRow.$type,\n        properties: {\n          indent: {\n            name: TreemapRow.indent\n          },\n          item: {\n            name: TreemapRow.item\n          }\n        },\n        superTypes: []\n      }\n    };\n  }\n  static {\n    __name(this, \"MermaidAstReflection\");\n  }\n};\nvar reflection = new MermaidAstReflection();\n\n// src/language/generated/grammar.ts\nimport { loadGrammarFromJson } from \"langium\";\nvar loadedArchitectureGrammarGrammar;\nvar ArchitectureGrammarGrammar = /* @__PURE__ */ __name(() => loadedArchitectureGrammarGrammar ?? (loadedArchitectureGrammarGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"ArchitectureGrammar\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Architecture\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@23\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"architecture-beta\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@23\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}],\"cardinality\":\"*\"}]},\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Statement\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"groups\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"services\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"junctions\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"edges\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}}]},\"entry\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"LeftPort\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"lhsDir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}]},\"entry\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"RightPort\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"rhsDir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\":\"}]},\"entry\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Arrow\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"lhsInto\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"--\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"-\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@29\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\"-\"}]}]},{\"$type\":\"Assignment\",\"feature\":\"rhsInto\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}]},\"entry\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"Group\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"group\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"icon\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@28\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@29\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"Service\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"service\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"iconText\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@21\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"icon\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@28\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@29\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"Junction\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"junction\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"Edge\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"lhsId\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"lhsGroup\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"rhsId\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"rhsGroup\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_DIRECTION\",\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"L\"},\"parenthesized\":false},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"R\"},\"parenthesized\":false}],\"parenthesized\":false},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"T\"},\"parenthesized\":false}],\"parenthesized\":false},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"B\"},\"parenthesized\":false}],\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_GROUP\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\{group\\\\\\\\}/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_INTO\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/<|>/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@23\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"entry\":false,\"parameters\":[]},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"},\"parenthesized\":false},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"},\"parenthesized\":false}],\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"parenthesized\":false},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"parenthesized\":false}],\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_ICON\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\([\\\\\\\\w-:]+\\\\\\\\)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\[[\\\\\\\\w ]+\\\\\\\\]/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false}],\"interfaces\":[],\"types\":[]}`)), \"ArchitectureGrammarGrammar\");\nvar loadedGitGraphGrammarGrammar;\nvar GitGraphGrammarGrammar = /* @__PURE__ */ __name(() => loadedGitGraphGrammarGrammar ?? (loadedGitGraphGrammarGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"GitGraphGrammar\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"GitGraph\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"Keyword\",\"value\":\":\"}]},{\"$type\":\"Keyword\",\"value\":\"gitGraph:\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]},{\"$type\":\"Keyword\",\"value\":\":\"}]}]},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"statements\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"Statement\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"Direction\",\"definition\":{\"$type\":\"Assignment\",\"feature\":\"dir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"LR\"},{\"$type\":\"Keyword\",\"value\":\"TB\"},{\"$type\":\"Keyword\",\"value\":\"BT\"}]}},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"Commit\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"commit\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"msg:\",\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"message\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"type:\"},{\"$type\":\"Assignment\",\"feature\":\"type\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"NORMAL\"},{\"$type\":\"Keyword\",\"value\":\"REVERSE\"},{\"$type\":\"Keyword\",\"value\":\"HIGHLIGHT\"}]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"Branch\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"branch\"},{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@24\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"order:\"},{\"$type\":\"Assignment\",\"feature\":\"order\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"Merge\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"merge\"},{\"$type\":\"Assignment\",\"feature\":\"branch\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@24\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]}},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"type:\"},{\"$type\":\"Assignment\",\"feature\":\"type\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"NORMAL\"},{\"$type\":\"Keyword\",\"value\":\"REVERSE\"},{\"$type\":\"Keyword\",\"value\":\"HIGHLIGHT\"}]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"Checkout\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"checkout\"},{\"$type\":\"Keyword\",\"value\":\"switch\"}]},{\"$type\":\"Assignment\",\"feature\":\"branch\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@24\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"CherryPicking\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"cherry-pick\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"parent:\"},{\"$type\":\"Assignment\",\"feature\":\"parent\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"entry\":false,\"parameters\":[]},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"},\"parenthesized\":false},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"},\"parenthesized\":false}],\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"parenthesized\":false},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"parenthesized\":false}],\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"name\":\"REFERENCE\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\w([-\\\\\\\\./\\\\\\\\w]*[-\\\\\\\\w])?/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false}],\"interfaces\":[],\"types\":[]}`)), \"GitGraphGrammarGrammar\");\nvar loadedInfoGrammarGrammar;\nvar InfoGrammarGrammar = /* @__PURE__ */ __name(() => loadedInfoGrammarGrammar ?? (loadedInfoGrammarGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"InfoGrammar\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Info\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"info\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"showInfo\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[],\"cardinality\":\"*\"}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"?\"}]},\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"entry\":false,\"parameters\":[]},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"},\"parenthesized\":false},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"},\"parenthesized\":false}],\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"parenthesized\":false},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"parenthesized\":false}],\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\",\"parenthesized\":false},\"fragment\":false}],\"interfaces\":[],\"types\":[]}`)), \"InfoGrammarGrammar\");\nvar loadedPacketGrammarGrammar;\nvar PacketGrammarGrammar = /* @__PURE__ */ __name(() => loadedPacketGrammarGrammar ?? (loadedPacketGrammarGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"PacketGrammar\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Packet\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"packet\"},{\"$type\":\"Keyword\",\"value\":\"packet-beta\"}]},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"blocks\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]}],\"cardinality\":\"*\"}]},\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"PacketBlock\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"start\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"-\"},{\"$type\":\"Assignment\",\"feature\":\"end\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}],\"cardinality\":\"?\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"+\"},{\"$type\":\"Assignment\",\"feature\":\"bits\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}]}]},{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"label\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"entry\":false,\"parameters\":[]},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"},\"parenthesized\":false},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"},\"parenthesized\":false}],\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"parenthesized\":false},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"parenthesized\":false}],\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\",\"parenthesized\":false},\"fragment\":false}],\"interfaces\":[],\"types\":[]}`)), \"PacketGrammarGrammar\");\nvar loadedPieGrammarGrammar;\nvar PieGrammarGrammar = /* @__PURE__ */ __name(() => loadedPieGrammarGrammar ?? (loadedPieGrammarGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"PieGrammar\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Pie\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"pie\"},{\"$type\":\"Assignment\",\"feature\":\"showData\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"showData\"},\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"sections\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]}],\"cardinality\":\"*\"}]},\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"PieSection\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"label\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT_PIE\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/-?[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT_PIE\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/-?(0|[1-9][0-9]*)(?!\\\\\\\\.)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER_PIE\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"parenthesized\":false},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"parenthesized\":false}],\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"entry\":false,\"parameters\":[]},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"},\"parenthesized\":false},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"},\"parenthesized\":false}],\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"parenthesized\":false},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"parenthesized\":false}],\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\",\"parenthesized\":false},\"fragment\":false}],\"interfaces\":[],\"types\":[]}`)), \"PieGrammarGrammar\");\nvar loadedRadarGrammarGrammar;\nvar RadarGrammarGrammar = /* @__PURE__ */ __name(() => loadedRadarGrammarGrammar ?? (loadedRadarGrammarGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"RadarGrammar\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Radar\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"radar-beta\"},{\"$type\":\"Keyword\",\"value\":\"radar-beta:\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"radar-beta\"},{\"$type\":\"Keyword\",\"value\":\":\"}]}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"axis\"},{\"$type\":\"Assignment\",\"feature\":\"axes\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"Assignment\",\"feature\":\"axes\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"curve\"},{\"$type\":\"Assignment\",\"feature\":\"curves\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"Assignment\",\"feature\":\"curves\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"options\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"Assignment\",\"feature\":\"options\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}],\"cardinality\":\"*\"}]},\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Label\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"[\"},{\"$type\":\"Assignment\",\"feature\":\"label\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\"]\"}]},\"entry\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"Axis\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[],\"cardinality\":\"?\"}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"Curve\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[],\"cardinality\":\"?\"},{\"$type\":\"Keyword\",\"value\":\"{\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"Keyword\",\"value\":\"}\"}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Entries\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"}]}]},\"entry\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"DetailedEntry\",\"returnType\":{\"$ref\":\"#/interfaces@0\"},\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"axis\",\"operator\":\"=\",\"terminal\":{\"$type\":\"CrossReference\",\"type\":{\"$ref\":\"#/rules@2\"},\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},\"deprecatedSyntax\":false,\"isMulti\":false}},{\"$type\":\"Keyword\",\"value\":\":\",\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"NumberEntry\",\"returnType\":{\"$ref\":\"#/interfaces@0\"},\"definition\":{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"Option\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"showLegend\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"ticks\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"max\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"min\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"graticule\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}}]}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"TerminalRule\",\"name\":\"GRATICULE\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"circle\"},\"parenthesized\":false},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"polygon\"},\"parenthesized\":false}],\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"entry\":false,\"parameters\":[]},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"},\"parenthesized\":false},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"},\"parenthesized\":false}],\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"parenthesized\":false},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"parenthesized\":false}],\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\",\"parenthesized\":false},\"fragment\":false}],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Entry\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"axis\",\"isOptional\":true,\"type\":{\"$type\":\"ReferenceType\",\"referenceType\":{\"$type\":\"SimpleType\",\"typeRef\":{\"$ref\":\"#/rules@2\"}},\"isMulti\":false}},{\"$type\":\"TypeAttribute\",\"name\":\"value\",\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"number\"},\"isOptional\":false}],\"superTypes\":[]}],\"types\":[]}`)), \"RadarGrammarGrammar\");\nvar loadedTreemapGrammarGrammar;\nvar TreemapGrammarGrammar = /* @__PURE__ */ __name(() => loadedTreemapGrammarGrammar ?? (loadedTreemapGrammarGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"TreemapGrammar\",\"rules\":[{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]}}],\"cardinality\":\"+\"},\"entry\":false,\"parameters\":[]},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"},\"parenthesized\":false},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"},\"parenthesized\":false}],\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Treemap\",\"returnType\":{\"$ref\":\"#/interfaces@4\"},\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@0\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"TreemapRows\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},\"fragment\":false,\"parameters\":[]},{\"$type\":\"TerminalRule\",\"name\":\"TREEMAP_KEYWORD\",\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"treemap-beta\"},\"parenthesized\":false},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"treemap\"},\"parenthesized\":false}],\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"CLASS_DEF\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/classDef\\\\\\\\s+([a-zA-Z_][a-zA-Z0-9_]+)(?:\\\\\\\\s+([^;\\\\\\\\r\\\\\\\\n]*))?(?:;)?/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STYLE_SEPARATOR\",\"definition\":{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\":::\"},\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"SEPARATOR\",\"definition\":{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\":\"},\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"COMMA\",\"definition\":{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\",\"},\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INDENTATION\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[ \\\\\\\\t]{1,}/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WS\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[ \\\\\\\\t]+/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"ML_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\%\\\\\\\\%[^\\\\\\\\n]*/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"NL\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\",\"parenthesized\":false},\"fragment\":false},{\"$type\":\"ParserRule\",\"name\":\"TreemapRow\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"indent\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"item\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]}]}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"ClassDef\",\"dataType\":\"string\",\"definition\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"Item\",\"returnType\":{\"$ref\":\"#/interfaces@0\"},\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"Section\",\"returnType\":{\"$ref\":\"#/interfaces@1\"},\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@23\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"classSelector\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}],\"cardinality\":\"?\"}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"ParserRule\",\"name\":\"Leaf\",\"returnType\":{\"$ref\":\"#/interfaces@2\"},\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@23\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[],\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[],\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"classSelector\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}],\"cardinality\":\"?\"}]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"TerminalRule\",\"name\":\"ID2\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[a-zA-Z_][a-zA-Z0-9_]*/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER2\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9_\\\\\\\\.\\\\\\\\,]+/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"name\":\"MyNumber\",\"dataType\":\"number\",\"definition\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@21\"},\"arguments\":[]},\"entry\":false,\"fragment\":false,\"parameters\":[]},{\"$type\":\"TerminalRule\",\"name\":\"STRING2\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"[^\\\\\"]*\\\\\"|'[^']*'/\",\"parenthesized\":false},\"fragment\":false,\"hidden\":false}],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Item\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"name\",\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"},\"isOptional\":false},{\"$type\":\"TypeAttribute\",\"name\":\"classSelector\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]},{\"$type\":\"Interface\",\"name\":\"Section\",\"superTypes\":[{\"$ref\":\"#/interfaces@0\"}],\"attributes\":[]},{\"$type\":\"Interface\",\"name\":\"Leaf\",\"superTypes\":[{\"$ref\":\"#/interfaces@0\"}],\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"value\",\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"number\"},\"isOptional\":false}]},{\"$type\":\"Interface\",\"name\":\"ClassDefStatement\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"className\",\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"},\"isOptional\":false},{\"$type\":\"TypeAttribute\",\"name\":\"styleText\",\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"},\"isOptional\":false}],\"superTypes\":[]},{\"$type\":\"Interface\",\"name\":\"Treemap\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"TreemapRows\",\"type\":{\"$type\":\"ArrayType\",\"elementType\":{\"$type\":\"SimpleType\",\"typeRef\":{\"$ref\":\"#/rules@15\"}}},\"isOptional\":false},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"imports\":[],\"types\":[],\"$comment\":\"/**\\\\n * Treemap grammar for Langium\\\\n * Converted from mindmap grammar\\\\n *\\\\n * The ML_COMMENT and NL hidden terminals handle whitespace, comments, and newlines\\\\n * before the treemap keyword, allowing for empty lines and comments before the\\\\n * treemap declaration.\\\\n */\"}`)), \"TreemapGrammarGrammar\");\n\n// src/language/generated/module.ts\nvar ArchitectureGrammarLanguageMetaData = {\n  languageId: \"architecture\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar GitGraphGrammarLanguageMetaData = {\n  languageId: \"gitGraph\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar InfoGrammarLanguageMetaData = {\n  languageId: \"info\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar PacketGrammarLanguageMetaData = {\n  languageId: \"packet\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar PieGrammarLanguageMetaData = {\n  languageId: \"pie\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar RadarGrammarLanguageMetaData = {\n  languageId: \"radar\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar TreemapGrammarLanguageMetaData = {\n  languageId: \"treemap\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar MermaidGeneratedSharedModule = {\n  AstReflection: /* @__PURE__ */ __name(() => new MermaidAstReflection(), \"AstReflection\")\n};\nvar ArchitectureGrammarGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => ArchitectureGrammarGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => ArchitectureGrammarLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar GitGraphGrammarGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => GitGraphGrammarGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => GitGraphGrammarLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar InfoGrammarGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => InfoGrammarGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => InfoGrammarLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar PacketGrammarGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => PacketGrammarGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => PacketGrammarLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar PieGrammarGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => PieGrammarGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => PieGrammarLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar RadarGrammarGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => RadarGrammarGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => RadarGrammarLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar TreemapGrammarGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => TreemapGrammarGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => TreemapGrammarLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\n\n// src/language/common/valueConverter.ts\nimport { DefaultValueConverter } from \"langium\";\n\n// src/language/common/matcher.ts\nvar accessibilityDescrRegex = /accDescr(?:[\\t ]*:([^\\n\\r]*)|\\s*{([^}]*)})/;\nvar accessibilityTitleRegex = /accTitle[\\t ]*:([^\\n\\r]*)/;\nvar titleRegex = /title([\\t ][^\\n\\r]*|)/;\n\n// src/language/common/valueConverter.ts\nvar rulesRegexes = {\n  ACC_DESCR: accessibilityDescrRegex,\n  ACC_TITLE: accessibilityTitleRegex,\n  TITLE: titleRegex\n};\nvar AbstractMermaidValueConverter = class extends DefaultValueConverter {\n  static {\n    __name(this, \"AbstractMermaidValueConverter\");\n  }\n  runConverter(rule, input, cstNode) {\n    let value = this.runCommonConverter(rule, input, cstNode);\n    if (value === void 0) {\n      value = this.runCustomConverter(rule, input, cstNode);\n    }\n    if (value === void 0) {\n      return super.runConverter(rule, input, cstNode);\n    }\n    return value;\n  }\n  runCommonConverter(rule, input, _cstNode) {\n    const regex = rulesRegexes[rule.name];\n    if (regex === void 0) {\n      return void 0;\n    }\n    const match = regex.exec(input);\n    if (match === null) {\n      return void 0;\n    }\n    if (match[1] !== void 0) {\n      return match[1].trim().replace(/[\\t ]{2,}/gm, \" \");\n    }\n    if (match[2] !== void 0) {\n      return match[2].replace(/^\\s*/gm, \"\").replace(/\\s+$/gm, \"\").replace(/[\\t ]{2,}/gm, \" \").replace(/[\\n\\r]{2,}/gm, \"\\n\");\n    }\n    return void 0;\n  }\n};\nvar CommonValueConverter = class extends AbstractMermaidValueConverter {\n  static {\n    __name(this, \"CommonValueConverter\");\n  }\n  runCustomConverter(_rule, _input, _cstNode) {\n    return void 0;\n  }\n};\n\n// src/language/common/tokenBuilder.ts\nimport { DefaultTokenBuilder } from \"langium\";\nvar AbstractMermaidTokenBuilder = class extends DefaultTokenBuilder {\n  static {\n    __name(this, \"AbstractMermaidTokenBuilder\");\n  }\n  constructor(keywords) {\n    super();\n    this.keywords = new Set(keywords);\n  }\n  buildKeywordTokens(rules, terminalTokens, options) {\n    const tokenTypes = super.buildKeywordTokens(rules, terminalTokens, options);\n    tokenTypes.forEach((tokenType) => {\n      if (this.keywords.has(tokenType.name) && tokenType.PATTERN !== void 0) {\n        tokenType.PATTERN = new RegExp(tokenType.PATTERN.toString() + \"(?:(?=%%)|(?!\\\\S))\");\n      }\n    });\n    return tokenTypes;\n  }\n};\nvar CommonTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"CommonTokenBuilder\");\n  }\n};\n\nexport {\n  __name,\n  Architecture,\n  isArchitecture,\n  Branch,\n  isBranch,\n  Commit,\n  isCommit,\n  GitGraph,\n  isGitGraph,\n  Info,\n  isInfo,\n  Merge,\n  isMerge,\n  Packet,\n  isPacket,\n  PacketBlock,\n  isPacketBlock,\n  Pie,\n  isPie,\n  PieSection,\n  isPieSection,\n  Radar,\n  Statement,\n  Treemap,\n  isTreemap,\n  MermaidGeneratedSharedModule,\n  ArchitectureGrammarGeneratedModule,\n  GitGraphGrammarGeneratedModule,\n  InfoGrammarGeneratedModule,\n  PacketGrammarGeneratedModule,\n  PieGrammarGeneratedModule,\n  RadarGrammarGeneratedModule,\n  TreemapGrammarGeneratedModule,\n  AbstractMermaidValueConverter,\n  CommonValueConverter,\n  AbstractMermaidTokenBuilder,\n  CommonTokenBuilder\n};\n","import {\n  AbstractMermaidTokenBuilder,\n  CommonValueConverter,\n  MermaidGeneratedSharedModule,\n  RadarGrammarGeneratedModule,\n  __name\n} from \"./chunk-TCCFYFTB.mjs\";\n\n// src/language/radar/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/radar/tokenBuilder.ts\nvar RadarTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"RadarTokenBuilder\");\n  }\n  constructor() {\n    super([\"radar-beta\"]);\n  }\n};\n\n// src/language/radar/module.ts\nvar RadarModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new RadarTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new CommonValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createRadarServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Radar = inject(\n    createDefaultCoreModule({ shared }),\n    RadarGrammarGeneratedModule,\n    RadarModule\n  );\n  shared.ServiceRegistry.register(Radar);\n  return { shared, Radar };\n}\n__name(createRadarServices, \"createRadarServices\");\n\nexport {\n  RadarModule,\n  createRadarServices\n};\n","import {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  ArchitectureGrammarGeneratedModule,\n  MermaidGeneratedSharedModule,\n  __name\n} from \"./chunk-TCCFYFTB.mjs\";\n\n// src/language/architecture/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/architecture/tokenBuilder.ts\nvar ArchitectureTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"ArchitectureTokenBuilder\");\n  }\n  constructor() {\n    super([\"architecture\"]);\n  }\n};\n\n// src/language/architecture/valueConverter.ts\nvar ArchitectureValueConverter = class extends AbstractMermaidValueConverter {\n  static {\n    __name(this, \"ArchitectureValueConverter\");\n  }\n  runCustomConverter(rule, input, _cstNode) {\n    if (rule.name === \"ARCH_ICON\") {\n      return input.replace(/[()]/g, \"\").trim();\n    } else if (rule.name === \"ARCH_TEXT_ICON\") {\n      return input.replace(/[\"()]/g, \"\");\n    } else if (rule.name === \"ARCH_TITLE\") {\n      return input.replace(/[[\\]]/g, \"\").trim();\n    }\n    return void 0;\n  }\n};\n\n// src/language/architecture/module.ts\nvar ArchitectureModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new ArchitectureTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new ArchitectureValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createArchitectureServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Architecture = inject(\n    createDefaultCoreModule({ shared }),\n    ArchitectureGrammarGeneratedModule,\n    ArchitectureModule\n  );\n  shared.ServiceRegistry.register(Architecture);\n  return { shared, Architecture };\n}\n__name(createArchitectureServices, \"createArchitectureServices\");\n\nexport {\n  ArchitectureModule,\n  createArchitectureServices\n};\n","import {\n  GitGraphModule,\n  createGitGraphServices\n} from \"./chunks/mermaid-parser.core/chunk-4F5CHEZ2.mjs\";\nimport {\n  InfoModule,\n  createInfoServices\n} from \"./chunks/mermaid-parser.core/chunk-FRFDVMJY.mjs\";\nimport {\n  PacketModule,\n  createPacketServices\n} from \"./chunks/mermaid-parser.core/chunk-SJTYNZTY.mjs\";\nimport {\n  PieModule,\n  createPieServices\n} from \"./chunks/mermaid-parser.core/chunk-PL6DKKU2.mjs\";\nimport {\n  ArchitectureModule,\n  createArchitectureServices\n} from \"./chunks/mermaid-parser.core/chunk-UMXZTB3W.mjs\";\nimport {\n  RadarModule,\n  createRadarServices\n} from \"./chunks/mermaid-parser.core/chunk-TQ3KTPDO.mjs\";\nimport {\n  TreemapModule,\n  createTreemapServices\n} from \"./chunks/mermaid-parser.core/chunk-B2363JML.mjs\";\nimport {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  Architecture,\n  ArchitectureGrammarGeneratedModule,\n  Branch,\n  Commit,\n  CommonTokenBuilder,\n  CommonValueConverter,\n  GitGraph,\n  GitGraphGrammarGeneratedModule,\n  Info,\n  InfoGrammarGeneratedModule,\n  Merge,\n  MermaidGeneratedSharedModule,\n  Packet,\n  PacketBlock,\n  PacketGrammarGeneratedModule,\n  Pie,\n  PieGrammarGeneratedModule,\n  PieSection,\n  Radar,\n  RadarGrammarGeneratedModule,\n  Statement,\n  Treemap,\n  TreemapGrammarGeneratedModule,\n  __name,\n  isArchitecture,\n  isBranch,\n  isCommit,\n  isGitGraph,\n  isInfo,\n  isMerge,\n  isPacket,\n  isPacketBlock,\n  isPie,\n  isPieSection,\n  isTreemap\n} from \"./chunks/mermaid-parser.core/chunk-TCCFYFTB.mjs\";\n\n// src/parse.ts\nvar parsers = {};\nvar initializers = {\n  info: /* @__PURE__ */ __name(async () => {\n    const { createInfoServices: createInfoServices2 } = await import(\"./chunks/mermaid-parser.core/info-VBDWY6EO.mjs\");\n    const parser = createInfoServices2().Info.parser.LangiumParser;\n    parsers.info = parser;\n  }, \"info\"),\n  packet: /* @__PURE__ */ __name(async () => {\n    const { createPacketServices: createPacketServices2 } = await import(\"./chunks/mermaid-parser.core/packet-DYOGHKS2.mjs\");\n    const parser = createPacketServices2().Packet.parser.LangiumParser;\n    parsers.packet = parser;\n  }, \"packet\"),\n  pie: /* @__PURE__ */ __name(async () => {\n    const { createPieServices: createPieServices2 } = await import(\"./chunks/mermaid-parser.core/pie-VRWISCQL.mjs\");\n    const parser = createPieServices2().Pie.parser.LangiumParser;\n    parsers.pie = parser;\n  }, \"pie\"),\n  architecture: /* @__PURE__ */ __name(async () => {\n    const { createArchitectureServices: createArchitectureServices2 } = await import(\"./chunks/mermaid-parser.core/architecture-7HQA4BMR.mjs\");\n    const parser = createArchitectureServices2().Architecture.parser.LangiumParser;\n    parsers.architecture = parser;\n  }, \"architecture\"),\n  gitGraph: /* @__PURE__ */ __name(async () => {\n    const { createGitGraphServices: createGitGraphServices2 } = await import(\"./chunks/mermaid-parser.core/gitGraph-G5XIXVHT.mjs\");\n    const parser = createGitGraphServices2().GitGraph.parser.LangiumParser;\n    parsers.gitGraph = parser;\n  }, \"gitGraph\"),\n  radar: /* @__PURE__ */ __name(async () => {\n    const { createRadarServices: createRadarServices2 } = await import(\"./chunks/mermaid-parser.core/radar-ZZBFDIW7.mjs\");\n    const parser = createRadarServices2().Radar.parser.LangiumParser;\n    parsers.radar = parser;\n  }, \"radar\"),\n  treemap: /* @__PURE__ */ __name(async () => {\n    const { createTreemapServices: createTreemapServices2 } = await import(\"./chunks/mermaid-parser.core/treemap-GDKQZRPO.mjs\");\n    const parser = createTreemapServices2().Treemap.parser.LangiumParser;\n    parsers.treemap = parser;\n  }, \"treemap\")\n};\nasync function parse(diagramType, text) {\n  const initializer = initializers[diagramType];\n  if (!initializer) {\n    throw new Error(`Unknown diagram type: ${diagramType}`);\n  }\n  if (!parsers[diagramType]) {\n    await initializer();\n  }\n  const parser = parsers[diagramType];\n  const result = parser.parse(text);\n  if (result.lexerErrors.length > 0 || result.parserErrors.length > 0) {\n    throw new MermaidParseError(result);\n  }\n  return result.value;\n}\n__name(parse, \"parse\");\nvar MermaidParseError = class extends Error {\n  constructor(result) {\n    const lexerErrors = result.lexerErrors.map((err) => err.message).join(\"\\n\");\n    const parserErrors = result.parserErrors.map((err) => err.message).join(\"\\n\");\n    super(`Parsing failed: ${lexerErrors} ${parserErrors}`);\n    this.result = result;\n  }\n  static {\n    __name(this, \"MermaidParseError\");\n  }\n};\nexport {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  Architecture,\n  ArchitectureGrammarGeneratedModule as ArchitectureGeneratedModule,\n  ArchitectureModule,\n  Branch,\n  Commit,\n  CommonTokenBuilder,\n  CommonValueConverter,\n  GitGraph,\n  GitGraphGrammarGeneratedModule as GitGraphGeneratedModule,\n  GitGraphModule,\n  Info,\n  InfoGrammarGeneratedModule as InfoGeneratedModule,\n  InfoModule,\n  Merge,\n  MermaidGeneratedSharedModule,\n  MermaidParseError,\n  Packet,\n  PacketBlock,\n  PacketGrammarGeneratedModule as PacketGeneratedModule,\n  PacketModule,\n  Pie,\n  PieGrammarGeneratedModule as PieGeneratedModule,\n  PieModule,\n  PieSection,\n  Radar,\n  RadarGrammarGeneratedModule as RadarGeneratedModule,\n  RadarModule,\n  Statement,\n  Treemap,\n  TreemapGrammarGeneratedModule as TreemapGeneratedModule,\n  TreemapModule,\n  createArchitectureServices,\n  createGitGraphServices,\n  createInfoServices,\n  createPacketServices,\n  createPieServices,\n  createRadarServices,\n  createTreemapServices,\n  isArchitecture,\n  isBranch,\n  isCommit,\n  isGitGraph,\n  isInfo,\n  isMerge,\n  isPacket,\n  isPacketBlock,\n  isPie,\n  isPieSection,\n  isTreemap,\n  parse\n};\n","// based on: https://github.com/petkaantonov/bluebird/blob/b97c0d2d487e8c5076e8bd897e0dcd4622d31846/src/util.js#L201-L216\nexport function toFastProperties(toBecomeFast) {\n    function FakeConstructor() { }\n    // If our object is used as a constructor, it would receive\n    FakeConstructor.prototype = toBecomeFast;\n    const fakeInstance = new FakeConstructor();\n    function fakeAccess() {\n        return typeof fakeInstance.bar;\n    }\n    // help V8 understand this is a \"real\" prototype by actually using\n    // the fake instance.\n    fakeAccess();\n    fakeAccess();\n    // Always true condition to suppress the Firefox warning of unreachable\n    // code after a return statement.\n    if (1)\n        return toBecomeFast;\n    // Eval prevents optimization of this method (even though this is dead code)\n    // - https://esbuild.github.io/content-types/#direct-eval\n    /* istanbul ignore next */\n    // tslint:disable-next-line\n    (0, eval)(toBecomeFast);\n}\n//# sourceMappingURL=to-fast-properties.js.map","/**\n * The base implementation of `_.slice` without an iteratee call guard.\n *\n * @private\n * @param {Array} array The array to slice.\n * @param {number} [start=0] The start position.\n * @param {number} [end=array.length] The end position.\n * @returns {Array} Returns the slice of `array`.\n */\nfunction baseSlice(array, start, end) {\n  var index = -1,\n      length = array.length;\n\n  if (start < 0) {\n    start = -start > length ? 0 : (length + start);\n  }\n  end = end > length ? length : end;\n  if (end < 0) {\n    end += length;\n  }\n  length = start > end ? 0 : ((end - start) >>> 0);\n  start >>>= 0;\n\n  var result = Array(length);\n  while (++index < length) {\n    result[index] = array[index + start];\n  }\n  return result;\n}\n\nexport default baseSlice;\n","import baseSlice from './_baseSlice.js';\nimport toInteger from './toInteger.js';\n\n/**\n * Creates a slice of `array` with `n` elements dropped from the beginning.\n *\n * @static\n * @memberOf _\n * @since 0.5.0\n * @category Array\n * @param {Array} array The array to query.\n * @param {number} [n=1] The number of elements to drop.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {Array} Returns the slice of `array`.\n * @example\n *\n * _.drop([1, 2, 3]);\n * // => [2, 3]\n *\n * _.drop([1, 2, 3], 2);\n * // => [3]\n *\n * _.drop([1, 2, 3], 5);\n * // => []\n *\n * _.drop([1, 2, 3], 0);\n * // => [1, 2, 3]\n */\nfunction drop(array, n, guard) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return [];\n  }\n  n = (guard || n === undefined) ? 1 : toInteger(n);\n  return baseSlice(array, n < 0 ? 0 : n, length);\n}\n\nexport default drop;\n","import assignValue from './_assignValue.js';\nimport copyObject from './_copyObject.js';\nimport createAssigner from './_createAssigner.js';\nimport isArrayLike from './isArrayLike.js';\nimport isPrototype from './_isPrototype.js';\nimport keys from './keys.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Assigns own enumerable string keyed properties of source objects to the\n * destination object. Source objects are applied from left to right.\n * Subsequent sources overwrite property assignments of previous sources.\n *\n * **Note:** This method mutates `object` and is loosely based on\n * [`Object.assign`](https://mdn.io/Object/assign).\n *\n * @static\n * @memberOf _\n * @since 0.10.0\n * @category Object\n * @param {Object} object The destination object.\n * @param {...Object} [sources] The source objects.\n * @returns {Object} Returns `object`.\n * @see _.assignIn\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n * }\n *\n * function Bar() {\n *   this.c = 3;\n * }\n *\n * Foo.prototype.b = 2;\n * Bar.prototype.d = 4;\n *\n * _.assign({ 'a': 0 }, new Foo, new Bar);\n * // => { 'a': 1, 'c': 3 }\n */\nvar assign = createAssigner(function(object, source) {\n  if (isPrototype(source) || isArrayLike(source)) {\n    copyObject(source, keys(source), object);\n    return;\n  }\n  for (var key in source) {\n    if (hasOwnProperty.call(source, key)) {\n      assignValue(object, key, source[key]);\n    }\n  }\n});\n\nexport default assign;\n","import arrayMap from './_arrayMap.js';\nimport baseIteratee from './_baseIteratee.js';\nimport basePickBy from './_basePickBy.js';\nimport getAllKeysIn from './_getAllKeysIn.js';\n\n/**\n * Creates an object composed of the `object` properties `predicate` returns\n * truthy for. The predicate is invoked with two arguments: (value, key).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Object\n * @param {Object} object The source object.\n * @param {Function} [predicate=_.identity] The function invoked per property.\n * @returns {Object} Returns the new object.\n * @example\n *\n * var object = { 'a': 1, 'b': '2', 'c': 3 };\n *\n * _.pickBy(object, _.isNumber);\n * // => { 'a': 1, 'c': 3 }\n */\nfunction pickBy(object, predicate) {\n  if (object == null) {\n    return {};\n  }\n  var props = arrayMap(getAllKeysIn(object), function(prop) {\n    return [prop];\n  });\n  predicate = baseIteratee(predicate);\n  return basePickBy(object, props, function(value, path) {\n    return predicate(value, path[0]);\n  });\n}\n\nexport default pickBy;\n","import baseGetTag from './_baseGetTag.js';\nimport isObjectLike from './isObjectLike.js';\n\n/** `Object#toString` result references. */\nvar regexpTag = '[object RegExp]';\n\n/**\n * The base implementation of `_.isRegExp` without Node.js optimizations.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a regexp, else `false`.\n */\nfunction baseIsRegExp(value) {\n  return isObjectLike(value) && baseGetTag(value) == regexpTag;\n}\n\nexport default baseIsRegExp;\n","import baseIsRegExp from './_baseIsRegExp.js';\nimport baseUnary from './_baseUnary.js';\nimport nodeUtil from './_nodeUtil.js';\n\n/* Node.js helper references. */\nvar nodeIsRegExp = nodeUtil && nodeUtil.isRegExp;\n\n/**\n * Checks if `value` is classified as a `RegExp` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a regexp, else `false`.\n * @example\n *\n * _.isRegExp(/abc/);\n * // => true\n *\n * _.isRegExp('/abc/');\n * // => false\n */\nvar isRegExp = nodeIsRegExp ? baseUnary(nodeIsRegExp) : baseIsRegExp;\n\nexport default isRegExp;\n","import { assign, forEach, isRegExp, isString, map, pickBy } from \"lodash-es\";\n// TODO: duplicated code to avoid extracting another sub-package -- how to avoid?\nfunction tokenLabel(tokType) {\n    if (hasTokenLabel(tokType)) {\n        return tokType.LABEL;\n    }\n    else {\n        return tokType.name;\n    }\n}\n// TODO: duplicated code to avoid extracting another sub-package -- how to avoid?\nfunction hasTokenLabel(obj) {\n    return isString(obj.LABEL) && obj.LABEL !== \"\";\n}\nexport class AbstractProduction {\n    get definition() {\n        return this._definition;\n    }\n    set definition(value) {\n        this._definition = value;\n    }\n    constructor(_definition) {\n        this._definition = _definition;\n    }\n    accept(visitor) {\n        visitor.visit(this);\n        forEach(this.definition, (prod) => {\n            prod.accept(visitor);\n        });\n    }\n}\nexport class NonTerminal extends AbstractProduction {\n    constructor(options) {\n        super([]);\n        this.idx = 1;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n    set definition(definition) {\n        // immutable\n    }\n    get definition() {\n        if (this.referencedRule !== undefined) {\n            return this.referencedRule.definition;\n        }\n        return [];\n    }\n    accept(visitor) {\n        visitor.visit(this);\n        // don't visit children of a reference, we will get cyclic infinite loops if we do so\n    }\n}\nexport class Rule extends AbstractProduction {\n    constructor(options) {\n        super(options.definition);\n        this.orgText = \"\";\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n}\nexport class Alternative extends AbstractProduction {\n    constructor(options) {\n        super(options.definition);\n        this.ignoreAmbiguities = false;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n}\nexport class Option extends AbstractProduction {\n    constructor(options) {\n        super(options.definition);\n        this.idx = 1;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n}\nexport class RepetitionMandatory extends AbstractProduction {\n    constructor(options) {\n        super(options.definition);\n        this.idx = 1;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n}\nexport class RepetitionMandatoryWithSeparator extends AbstractProduction {\n    constructor(options) {\n        super(options.definition);\n        this.idx = 1;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n}\nexport class Repetition extends AbstractProduction {\n    constructor(options) {\n        super(options.definition);\n        this.idx = 1;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n}\nexport class RepetitionWithSeparator extends AbstractProduction {\n    constructor(options) {\n        super(options.definition);\n        this.idx = 1;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n}\nexport class Alternation extends AbstractProduction {\n    get definition() {\n        return this._definition;\n    }\n    set definition(value) {\n        this._definition = value;\n    }\n    constructor(options) {\n        super(options.definition);\n        this.idx = 1;\n        this.ignoreAmbiguities = false;\n        this.hasPredicates = false;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n}\nexport class Terminal {\n    constructor(options) {\n        this.idx = 1;\n        assign(this, pickBy(options, (v) => v !== undefined));\n    }\n    accept(visitor) {\n        visitor.visit(this);\n    }\n}\nexport function serializeGrammar(topRules) {\n    return map(topRules, serializeProduction);\n}\nexport function serializeProduction(node) {\n    function convertDefinition(definition) {\n        return map(definition, serializeProduction);\n    }\n    /* istanbul ignore else */\n    if (node instanceof NonTerminal) {\n        const serializedNonTerminal = {\n            type: \"NonTerminal\",\n            name: node.nonTerminalName,\n            idx: node.idx,\n        };\n        if (isString(node.label)) {\n            serializedNonTerminal.label = node.label;\n        }\n        return serializedNonTerminal;\n    }\n    else if (node instanceof Alternative) {\n        return {\n            type: \"Alternative\",\n            definition: convertDefinition(node.definition),\n        };\n    }\n    else if (node instanceof Option) {\n        return {\n            type: \"Option\",\n            idx: node.idx,\n            definition: convertDefinition(node.definition),\n        };\n    }\n    else if (node instanceof RepetitionMandatory) {\n        return {\n            type: \"RepetitionMandatory\",\n            idx: node.idx,\n            definition: convertDefinition(node.definition),\n        };\n    }\n    else if (node instanceof RepetitionMandatoryWithSeparator) {\n        return {\n            type: \"RepetitionMandatoryWithSeparator\",\n            idx: node.idx,\n            separator: (serializeProduction(new Terminal({ terminalType: node.separator }))),\n            definition: convertDefinition(node.definition),\n        };\n    }\n    else if (node instanceof RepetitionWithSeparator) {\n        return {\n            type: \"RepetitionWithSeparator\",\n            idx: node.idx,\n            separator: (serializeProduction(new Terminal({ terminalType: node.separator }))),\n            definition: convertDefinition(node.definition),\n        };\n    }\n    else if (node instanceof Repetition) {\n        return {\n            type: \"Repetition\",\n            idx: node.idx,\n            definition: convertDefinition(node.definition),\n        };\n    }\n    else if (node instanceof Alternation) {\n        return {\n            type: \"Alternation\",\n            idx: node.idx,\n            definition: convertDefinition(node.definition),\n        };\n    }\n    else if (node instanceof Terminal) {\n        const serializedTerminal = {\n            type: \"Terminal\",\n            name: node.terminalType.name,\n            label: tokenLabel(node.terminalType),\n            idx: node.idx,\n        };\n        if (isString(node.label)) {\n            serializedTerminal.terminalLabel = node.label;\n        }\n        const pattern = node.terminalType.PATTERN;\n        if (node.terminalType.PATTERN) {\n            serializedTerminal.pattern = isRegExp(pattern)\n                ? pattern.source\n                : pattern;\n        }\n        return serializedTerminal;\n    }\n    else if (node instanceof Rule) {\n        return {\n            type: \"Rule\",\n            name: node.name,\n            orgText: node.orgText,\n            definition: convertDefinition(node.definition),\n        };\n        /* c8 ignore next 3 */\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\n//# sourceMappingURL=model.js.map","import { drop, forEach } from \"lodash-es\";\nimport { Alternation, Alternative, NonTerminal, Option, Repetition, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, Terminal, } from \"@chevrotain/gast\";\n/**\n *  A Grammar Walker that computes the \"remaining\" grammar \"after\" a productions in the grammar.\n */\nexport class RestWalker {\n    walk(prod, prevRest = []) {\n        forEach(prod.definition, (subProd, index) => {\n            const currRest = drop(prod.definition, index + 1);\n            /* istanbul ignore else */\n            if (subProd instanceof NonTerminal) {\n                this.walkProdRef(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof Terminal) {\n                this.walkTerminal(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof Alternative) {\n                this.walkFlat(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof Option) {\n                this.walkOption(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof RepetitionMandatory) {\n                this.walkAtLeastOne(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof RepetitionMandatoryWithSeparator) {\n                this.walkAtLeastOneSep(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof RepetitionWithSeparator) {\n                this.walkManySep(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof Repetition) {\n                this.walkMany(subProd, currRest, prevRest);\n            }\n            else if (subProd instanceof Alternation) {\n                this.walkOr(subProd, currRest, prevRest);\n            }\n            else {\n                throw Error(\"non exhaustive match\");\n            }\n        });\n    }\n    walkTerminal(terminal, currRest, prevRest) { }\n    walkProdRef(refProd, currRest, prevRest) { }\n    walkFlat(flatProd, currRest, prevRest) {\n        // ABCDEF => after the D the rest is EF\n        const fullOrRest = currRest.concat(prevRest);\n        this.walk(flatProd, fullOrRest);\n    }\n    walkOption(optionProd, currRest, prevRest) {\n        // ABC(DE)?F => after the (DE)? the rest is F\n        const fullOrRest = currRest.concat(prevRest);\n        this.walk(optionProd, fullOrRest);\n    }\n    walkAtLeastOne(atLeastOneProd, currRest, prevRest) {\n        // ABC(DE)+F => after the (DE)+ the rest is (DE)?F\n        const fullAtLeastOneRest = [\n            new Option({ definition: atLeastOneProd.definition }),\n        ].concat(currRest, prevRest);\n        this.walk(atLeastOneProd, fullAtLeastOneRest);\n    }\n    walkAtLeastOneSep(atLeastOneSepProd, currRest, prevRest) {\n        // ABC DE(,DE)* F => after the (,DE)+ the rest is (,DE)?F\n        const fullAtLeastOneSepRest = restForRepetitionWithSeparator(atLeastOneSepProd, currRest, prevRest);\n        this.walk(atLeastOneSepProd, fullAtLeastOneSepRest);\n    }\n    walkMany(manyProd, currRest, prevRest) {\n        // ABC(DE)*F => after the (DE)* the rest is (DE)?F\n        const fullManyRest = [\n            new Option({ definition: manyProd.definition }),\n        ].concat(currRest, prevRest);\n        this.walk(manyProd, fullManyRest);\n    }\n    walkManySep(manySepProd, currRest, prevRest) {\n        // ABC (DE(,DE)*)? F => after the (,DE)* the rest is (,DE)?F\n        const fullManySepRest = restForRepetitionWithSeparator(manySepProd, currRest, prevRest);\n        this.walk(manySepProd, fullManySepRest);\n    }\n    walkOr(orProd, currRest, prevRest) {\n        // ABC(D|E|F)G => when finding the (D|E|F) the rest is G\n        const fullOrRest = currRest.concat(prevRest);\n        // walk all different alternatives\n        forEach(orProd.definition, (alt) => {\n            // wrapping each alternative in a single definition wrapper\n            // to avoid errors in computing the rest of that alternative in the invocation to computeInProdFollows\n            // (otherwise for OR([alt1,alt2]) alt2 will be considered in 'rest' of alt1\n            const prodWrapper = new Alternative({ definition: [alt] });\n            this.walk(prodWrapper, fullOrRest);\n        });\n    }\n}\nfunction restForRepetitionWithSeparator(repSepProd, currRest, prevRest) {\n    const repSepRest = [\n        new Option({\n            definition: [\n                new Terminal({ terminalType: repSepProd.separator }),\n            ].concat(repSepProd.definition),\n        }),\n    ];\n    const fullRepSepRest = repSepRest.concat(currRest, prevRest);\n    return fullRepSepRest;\n}\n//# sourceMappingURL=rest.js.map","import baseUniq from './_baseUniq.js';\n\n/**\n * Creates a duplicate-free version of an array, using\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons, in which only the first occurrence of each element\n * is kept. The order of result values is determined by the order they occur\n * in the array.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @returns {Array} Returns the new duplicate free array.\n * @example\n *\n * _.uniq([2, 1, 2]);\n * // => [2, 1]\n */\nfunction uniq(array) {\n  return (array && array.length) ? baseUniq(array) : [];\n}\n\nexport default uniq;\n","import baseEach from './_baseEach.js';\n\n/**\n * The base implementation of `_.some` without support for iteratee shorthands.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {boolean} Returns `true` if any element passes the predicate check,\n *  else `false`.\n */\nfunction baseSome(collection, predicate) {\n  var result;\n\n  baseEach(collection, function(value, index, collection) {\n    result = predicate(value, index, collection);\n    return !result;\n  });\n  return !!result;\n}\n\nexport default baseSome;\n","import arraySome from './_arraySome.js';\nimport baseIteratee from './_baseIteratee.js';\nimport baseSome from './_baseSome.js';\nimport isArray from './isArray.js';\nimport isIterateeCall from './_isIterateeCall.js';\n\n/**\n * Checks if `predicate` returns truthy for **any** element of `collection`.\n * Iteration is stopped once `predicate` returns truthy. The predicate is\n * invoked with three arguments: (value, index|key, collection).\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {boolean} Returns `true` if any element passes the predicate check,\n *  else `false`.\n * @example\n *\n * _.some([null, 0, 'yes', false], Boolean);\n * // => true\n *\n * var users = [\n *   { 'user': 'barney', 'active': true },\n *   { 'user': 'fred',   'active': false }\n * ];\n *\n * // The `_.matches` iteratee shorthand.\n * _.some(users, { 'user': 'barney', 'active': false });\n * // => false\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.some(users, ['active', false]);\n * // => true\n *\n * // The `_.property` iteratee shorthand.\n * _.some(users, 'active');\n * // => true\n */\nfunction some(collection, predicate, guard) {\n  var func = isArray(collection) ? arraySome : baseSome;\n  if (guard && isIterateeCall(collection, predicate, guard)) {\n    predicate = undefined;\n  }\n  return func(collection, baseIteratee(predicate, 3));\n}\n\nexport default some;\n","import baseIndexOf from './_baseIndexOf.js';\nimport isArrayLike from './isArrayLike.js';\nimport isString from './isString.js';\nimport toInteger from './toInteger.js';\nimport values from './values.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * Checks if `value` is in `collection`. If `collection` is a string, it's\n * checked for a substring of `value`, otherwise\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * is used for equality comparisons. If `fromIndex` is negative, it's used as\n * the offset from the end of `collection`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object|string} collection The collection to inspect.\n * @param {*} value The value to search for.\n * @param {number} [fromIndex=0] The index to search from.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.reduce`.\n * @returns {boolean} Returns `true` if `value` is found, else `false`.\n * @example\n *\n * _.includes([1, 2, 3], 1);\n * // => true\n *\n * _.includes([1, 2, 3], 1, 2);\n * // => false\n *\n * _.includes({ 'a': 1, 'b': 2 }, 1);\n * // => true\n *\n * _.includes('abcd', 'bc');\n * // => true\n */\nfunction includes(collection, value, fromIndex, guard) {\n  collection = isArrayLike(collection) ? collection : values(collection);\n  fromIndex = (fromIndex && !guard) ? toInteger(fromIndex) : 0;\n\n  var length = collection.length;\n  if (fromIndex < 0) {\n    fromIndex = nativeMax(length + fromIndex, 0);\n  }\n  return isString(collection)\n    ? (fromIndex <= length && collection.indexOf(value, fromIndex) > -1)\n    : (!!length && baseIndexOf(collection, value, fromIndex) > -1);\n}\n\nexport default includes;\n","/**\n * A specialized version of `_.every` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {boolean} Returns `true` if all elements pass the predicate check,\n *  else `false`.\n */\nfunction arrayEvery(array, predicate) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  while (++index < length) {\n    if (!predicate(array[index], index, array)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport default arrayEvery;\n","import baseEach from './_baseEach.js';\n\n/**\n * The base implementation of `_.every` without support for iteratee shorthands.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {boolean} Returns `true` if all elements pass the predicate check,\n *  else `false`\n */\nfunction baseEvery(collection, predicate) {\n  var result = true;\n  baseEach(collection, function(value, index, collection) {\n    result = !!predicate(value, index, collection);\n    return result;\n  });\n  return result;\n}\n\nexport default baseEvery;\n","import arrayEvery from './_arrayEvery.js';\nimport baseEvery from './_baseEvery.js';\nimport baseIteratee from './_baseIteratee.js';\nimport isArray from './isArray.js';\nimport isIterateeCall from './_isIterateeCall.js';\n\n/**\n * Checks if `predicate` returns truthy for **all** elements of `collection`.\n * Iteration is stopped once `predicate` returns falsey. The predicate is\n * invoked with three arguments: (value, index|key, collection).\n *\n * **Note:** This method returns `true` for\n * [empty collections](https://en.wikipedia.org/wiki/Empty_set) because\n * [everything is true](https://en.wikipedia.org/wiki/Vacuous_truth) of\n * elements of empty collections.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {boolean} Returns `true` if all elements pass the predicate check,\n *  else `false`.\n * @example\n *\n * _.every([true, 1, null, 'yes'], Boolean);\n * // => false\n *\n * var users = [\n *   { 'user': 'barney', 'age': 36, 'active': false },\n *   { 'user': 'fred',   'age': 40, 'active': false }\n * ];\n *\n * // The `_.matches` iteratee shorthand.\n * _.every(users, { 'user': 'barney', 'active': false });\n * // => false\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.every(users, ['active', false]);\n * // => true\n *\n * // The `_.property` iteratee shorthand.\n * _.every(users, 'active');\n * // => false\n */\nfunction every(collection, predicate, guard) {\n  var func = isArray(collection) ? arrayEvery : baseEvery;\n  if (guard && isIterateeCall(collection, predicate, guard)) {\n    predicate = undefined;\n  }\n  return func(collection, baseIteratee(predicate, 3));\n}\n\nexport default every;\n","import { every, includes, some } from \"lodash-es\";\nimport { AbstractProduction, Alternation, Alternative, NonTerminal, Option, Repetition, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, Rule, Terminal, } from \"./model.js\";\nexport function isSequenceProd(prod) {\n    return (prod instanceof Alternative ||\n        prod instanceof Option ||\n        prod instanceof Repetition ||\n        prod instanceof RepetitionMandatory ||\n        prod instanceof RepetitionMandatoryWithSeparator ||\n        prod instanceof RepetitionWithSeparator ||\n        prod instanceof Terminal ||\n        prod instanceof Rule);\n}\nexport function isOptionalProd(prod, alreadyVisited = []) {\n    const isDirectlyOptional = prod instanceof Option ||\n        prod instanceof Repetition ||\n        prod instanceof RepetitionWithSeparator;\n    if (isDirectlyOptional) {\n        return true;\n    }\n    // note that this can cause infinite loop if one optional empty TOP production has a cyclic dependency with another\n    // empty optional top rule\n    // may be indirectly optional ((A?B?C?) | (D?E?F?))\n    if (prod instanceof Alternation) {\n        // for OR its enough for just one of the alternatives to be optional\n        return some(prod.definition, (subProd) => {\n            return isOptionalProd(subProd, alreadyVisited);\n        });\n    }\n    else if (prod instanceof NonTerminal && includes(alreadyVisited, prod)) {\n        // avoiding stack overflow due to infinite recursion\n        return false;\n    }\n    else if (prod instanceof AbstractProduction) {\n        if (prod instanceof NonTerminal) {\n            alreadyVisited.push(prod);\n        }\n        return every(prod.definition, (subProd) => {\n            return isOptionalProd(subProd, alreadyVisited);\n        });\n    }\n    else {\n        return false;\n    }\n}\nexport function isBranchingProd(prod) {\n    return prod instanceof Alternation;\n}\nexport function getProductionDslName(prod) {\n    /* istanbul ignore else */\n    if (prod instanceof NonTerminal) {\n        return \"SUBRULE\";\n    }\n    else if (prod instanceof Option) {\n        return \"OPTION\";\n    }\n    else if (prod instanceof Alternation) {\n        return \"OR\";\n    }\n    else if (prod instanceof RepetitionMandatory) {\n        return \"AT_LEAST_ONE\";\n    }\n    else if (prod instanceof RepetitionMandatoryWithSeparator) {\n        return \"AT_LEAST_ONE_SEP\";\n    }\n    else if (prod instanceof RepetitionWithSeparator) {\n        return \"MANY_SEP\";\n    }\n    else if (prod instanceof Repetition) {\n        return \"MANY\";\n    }\n    else if (prod instanceof Terminal) {\n        return \"CONSUME\";\n        /* c8 ignore next 3 */\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\n//# sourceMappingURL=helpers.js.map","import { flatten, map, uniq } from \"lodash-es\";\nimport { isBranchingProd, isOptionalProd, isSequenceProd, NonTerminal, Terminal, } from \"@chevrotain/gast\";\nexport function first(prod) {\n    /* istanbul ignore else */\n    if (prod instanceof NonTerminal) {\n        // this could in theory cause infinite loops if\n        // (1) prod A refs prod B.\n        // (2) prod B refs prod A\n        // (3) AB can match the empty set\n        // in other words a cycle where everything is optional so the first will keep\n        // looking ahead for the next optional part and will never exit\n        // currently there is no safeguard for this unique edge case because\n        // (1) not sure a grammar in which this can happen is useful for anything (productive)\n        return first(prod.referencedRule);\n    }\n    else if (prod instanceof Terminal) {\n        return firstForTerminal(prod);\n    }\n    else if (isSequenceProd(prod)) {\n        return firstForSequence(prod);\n    }\n    else if (isBranchingProd(prod)) {\n        return firstForBranching(prod);\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nexport function firstForSequence(prod) {\n    let firstSet = [];\n    const seq = prod.definition;\n    let nextSubProdIdx = 0;\n    let hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n    let currSubProd;\n    // so we enter the loop at least once (if the definition is not empty\n    let isLastInnerProdOptional = true;\n    // scan a sequence until it's end or until we have found a NONE optional production in it\n    while (hasInnerProdsRemaining && isLastInnerProdOptional) {\n        currSubProd = seq[nextSubProdIdx];\n        isLastInnerProdOptional = isOptionalProd(currSubProd);\n        firstSet = firstSet.concat(first(currSubProd));\n        nextSubProdIdx = nextSubProdIdx + 1;\n        hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n    }\n    return uniq(firstSet);\n}\nexport function firstForBranching(prod) {\n    const allAlternativesFirsts = map(prod.definition, (innerProd) => {\n        return first(innerProd);\n    });\n    return uniq(flatten(allAlternativesFirsts));\n}\nexport function firstForTerminal(terminal) {\n    return [terminal.terminalType];\n}\n//# sourceMappingURL=first.js.map","// TODO: can this be removed? where is it used?\nexport const IN = \"_~IN~_\";\n//# sourceMappingURL=constants.js.map","import { RestWalker } from \"./rest.js\";\nimport { first } from \"./first.js\";\nimport { assign, forEach } from \"lodash-es\";\nimport { IN } from \"../constants.js\";\nimport { Alternative } from \"@chevrotain/gast\";\n// This ResyncFollowsWalker computes all of the follows required for RESYNC\n// (skipping reference production).\nexport class ResyncFollowsWalker extends RestWalker {\n    constructor(topProd) {\n        super();\n        this.topProd = topProd;\n        this.follows = {};\n    }\n    startWalking() {\n        this.walk(this.topProd);\n        return this.follows;\n    }\n    walkTerminal(terminal, currRest, prevRest) {\n        // do nothing! just like in the public sector after 13:00\n    }\n    walkProdRef(refProd, currRest, prevRest) {\n        const followName = buildBetweenProdsFollowPrefix(refProd.referencedRule, refProd.idx) +\n            this.topProd.name;\n        const fullRest = currRest.concat(prevRest);\n        const restProd = new Alternative({ definition: fullRest });\n        const t_in_topProd_follows = first(restProd);\n        this.follows[followName] = t_in_topProd_follows;\n    }\n}\nexport function computeAllProdsFollows(topProductions) {\n    const reSyncFollows = {};\n    forEach(topProductions, (topProd) => {\n        const currRefsFollow = new ResyncFollowsWalker(topProd).startWalking();\n        assign(reSyncFollows, currRefsFollow);\n    });\n    return reSyncFollows;\n}\nexport function buildBetweenProdsFollowPrefix(inner, occurenceInParent) {\n    return inner.name + occurenceInParent + IN;\n}\nexport function buildInProdFollowPrefix(terminal) {\n    const terminalName = terminal.terminalType.name;\n    return terminalName + terminal.idx + IN;\n}\n//# sourceMappingURL=follow.js.map","/** Error message constants. */\nvar FUNC_ERROR_TEXT = 'Expected a function';\n\n/**\n * Creates a function that negates the result of the predicate `func`. The\n * `func` predicate is invoked with the `this` binding and arguments of the\n * created function.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Function\n * @param {Function} predicate The predicate to negate.\n * @returns {Function} Returns the new negated function.\n * @example\n *\n * function isEven(n) {\n *   return n % 2 == 0;\n * }\n *\n * _.filter([1, 2, 3, 4, 5, 6], _.negate(isEven));\n * // => [1, 3, 5]\n */\nfunction negate(predicate) {\n  if (typeof predicate != 'function') {\n    throw new TypeError(FUNC_ERROR_TEXT);\n  }\n  return function() {\n    var args = arguments;\n    switch (args.length) {\n      case 0: return !predicate.call(this);\n      case 1: return !predicate.call(this, args[0]);\n      case 2: return !predicate.call(this, args[0], args[1]);\n      case 3: return !predicate.call(this, args[0], args[1], args[2]);\n    }\n    return !predicate.apply(this, args);\n  };\n}\n\nexport default negate;\n","import arrayFilter from './_arrayFilter.js';\nimport baseFilter from './_baseFilter.js';\nimport baseIteratee from './_baseIteratee.js';\nimport isArray from './isArray.js';\nimport negate from './negate.js';\n\n/**\n * The opposite of `_.filter`; this method returns the elements of `collection`\n * that `predicate` does **not** return truthy for.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @returns {Array} Returns the new filtered array.\n * @see _.filter\n * @example\n *\n * var users = [\n *   { 'user': 'barney', 'age': 36, 'active': false },\n *   { 'user': 'fred',   'age': 40, 'active': true }\n * ];\n *\n * _.reject(users, function(o) { return !o.active; });\n * // => objects for ['fred']\n *\n * // The `_.matches` iteratee shorthand.\n * _.reject(users, { 'age': 40, 'active': true });\n * // => objects for ['barney']\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.reject(users, ['active', false]);\n * // => objects for ['fred']\n *\n * // The `_.property` iteratee shorthand.\n * _.reject(users, 'active');\n * // => objects for ['barney']\n */\nfunction reject(collection, predicate) {\n  var func = isArray(collection) ? arrayFilter : baseFilter;\n  return func(collection, negate(baseIteratee(predicate, 3)));\n}\n\nexport default reject;\n","import baseIndexOf from './_baseIndexOf.js';\nimport toInteger from './toInteger.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * Gets the index at which the first occurrence of `value` is found in `array`\n * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons. If `fromIndex` is negative, it's used as the\n * offset from the end of `array`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {*} value The value to search for.\n * @param {number} [fromIndex=0] The index to search from.\n * @returns {number} Returns the index of the matched value, else `-1`.\n * @example\n *\n * _.indexOf([1, 2, 1, 2], 2);\n * // => 1\n *\n * // Search from the `fromIndex`.\n * _.indexOf([1, 2, 1, 2], 2, 2);\n * // => 3\n */\nfunction indexOf(array, value, fromIndex) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return -1;\n  }\n  var index = fromIndex == null ? 0 : toInteger(fromIndex);\n  if (index < 0) {\n    index = nativeMax(length + index, 0);\n  }\n  return baseIndexOf(array, value, index);\n}\n\nexport default indexOf;\n","import SetCache from './_SetCache.js';\nimport arrayIncludes from './_arrayIncludes.js';\nimport arrayIncludesWith from './_arrayIncludesWith.js';\nimport arrayMap from './_arrayMap.js';\nimport baseUnary from './_baseUnary.js';\nimport cacheHas from './_cacheHas.js';\n\n/** Used as the size to enable large array optimizations. */\nvar LARGE_ARRAY_SIZE = 200;\n\n/**\n * The base implementation of methods like `_.difference` without support\n * for excluding multiple arrays or iteratee shorthands.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {Array} values The values to exclude.\n * @param {Function} [iteratee] The iteratee invoked per element.\n * @param {Function} [comparator] The comparator invoked per element.\n * @returns {Array} Returns the new array of filtered values.\n */\nfunction baseDifference(array, values, iteratee, comparator) {\n  var index = -1,\n      includes = arrayIncludes,\n      isCommon = true,\n      length = array.length,\n      result = [],\n      valuesLength = values.length;\n\n  if (!length) {\n    return result;\n  }\n  if (iteratee) {\n    values = arrayMap(values, baseUnary(iteratee));\n  }\n  if (comparator) {\n    includes = arrayIncludesWith;\n    isCommon = false;\n  }\n  else if (values.length >= LARGE_ARRAY_SIZE) {\n    includes = cacheHas;\n    isCommon = false;\n    values = new SetCache(values);\n  }\n  outer:\n  while (++index < length) {\n    var value = array[index],\n        computed = iteratee == null ? value : iteratee(value);\n\n    value = (comparator || value !== 0) ? value : 0;\n    if (isCommon && computed === computed) {\n      var valuesIndex = valuesLength;\n      while (valuesIndex--) {\n        if (values[valuesIndex] === computed) {\n          continue outer;\n        }\n      }\n      result.push(value);\n    }\n    else if (!includes(values, computed, comparator)) {\n      result.push(value);\n    }\n  }\n  return result;\n}\n\nexport default baseDifference;\n","import baseDifference from './_baseDifference.js';\nimport baseFlatten from './_baseFlatten.js';\nimport baseRest from './_baseRest.js';\nimport isArrayLikeObject from './isArrayLikeObject.js';\n\n/**\n * Creates an array of `array` values not included in the other given arrays\n * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons. The order and references of result values are\n * determined by the first array.\n *\n * **Note:** Unlike `_.pullAll`, this method returns a new array.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {...Array} [values] The values to exclude.\n * @returns {Array} Returns the new array of filtered values.\n * @see _.without, _.xor\n * @example\n *\n * _.difference([2, 1], [2, 3]);\n * // => [1]\n */\nvar difference = baseRest(function(array, values) {\n  return isArrayLikeObject(array)\n    ? baseDifference(array, baseFlatten(values, 1, isArrayLikeObject, true))\n    : [];\n});\n\nexport default difference;\n","/**\n * Creates an array with all falsey values removed. The values `false`, `null`,\n * `0`, `\"\"`, `undefined`, and `NaN` are falsey.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to compact.\n * @returns {Array} Returns the new array of filtered values.\n * @example\n *\n * _.compact([0, 1, false, 2, '', 3]);\n * // => [1, 2, 3]\n */\nfunction compact(array) {\n  var index = -1,\n      length = array == null ? 0 : array.length,\n      resIndex = 0,\n      result = [];\n\n  while (++index < length) {\n    var value = array[index];\n    if (value) {\n      result[resIndex++] = value;\n    }\n  }\n  return result;\n}\n\nexport default compact;\n","/**\n * Gets the first element of `array`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @alias first\n * @category Array\n * @param {Array} array The array to query.\n * @returns {*} Returns the first element of `array`.\n * @example\n *\n * _.head([1, 2, 3]);\n * // => 1\n *\n * _.head([]);\n * // => undefined\n */\nfunction head(array) {\n  return (array && array.length) ? array[0] : undefined;\n}\n\nexport default head;\n","export function PRINT_ERROR(msg) {\n    /* istanbul ignore else - can't override global.console in node.js */\n    if (console && console.error) {\n        console.error(`Error: ${msg}`);\n    }\n}\nexport function PRINT_WARNING(msg) {\n    /* istanbul ignore else - can't override global.console in node.js*/\n    if (console && console.warn) {\n        // TODO: modify docs accordingly\n        console.warn(`Warning: ${msg}`);\n    }\n}\n//# sourceMappingURL=print.js.map","import { RegExpParser, } from \"@chevrotain/regexp-to-ast\";\nlet regExpAstCache = {};\nconst regExpParser = new RegExpParser();\nexport function getRegExpAst(regExp) {\n    const regExpStr = regExp.toString();\n    if (regExpAstCache.hasOwnProperty(regExpStr)) {\n        return regExpAstCache[regExpStr];\n    }\n    else {\n        const regExpAst = regExpParser.pattern(regExpStr);\n        regExpAstCache[regExpStr] = regExpAst;\n        return regExpAst;\n    }\n}\nexport function clearRegExpParserCache() {\n    regExpAstCache = {};\n}\n//# sourceMappingURL=reg_exp_parser.js.map","import { BaseRegExpVisitor, } from \"@chevrotain/regexp-to-ast\";\nimport { every, find, forEach, includes, isArray, values } from \"lodash-es\";\nimport { PRINT_ERROR, PRINT_WARNING } from \"@chevrotain/utils\";\nimport { getRegExpAst } from \"./reg_exp_parser.js\";\nimport { charCodeToOptimizedIndex, minOptimizationVal } from \"./lexer.js\";\nconst complementErrorMessage = \"Complement Sets are not supported for first char optimization\";\nexport const failedOptimizationPrefixMsg = 'Unable to use \"first char\" lexer optimizations:\\n';\nexport function getOptimizedStartCodesIndices(regExp, ensureOptimizations = false) {\n    try {\n        const ast = getRegExpAst(regExp);\n        const firstChars = firstCharOptimizedIndices(ast.value, {}, ast.flags.ignoreCase);\n        return firstChars;\n    }\n    catch (e) {\n        /* istanbul ignore next */\n        // Testing this relies on the regexp-to-ast library having a bug... */\n        // TODO: only the else branch needs to be ignored, try to fix with newer prettier / tsc\n        if (e.message === complementErrorMessage) {\n            if (ensureOptimizations) {\n                PRINT_WARNING(`${failedOptimizationPrefixMsg}` +\n                    `\\tUnable to optimize: < ${regExp.toString()} >\\n` +\n                    \"\\tComplement Sets cannot be automatically optimized.\\n\" +\n                    \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                    \"\\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#COMPLEMENT for details.\");\n            }\n        }\n        else {\n            let msgSuffix = \"\";\n            if (ensureOptimizations) {\n                msgSuffix =\n                    \"\\n\\tThis will disable the lexer's first char optimizations.\\n\" +\n                        \"\\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#REGEXP_PARSING for details.\";\n            }\n            PRINT_ERROR(`${failedOptimizationPrefixMsg}\\n` +\n                `\\tFailed parsing: < ${regExp.toString()} >\\n` +\n                `\\tUsing the @chevrotain/regexp-to-ast library\\n` +\n                \"\\tPlease open an issue at: https://github.com/chevrotain/chevrotain/issues\" +\n                msgSuffix);\n        }\n    }\n    return [];\n}\nexport function firstCharOptimizedIndices(ast, result, ignoreCase) {\n    switch (ast.type) {\n        case \"Disjunction\":\n            for (let i = 0; i < ast.value.length; i++) {\n                firstCharOptimizedIndices(ast.value[i], result, ignoreCase);\n            }\n            break;\n        case \"Alternative\":\n            const terms = ast.value;\n            for (let i = 0; i < terms.length; i++) {\n                const term = terms[i];\n                // skip terms that cannot effect the first char results\n                switch (term.type) {\n                    case \"EndAnchor\":\n                    // A group back reference cannot affect potential starting char.\n                    // because if a back reference is the first production than automatically\n                    // the group being referenced has had to come BEFORE so its codes have already been added\n                    case \"GroupBackReference\":\n                    // assertions do not affect potential starting codes\n                    case \"Lookahead\":\n                    case \"NegativeLookahead\":\n                    case \"Lookbehind\":\n                    case \"NegativeLookbehind\":\n                    case \"StartAnchor\":\n                    case \"WordBoundary\":\n                    case \"NonWordBoundary\":\n                        continue;\n                }\n                const atom = term;\n                switch (atom.type) {\n                    case \"Character\":\n                        addOptimizedIdxToResult(atom.value, result, ignoreCase);\n                        break;\n                    case \"Set\":\n                        if (atom.complement === true) {\n                            throw Error(complementErrorMessage);\n                        }\n                        forEach(atom.value, (code) => {\n                            if (typeof code === \"number\") {\n                                addOptimizedIdxToResult(code, result, ignoreCase);\n                            }\n                            else {\n                                // range\n                                const range = code;\n                                // cannot optimize when ignoreCase is\n                                if (ignoreCase === true) {\n                                    for (let rangeCode = range.from; rangeCode <= range.to; rangeCode++) {\n                                        addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                                    }\n                                }\n                                // Optimization (2 orders of magnitude less work for very large ranges)\n                                else {\n                                    // handle unoptimized values\n                                    for (let rangeCode = range.from; rangeCode <= range.to && rangeCode < minOptimizationVal; rangeCode++) {\n                                        addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                                    }\n                                    // Less common charCode where we optimize for faster init time, by using larger \"buckets\"\n                                    if (range.to >= minOptimizationVal) {\n                                        const minUnOptVal = range.from >= minOptimizationVal\n                                            ? range.from\n                                            : minOptimizationVal;\n                                        const maxUnOptVal = range.to;\n                                        const minOptIdx = charCodeToOptimizedIndex(minUnOptVal);\n                                        const maxOptIdx = charCodeToOptimizedIndex(maxUnOptVal);\n                                        for (let currOptIdx = minOptIdx; currOptIdx <= maxOptIdx; currOptIdx++) {\n                                            result[currOptIdx] = currOptIdx;\n                                        }\n                                    }\n                                }\n                            }\n                        });\n                        break;\n                    case \"Group\":\n                        firstCharOptimizedIndices(atom.value, result, ignoreCase);\n                        break;\n                    /* istanbul ignore next */\n                    default:\n                        throw Error(\"Non Exhaustive Match\");\n                }\n                // reached a mandatory production, no more **start** codes can be found on this alternative\n                const isOptionalQuantifier = atom.quantifier !== undefined && atom.quantifier.atLeast === 0;\n                if (\n                // A group may be optional due to empty contents /(?:)/\n                // or if everything inside it is optional /((a)?)/\n                (atom.type === \"Group\" && isWholeOptional(atom) === false) ||\n                    // If this term is not a group it may only be optional if it has an optional quantifier\n                    (atom.type !== \"Group\" && isOptionalQuantifier === false)) {\n                    break;\n                }\n            }\n            break;\n        /* istanbul ignore next */\n        default:\n            throw Error(\"non exhaustive match!\");\n    }\n    // console.log(Object.keys(result).length)\n    return values(result);\n}\nfunction addOptimizedIdxToResult(code, result, ignoreCase) {\n    const optimizedCharIdx = charCodeToOptimizedIndex(code);\n    result[optimizedCharIdx] = optimizedCharIdx;\n    if (ignoreCase === true) {\n        handleIgnoreCase(code, result);\n    }\n}\nfunction handleIgnoreCase(code, result) {\n    const char = String.fromCharCode(code);\n    const upperChar = char.toUpperCase();\n    /* istanbul ignore else */\n    if (upperChar !== char) {\n        const optimizedCharIdx = charCodeToOptimizedIndex(upperChar.charCodeAt(0));\n        result[optimizedCharIdx] = optimizedCharIdx;\n    }\n    else {\n        const lowerChar = char.toLowerCase();\n        if (lowerChar !== char) {\n            const optimizedCharIdx = charCodeToOptimizedIndex(lowerChar.charCodeAt(0));\n            result[optimizedCharIdx] = optimizedCharIdx;\n        }\n    }\n}\nfunction findCode(setNode, targetCharCodes) {\n    return find(setNode.value, (codeOrRange) => {\n        if (typeof codeOrRange === \"number\") {\n            return includes(targetCharCodes, codeOrRange);\n        }\n        else {\n            // range\n            const range = codeOrRange;\n            return (find(targetCharCodes, (targetCode) => range.from <= targetCode && targetCode <= range.to) !== undefined);\n        }\n    });\n}\nfunction isWholeOptional(ast) {\n    const quantifier = ast.quantifier;\n    if (quantifier && quantifier.atLeast === 0) {\n        return true;\n    }\n    if (!ast.value) {\n        return false;\n    }\n    return isArray(ast.value)\n        ? every(ast.value, isWholeOptional)\n        : isWholeOptional(ast.value);\n}\nclass CharCodeFinder extends BaseRegExpVisitor {\n    constructor(targetCharCodes) {\n        super();\n        this.targetCharCodes = targetCharCodes;\n        this.found = false;\n    }\n    visitChildren(node) {\n        // No need to keep looking...\n        if (this.found === true) {\n            return;\n        }\n        // switch lookaheads / lookbehinds as they do not actually consume any characters thus\n        // finding a charCode at lookahead context does not mean that regexp can actually contain it in a match.\n        switch (node.type) {\n            case \"Lookahead\":\n                this.visitLookahead(node);\n                return;\n            case \"NegativeLookahead\":\n                this.visitNegativeLookahead(node);\n                return;\n            case \"Lookbehind\":\n                this.visitLookbehind(node);\n                return;\n            case \"NegativeLookbehind\":\n                this.visitNegativeLookbehind(node);\n                return;\n        }\n        super.visitChildren(node);\n    }\n    visitCharacter(node) {\n        if (includes(this.targetCharCodes, node.value)) {\n            this.found = true;\n        }\n    }\n    visitSet(node) {\n        if (node.complement) {\n            if (findCode(node, this.targetCharCodes) === undefined) {\n                this.found = true;\n            }\n        }\n        else {\n            if (findCode(node, this.targetCharCodes) !== undefined) {\n                this.found = true;\n            }\n        }\n    }\n}\nexport function canMatchCharCode(charCodes, pattern) {\n    if (pattern instanceof RegExp) {\n        const ast = getRegExpAst(pattern);\n        const charCodeFinder = new CharCodeFinder(charCodes);\n        charCodeFinder.visit(ast);\n        return charCodeFinder.found;\n    }\n    else {\n        return (find(pattern, (char) => {\n            return includes(charCodes, char.charCodeAt(0));\n        }) !== undefined);\n    }\n}\n//# sourceMappingURL=reg_exp.js.map","import { BaseRegExpVisitor } from \"@chevrotain/regexp-to-ast\";\nimport { Lexer, LexerDefinitionErrorType, } from \"./lexer_public.js\";\nimport { compact, defaults, difference, filter, find, first, flatten, forEach, has, includes, indexOf, isArray, isEmpty, isFunction, isRegExp, isString, isUndefined, keys, map, reduce, reject, values, } from \"lodash-es\";\nimport { PRINT_ERROR } from \"@chevrotain/utils\";\nimport { canMatchCharCode, failedOptimizationPrefixMsg, getOptimizedStartCodesIndices, } from \"./reg_exp.js\";\nimport { getRegExpAst } from \"./reg_exp_parser.js\";\nconst PATTERN = \"PATTERN\";\nexport const DEFAULT_MODE = \"defaultMode\";\nexport const MODES = \"modes\";\nexport let SUPPORT_STICKY = typeof new RegExp(\"(?:)\").sticky === \"boolean\";\nexport function disableSticky() {\n    SUPPORT_STICKY = false;\n}\nexport function enableSticky() {\n    SUPPORT_STICKY = true;\n}\nexport function analyzeTokenTypes(tokenTypes, options) {\n    options = defaults(options, {\n        useSticky: SUPPORT_STICKY,\n        debug: false,\n        safeMode: false,\n        positionTracking: \"full\",\n        lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n        tracer: (msg, action) => action(),\n    });\n    const tracer = options.tracer;\n    tracer(\"initCharCodeToOptimizedIndexMap\", () => {\n        initCharCodeToOptimizedIndexMap();\n    });\n    let onlyRelevantTypes;\n    tracer(\"Reject Lexer.NA\", () => {\n        onlyRelevantTypes = reject(tokenTypes, (currType) => {\n            return currType[PATTERN] === Lexer.NA;\n        });\n    });\n    let hasCustom = false;\n    let allTransformedPatterns;\n    tracer(\"Transform Patterns\", () => {\n        hasCustom = false;\n        allTransformedPatterns = map(onlyRelevantTypes, (currType) => {\n            const currPattern = currType[PATTERN];\n            /* istanbul ignore else */\n            if (isRegExp(currPattern)) {\n                const regExpSource = currPattern.source;\n                if (regExpSource.length === 1 &&\n                    // only these regExp meta characters which can appear in a length one regExp\n                    regExpSource !== \"^\" &&\n                    regExpSource !== \"$\" &&\n                    regExpSource !== \".\" &&\n                    !currPattern.ignoreCase) {\n                    return regExpSource;\n                }\n                else if (regExpSource.length === 2 &&\n                    regExpSource[0] === \"\\\\\" &&\n                    // not a meta character\n                    !includes([\n                        \"d\",\n                        \"D\",\n                        \"s\",\n                        \"S\",\n                        \"t\",\n                        \"r\",\n                        \"n\",\n                        \"t\",\n                        \"0\",\n                        \"c\",\n                        \"b\",\n                        \"B\",\n                        \"f\",\n                        \"v\",\n                        \"w\",\n                        \"W\",\n                    ], regExpSource[1])) {\n                    // escaped meta Characters: /\\+/ /\\[/\n                    // or redundant escaping: /\\a/\n                    // without the escaping \"\\\"\n                    return regExpSource[1];\n                }\n                else {\n                    return options.useSticky\n                        ? addStickyFlag(currPattern)\n                        : addStartOfInput(currPattern);\n                }\n            }\n            else if (isFunction(currPattern)) {\n                hasCustom = true;\n                // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n                return { exec: currPattern };\n            }\n            else if (typeof currPattern === \"object\") {\n                hasCustom = true;\n                // ICustomPattern\n                return currPattern;\n            }\n            else if (typeof currPattern === \"string\") {\n                if (currPattern.length === 1) {\n                    return currPattern;\n                }\n                else {\n                    const escapedRegExpString = currPattern.replace(/[\\\\^$.*+?()[\\]{}|]/g, \"\\\\$&\");\n                    const wrappedRegExp = new RegExp(escapedRegExpString);\n                    return options.useSticky\n                        ? addStickyFlag(wrappedRegExp)\n                        : addStartOfInput(wrappedRegExp);\n                }\n            }\n            else {\n                throw Error(\"non exhaustive match\");\n            }\n        });\n    });\n    let patternIdxToType;\n    let patternIdxToGroup;\n    let patternIdxToLongerAltIdxArr;\n    let patternIdxToPushMode;\n    let patternIdxToPopMode;\n    tracer(\"misc mapping\", () => {\n        patternIdxToType = map(onlyRelevantTypes, (currType) => currType.tokenTypeIdx);\n        patternIdxToGroup = map(onlyRelevantTypes, (clazz) => {\n            const groupName = clazz.GROUP;\n            /* istanbul ignore next */\n            if (groupName === Lexer.SKIPPED) {\n                return undefined;\n            }\n            else if (isString(groupName)) {\n                return groupName;\n            }\n            else if (isUndefined(groupName)) {\n                return false;\n            }\n            else {\n                throw Error(\"non exhaustive match\");\n            }\n        });\n        patternIdxToLongerAltIdxArr = map(onlyRelevantTypes, (clazz) => {\n            const longerAltType = clazz.LONGER_ALT;\n            if (longerAltType) {\n                const longerAltIdxArr = isArray(longerAltType)\n                    ? map(longerAltType, (type) => indexOf(onlyRelevantTypes, type))\n                    : [indexOf(onlyRelevantTypes, longerAltType)];\n                return longerAltIdxArr;\n            }\n        });\n        patternIdxToPushMode = map(onlyRelevantTypes, (clazz) => clazz.PUSH_MODE);\n        patternIdxToPopMode = map(onlyRelevantTypes, (clazz) => has(clazz, \"POP_MODE\"));\n    });\n    let patternIdxToCanLineTerminator;\n    tracer(\"Line Terminator Handling\", () => {\n        const lineTerminatorCharCodes = getCharCodes(options.lineTerminatorCharacters);\n        patternIdxToCanLineTerminator = map(onlyRelevantTypes, (tokType) => false);\n        if (options.positionTracking !== \"onlyOffset\") {\n            patternIdxToCanLineTerminator = map(onlyRelevantTypes, (tokType) => {\n                if (has(tokType, \"LINE_BREAKS\")) {\n                    return !!tokType.LINE_BREAKS;\n                }\n                else {\n                    return (checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false &&\n                        canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN));\n                }\n            });\n        }\n    });\n    let patternIdxToIsCustom;\n    let patternIdxToShort;\n    let emptyGroups;\n    let patternIdxToConfig;\n    tracer(\"Misc Mapping #2\", () => {\n        patternIdxToIsCustom = map(onlyRelevantTypes, isCustomPattern);\n        patternIdxToShort = map(allTransformedPatterns, isShortPattern);\n        emptyGroups = reduce(onlyRelevantTypes, (acc, clazz) => {\n            const groupName = clazz.GROUP;\n            if (isString(groupName) && !(groupName === Lexer.SKIPPED)) {\n                acc[groupName] = [];\n            }\n            return acc;\n        }, {});\n        patternIdxToConfig = map(allTransformedPatterns, (x, idx) => {\n            return {\n                pattern: allTransformedPatterns[idx],\n                longerAlt: patternIdxToLongerAltIdxArr[idx],\n                canLineTerminator: patternIdxToCanLineTerminator[idx],\n                isCustom: patternIdxToIsCustom[idx],\n                short: patternIdxToShort[idx],\n                group: patternIdxToGroup[idx],\n                push: patternIdxToPushMode[idx],\n                pop: patternIdxToPopMode[idx],\n                tokenTypeIdx: patternIdxToType[idx],\n                tokenType: onlyRelevantTypes[idx],\n            };\n        });\n    });\n    let canBeOptimized = true;\n    let charCodeToPatternIdxToConfig = [];\n    if (!options.safeMode) {\n        tracer(\"First Char Optimization\", () => {\n            charCodeToPatternIdxToConfig = reduce(onlyRelevantTypes, (result, currTokType, idx) => {\n                if (typeof currTokType.PATTERN === \"string\") {\n                    const charCode = currTokType.PATTERN.charCodeAt(0);\n                    const optimizedIdx = charCodeToOptimizedIndex(charCode);\n                    addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n                }\n                else if (isArray(currTokType.START_CHARS_HINT)) {\n                    let lastOptimizedIdx;\n                    forEach(currTokType.START_CHARS_HINT, (charOrInt) => {\n                        const charCode = typeof charOrInt === \"string\"\n                            ? charOrInt.charCodeAt(0)\n                            : charOrInt;\n                        const currOptimizedIdx = charCodeToOptimizedIndex(charCode);\n                        // Avoid adding the config multiple times\n                        /* istanbul ignore else */\n                        // - Difficult to check this scenario effects as it is only a performance\n                        //   optimization that does not change correctness\n                        if (lastOptimizedIdx !== currOptimizedIdx) {\n                            lastOptimizedIdx = currOptimizedIdx;\n                            addToMapOfArrays(result, currOptimizedIdx, patternIdxToConfig[idx]);\n                        }\n                    });\n                }\n                else if (isRegExp(currTokType.PATTERN)) {\n                    if (currTokType.PATTERN.unicode) {\n                        canBeOptimized = false;\n                        if (options.ensureOptimizations) {\n                            PRINT_ERROR(`${failedOptimizationPrefixMsg}` +\n                                `\\tUnable to analyze < ${currTokType.PATTERN.toString()} > pattern.\\n` +\n                                \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" +\n                                \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                                \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\");\n                        }\n                    }\n                    else {\n                        const optimizedCodes = getOptimizedStartCodesIndices(currTokType.PATTERN, options.ensureOptimizations);\n                        /* istanbul ignore if */\n                        // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n                        // the first should be a different validation and the second cannot be tested.\n                        if (isEmpty(optimizedCodes)) {\n                            // we cannot understand what codes may start possible matches\n                            // The optimization correctness requires knowing start codes for ALL patterns.\n                            // Not actually sure this is an error, no debug message\n                            canBeOptimized = false;\n                        }\n                        forEach(optimizedCodes, (code) => {\n                            addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n                        });\n                    }\n                }\n                else {\n                    if (options.ensureOptimizations) {\n                        PRINT_ERROR(`${failedOptimizationPrefixMsg}` +\n                            `\\tTokenType: <${currTokType.name}> is using a custom token pattern without providing <start_chars_hint> parameter.\\n` +\n                            \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\");\n                    }\n                    canBeOptimized = false;\n                }\n                return result;\n            }, []);\n        });\n    }\n    return {\n        emptyGroups: emptyGroups,\n        patternIdxToConfig: patternIdxToConfig,\n        charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n        hasCustom: hasCustom,\n        canBeOptimized: canBeOptimized,\n    };\n}\nexport function validatePatterns(tokenTypes, validModesNames) {\n    let errors = [];\n    const missingResult = findMissingPatterns(tokenTypes);\n    errors = errors.concat(missingResult.errors);\n    const invalidResult = findInvalidPatterns(missingResult.valid);\n    const validTokenTypes = invalidResult.valid;\n    errors = errors.concat(invalidResult.errors);\n    errors = errors.concat(validateRegExpPattern(validTokenTypes));\n    errors = errors.concat(findInvalidGroupType(validTokenTypes));\n    errors = errors.concat(findModesThatDoNotExist(validTokenTypes, validModesNames));\n    errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n    return errors;\n}\nfunction validateRegExpPattern(tokenTypes) {\n    let errors = [];\n    const withRegExpPatterns = filter(tokenTypes, (currTokType) => isRegExp(currTokType[PATTERN]));\n    errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n    errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n    errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n    errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n    errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n    return errors;\n}\nexport function findMissingPatterns(tokenTypes) {\n    const tokenTypesWithMissingPattern = filter(tokenTypes, (currType) => {\n        return !has(currType, PATTERN);\n    });\n    const errors = map(tokenTypesWithMissingPattern, (currType) => {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- missing static 'PATTERN' property\",\n            type: LexerDefinitionErrorType.MISSING_PATTERN,\n            tokenTypes: [currType],\n        };\n    });\n    const valid = difference(tokenTypes, tokenTypesWithMissingPattern);\n    return { errors, valid };\n}\nexport function findInvalidPatterns(tokenTypes) {\n    const tokenTypesWithInvalidPattern = filter(tokenTypes, (currType) => {\n        const pattern = currType[PATTERN];\n        return (!isRegExp(pattern) &&\n            !isFunction(pattern) &&\n            !has(pattern, \"exec\") &&\n            !isString(pattern));\n    });\n    const errors = map(tokenTypesWithInvalidPattern, (currType) => {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' can only be a RegExp, a\" +\n                \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n            type: LexerDefinitionErrorType.INVALID_PATTERN,\n            tokenTypes: [currType],\n        };\n    });\n    const valid = difference(tokenTypes, tokenTypesWithInvalidPattern);\n    return { errors, valid };\n}\nconst end_of_input = /[^\\\\][$]/;\nexport function findEndOfInputAnchor(tokenTypes) {\n    class EndAnchorFinder extends BaseRegExpVisitor {\n        constructor() {\n            super(...arguments);\n            this.found = false;\n        }\n        visitEndAnchor(node) {\n            this.found = true;\n        }\n    }\n    const invalidRegex = filter(tokenTypes, (currType) => {\n        const pattern = currType.PATTERN;\n        try {\n            const regexpAst = getRegExpAst(pattern);\n            const endAnchorVisitor = new EndAnchorFinder();\n            endAnchorVisitor.visit(regexpAst);\n            return endAnchorVisitor.found;\n        }\n        catch (e) {\n            // old behavior in case of runtime exceptions with regexp-to-ast.\n            /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n            return end_of_input.test(pattern.source);\n        }\n    });\n    const errors = map(invalidRegex, (currType) => {\n        return {\n            message: \"Unexpected RegExp Anchor Error:\\n\" +\n                \"\\tToken Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" +\n                \"\\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n                \"\\tfor details.\",\n            type: LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n            tokenTypes: [currType],\n        };\n    });\n    return errors;\n}\nexport function findEmptyMatchRegExps(tokenTypes) {\n    const matchesEmptyString = filter(tokenTypes, (currType) => {\n        const pattern = currType.PATTERN;\n        return pattern.test(\"\");\n    });\n    const errors = map(matchesEmptyString, (currType) => {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' must not match an empty string\",\n            type: LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n            tokenTypes: [currType],\n        };\n    });\n    return errors;\n}\nconst start_of_input = /[^\\\\[][\\^]|^\\^/;\nexport function findStartOfInputAnchor(tokenTypes) {\n    class StartAnchorFinder extends BaseRegExpVisitor {\n        constructor() {\n            super(...arguments);\n            this.found = false;\n        }\n        visitStartAnchor(node) {\n            this.found = true;\n        }\n    }\n    const invalidRegex = filter(tokenTypes, (currType) => {\n        const pattern = currType.PATTERN;\n        try {\n            const regexpAst = getRegExpAst(pattern);\n            const startAnchorVisitor = new StartAnchorFinder();\n            startAnchorVisitor.visit(regexpAst);\n            return startAnchorVisitor.found;\n        }\n        catch (e) {\n            // old behavior in case of runtime exceptions with regexp-to-ast.\n            /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n            return start_of_input.test(pattern.source);\n        }\n    });\n    const errors = map(invalidRegex, (currType) => {\n        return {\n            message: \"Unexpected RegExp Anchor Error:\\n\" +\n                \"\\tToken Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" +\n                \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n                \"\\tfor details.\",\n            type: LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n            tokenTypes: [currType],\n        };\n    });\n    return errors;\n}\nexport function findUnsupportedFlags(tokenTypes) {\n    const invalidFlags = filter(tokenTypes, (currType) => {\n        const pattern = currType[PATTERN];\n        return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n    });\n    const errors = map(invalidFlags, (currType) => {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n            type: LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n            tokenTypes: [currType],\n        };\n    });\n    return errors;\n}\n// This can only test for identical duplicate RegExps, not semantically equivalent ones.\nexport function findDuplicatePatterns(tokenTypes) {\n    const found = [];\n    let identicalPatterns = map(tokenTypes, (outerType) => {\n        return reduce(tokenTypes, (result, innerType) => {\n            if (outerType.PATTERN.source === innerType.PATTERN.source &&\n                !includes(found, innerType) &&\n                innerType.PATTERN !== Lexer.NA) {\n                // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n                // in essence we are creating Equivalence classes on equality relation.\n                found.push(innerType);\n                result.push(innerType);\n                return result;\n            }\n            return result;\n        }, []);\n    });\n    identicalPatterns = compact(identicalPatterns);\n    const duplicatePatterns = filter(identicalPatterns, (currIdenticalSet) => {\n        return currIdenticalSet.length > 1;\n    });\n    const errors = map(duplicatePatterns, (setOfIdentical) => {\n        const tokenTypeNames = map(setOfIdentical, (currType) => {\n            return currType.name;\n        });\n        const dupPatternSrc = first(setOfIdentical).PATTERN;\n        return {\n            message: `The same RegExp pattern ->${dupPatternSrc}<-` +\n                `has been used in all of the following Token Types: ${tokenTypeNames.join(\", \")} <-`,\n            type: LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n            tokenTypes: setOfIdentical,\n        };\n    });\n    return errors;\n}\nexport function findInvalidGroupType(tokenTypes) {\n    const invalidTypes = filter(tokenTypes, (clazz) => {\n        if (!has(clazz, \"GROUP\")) {\n            return false;\n        }\n        const group = clazz.GROUP;\n        return group !== Lexer.SKIPPED && group !== Lexer.NA && !isString(group);\n    });\n    const errors = map(invalidTypes, (currType) => {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n            type: LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n            tokenTypes: [currType],\n        };\n    });\n    return errors;\n}\nexport function findModesThatDoNotExist(tokenTypes, validModes) {\n    const invalidModes = filter(tokenTypes, (clazz) => {\n        return (clazz.PUSH_MODE !== undefined && !includes(validModes, clazz.PUSH_MODE));\n    });\n    const errors = map(invalidModes, (tokType) => {\n        const msg = `Token Type: ->${tokType.name}<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->${tokType.PUSH_MODE}<-` +\n            `which does not exist`;\n        return {\n            message: msg,\n            type: LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n            tokenTypes: [tokType],\n        };\n    });\n    return errors;\n}\nexport function findUnreachablePatterns(tokenTypes) {\n    const errors = [];\n    const canBeTested = reduce(tokenTypes, (result, tokType, idx) => {\n        const pattern = tokType.PATTERN;\n        if (pattern === Lexer.NA) {\n            return result;\n        }\n        // a more comprehensive validation for all forms of regExps would require\n        // deeper regExp analysis capabilities\n        if (isString(pattern)) {\n            result.push({ str: pattern, idx, tokenType: tokType });\n        }\n        else if (isRegExp(pattern) && noMetaChar(pattern)) {\n            result.push({ str: pattern.source, idx, tokenType: tokType });\n        }\n        return result;\n    }, []);\n    forEach(tokenTypes, (aTokType, aIdx) => {\n        forEach(canBeTested, ({ str: bStr, idx: bIdx, tokenType: bTokType }) => {\n            if (aIdx < bIdx && tryToMatchStrToPattern(bStr, aTokType.PATTERN)) {\n                const msg = `Token: ->${bTokType.name}<- can never be matched.\\n` +\n                    `Because it appears AFTER the Token Type ->${aTokType.name}<-` +\n                    `in the lexer's definition.\\n` +\n                    `See https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE`;\n                errors.push({\n                    message: msg,\n                    type: LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n                    tokenTypes: [aTokType, bTokType],\n                });\n            }\n        });\n    });\n    return errors;\n}\nfunction tryToMatchStrToPattern(str, pattern) {\n    if (isRegExp(pattern)) {\n        if (usesLookAheadOrBehind(pattern)) {\n            // if lookahead or lookbehind assertions are used\n            // we assume they would be responsible for disambiguating the match\n            // The alternative is to risk false positive unreachable pattern errors.\n            // e.g.: /(?<!a)b/ and /b/ tokens would cause such false positives.\n            return false;\n        }\n        const regExpArray = pattern.exec(str);\n        return regExpArray !== null && regExpArray.index === 0;\n    }\n    else if (isFunction(pattern)) {\n        // maintain the API of custom patterns\n        return pattern(str, 0, [], {});\n    }\n    else if (has(pattern, \"exec\")) {\n        // maintain the API of custom patterns\n        return pattern.exec(str, 0, [], {});\n    }\n    else if (typeof pattern === \"string\") {\n        return pattern === str;\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nfunction noMetaChar(regExp) {\n    //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n    const metaChars = [\n        \".\",\n        \"\\\\\",\n        \"[\",\n        \"]\",\n        \"|\",\n        \"^\",\n        \"$\",\n        \"(\",\n        \")\",\n        \"?\",\n        \"*\",\n        \"+\",\n        \"{\",\n    ];\n    return (find(metaChars, (char) => regExp.source.indexOf(char) !== -1) === undefined);\n}\nfunction usesLookAheadOrBehind(regExp) {\n    return /(\\(\\?=)|(\\(\\?!)|(\\(\\?<=)|(\\(\\?<!)/.test(regExp.source);\n}\nexport function addStartOfInput(pattern) {\n    const flags = pattern.ignoreCase ? \"i\" : \"\";\n    // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n    // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n    return new RegExp(`^(?:${pattern.source})`, flags);\n}\nexport function addStickyFlag(pattern) {\n    const flags = pattern.ignoreCase ? \"iy\" : \"y\";\n    // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n    // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n    return new RegExp(`${pattern.source}`, flags);\n}\nexport function performRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n    const errors = [];\n    // some run time checks to help the end users.\n    if (!has(lexerDefinition, DEFAULT_MODE)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized without a <\" +\n                DEFAULT_MODE +\n                \"> property in its definition\\n\",\n            type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE,\n        });\n    }\n    if (!has(lexerDefinition, MODES)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized without a <\" +\n                MODES +\n                \"> property in its definition\\n\",\n            type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY,\n        });\n    }\n    if (has(lexerDefinition, MODES) &&\n        has(lexerDefinition, DEFAULT_MODE) &&\n        !has(lexerDefinition.modes, lexerDefinition.defaultMode)) {\n        errors.push({\n            message: `A MultiMode Lexer cannot be initialized with a ${DEFAULT_MODE}: <${lexerDefinition.defaultMode}>` +\n                `which does not exist\\n`,\n            type: LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST,\n        });\n    }\n    if (has(lexerDefinition, MODES)) {\n        forEach(lexerDefinition.modes, (currModeValue, currModeName) => {\n            forEach(currModeValue, (currTokType, currIdx) => {\n                if (isUndefined(currTokType)) {\n                    errors.push({\n                        message: `A Lexer cannot be initialized using an undefined Token Type. Mode:` +\n                            `<${currModeName}> at index: <${currIdx}>\\n`,\n                        type: LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED,\n                    });\n                }\n                else if (has(currTokType, \"LONGER_ALT\")) {\n                    const longerAlt = isArray(currTokType.LONGER_ALT)\n                        ? currTokType.LONGER_ALT\n                        : [currTokType.LONGER_ALT];\n                    forEach(longerAlt, (currLongerAlt) => {\n                        if (!isUndefined(currLongerAlt) &&\n                            !includes(currModeValue, currLongerAlt)) {\n                            errors.push({\n                                message: `A MultiMode Lexer cannot be initialized with a longer_alt <${currLongerAlt.name}> on token <${currTokType.name}> outside of mode <${currModeName}>\\n`,\n                                type: LexerDefinitionErrorType.MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE,\n                            });\n                        }\n                    });\n                }\n            });\n        });\n    }\n    return errors;\n}\nexport function performWarningRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n    const warnings = [];\n    let hasAnyLineBreak = false;\n    const allTokenTypes = compact(flatten(values(lexerDefinition.modes)));\n    const concreteTokenTypes = reject(allTokenTypes, (currType) => currType[PATTERN] === Lexer.NA);\n    const terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n    if (trackLines) {\n        forEach(concreteTokenTypes, (tokType) => {\n            const currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n            if (currIssue !== false) {\n                const message = buildLineBreakIssueMessage(tokType, currIssue);\n                const warningDescriptor = {\n                    message,\n                    type: currIssue.issue,\n                    tokenType: tokType,\n                };\n                warnings.push(warningDescriptor);\n            }\n            else {\n                // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n                if (has(tokType, \"LINE_BREAKS\")) {\n                    if (tokType.LINE_BREAKS === true) {\n                        hasAnyLineBreak = true;\n                    }\n                }\n                else {\n                    if (canMatchCharCode(terminatorCharCodes, tokType.PATTERN)) {\n                        hasAnyLineBreak = true;\n                    }\n                }\n            }\n        });\n    }\n    if (trackLines && !hasAnyLineBreak) {\n        warnings.push({\n            message: \"Warning: No LINE_BREAKS Found.\\n\" +\n                \"\\tThis Lexer has been defined to track line and column information,\\n\" +\n                \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" +\n                \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" +\n                \"\\tfor details.\",\n            type: LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS,\n        });\n    }\n    return warnings;\n}\nexport function cloneEmptyGroups(emptyGroups) {\n    const clonedResult = {};\n    const groupKeys = keys(emptyGroups);\n    forEach(groupKeys, (currKey) => {\n        const currGroupValue = emptyGroups[currKey];\n        /* istanbul ignore else */\n        if (isArray(currGroupValue)) {\n            clonedResult[currKey] = [];\n        }\n        else {\n            throw Error(\"non exhaustive match\");\n        }\n    });\n    return clonedResult;\n}\n// TODO: refactor to avoid duplication\nexport function isCustomPattern(tokenType) {\n    const pattern = tokenType.PATTERN;\n    /* istanbul ignore else */\n    if (isRegExp(pattern)) {\n        return false;\n    }\n    else if (isFunction(pattern)) {\n        // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n        return true;\n    }\n    else if (has(pattern, \"exec\")) {\n        // ICustomPattern\n        return true;\n    }\n    else if (isString(pattern)) {\n        return false;\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nexport function isShortPattern(pattern) {\n    if (isString(pattern) && pattern.length === 1) {\n        return pattern.charCodeAt(0);\n    }\n    else {\n        return false;\n    }\n}\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\nexport const LineTerminatorOptimizedTester = {\n    // implements /\\n|\\r\\n?/g.test\n    test: function (text) {\n        const len = text.length;\n        for (let i = this.lastIndex; i < len; i++) {\n            const c = text.charCodeAt(i);\n            if (c === 10) {\n                this.lastIndex = i + 1;\n                return true;\n            }\n            else if (c === 13) {\n                if (text.charCodeAt(i + 1) === 10) {\n                    this.lastIndex = i + 2;\n                }\n                else {\n                    this.lastIndex = i + 1;\n                }\n                return true;\n            }\n        }\n        return false;\n    },\n    lastIndex: 0,\n};\nfunction checkLineBreaksIssues(tokType, lineTerminatorCharCodes) {\n    if (has(tokType, \"LINE_BREAKS\")) {\n        // if the user explicitly declared the line_breaks option we will respect their choice\n        // and assume it is correct.\n        return false;\n    }\n    else {\n        /* istanbul ignore else */\n        if (isRegExp(tokType.PATTERN)) {\n            try {\n                // TODO: why is the casting suddenly needed?\n                canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\n            }\n            catch (e) {\n                /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n                return {\n                    issue: LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n                    errMsg: e.message,\n                };\n            }\n            return false;\n        }\n        else if (isString(tokType.PATTERN)) {\n            // string literal patterns can always be analyzed to detect line terminator usage\n            return false;\n        }\n        else if (isCustomPattern(tokType)) {\n            // custom token types\n            return { issue: LexerDefinitionErrorType.CUSTOM_LINE_BREAK };\n        }\n        else {\n            throw Error(\"non exhaustive match\");\n        }\n    }\n}\nexport function buildLineBreakIssueMessage(tokType, details) {\n    /* istanbul ignore else */\n    if (details.issue === LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n        return (\"Warning: unable to identify line terminator usage in pattern.\\n\" +\n            `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n            `\\t Root cause: ${details.errMsg}.\\n` +\n            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\");\n    }\n    else if (details.issue === LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n        return (\"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" +\n            `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\");\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nfunction getCharCodes(charsOrCodes) {\n    const charCodes = map(charsOrCodes, (numOrString) => {\n        if (isString(numOrString)) {\n            return numOrString.charCodeAt(0);\n        }\n        else {\n            return numOrString;\n        }\n    });\n    return charCodes;\n}\nfunction addToMapOfArrays(map, key, value) {\n    if (map[key] === undefined) {\n        map[key] = [value];\n    }\n    else {\n        map[key].push(value);\n    }\n}\nexport const minOptimizationVal = 256;\n/**\n * We are mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\nlet charCodeToOptimizedIdxMap = [];\nexport function charCodeToOptimizedIndex(charCode) {\n    return charCode < minOptimizationVal\n        ? charCode\n        : charCodeToOptimizedIdxMap[charCode];\n}\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\nfunction initCharCodeToOptimizedIndexMap() {\n    if (isEmpty(charCodeToOptimizedIdxMap)) {\n        charCodeToOptimizedIdxMap = new Array(65536);\n        for (let i = 0; i < 65536; i++) {\n            charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n        }\n    }\n}\n//# sourceMappingURL=lexer.js.map","export function timer(func) {\n    const start = new Date().getTime();\n    const val = func();\n    const end = new Date().getTime();\n    const total = end - start;\n    return { time: total, value: val };\n}\n//# sourceMappingURL=timer.js.map","import { clone, compact, difference, flatten, forEach, has, includes, isArray, isEmpty, map, } from \"lodash-es\";\nexport function tokenStructuredMatcher(tokInstance, tokConstructor) {\n    const instanceType = tokInstance.tokenTypeIdx;\n    if (instanceType === tokConstructor.tokenTypeIdx) {\n        return true;\n    }\n    else {\n        return (tokConstructor.isParent === true &&\n            tokConstructor.categoryMatchesMap[instanceType] === true);\n    }\n}\n// Optimized tokenMatcher in case our grammar does not use token categories\n// Being so tiny it is much more likely to be in-lined and this avoid the function call overhead\nexport function tokenStructuredMatcherNoCategories(token, tokType) {\n    return token.tokenTypeIdx === tokType.tokenTypeIdx;\n}\nexport let tokenShortNameIdx = 1;\nexport const tokenIdxToClass = {};\nexport function augmentTokenTypes(tokenTypes) {\n    // collect the parent Token Types as well.\n    const tokenTypesAndParents = expandCategories(tokenTypes);\n    // add required tokenType and categoryMatches properties\n    assignTokenDefaultProps(tokenTypesAndParents);\n    // fill up the categoryMatches\n    assignCategoriesMapProp(tokenTypesAndParents);\n    assignCategoriesTokensProp(tokenTypesAndParents);\n    forEach(tokenTypesAndParents, (tokType) => {\n        tokType.isParent = tokType.categoryMatches.length > 0;\n    });\n}\nexport function expandCategories(tokenTypes) {\n    let result = clone(tokenTypes);\n    let categories = tokenTypes;\n    let searching = true;\n    while (searching) {\n        categories = compact(flatten(map(categories, (currTokType) => currTokType.CATEGORIES)));\n        const newCategories = difference(categories, result);\n        result = result.concat(newCategories);\n        if (isEmpty(newCategories)) {\n            searching = false;\n        }\n        else {\n            categories = newCategories;\n        }\n    }\n    return result;\n}\nexport function assignTokenDefaultProps(tokenTypes) {\n    forEach(tokenTypes, (currTokType) => {\n        if (!hasShortKeyProperty(currTokType)) {\n            tokenIdxToClass[tokenShortNameIdx] = currTokType;\n            currTokType.tokenTypeIdx = tokenShortNameIdx++;\n        }\n        // CATEGORIES? : TokenType | TokenType[]\n        if (hasCategoriesProperty(currTokType) &&\n            !isArray(currTokType.CATEGORIES)\n        // &&\n        // !isUndefined(currTokType.CATEGORIES.PATTERN)\n        ) {\n            currTokType.CATEGORIES = [currTokType.CATEGORIES];\n        }\n        if (!hasCategoriesProperty(currTokType)) {\n            currTokType.CATEGORIES = [];\n        }\n        if (!hasExtendingTokensTypesProperty(currTokType)) {\n            currTokType.categoryMatches = [];\n        }\n        if (!hasExtendingTokensTypesMapProperty(currTokType)) {\n            currTokType.categoryMatchesMap = {};\n        }\n    });\n}\nexport function assignCategoriesTokensProp(tokenTypes) {\n    forEach(tokenTypes, (currTokType) => {\n        // avoid duplications\n        currTokType.categoryMatches = [];\n        forEach(currTokType.categoryMatchesMap, (val, key) => {\n            currTokType.categoryMatches.push(tokenIdxToClass[key].tokenTypeIdx);\n        });\n    });\n}\nexport function assignCategoriesMapProp(tokenTypes) {\n    forEach(tokenTypes, (currTokType) => {\n        singleAssignCategoriesToksMap([], currTokType);\n    });\n}\nexport function singleAssignCategoriesToksMap(path, nextNode) {\n    forEach(path, (pathNode) => {\n        nextNode.categoryMatchesMap[pathNode.tokenTypeIdx] = true;\n    });\n    forEach(nextNode.CATEGORIES, (nextCategory) => {\n        const newPath = path.concat(nextNode);\n        // avoids infinite loops due to cyclic categories.\n        if (!includes(newPath, nextCategory)) {\n            singleAssignCategoriesToksMap(newPath, nextCategory);\n        }\n    });\n}\nexport function hasShortKeyProperty(tokType) {\n    return has(tokType, \"tokenTypeIdx\");\n}\nexport function hasCategoriesProperty(tokType) {\n    return has(tokType, \"CATEGORIES\");\n}\nexport function hasExtendingTokensTypesProperty(tokType) {\n    return has(tokType, \"categoryMatches\");\n}\nexport function hasExtendingTokensTypesMapProperty(tokType) {\n    return has(tokType, \"categoryMatchesMap\");\n}\nexport function isTokenType(tokType) {\n    return has(tokType, \"tokenTypeIdx\");\n}\n//# sourceMappingURL=tokens.js.map","export const defaultLexerErrorProvider = {\n    buildUnableToPopLexerModeMessage(token) {\n        return `Unable to pop Lexer Mode after encountering Token ->${token.image}<- The Mode Stack is empty`;\n    },\n    buildUnexpectedCharactersMessage(fullText, startOffset, length, line, column, mode) {\n        return (`unexpected character: ->${fullText.charAt(startOffset)}<- at offset: ${startOffset},` + ` skipped ${length} characters.`);\n    },\n};\n//# sourceMappingURL=lexer_errors_public.js.map","import { analyzeTokenTypes, charCodeToOptimizedIndex, cloneEmptyGroups, DEFAULT_MODE, LineTerminatorOptimizedTester, performRuntimeChecks, performWarningRuntimeChecks, SUPPORT_STICKY, validatePatterns, } from \"./lexer.js\";\nimport { assign, clone, forEach, identity, isArray, isEmpty, isUndefined, keys, last, map, noop, reduce, reject, } from \"lodash-es\";\nimport { PRINT_WARNING, timer, toFastProperties } from \"@chevrotain/utils\";\nimport { augmentTokenTypes } from \"./tokens.js\";\nimport { defaultLexerErrorProvider } from \"./lexer_errors_public.js\";\nimport { clearRegExpParserCache } from \"./reg_exp_parser.js\";\nexport var LexerDefinitionErrorType;\n(function (LexerDefinitionErrorType) {\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MISSING_PATTERN\"] = 0] = \"MISSING_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_PATTERN\"] = 1] = \"INVALID_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"EOI_ANCHOR_FOUND\"] = 2] = \"EOI_ANCHOR_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"UNSUPPORTED_FLAGS_FOUND\"] = 3] = \"UNSUPPORTED_FLAGS_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"DUPLICATE_PATTERNS_FOUND\"] = 4] = \"DUPLICATE_PATTERNS_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_GROUP_TYPE_FOUND\"] = 5] = \"INVALID_GROUP_TYPE_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"PUSH_MODE_DOES_NOT_EXIST\"] = 6] = \"PUSH_MODE_DOES_NOT_EXIST\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\"] = 7] = \"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\"] = 8] = \"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\"] = 9] = \"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\"] = 10] = \"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"SOI_ANCHOR_FOUND\"] = 11] = \"SOI_ANCHOR_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"EMPTY_MATCH_PATTERN\"] = 12] = \"EMPTY_MATCH_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"NO_LINE_BREAKS_FLAGS\"] = 13] = \"NO_LINE_BREAKS_FLAGS\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"UNREACHABLE_PATTERN\"] = 14] = \"UNREACHABLE_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"IDENTIFY_TERMINATOR\"] = 15] = \"IDENTIFY_TERMINATOR\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"CUSTOM_LINE_BREAK\"] = 16] = \"CUSTOM_LINE_BREAK\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\"] = 17] = \"MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\";\n})(LexerDefinitionErrorType || (LexerDefinitionErrorType = {}));\nconst DEFAULT_LEXER_CONFIG = {\n    deferDefinitionErrorsHandling: false,\n    positionTracking: \"full\",\n    lineTerminatorsPattern: /\\n|\\r\\n?/g,\n    lineTerminatorCharacters: [\"\\n\", \"\\r\"],\n    ensureOptimizations: false,\n    safeMode: false,\n    errorMessageProvider: defaultLexerErrorProvider,\n    traceInitPerf: false,\n    skipValidations: false,\n    recoveryEnabled: true,\n};\nObject.freeze(DEFAULT_LEXER_CONFIG);\nexport class Lexer {\n    constructor(lexerDefinition, config = DEFAULT_LEXER_CONFIG) {\n        this.lexerDefinition = lexerDefinition;\n        this.lexerDefinitionErrors = [];\n        this.lexerDefinitionWarning = [];\n        this.patternIdxToConfig = {};\n        this.charCodeToPatternIdxToConfig = {};\n        this.modes = [];\n        this.emptyGroups = {};\n        this.trackStartLines = true;\n        this.trackEndLines = true;\n        this.hasCustom = false;\n        this.canModeBeOptimized = {};\n        // Duplicated from the parser's perf trace trait to allow future extraction\n        // of the lexer to a separate package.\n        this.TRACE_INIT = (phaseDesc, phaseImpl) => {\n            // No need to optimize this using NOOP pattern because\n            // It is not called in a hot spot...\n            if (this.traceInitPerf === true) {\n                this.traceInitIndent++;\n                const indent = new Array(this.traceInitIndent + 1).join(\"\\t\");\n                if (this.traceInitIndent < this.traceInitMaxIdent) {\n                    console.log(`${indent}--> <${phaseDesc}>`);\n                }\n                const { time, value } = timer(phaseImpl);\n                /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n                const traceMethod = time > 10 ? console.warn : console.log;\n                if (this.traceInitIndent < this.traceInitMaxIdent) {\n                    traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n                }\n                this.traceInitIndent--;\n                return value;\n            }\n            else {\n                return phaseImpl();\n            }\n        };\n        if (typeof config === \"boolean\") {\n            throw Error(\"The second argument to the Lexer constructor is now an ILexerConfig Object.\\n\" +\n                \"a boolean 2nd argument is no longer supported\");\n        }\n        // todo: defaults func?\n        this.config = assign({}, DEFAULT_LEXER_CONFIG, config);\n        const traceInitVal = this.config.traceInitPerf;\n        if (traceInitVal === true) {\n            this.traceInitMaxIdent = Infinity;\n            this.traceInitPerf = true;\n        }\n        else if (typeof traceInitVal === \"number\") {\n            this.traceInitMaxIdent = traceInitVal;\n            this.traceInitPerf = true;\n        }\n        this.traceInitIndent = -1;\n        this.TRACE_INIT(\"Lexer Constructor\", () => {\n            let actualDefinition;\n            let hasOnlySingleMode = true;\n            this.TRACE_INIT(\"Lexer Config handling\", () => {\n                if (this.config.lineTerminatorsPattern ===\n                    DEFAULT_LEXER_CONFIG.lineTerminatorsPattern) {\n                    // optimized built-in implementation for the defaults definition of lineTerminators\n                    this.config.lineTerminatorsPattern = LineTerminatorOptimizedTester;\n                }\n                else {\n                    if (this.config.lineTerminatorCharacters ===\n                        DEFAULT_LEXER_CONFIG.lineTerminatorCharacters) {\n                        throw Error(\"Error: Missing <lineTerminatorCharacters> property on the Lexer config.\\n\" +\n                            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\");\n                    }\n                }\n                if (config.safeMode && config.ensureOptimizations) {\n                    throw Error('\"safeMode\" and \"ensureOptimizations\" flags are mutually exclusive.');\n                }\n                this.trackStartLines = /full|onlyStart/i.test(this.config.positionTracking);\n                this.trackEndLines = /full/i.test(this.config.positionTracking);\n                // Convert SingleModeLexerDefinition into a IMultiModeLexerDefinition.\n                if (isArray(lexerDefinition)) {\n                    actualDefinition = {\n                        modes: { defaultMode: clone(lexerDefinition) },\n                        defaultMode: DEFAULT_MODE,\n                    };\n                }\n                else {\n                    // no conversion needed, input should already be a IMultiModeLexerDefinition\n                    hasOnlySingleMode = false;\n                    actualDefinition = clone(lexerDefinition);\n                }\n            });\n            if (this.config.skipValidations === false) {\n                this.TRACE_INIT(\"performRuntimeChecks\", () => {\n                    this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(performRuntimeChecks(actualDefinition, this.trackStartLines, this.config.lineTerminatorCharacters));\n                });\n                this.TRACE_INIT(\"performWarningRuntimeChecks\", () => {\n                    this.lexerDefinitionWarning = this.lexerDefinitionWarning.concat(performWarningRuntimeChecks(actualDefinition, this.trackStartLines, this.config.lineTerminatorCharacters));\n                });\n            }\n            // for extra robustness to avoid throwing an none informative error message\n            actualDefinition.modes = actualDefinition.modes\n                ? actualDefinition.modes\n                : {};\n            // an error of undefined TokenTypes will be detected in \"performRuntimeChecks\" above.\n            // this transformation is to increase robustness in the case of partially invalid lexer definition.\n            forEach(actualDefinition.modes, (currModeValue, currModeName) => {\n                actualDefinition.modes[currModeName] = reject(currModeValue, (currTokType) => isUndefined(currTokType));\n            });\n            const allModeNames = keys(actualDefinition.modes);\n            forEach(actualDefinition.modes, (currModDef, currModName) => {\n                this.TRACE_INIT(`Mode: <${currModName}> processing`, () => {\n                    this.modes.push(currModName);\n                    if (this.config.skipValidations === false) {\n                        this.TRACE_INIT(`validatePatterns`, () => {\n                            this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(validatePatterns(currModDef, allModeNames));\n                        });\n                    }\n                    // If definition errors were encountered, the analysis phase may fail unexpectedly/\n                    // Considering a lexer with definition errors may never be used, there is no point\n                    // to performing the analysis anyhow...\n                    if (isEmpty(this.lexerDefinitionErrors)) {\n                        augmentTokenTypes(currModDef);\n                        let currAnalyzeResult;\n                        this.TRACE_INIT(`analyzeTokenTypes`, () => {\n                            currAnalyzeResult = analyzeTokenTypes(currModDef, {\n                                lineTerminatorCharacters: this.config.lineTerminatorCharacters,\n                                positionTracking: config.positionTracking,\n                                ensureOptimizations: config.ensureOptimizations,\n                                safeMode: config.safeMode,\n                                tracer: this.TRACE_INIT,\n                            });\n                        });\n                        this.patternIdxToConfig[currModName] =\n                            currAnalyzeResult.patternIdxToConfig;\n                        this.charCodeToPatternIdxToConfig[currModName] =\n                            currAnalyzeResult.charCodeToPatternIdxToConfig;\n                        this.emptyGroups = assign({}, this.emptyGroups, currAnalyzeResult.emptyGroups);\n                        this.hasCustom = currAnalyzeResult.hasCustom || this.hasCustom;\n                        this.canModeBeOptimized[currModName] =\n                            currAnalyzeResult.canBeOptimized;\n                    }\n                });\n            });\n            this.defaultMode = actualDefinition.defaultMode;\n            if (!isEmpty(this.lexerDefinitionErrors) &&\n                !this.config.deferDefinitionErrorsHandling) {\n                const allErrMessages = map(this.lexerDefinitionErrors, (error) => {\n                    return error.message;\n                });\n                const allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n                throw new Error(\"Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n            }\n            // Only print warning if there are no errors, This will avoid pl\n            forEach(this.lexerDefinitionWarning, (warningDescriptor) => {\n                PRINT_WARNING(warningDescriptor.message);\n            });\n            this.TRACE_INIT(\"Choosing sub-methods implementations\", () => {\n                // Choose the relevant internal implementations for this specific parser.\n                // These implementations should be in-lined by the JavaScript engine\n                // to provide optimal performance in each scenario.\n                if (SUPPORT_STICKY) {\n                    this.chopInput = identity;\n                    this.match = this.matchWithTest;\n                }\n                else {\n                    this.updateLastIndex = noop;\n                    this.match = this.matchWithExec;\n                }\n                if (hasOnlySingleMode) {\n                    this.handleModes = noop;\n                }\n                if (this.trackStartLines === false) {\n                    this.computeNewColumn = identity;\n                }\n                if (this.trackEndLines === false) {\n                    this.updateTokenEndLineColumnLocation = noop;\n                }\n                if (/full/i.test(this.config.positionTracking)) {\n                    this.createTokenInstance = this.createFullToken;\n                }\n                else if (/onlyStart/i.test(this.config.positionTracking)) {\n                    this.createTokenInstance = this.createStartOnlyToken;\n                }\n                else if (/onlyOffset/i.test(this.config.positionTracking)) {\n                    this.createTokenInstance = this.createOffsetOnlyToken;\n                }\n                else {\n                    throw Error(`Invalid <positionTracking> config option: \"${this.config.positionTracking}\"`);\n                }\n                if (this.hasCustom) {\n                    this.addToken = this.addTokenUsingPush;\n                    this.handlePayload = this.handlePayloadWithCustom;\n                }\n                else {\n                    this.addToken = this.addTokenUsingMemberAccess;\n                    this.handlePayload = this.handlePayloadNoCustom;\n                }\n            });\n            this.TRACE_INIT(\"Failed Optimization Warnings\", () => {\n                const unOptimizedModes = reduce(this.canModeBeOptimized, (cannotBeOptimized, canBeOptimized, modeName) => {\n                    if (canBeOptimized === false) {\n                        cannotBeOptimized.push(modeName);\n                    }\n                    return cannotBeOptimized;\n                }, []);\n                if (config.ensureOptimizations && !isEmpty(unOptimizedModes)) {\n                    throw Error(`Lexer Modes: < ${unOptimizedModes.join(\", \")} > cannot be optimized.\\n` +\n                        '\\t Disable the \"ensureOptimizations\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\\n' +\n                        \"\\t Or inspect the console log for details on how to resolve these issues.\");\n                }\n            });\n            this.TRACE_INIT(\"clearRegExpParserCache\", () => {\n                clearRegExpParserCache();\n            });\n            this.TRACE_INIT(\"toFastProperties\", () => {\n                toFastProperties(this);\n            });\n        });\n    }\n    tokenize(text, initialMode = this.defaultMode) {\n        if (!isEmpty(this.lexerDefinitionErrors)) {\n            const allErrMessages = map(this.lexerDefinitionErrors, (error) => {\n                return error.message;\n            });\n            const allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n            throw new Error(\"Unable to Tokenize because Errors detected in definition of Lexer:\\n\" +\n                allErrMessagesString);\n        }\n        return this.tokenizeInternal(text, initialMode);\n    }\n    // There is quite a bit of duplication between this and \"tokenizeInternalLazy\"\n    // This is intentional due to performance considerations.\n    // this method also used quite a bit of `!` none null assertions because it is too optimized\n    // for `tsc` to always understand it is \"safe\"\n    tokenizeInternal(text, initialMode) {\n        let i, j, k, matchAltImage, longerAlt, matchedImage, payload, altPayload, imageLength, group, tokType, newToken, errLength, droppedChar, msg, match;\n        const orgText = text;\n        const orgLength = orgText.length;\n        let offset = 0;\n        let matchedTokensIndex = 0;\n        // initializing the tokensArray to the \"guessed\" size.\n        // guessing too little will still reduce the number of array re-sizes on pushes.\n        // guessing too large (Tested by guessing x4 too large) may cost a bit more of memory\n        // but would still have a faster runtime by avoiding (All but one) array resizing.\n        const guessedNumberOfTokens = this.hasCustom\n            ? 0 // will break custom token pattern APIs the matchedTokens array will contain undefined elements.\n            : Math.floor(text.length / 10);\n        const matchedTokens = new Array(guessedNumberOfTokens);\n        const errors = [];\n        let line = this.trackStartLines ? 1 : undefined;\n        let column = this.trackStartLines ? 1 : undefined;\n        const groups = cloneEmptyGroups(this.emptyGroups);\n        const trackLines = this.trackStartLines;\n        const lineTerminatorPattern = this.config.lineTerminatorsPattern;\n        let currModePatternsLength = 0;\n        let patternIdxToConfig = [];\n        let currCharCodeToPatternIdxToConfig = [];\n        const modeStack = [];\n        const emptyArray = [];\n        Object.freeze(emptyArray);\n        let getPossiblePatterns;\n        function getPossiblePatternsSlow() {\n            return patternIdxToConfig;\n        }\n        function getPossiblePatternsOptimized(charCode) {\n            const optimizedCharIdx = charCodeToOptimizedIndex(charCode);\n            const possiblePatterns = currCharCodeToPatternIdxToConfig[optimizedCharIdx];\n            if (possiblePatterns === undefined) {\n                return emptyArray;\n            }\n            else {\n                return possiblePatterns;\n            }\n        }\n        const pop_mode = (popToken) => {\n            // TODO: perhaps avoid this error in the edge case there is no more input?\n            if (modeStack.length === 1 &&\n                // if we have both a POP_MODE and a PUSH_MODE this is in-fact a \"transition\"\n                // So no error should occur.\n                popToken.tokenType.PUSH_MODE === undefined) {\n                // if we try to pop the last mode there lexer will no longer have ANY mode.\n                // thus the pop is ignored, an error will be created and the lexer will continue parsing in the previous mode.\n                const msg = this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(popToken);\n                errors.push({\n                    offset: popToken.startOffset,\n                    line: popToken.startLine,\n                    column: popToken.startColumn,\n                    length: popToken.image.length,\n                    message: msg,\n                });\n            }\n            else {\n                modeStack.pop();\n                const newMode = last(modeStack);\n                patternIdxToConfig = this.patternIdxToConfig[newMode];\n                currCharCodeToPatternIdxToConfig =\n                    this.charCodeToPatternIdxToConfig[newMode];\n                currModePatternsLength = patternIdxToConfig.length;\n                const modeCanBeOptimized = this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n                if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n                    getPossiblePatterns = getPossiblePatternsOptimized;\n                }\n                else {\n                    getPossiblePatterns = getPossiblePatternsSlow;\n                }\n            }\n        };\n        function push_mode(newMode) {\n            modeStack.push(newMode);\n            currCharCodeToPatternIdxToConfig =\n                this.charCodeToPatternIdxToConfig[newMode];\n            patternIdxToConfig = this.patternIdxToConfig[newMode];\n            currModePatternsLength = patternIdxToConfig.length;\n            currModePatternsLength = patternIdxToConfig.length;\n            const modeCanBeOptimized = this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n            if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n                getPossiblePatterns = getPossiblePatternsOptimized;\n            }\n            else {\n                getPossiblePatterns = getPossiblePatternsSlow;\n            }\n        }\n        // this pattern seems to avoid a V8 de-optimization, although that de-optimization does not\n        // seem to matter performance wise.\n        push_mode.call(this, initialMode);\n        let currConfig;\n        const recoveryEnabled = this.config.recoveryEnabled;\n        while (offset < orgLength) {\n            matchedImage = null;\n            const nextCharCode = orgText.charCodeAt(offset);\n            const chosenPatternIdxToConfig = getPossiblePatterns(nextCharCode);\n            const chosenPatternsLength = chosenPatternIdxToConfig.length;\n            for (i = 0; i < chosenPatternsLength; i++) {\n                currConfig = chosenPatternIdxToConfig[i];\n                const currPattern = currConfig.pattern;\n                payload = null;\n                // manually in-lined because > 600 chars won't be in-lined in V8\n                const singleCharCode = currConfig.short;\n                if (singleCharCode !== false) {\n                    if (nextCharCode === singleCharCode) {\n                        // single character string\n                        matchedImage = currPattern;\n                    }\n                }\n                else if (currConfig.isCustom === true) {\n                    match = currPattern.exec(orgText, offset, matchedTokens, groups);\n                    if (match !== null) {\n                        matchedImage = match[0];\n                        if (match.payload !== undefined) {\n                            payload = match.payload;\n                        }\n                    }\n                    else {\n                        matchedImage = null;\n                    }\n                }\n                else {\n                    this.updateLastIndex(currPattern, offset);\n                    matchedImage = this.match(currPattern, text, offset);\n                }\n                if (matchedImage !== null) {\n                    // even though this pattern matched we must try a another longer alternative.\n                    // this can be used to prioritize keywords over identifiers\n                    longerAlt = currConfig.longerAlt;\n                    if (longerAlt !== undefined) {\n                        // TODO: micro optimize, avoid extra prop access\n                        // by saving/linking longerAlt on the original config?\n                        const longerAltLength = longerAlt.length;\n                        for (k = 0; k < longerAltLength; k++) {\n                            const longerAltConfig = patternIdxToConfig[longerAlt[k]];\n                            const longerAltPattern = longerAltConfig.pattern;\n                            altPayload = null;\n                            // single Char can never be a longer alt so no need to test it.\n                            // manually in-lined because > 600 chars won't be in-lined in V8\n                            if (longerAltConfig.isCustom === true) {\n                                match = longerAltPattern.exec(orgText, offset, matchedTokens, groups);\n                                if (match !== null) {\n                                    matchAltImage = match[0];\n                                    if (match.payload !== undefined) {\n                                        altPayload = match.payload;\n                                    }\n                                }\n                                else {\n                                    matchAltImage = null;\n                                }\n                            }\n                            else {\n                                this.updateLastIndex(longerAltPattern, offset);\n                                matchAltImage = this.match(longerAltPattern, text, offset);\n                            }\n                            if (matchAltImage && matchAltImage.length > matchedImage.length) {\n                                matchedImage = matchAltImage;\n                                payload = altPayload;\n                                currConfig = longerAltConfig;\n                                // Exit the loop early after matching one of the longer alternatives\n                                // The first matched alternative takes precedence\n                                break;\n                            }\n                        }\n                    }\n                    break;\n                }\n            }\n            // successful match\n            if (matchedImage !== null) {\n                imageLength = matchedImage.length;\n                group = currConfig.group;\n                if (group !== undefined) {\n                    tokType = currConfig.tokenTypeIdx;\n                    // TODO: \"offset + imageLength\" and the new column may be computed twice in case of \"full\" location information inside\n                    // createFullToken method\n                    newToken = this.createTokenInstance(matchedImage, offset, tokType, currConfig.tokenType, line, column, imageLength);\n                    this.handlePayload(newToken, payload);\n                    // TODO: optimize NOOP in case there are no special groups?\n                    if (group === false) {\n                        matchedTokensIndex = this.addToken(matchedTokens, matchedTokensIndex, newToken);\n                    }\n                    else {\n                        groups[group].push(newToken);\n                    }\n                }\n                text = this.chopInput(text, imageLength);\n                offset = offset + imageLength;\n                // TODO: with newlines the column may be assigned twice\n                column = this.computeNewColumn(column, imageLength);\n                if (trackLines === true && currConfig.canLineTerminator === true) {\n                    let numOfLTsInMatch = 0;\n                    let foundTerminator;\n                    let lastLTEndOffset;\n                    lineTerminatorPattern.lastIndex = 0;\n                    do {\n                        foundTerminator = lineTerminatorPattern.test(matchedImage);\n                        if (foundTerminator === true) {\n                            lastLTEndOffset = lineTerminatorPattern.lastIndex - 1;\n                            numOfLTsInMatch++;\n                        }\n                    } while (foundTerminator === true);\n                    if (numOfLTsInMatch !== 0) {\n                        line = line + numOfLTsInMatch;\n                        column = imageLength - lastLTEndOffset;\n                        this.updateTokenEndLineColumnLocation(newToken, group, lastLTEndOffset, numOfLTsInMatch, line, column, imageLength);\n                    }\n                }\n                // will be NOOP if no modes present\n                this.handleModes(currConfig, pop_mode, push_mode, newToken);\n            }\n            else {\n                // error recovery, drop characters until we identify a valid token's start point\n                const errorStartOffset = offset;\n                const errorLine = line;\n                const errorColumn = column;\n                let foundResyncPoint = recoveryEnabled === false;\n                while (foundResyncPoint === false && offset < orgLength) {\n                    // Identity Func (when sticky flag is enabled)\n                    text = this.chopInput(text, 1);\n                    offset++;\n                    for (j = 0; j < currModePatternsLength; j++) {\n                        const currConfig = patternIdxToConfig[j];\n                        const currPattern = currConfig.pattern;\n                        // manually in-lined because > 600 chars won't be in-lined in V8\n                        const singleCharCode = currConfig.short;\n                        if (singleCharCode !== false) {\n                            if (orgText.charCodeAt(offset) === singleCharCode) {\n                                // single character string\n                                foundResyncPoint = true;\n                            }\n                        }\n                        else if (currConfig.isCustom === true) {\n                            foundResyncPoint =\n                                currPattern.exec(orgText, offset, matchedTokens, groups) !== null;\n                        }\n                        else {\n                            this.updateLastIndex(currPattern, offset);\n                            foundResyncPoint = currPattern.exec(text) !== null;\n                        }\n                        if (foundResyncPoint === true) {\n                            break;\n                        }\n                    }\n                }\n                errLength = offset - errorStartOffset;\n                column = this.computeNewColumn(column, errLength);\n                // at this point we either re-synced or reached the end of the input text\n                msg = this.config.errorMessageProvider.buildUnexpectedCharactersMessage(orgText, errorStartOffset, errLength, errorLine, errorColumn, last(modeStack));\n                errors.push({\n                    offset: errorStartOffset,\n                    line: errorLine,\n                    column: errorColumn,\n                    length: errLength,\n                    message: msg,\n                });\n                if (recoveryEnabled === false) {\n                    break;\n                }\n            }\n        }\n        // if we do have custom patterns which push directly into the\n        // TODO: custom tokens should not push directly??\n        if (!this.hasCustom) {\n            // if we guessed a too large size for the tokens array this will shrink it to the right size.\n            matchedTokens.length = matchedTokensIndex;\n        }\n        return {\n            tokens: matchedTokens,\n            groups: groups,\n            errors: errors,\n        };\n    }\n    handleModes(config, pop_mode, push_mode, newToken) {\n        if (config.pop === true) {\n            // need to save the PUSH_MODE property as if the mode is popped\n            // patternIdxToPopMode is updated to reflect the new mode after popping the stack\n            const pushMode = config.push;\n            pop_mode(newToken);\n            if (pushMode !== undefined) {\n                push_mode.call(this, pushMode);\n            }\n        }\n        else if (config.push !== undefined) {\n            push_mode.call(this, config.push);\n        }\n    }\n    chopInput(text, length) {\n        return text.substring(length);\n    }\n    updateLastIndex(regExp, newLastIndex) {\n        regExp.lastIndex = newLastIndex;\n    }\n    // TODO: decrease this under 600 characters? inspect stripping comments option in TSC compiler\n    updateTokenEndLineColumnLocation(newToken, group, lastLTIdx, numOfLTsInMatch, line, column, imageLength) {\n        let lastCharIsLT, fixForEndingInLT;\n        if (group !== undefined) {\n            // a none skipped multi line Token, need to update endLine/endColumn\n            lastCharIsLT = lastLTIdx === imageLength - 1;\n            fixForEndingInLT = lastCharIsLT ? -1 : 0;\n            if (!(numOfLTsInMatch === 1 && lastCharIsLT === true)) {\n                // if a token ends in a LT that last LT only affects the line numbering of following Tokens\n                newToken.endLine = line + fixForEndingInLT;\n                // the last LT in a token does not affect the endColumn either as the [columnStart ... columnEnd)\n                // inclusive to exclusive range.\n                newToken.endColumn = column - 1 + -fixForEndingInLT;\n            }\n            // else single LT in the last character of a token, no need to modify the endLine/EndColumn\n        }\n    }\n    computeNewColumn(oldColumn, imageLength) {\n        return oldColumn + imageLength;\n    }\n    createOffsetOnlyToken(image, startOffset, tokenTypeIdx, tokenType) {\n        return {\n            image,\n            startOffset,\n            tokenTypeIdx,\n            tokenType,\n        };\n    }\n    createStartOnlyToken(image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn) {\n        return {\n            image,\n            startOffset,\n            startLine,\n            startColumn,\n            tokenTypeIdx,\n            tokenType,\n        };\n    }\n    createFullToken(image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn, imageLength) {\n        return {\n            image,\n            startOffset,\n            endOffset: startOffset + imageLength - 1,\n            startLine,\n            endLine: startLine,\n            startColumn,\n            endColumn: startColumn + imageLength - 1,\n            tokenTypeIdx,\n            tokenType,\n        };\n    }\n    addTokenUsingPush(tokenVector, index, tokenToAdd) {\n        tokenVector.push(tokenToAdd);\n        return index;\n    }\n    addTokenUsingMemberAccess(tokenVector, index, tokenToAdd) {\n        tokenVector[index] = tokenToAdd;\n        index++;\n        return index;\n    }\n    handlePayloadNoCustom(token, payload) { }\n    handlePayloadWithCustom(token, payload) {\n        if (payload !== null) {\n            token.payload = payload;\n        }\n    }\n    matchWithTest(pattern, text, offset) {\n        const found = pattern.test(text);\n        if (found === true) {\n            return text.substring(offset, pattern.lastIndex);\n        }\n        return null;\n    }\n    matchWithExec(pattern, text) {\n        const regExpArray = pattern.exec(text);\n        return regExpArray !== null ? regExpArray[0] : null;\n    }\n}\nLexer.SKIPPED = \"This marks a skipped Token pattern, this means each token identified by it will \" +\n    \"be consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\";\nLexer.NA = /NOT_APPLICABLE/;\n//# sourceMappingURL=lexer_public.js.map","import { has, isString, isUndefined } from \"lodash-es\";\nimport { Lexer } from \"./lexer_public.js\";\nimport { augmentTokenTypes, tokenStructuredMatcher } from \"./tokens.js\";\nexport function tokenLabel(tokType) {\n    if (hasTokenLabel(tokType)) {\n        return tokType.LABEL;\n    }\n    else {\n        return tokType.name;\n    }\n}\nexport function tokenName(tokType) {\n    return tokType.name;\n}\nexport function hasTokenLabel(obj) {\n    return isString(obj.LABEL) && obj.LABEL !== \"\";\n}\nconst PARENT = \"parent\";\nconst CATEGORIES = \"categories\";\nconst LABEL = \"label\";\nconst GROUP = \"group\";\nconst PUSH_MODE = \"push_mode\";\nconst POP_MODE = \"pop_mode\";\nconst LONGER_ALT = \"longer_alt\";\nconst LINE_BREAKS = \"line_breaks\";\nconst START_CHARS_HINT = \"start_chars_hint\";\nexport function createToken(config) {\n    return createTokenInternal(config);\n}\nfunction createTokenInternal(config) {\n    const pattern = config.pattern;\n    const tokenType = {};\n    tokenType.name = config.name;\n    if (!isUndefined(pattern)) {\n        tokenType.PATTERN = pattern;\n    }\n    if (has(config, PARENT)) {\n        throw (\"The parent property is no longer supported.\\n\" +\n            \"See: https://github.com/chevrotain/chevrotain/issues/564#issuecomment-349062346 for details.\");\n    }\n    if (has(config, CATEGORIES)) {\n        // casting to ANY as this will be fixed inside `augmentTokenTypes``\n        tokenType.CATEGORIES = config[CATEGORIES];\n    }\n    augmentTokenTypes([tokenType]);\n    if (has(config, LABEL)) {\n        tokenType.LABEL = config[LABEL];\n    }\n    if (has(config, GROUP)) {\n        tokenType.GROUP = config[GROUP];\n    }\n    if (has(config, POP_MODE)) {\n        tokenType.POP_MODE = config[POP_MODE];\n    }\n    if (has(config, PUSH_MODE)) {\n        tokenType.PUSH_MODE = config[PUSH_MODE];\n    }\n    if (has(config, LONGER_ALT)) {\n        tokenType.LONGER_ALT = config[LONGER_ALT];\n    }\n    if (has(config, LINE_BREAKS)) {\n        tokenType.LINE_BREAKS = config[LINE_BREAKS];\n    }\n    if (has(config, START_CHARS_HINT)) {\n        tokenType.START_CHARS_HINT = config[START_CHARS_HINT];\n    }\n    return tokenType;\n}\nexport const EOF = createToken({ name: \"EOF\", pattern: Lexer.NA });\naugmentTokenTypes([EOF]);\nexport function createTokenInstance(tokType, image, startOffset, endOffset, startLine, endLine, startColumn, endColumn) {\n    return {\n        image,\n        startOffset,\n        endOffset,\n        startLine,\n        endLine,\n        startColumn,\n        endColumn,\n        tokenTypeIdx: tokType.tokenTypeIdx,\n        tokenType: tokType,\n    };\n}\nexport function tokenMatcher(token, tokType) {\n    return tokenStructuredMatcher(token, tokType);\n}\n//# sourceMappingURL=tokens_public.js.map","import { hasTokenLabel, tokenLabel } from \"../scan/tokens_public.js\";\nimport { first, map, reduce } from \"lodash-es\";\nimport { getProductionDslName, NonTerminal, Rule, Terminal, } from \"@chevrotain/gast\";\nexport const defaultParserErrorProvider = {\n    buildMismatchTokenMessage({ expected, actual, previous, ruleName }) {\n        const hasLabel = hasTokenLabel(expected);\n        const expectedMsg = hasLabel\n            ? `--> ${tokenLabel(expected)} <--`\n            : `token of type --> ${expected.name} <--`;\n        const msg = `Expecting ${expectedMsg} but found --> '${actual.image}' <--`;\n        return msg;\n    },\n    buildNotAllInputParsedMessage({ firstRedundant, ruleName }) {\n        return \"Redundant input, expecting EOF but found: \" + firstRedundant.image;\n    },\n    buildNoViableAltMessage({ expectedPathsPerAlt, actual, previous, customUserDescription, ruleName, }) {\n        const errPrefix = \"Expecting: \";\n        // TODO: issue: No Viable Alternative Error may have incomplete details. #502\n        const actualText = first(actual).image;\n        const errSuffix = \"\\nbut found: '\" + actualText + \"'\";\n        if (customUserDescription) {\n            return errPrefix + customUserDescription + errSuffix;\n        }\n        else {\n            const allLookAheadPaths = reduce(expectedPathsPerAlt, (result, currAltPaths) => result.concat(currAltPaths), []);\n            const nextValidTokenSequences = map(allLookAheadPaths, (currPath) => `[${map(currPath, (currTokenType) => tokenLabel(currTokenType)).join(\", \")}]`);\n            const nextValidSequenceItems = map(nextValidTokenSequences, (itemMsg, idx) => `  ${idx + 1}. ${itemMsg}`);\n            const calculatedDescription = `one of these possible Token sequences:\\n${nextValidSequenceItems.join(\"\\n\")}`;\n            return errPrefix + calculatedDescription + errSuffix;\n        }\n    },\n    buildEarlyExitMessage({ expectedIterationPaths, actual, customUserDescription, ruleName, }) {\n        const errPrefix = \"Expecting: \";\n        // TODO: issue: No Viable Alternative Error may have incomplete details. #502\n        const actualText = first(actual).image;\n        const errSuffix = \"\\nbut found: '\" + actualText + \"'\";\n        if (customUserDescription) {\n            return errPrefix + customUserDescription + errSuffix;\n        }\n        else {\n            const nextValidTokenSequences = map(expectedIterationPaths, (currPath) => `[${map(currPath, (currTokenType) => tokenLabel(currTokenType)).join(\",\")}]`);\n            const calculatedDescription = `expecting at least one iteration which starts with one of these possible Token sequences::\\n  ` +\n                `<${nextValidTokenSequences.join(\" ,\")}>`;\n            return errPrefix + calculatedDescription + errSuffix;\n        }\n    },\n};\nObject.freeze(defaultParserErrorProvider);\nexport const defaultGrammarResolverErrorProvider = {\n    buildRuleNotFoundError(topLevelRule, undefinedRule) {\n        const msg = \"Invalid grammar, reference to a rule which is not defined: ->\" +\n            undefinedRule.nonTerminalName +\n            \"<-\\n\" +\n            \"inside top level rule: ->\" +\n            topLevelRule.name +\n            \"<-\";\n        return msg;\n    },\n};\nexport const defaultGrammarValidatorErrorProvider = {\n    buildDuplicateFoundError(topLevelRule, duplicateProds) {\n        function getExtraProductionArgument(prod) {\n            if (prod instanceof Terminal) {\n                return prod.terminalType.name;\n            }\n            else if (prod instanceof NonTerminal) {\n                return prod.nonTerminalName;\n            }\n            else {\n                return \"\";\n            }\n        }\n        const topLevelName = topLevelRule.name;\n        const duplicateProd = first(duplicateProds);\n        const index = duplicateProd.idx;\n        const dslName = getProductionDslName(duplicateProd);\n        const extraArgument = getExtraProductionArgument(duplicateProd);\n        const hasExplicitIndex = index > 0;\n        let msg = `->${dslName}${hasExplicitIndex ? index : \"\"}<- ${extraArgument ? `with argument: ->${extraArgument}<-` : \"\"}\n                  appears more than once (${duplicateProds.length} times) in the top level rule: ->${topLevelName}<-.                  \n                  For further details see: https://chevrotain.io/docs/FAQ.html#NUMERICAL_SUFFIXES \n                  `;\n        // white space trimming time! better to trim afterwards as it allows to use WELL formatted multi line template strings...\n        msg = msg.replace(/[ \\t]+/g, \" \");\n        msg = msg.replace(/\\s\\s+/g, \"\\n\");\n        return msg;\n    },\n    buildNamespaceConflictError(rule) {\n        const errMsg = `Namespace conflict found in grammar.\\n` +\n            `The grammar has both a Terminal(Token) and a Non-Terminal(Rule) named: <${rule.name}>.\\n` +\n            `To resolve this make sure each Terminal and Non-Terminal names are unique\\n` +\n            `This is easy to accomplish by using the convention that Terminal names start with an uppercase letter\\n` +\n            `and Non-Terminal names start with a lower case letter.`;\n        return errMsg;\n    },\n    buildAlternationPrefixAmbiguityError(options) {\n        const pathMsg = map(options.prefixPath, (currTok) => tokenLabel(currTok)).join(\", \");\n        const occurrence = options.alternation.idx === 0 ? \"\" : options.alternation.idx;\n        const errMsg = `Ambiguous alternatives: <${options.ambiguityIndices.join(\" ,\")}> due to common lookahead prefix\\n` +\n            `in <OR${occurrence}> inside <${options.topLevelRule.name}> Rule,\\n` +\n            `<${pathMsg}> may appears as a prefix path in all these alternatives.\\n` +\n            `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#COMMON_PREFIX\\n` +\n            `For Further details.`;\n        return errMsg;\n    },\n    buildAlternationAmbiguityError(options) {\n        const pathMsg = map(options.prefixPath, (currtok) => tokenLabel(currtok)).join(\", \");\n        const occurrence = options.alternation.idx === 0 ? \"\" : options.alternation.idx;\n        let currMessage = `Ambiguous Alternatives Detected: <${options.ambiguityIndices.join(\" ,\")}> in <OR${occurrence}>` +\n            ` inside <${options.topLevelRule.name}> Rule,\\n` +\n            `<${pathMsg}> may appears as a prefix path in all these alternatives.\\n`;\n        currMessage =\n            currMessage +\n                `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#AMBIGUOUS_ALTERNATIVES\\n` +\n                `For Further details.`;\n        return currMessage;\n    },\n    buildEmptyRepetitionError(options) {\n        let dslName = getProductionDslName(options.repetition);\n        if (options.repetition.idx !== 0) {\n            dslName += options.repetition.idx;\n        }\n        const errMsg = `The repetition <${dslName}> within Rule <${options.topLevelRule.name}> can never consume any tokens.\\n` +\n            `This could lead to an infinite loop.`;\n        return errMsg;\n    },\n    // TODO: remove - `errors_public` from nyc.config.js exclude\n    //       once this method is fully removed from this file\n    buildTokenNameError(options) {\n        /* istanbul ignore next */\n        return \"deprecated\";\n    },\n    buildEmptyAlternationError(options) {\n        const errMsg = `Ambiguous empty alternative: <${options.emptyChoiceIdx + 1}>` +\n            ` in <OR${options.alternation.idx}> inside <${options.topLevelRule.name}> Rule.\\n` +\n            `Only the last alternative may be an empty alternative.`;\n        return errMsg;\n    },\n    buildTooManyAlternativesError(options) {\n        const errMsg = `An Alternation cannot have more than 256 alternatives:\\n` +\n            `<OR${options.alternation.idx}> inside <${options.topLevelRule.name}> Rule.\\n has ${options.alternation.definition.length + 1} alternatives.`;\n        return errMsg;\n    },\n    buildLeftRecursionError(options) {\n        const ruleName = options.topLevelRule.name;\n        const pathNames = map(options.leftRecursionPath, (currRule) => currRule.name);\n        const leftRecursivePath = `${ruleName} --> ${pathNames\n            .concat([ruleName])\n            .join(\" --> \")}`;\n        const errMsg = `Left Recursion found in grammar.\\n` +\n            `rule: <${ruleName}> can be invoked from itself (directly or indirectly)\\n` +\n            `without consuming any Tokens. The grammar path that causes this is: \\n ${leftRecursivePath}\\n` +\n            ` To fix this refactor your grammar to remove the left recursion.\\n` +\n            `see: https://en.wikipedia.org/wiki/LL_parser#Left_factoring.`;\n        return errMsg;\n    },\n    // TODO: remove - `errors_public` from nyc.config.js exclude\n    //       once this method is fully removed from this file\n    buildInvalidRuleNameError(options) {\n        /* istanbul ignore next */\n        return \"deprecated\";\n    },\n    buildDuplicateRuleNameError(options) {\n        let ruleName;\n        if (options.topLevelRule instanceof Rule) {\n            ruleName = options.topLevelRule.name;\n        }\n        else {\n            ruleName = options.topLevelRule;\n        }\n        const errMsg = `Duplicate definition, rule: ->${ruleName}<- is already defined in the grammar: ->${options.grammarName}<-`;\n        return errMsg;\n    },\n};\n//# sourceMappingURL=errors_public.js.map","import { Alternation, Alternative, NonTerminal, Option, Repetition, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, Rule, Terminal, } from \"./model.js\";\nexport class GAstVisitor {\n    visit(node) {\n        const nodeAny = node;\n        switch (nodeAny.constructor) {\n            case NonTerminal:\n                return this.visitNonTerminal(nodeAny);\n            case Alternative:\n                return this.visitAlternative(nodeAny);\n            case Option:\n                return this.visitOption(nodeAny);\n            case RepetitionMandatory:\n                return this.visitRepetitionMandatory(nodeAny);\n            case RepetitionMandatoryWithSeparator:\n                return this.visitRepetitionMandatoryWithSeparator(nodeAny);\n            case RepetitionWithSeparator:\n                return this.visitRepetitionWithSeparator(nodeAny);\n            case Repetition:\n                return this.visitRepetition(nodeAny);\n            case Alternation:\n                return this.visitAlternation(nodeAny);\n            case Terminal:\n                return this.visitTerminal(nodeAny);\n            case Rule:\n                return this.visitRule(nodeAny);\n            /* c8 ignore next 2 */\n            default:\n                throw Error(\"non exhaustive match\");\n        }\n    }\n    /* c8 ignore next */\n    visitNonTerminal(node) { }\n    /* c8 ignore next */\n    visitAlternative(node) { }\n    /* c8 ignore next */\n    visitOption(node) { }\n    /* c8 ignore next */\n    visitRepetition(node) { }\n    /* c8 ignore next */\n    visitRepetitionMandatory(node) { }\n    /* c8 ignore next 3 */\n    visitRepetitionMandatoryWithSeparator(node) { }\n    /* c8 ignore next */\n    visitRepetitionWithSeparator(node) { }\n    /* c8 ignore next */\n    visitAlternation(node) { }\n    /* c8 ignore next */\n    visitTerminal(node) { }\n    /* c8 ignore next */\n    visitRule(node) { }\n}\n//# sourceMappingURL=visitor.js.map","import { ParserDefinitionErrorType, } from \"../parser/parser.js\";\nimport { forEach, values } from \"lodash-es\";\nimport { GAstVisitor } from \"@chevrotain/gast\";\nexport function resolveGrammar(topLevels, errMsgProvider) {\n    const refResolver = new GastRefResolverVisitor(topLevels, errMsgProvider);\n    refResolver.resolveRefs();\n    return refResolver.errors;\n}\nexport class GastRefResolverVisitor extends GAstVisitor {\n    constructor(nameToTopRule, errMsgProvider) {\n        super();\n        this.nameToTopRule = nameToTopRule;\n        this.errMsgProvider = errMsgProvider;\n        this.errors = [];\n    }\n    resolveRefs() {\n        forEach(values(this.nameToTopRule), (prod) => {\n            this.currTopLevel = prod;\n            prod.accept(this);\n        });\n    }\n    visitNonTerminal(node) {\n        const ref = this.nameToTopRule[node.nonTerminalName];\n        if (!ref) {\n            const msg = this.errMsgProvider.buildRuleNotFoundError(this.currTopLevel, node);\n            this.errors.push({\n                message: msg,\n                type: ParserDefinitionErrorType.UNRESOLVED_SUBRULE_REF,\n                ruleName: this.currTopLevel.name,\n                unresolvedRefName: node.nonTerminalName,\n            });\n        }\n        else {\n            node.referencedRule = ref;\n        }\n    }\n}\n//# sourceMappingURL=resolver.js.map","/**\n * A specialized version of `baseAggregator` for arrays.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} setter The function to set `accumulator` values.\n * @param {Function} iteratee The iteratee to transform keys.\n * @param {Object} accumulator The initial aggregated object.\n * @returns {Function} Returns `accumulator`.\n */\nfunction arrayAggregator(array, setter, iteratee, accumulator) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  while (++index < length) {\n    var value = array[index];\n    setter(accumulator, value, iteratee(value), array);\n  }\n  return accumulator;\n}\n\nexport default arrayAggregator;\n","import baseEach from './_baseEach.js';\n\n/**\n * Aggregates elements of `collection` on `accumulator` with keys transformed\n * by `iteratee` and values set by `setter`.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} setter The function to set `accumulator` values.\n * @param {Function} iteratee The iteratee to transform keys.\n * @param {Object} accumulator The initial aggregated object.\n * @returns {Function} Returns `accumulator`.\n */\nfunction baseAggregator(collection, setter, iteratee, accumulator) {\n  baseEach(collection, function(value, key, collection) {\n    setter(accumulator, value, iteratee(value), collection);\n  });\n  return accumulator;\n}\n\nexport default baseAggregator;\n","import arrayAggregator from './_arrayAggregator.js';\nimport baseAggregator from './_baseAggregator.js';\nimport baseIteratee from './_baseIteratee.js';\nimport isArray from './isArray.js';\n\n/**\n * Creates a function like `_.groupBy`.\n *\n * @private\n * @param {Function} setter The function to set accumulator values.\n * @param {Function} [initializer] The accumulator object initializer.\n * @returns {Function} Returns the new aggregator function.\n */\nfunction createAggregator(setter, initializer) {\n  return function(collection, iteratee) {\n    var func = isArray(collection) ? arrayAggregator : baseAggregator,\n        accumulator = initializer ? initializer() : {};\n\n    return func(collection, setter, baseIteratee(iteratee, 2), accumulator);\n  };\n}\n\nexport default createAggregator;\n","import baseAssignValue from './_baseAssignValue.js';\nimport createAggregator from './_createAggregator.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Creates an object composed of keys generated from the results of running\n * each element of `collection` thru `iteratee`. The order of grouped values\n * is determined by the order they occur in `collection`. The corresponding\n * value of each key is an array of elements responsible for generating the\n * key. The iteratee is invoked with one argument: (value).\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The iteratee to transform keys.\n * @returns {Object} Returns the composed aggregate object.\n * @example\n *\n * _.groupBy([6.1, 4.2, 6.3], Math.floor);\n * // => { '4': [4.2], '6': [6.1, 6.3] }\n *\n * // The `_.property` iteratee shorthand.\n * _.groupBy(['one', 'two', 'three'], 'length');\n * // => { '3': ['one', 'two'], '5': ['three'] }\n */\nvar groupBy = createAggregator(function(result, value, key) {\n  if (hasOwnProperty.call(result, key)) {\n    result[key].push(value);\n  } else {\n    baseAssignValue(result, key, [value]);\n  }\n});\n\nexport default groupBy;\n","import baseSlice from './_baseSlice.js';\nimport toInteger from './toInteger.js';\n\n/**\n * Creates a slice of `array` with `n` elements dropped from the end.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Array\n * @param {Array} array The array to query.\n * @param {number} [n=1] The number of elements to drop.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {Array} Returns the slice of `array`.\n * @example\n *\n * _.dropRight([1, 2, 3]);\n * // => [1, 2]\n *\n * _.dropRight([1, 2, 3], 2);\n * // => [1]\n *\n * _.dropRight([1, 2, 3], 5);\n * // => []\n *\n * _.dropRight([1, 2, 3], 0);\n * // => [1, 2, 3]\n */\nfunction dropRight(array, n, guard) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return [];\n  }\n  n = (guard || n === undefined) ? 1 : toInteger(n);\n  n = length - n;\n  return baseSlice(array, 0, n < 0 ? 0 : n);\n}\n\nexport default dropRight;\n","import { clone, drop, dropRight, first as _first, forEach, isEmpty, last, } from \"lodash-es\";\nimport { first } from \"./first.js\";\nimport { RestWalker } from \"./rest.js\";\nimport { Alternation, Alternative, NonTerminal, Option, Repetition, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, Rule, Terminal, } from \"@chevrotain/gast\";\nexport class AbstractNextPossibleTokensWalker extends RestWalker {\n    constructor(topProd, path) {\n        super();\n        this.topProd = topProd;\n        this.path = path;\n        this.possibleTokTypes = [];\n        this.nextProductionName = \"\";\n        this.nextProductionOccurrence = 0;\n        this.found = false;\n        this.isAtEndOfPath = false;\n    }\n    startWalking() {\n        this.found = false;\n        if (this.path.ruleStack[0] !== this.topProd.name) {\n            throw Error(\"The path does not start with the walker's top Rule!\");\n        }\n        // immutable for the win\n        this.ruleStack = clone(this.path.ruleStack).reverse(); // intelij bug requires assertion\n        this.occurrenceStack = clone(this.path.occurrenceStack).reverse(); // intelij bug requires assertion\n        // already verified that the first production is valid, we now seek the 2nd production\n        this.ruleStack.pop();\n        this.occurrenceStack.pop();\n        this.updateExpectedNext();\n        this.walk(this.topProd);\n        return this.possibleTokTypes;\n    }\n    walk(prod, prevRest = []) {\n        // stop scanning once we found the path\n        if (!this.found) {\n            super.walk(prod, prevRest);\n        }\n    }\n    walkProdRef(refProd, currRest, prevRest) {\n        // found the next production, need to keep walking in it\n        if (refProd.referencedRule.name === this.nextProductionName &&\n            refProd.idx === this.nextProductionOccurrence) {\n            const fullRest = currRest.concat(prevRest);\n            this.updateExpectedNext();\n            this.walk(refProd.referencedRule, fullRest);\n        }\n    }\n    updateExpectedNext() {\n        // need to consume the Terminal\n        if (isEmpty(this.ruleStack)) {\n            // must reset nextProductionXXX to avoid walking down another Top Level production while what we are\n            // really seeking is the last Terminal...\n            this.nextProductionName = \"\";\n            this.nextProductionOccurrence = 0;\n            this.isAtEndOfPath = true;\n        }\n        else {\n            this.nextProductionName = this.ruleStack.pop();\n            this.nextProductionOccurrence = this.occurrenceStack.pop();\n        }\n    }\n}\nexport class NextAfterTokenWalker extends AbstractNextPossibleTokensWalker {\n    constructor(topProd, path) {\n        super(topProd, path);\n        this.path = path;\n        this.nextTerminalName = \"\";\n        this.nextTerminalOccurrence = 0;\n        this.nextTerminalName = this.path.lastTok.name;\n        this.nextTerminalOccurrence = this.path.lastTokOccurrence;\n    }\n    walkTerminal(terminal, currRest, prevRest) {\n        if (this.isAtEndOfPath &&\n            terminal.terminalType.name === this.nextTerminalName &&\n            terminal.idx === this.nextTerminalOccurrence &&\n            !this.found) {\n            const fullRest = currRest.concat(prevRest);\n            const restProd = new Alternative({ definition: fullRest });\n            this.possibleTokTypes = first(restProd);\n            this.found = true;\n        }\n    }\n}\n/**\n * This walker only \"walks\" a single \"TOP\" level in the Grammar Ast, this means\n * it never \"follows\" production refs\n */\nexport class AbstractNextTerminalAfterProductionWalker extends RestWalker {\n    constructor(topRule, occurrence) {\n        super();\n        this.topRule = topRule;\n        this.occurrence = occurrence;\n        this.result = {\n            token: undefined,\n            occurrence: undefined,\n            isEndOfRule: undefined,\n        };\n    }\n    startWalking() {\n        this.walk(this.topRule);\n        return this.result;\n    }\n}\nexport class NextTerminalAfterManyWalker extends AbstractNextTerminalAfterProductionWalker {\n    walkMany(manyProd, currRest, prevRest) {\n        if (manyProd.idx === this.occurrence) {\n            const firstAfterMany = _first(currRest.concat(prevRest));\n            this.result.isEndOfRule = firstAfterMany === undefined;\n            if (firstAfterMany instanceof Terminal) {\n                this.result.token = firstAfterMany.terminalType;\n                this.result.occurrence = firstAfterMany.idx;\n            }\n        }\n        else {\n            super.walkMany(manyProd, currRest, prevRest);\n        }\n    }\n}\nexport class NextTerminalAfterManySepWalker extends AbstractNextTerminalAfterProductionWalker {\n    walkManySep(manySepProd, currRest, prevRest) {\n        if (manySepProd.idx === this.occurrence) {\n            const firstAfterManySep = _first(currRest.concat(prevRest));\n            this.result.isEndOfRule = firstAfterManySep === undefined;\n            if (firstAfterManySep instanceof Terminal) {\n                this.result.token = firstAfterManySep.terminalType;\n                this.result.occurrence = firstAfterManySep.idx;\n            }\n        }\n        else {\n            super.walkManySep(manySepProd, currRest, prevRest);\n        }\n    }\n}\nexport class NextTerminalAfterAtLeastOneWalker extends AbstractNextTerminalAfterProductionWalker {\n    walkAtLeastOne(atLeastOneProd, currRest, prevRest) {\n        if (atLeastOneProd.idx === this.occurrence) {\n            const firstAfterAtLeastOne = _first(currRest.concat(prevRest));\n            this.result.isEndOfRule = firstAfterAtLeastOne === undefined;\n            if (firstAfterAtLeastOne instanceof Terminal) {\n                this.result.token = firstAfterAtLeastOne.terminalType;\n                this.result.occurrence = firstAfterAtLeastOne.idx;\n            }\n        }\n        else {\n            super.walkAtLeastOne(atLeastOneProd, currRest, prevRest);\n        }\n    }\n}\n// TODO: reduce code duplication in the AfterWalkers\nexport class NextTerminalAfterAtLeastOneSepWalker extends AbstractNextTerminalAfterProductionWalker {\n    walkAtLeastOneSep(atleastOneSepProd, currRest, prevRest) {\n        if (atleastOneSepProd.idx === this.occurrence) {\n            const firstAfterfirstAfterAtLeastOneSep = _first(currRest.concat(prevRest));\n            this.result.isEndOfRule = firstAfterfirstAfterAtLeastOneSep === undefined;\n            if (firstAfterfirstAfterAtLeastOneSep instanceof Terminal) {\n                this.result.token = firstAfterfirstAfterAtLeastOneSep.terminalType;\n                this.result.occurrence = firstAfterfirstAfterAtLeastOneSep.idx;\n            }\n        }\n        else {\n            super.walkAtLeastOneSep(atleastOneSepProd, currRest, prevRest);\n        }\n    }\n}\nexport function possiblePathsFrom(targetDef, maxLength, currPath = []) {\n    // avoid side effects\n    currPath = clone(currPath);\n    let result = [];\n    let i = 0;\n    // TODO: avoid inner funcs\n    function remainingPathWith(nextDef) {\n        return nextDef.concat(drop(targetDef, i + 1));\n    }\n    // TODO: avoid inner funcs\n    function getAlternativesForProd(definition) {\n        const alternatives = possiblePathsFrom(remainingPathWith(definition), maxLength, currPath);\n        return result.concat(alternatives);\n    }\n    /**\n     * Mandatory productions will halt the loop as the paths computed from their recursive calls will already contain the\n     * following (rest) of the targetDef.\n     *\n     * For optional productions (Option/Repetition/...) the loop will continue to represent the paths that do not include the\n     * the optional production.\n     */\n    while (currPath.length < maxLength && i < targetDef.length) {\n        const prod = targetDef[i];\n        /* istanbul ignore else */\n        if (prod instanceof Alternative) {\n            return getAlternativesForProd(prod.definition);\n        }\n        else if (prod instanceof NonTerminal) {\n            return getAlternativesForProd(prod.definition);\n        }\n        else if (prod instanceof Option) {\n            result = getAlternativesForProd(prod.definition);\n        }\n        else if (prod instanceof RepetitionMandatory) {\n            const newDef = prod.definition.concat([\n                new Repetition({\n                    definition: prod.definition,\n                }),\n            ]);\n            return getAlternativesForProd(newDef);\n        }\n        else if (prod instanceof RepetitionMandatoryWithSeparator) {\n            const newDef = [\n                new Alternative({ definition: prod.definition }),\n                new Repetition({\n                    definition: [new Terminal({ terminalType: prod.separator })].concat(prod.definition),\n                }),\n            ];\n            return getAlternativesForProd(newDef);\n        }\n        else if (prod instanceof RepetitionWithSeparator) {\n            const newDef = prod.definition.concat([\n                new Repetition({\n                    definition: [new Terminal({ terminalType: prod.separator })].concat(prod.definition),\n                }),\n            ]);\n            result = getAlternativesForProd(newDef);\n        }\n        else if (prod instanceof Repetition) {\n            const newDef = prod.definition.concat([\n                new Repetition({\n                    definition: prod.definition,\n                }),\n            ]);\n            result = getAlternativesForProd(newDef);\n        }\n        else if (prod instanceof Alternation) {\n            forEach(prod.definition, (currAlt) => {\n                // TODO: this is a limited check for empty alternatives\n                //   It would prevent a common case of infinite loops during parser initialization.\n                //   However **in-directly** empty alternatives may still cause issues.\n                if (isEmpty(currAlt.definition) === false) {\n                    result = getAlternativesForProd(currAlt.definition);\n                }\n            });\n            return result;\n        }\n        else if (prod instanceof Terminal) {\n            currPath.push(prod.terminalType);\n        }\n        else {\n            throw Error(\"non exhaustive match\");\n        }\n        i++;\n    }\n    result.push({\n        partialPath: currPath,\n        suffixDef: drop(targetDef, i),\n    });\n    return result;\n}\nexport function nextPossibleTokensAfter(initialDef, tokenVector, tokMatcher, maxLookAhead) {\n    const EXIT_NON_TERMINAL = \"EXIT_NONE_TERMINAL\";\n    // to avoid creating a new Array each time.\n    const EXIT_NON_TERMINAL_ARR = [EXIT_NON_TERMINAL];\n    const EXIT_ALTERNATIVE = \"EXIT_ALTERNATIVE\";\n    let foundCompletePath = false;\n    const tokenVectorLength = tokenVector.length;\n    const minimalAlternativesIndex = tokenVectorLength - maxLookAhead - 1;\n    const result = [];\n    const possiblePaths = [];\n    possiblePaths.push({\n        idx: -1,\n        def: initialDef,\n        ruleStack: [],\n        occurrenceStack: [],\n    });\n    while (!isEmpty(possiblePaths)) {\n        const currPath = possiblePaths.pop();\n        // skip alternatives if no more results can be found (assuming deterministic grammar with fixed lookahead)\n        if (currPath === EXIT_ALTERNATIVE) {\n            if (foundCompletePath &&\n                last(possiblePaths).idx <= minimalAlternativesIndex) {\n                // remove irrelevant alternative\n                possiblePaths.pop();\n            }\n            continue;\n        }\n        const currDef = currPath.def;\n        const currIdx = currPath.idx;\n        const currRuleStack = currPath.ruleStack;\n        const currOccurrenceStack = currPath.occurrenceStack;\n        // For Example: an empty path could exist in a valid grammar in the case of an EMPTY_ALT\n        if (isEmpty(currDef)) {\n            continue;\n        }\n        const prod = currDef[0];\n        /* istanbul ignore else */\n        if (prod === EXIT_NON_TERMINAL) {\n            const nextPath = {\n                idx: currIdx,\n                def: drop(currDef),\n                ruleStack: dropRight(currRuleStack),\n                occurrenceStack: dropRight(currOccurrenceStack),\n            };\n            possiblePaths.push(nextPath);\n        }\n        else if (prod instanceof Terminal) {\n            /* istanbul ignore else */\n            if (currIdx < tokenVectorLength - 1) {\n                const nextIdx = currIdx + 1;\n                const actualToken = tokenVector[nextIdx];\n                if (tokMatcher(actualToken, prod.terminalType)) {\n                    const nextPath = {\n                        idx: nextIdx,\n                        def: drop(currDef),\n                        ruleStack: currRuleStack,\n                        occurrenceStack: currOccurrenceStack,\n                    };\n                    possiblePaths.push(nextPath);\n                }\n                // end of the line\n            }\n            else if (currIdx === tokenVectorLength - 1) {\n                // IGNORE ABOVE ELSE\n                result.push({\n                    nextTokenType: prod.terminalType,\n                    nextTokenOccurrence: prod.idx,\n                    ruleStack: currRuleStack,\n                    occurrenceStack: currOccurrenceStack,\n                });\n                foundCompletePath = true;\n            }\n            else {\n                throw Error(\"non exhaustive match\");\n            }\n        }\n        else if (prod instanceof NonTerminal) {\n            const newRuleStack = clone(currRuleStack);\n            newRuleStack.push(prod.nonTerminalName);\n            const newOccurrenceStack = clone(currOccurrenceStack);\n            newOccurrenceStack.push(prod.idx);\n            const nextPath = {\n                idx: currIdx,\n                def: prod.definition.concat(EXIT_NON_TERMINAL_ARR, drop(currDef)),\n                ruleStack: newRuleStack,\n                occurrenceStack: newOccurrenceStack,\n            };\n            possiblePaths.push(nextPath);\n        }\n        else if (prod instanceof Option) {\n            // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n            const nextPathWithout = {\n                idx: currIdx,\n                def: drop(currDef),\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            };\n            possiblePaths.push(nextPathWithout);\n            // required marker to avoid backtracking paths whose higher priority alternatives already matched\n            possiblePaths.push(EXIT_ALTERNATIVE);\n            const nextPathWith = {\n                idx: currIdx,\n                def: prod.definition.concat(drop(currDef)),\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            };\n            possiblePaths.push(nextPathWith);\n        }\n        else if (prod instanceof RepetitionMandatory) {\n            // TODO:(THE NEW operators here take a while...) (convert once?)\n            const secondIteration = new Repetition({\n                definition: prod.definition,\n                idx: prod.idx,\n            });\n            const nextDef = prod.definition.concat([secondIteration], drop(currDef));\n            const nextPath = {\n                idx: currIdx,\n                def: nextDef,\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            };\n            possiblePaths.push(nextPath);\n        }\n        else if (prod instanceof RepetitionMandatoryWithSeparator) {\n            // TODO:(THE NEW operators here take a while...) (convert once?)\n            const separatorGast = new Terminal({\n                terminalType: prod.separator,\n            });\n            const secondIteration = new Repetition({\n                definition: [separatorGast].concat(prod.definition),\n                idx: prod.idx,\n            });\n            const nextDef = prod.definition.concat([secondIteration], drop(currDef));\n            const nextPath = {\n                idx: currIdx,\n                def: nextDef,\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            };\n            possiblePaths.push(nextPath);\n        }\n        else if (prod instanceof RepetitionWithSeparator) {\n            // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n            const nextPathWithout = {\n                idx: currIdx,\n                def: drop(currDef),\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            };\n            possiblePaths.push(nextPathWithout);\n            // required marker to avoid backtracking paths whose higher priority alternatives already matched\n            possiblePaths.push(EXIT_ALTERNATIVE);\n            const separatorGast = new Terminal({\n                terminalType: prod.separator,\n            });\n            const nthRepetition = new Repetition({\n                definition: [separatorGast].concat(prod.definition),\n                idx: prod.idx,\n            });\n            const nextDef = prod.definition.concat([nthRepetition], drop(currDef));\n            const nextPathWith = {\n                idx: currIdx,\n                def: nextDef,\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            };\n            possiblePaths.push(nextPathWith);\n        }\n        else if (prod instanceof Repetition) {\n            // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n            const nextPathWithout = {\n                idx: currIdx,\n                def: drop(currDef),\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            };\n            possiblePaths.push(nextPathWithout);\n            // required marker to avoid backtracking paths whose higher priority alternatives already matched\n            possiblePaths.push(EXIT_ALTERNATIVE);\n            // TODO: an empty repetition will cause infinite loops here, will the parser detect this in selfAnalysis?\n            const nthRepetition = new Repetition({\n                definition: prod.definition,\n                idx: prod.idx,\n            });\n            const nextDef = prod.definition.concat([nthRepetition], drop(currDef));\n            const nextPathWith = {\n                idx: currIdx,\n                def: nextDef,\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            };\n            possiblePaths.push(nextPathWith);\n        }\n        else if (prod instanceof Alternation) {\n            // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n            for (let i = prod.definition.length - 1; i >= 0; i--) {\n                const currAlt = prod.definition[i];\n                const currAltPath = {\n                    idx: currIdx,\n                    def: currAlt.definition.concat(drop(currDef)),\n                    ruleStack: currRuleStack,\n                    occurrenceStack: currOccurrenceStack,\n                };\n                possiblePaths.push(currAltPath);\n                possiblePaths.push(EXIT_ALTERNATIVE);\n            }\n        }\n        else if (prod instanceof Alternative) {\n            possiblePaths.push({\n                idx: currIdx,\n                def: prod.definition.concat(drop(currDef)),\n                ruleStack: currRuleStack,\n                occurrenceStack: currOccurrenceStack,\n            });\n        }\n        else if (prod instanceof Rule) {\n            // last because we should only encounter at most a single one of these per invocation.\n            possiblePaths.push(expandTopLevelRule(prod, currIdx, currRuleStack, currOccurrenceStack));\n        }\n        else {\n            throw Error(\"non exhaustive match\");\n        }\n    }\n    return result;\n}\nfunction expandTopLevelRule(topRule, currIdx, currRuleStack, currOccurrenceStack) {\n    const newRuleStack = clone(currRuleStack);\n    newRuleStack.push(topRule.name);\n    const newCurrOccurrenceStack = clone(currOccurrenceStack);\n    // top rule is always assumed to have been called with occurrence index 1\n    newCurrOccurrenceStack.push(1);\n    return {\n        idx: currIdx,\n        def: topRule.definition,\n        ruleStack: newRuleStack,\n        occurrenceStack: newCurrOccurrenceStack,\n    };\n}\n//# sourceMappingURL=interpreter.js.map","import { every, flatten, forEach, has, isEmpty, map, reduce } from \"lodash-es\";\nimport { possiblePathsFrom } from \"./interpreter.js\";\nimport { RestWalker } from \"./rest.js\";\nimport { tokenStructuredMatcher, tokenStructuredMatcherNoCategories, } from \"../../scan/tokens.js\";\nimport { Alternation, Alternative as AlternativeGAST, GAstVisitor, Option, Repetition, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, } from \"@chevrotain/gast\";\nexport var PROD_TYPE;\n(function (PROD_TYPE) {\n    PROD_TYPE[PROD_TYPE[\"OPTION\"] = 0] = \"OPTION\";\n    PROD_TYPE[PROD_TYPE[\"REPETITION\"] = 1] = \"REPETITION\";\n    PROD_TYPE[PROD_TYPE[\"REPETITION_MANDATORY\"] = 2] = \"REPETITION_MANDATORY\";\n    PROD_TYPE[PROD_TYPE[\"REPETITION_MANDATORY_WITH_SEPARATOR\"] = 3] = \"REPETITION_MANDATORY_WITH_SEPARATOR\";\n    PROD_TYPE[PROD_TYPE[\"REPETITION_WITH_SEPARATOR\"] = 4] = \"REPETITION_WITH_SEPARATOR\";\n    PROD_TYPE[PROD_TYPE[\"ALTERNATION\"] = 5] = \"ALTERNATION\";\n})(PROD_TYPE || (PROD_TYPE = {}));\nexport function getProdType(prod) {\n    /* istanbul ignore else */\n    if (prod instanceof Option || prod === \"Option\") {\n        return PROD_TYPE.OPTION;\n    }\n    else if (prod instanceof Repetition || prod === \"Repetition\") {\n        return PROD_TYPE.REPETITION;\n    }\n    else if (prod instanceof RepetitionMandatory ||\n        prod === \"RepetitionMandatory\") {\n        return PROD_TYPE.REPETITION_MANDATORY;\n    }\n    else if (prod instanceof RepetitionMandatoryWithSeparator ||\n        prod === \"RepetitionMandatoryWithSeparator\") {\n        return PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR;\n    }\n    else if (prod instanceof RepetitionWithSeparator ||\n        prod === \"RepetitionWithSeparator\") {\n        return PROD_TYPE.REPETITION_WITH_SEPARATOR;\n    }\n    else if (prod instanceof Alternation || prod === \"Alternation\") {\n        return PROD_TYPE.ALTERNATION;\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nexport function getLookaheadPaths(options) {\n    const { occurrence, rule, prodType, maxLookahead } = options;\n    const type = getProdType(prodType);\n    if (type === PROD_TYPE.ALTERNATION) {\n        return getLookaheadPathsForOr(occurrence, rule, maxLookahead);\n    }\n    else {\n        return getLookaheadPathsForOptionalProd(occurrence, rule, type, maxLookahead);\n    }\n}\nexport function buildLookaheadFuncForOr(occurrence, ruleGrammar, maxLookahead, hasPredicates, dynamicTokensEnabled, laFuncBuilder) {\n    const lookAheadPaths = getLookaheadPathsForOr(occurrence, ruleGrammar, maxLookahead);\n    const tokenMatcher = areTokenCategoriesNotUsed(lookAheadPaths)\n        ? tokenStructuredMatcherNoCategories\n        : tokenStructuredMatcher;\n    return laFuncBuilder(lookAheadPaths, hasPredicates, tokenMatcher, dynamicTokensEnabled);\n}\n/**\n *  When dealing with an Optional production (OPTION/MANY/2nd iteration of AT_LEAST_ONE/...) we need to compare\n *  the lookahead \"inside\" the production and the lookahead immediately \"after\" it in the same top level rule (context free).\n *\n *  Example: given a production:\n *  ABC(DE)?DF\n *\n *  The optional '(DE)?' should only be entered if we see 'DE'. a single Token 'D' is not sufficient to distinguish between the two\n *  alternatives.\n *\n *  @returns A Lookahead function which will return true IFF the parser should parse the Optional production.\n */\nexport function buildLookaheadFuncForOptionalProd(occurrence, ruleGrammar, k, dynamicTokensEnabled, prodType, lookaheadBuilder) {\n    const lookAheadPaths = getLookaheadPathsForOptionalProd(occurrence, ruleGrammar, prodType, k);\n    const tokenMatcher = areTokenCategoriesNotUsed(lookAheadPaths)\n        ? tokenStructuredMatcherNoCategories\n        : tokenStructuredMatcher;\n    return lookaheadBuilder(lookAheadPaths[0], tokenMatcher, dynamicTokensEnabled);\n}\nexport function buildAlternativesLookAheadFunc(alts, hasPredicates, tokenMatcher, dynamicTokensEnabled) {\n    const numOfAlts = alts.length;\n    const areAllOneTokenLookahead = every(alts, (currAlt) => {\n        return every(currAlt, (currPath) => {\n            return currPath.length === 1;\n        });\n    });\n    // This version takes into account the predicates as well.\n    if (hasPredicates) {\n        /**\n         * @returns {number} - The chosen alternative index\n         */\n        return function (orAlts) {\n            // unfortunately the predicates must be extracted every single time\n            // as they cannot be cached due to references to parameters(vars) which are no longer valid.\n            // note that in the common case of no predicates, no cpu time will be wasted on this (see else block)\n            const predicates = map(orAlts, (currAlt) => currAlt.GATE);\n            for (let t = 0; t < numOfAlts; t++) {\n                const currAlt = alts[t];\n                const currNumOfPaths = currAlt.length;\n                const currPredicate = predicates[t];\n                if (currPredicate !== undefined && currPredicate.call(this) === false) {\n                    // if the predicate does not match there is no point in checking the paths\n                    continue;\n                }\n                nextPath: for (let j = 0; j < currNumOfPaths; j++) {\n                    const currPath = currAlt[j];\n                    const currPathLength = currPath.length;\n                    for (let i = 0; i < currPathLength; i++) {\n                        const nextToken = this.LA(i + 1);\n                        if (tokenMatcher(nextToken, currPath[i]) === false) {\n                            // mismatch in current path\n                            // try the next pth\n                            continue nextPath;\n                        }\n                    }\n                    // found a full path that matches.\n                    // this will also work for an empty ALT as the loop will be skipped\n                    return t;\n                }\n                // none of the paths for the current alternative matched\n                // try the next alternative\n            }\n            // none of the alternatives could be matched\n            return undefined;\n        };\n    }\n    else if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n        // optimized (common) case of all the lookaheads paths requiring only\n        // a single token lookahead. These Optimizations cannot work if dynamically defined Tokens are used.\n        const singleTokenAlts = map(alts, (currAlt) => {\n            return flatten(currAlt);\n        });\n        const choiceToAlt = reduce(singleTokenAlts, (result, currAlt, idx) => {\n            forEach(currAlt, (currTokType) => {\n                if (!has(result, currTokType.tokenTypeIdx)) {\n                    result[currTokType.tokenTypeIdx] = idx;\n                }\n                forEach(currTokType.categoryMatches, (currExtendingType) => {\n                    if (!has(result, currExtendingType)) {\n                        result[currExtendingType] = idx;\n                    }\n                });\n            });\n            return result;\n        }, {});\n        /**\n         * @returns {number} - The chosen alternative index\n         */\n        return function () {\n            const nextToken = this.LA(1);\n            return choiceToAlt[nextToken.tokenTypeIdx];\n        };\n    }\n    else {\n        // optimized lookahead without needing to check the predicates at all.\n        // this causes code duplication which is intentional to improve performance.\n        /**\n         * @returns {number} - The chosen alternative index\n         */\n        return function () {\n            for (let t = 0; t < numOfAlts; t++) {\n                const currAlt = alts[t];\n                const currNumOfPaths = currAlt.length;\n                nextPath: for (let j = 0; j < currNumOfPaths; j++) {\n                    const currPath = currAlt[j];\n                    const currPathLength = currPath.length;\n                    for (let i = 0; i < currPathLength; i++) {\n                        const nextToken = this.LA(i + 1);\n                        if (tokenMatcher(nextToken, currPath[i]) === false) {\n                            // mismatch in current path\n                            // try the next pth\n                            continue nextPath;\n                        }\n                    }\n                    // found a full path that matches.\n                    // this will also work for an empty ALT as the loop will be skipped\n                    return t;\n                }\n                // none of the paths for the current alternative matched\n                // try the next alternative\n            }\n            // none of the alternatives could be matched\n            return undefined;\n        };\n    }\n}\nexport function buildSingleAlternativeLookaheadFunction(alt, tokenMatcher, dynamicTokensEnabled) {\n    const areAllOneTokenLookahead = every(alt, (currPath) => {\n        return currPath.length === 1;\n    });\n    const numOfPaths = alt.length;\n    // optimized (common) case of all the lookaheads paths requiring only\n    // a single token lookahead.\n    if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n        const singleTokensTypes = flatten(alt);\n        if (singleTokensTypes.length === 1 &&\n            isEmpty(singleTokensTypes[0].categoryMatches)) {\n            const expectedTokenType = singleTokensTypes[0];\n            const expectedTokenUniqueKey = expectedTokenType.tokenTypeIdx;\n            return function () {\n                return this.LA(1).tokenTypeIdx === expectedTokenUniqueKey;\n            };\n        }\n        else {\n            const choiceToAlt = reduce(singleTokensTypes, (result, currTokType, idx) => {\n                result[currTokType.tokenTypeIdx] = true;\n                forEach(currTokType.categoryMatches, (currExtendingType) => {\n                    result[currExtendingType] = true;\n                });\n                return result;\n            }, []);\n            return function () {\n                const nextToken = this.LA(1);\n                return choiceToAlt[nextToken.tokenTypeIdx] === true;\n            };\n        }\n    }\n    else {\n        return function () {\n            nextPath: for (let j = 0; j < numOfPaths; j++) {\n                const currPath = alt[j];\n                const currPathLength = currPath.length;\n                for (let i = 0; i < currPathLength; i++) {\n                    const nextToken = this.LA(i + 1);\n                    if (tokenMatcher(nextToken, currPath[i]) === false) {\n                        // mismatch in current path\n                        // try the next pth\n                        continue nextPath;\n                    }\n                }\n                // found a full path that matches.\n                return true;\n            }\n            // none of the paths matched\n            return false;\n        };\n    }\n}\nclass RestDefinitionFinderWalker extends RestWalker {\n    constructor(topProd, targetOccurrence, targetProdType) {\n        super();\n        this.topProd = topProd;\n        this.targetOccurrence = targetOccurrence;\n        this.targetProdType = targetProdType;\n    }\n    startWalking() {\n        this.walk(this.topProd);\n        return this.restDef;\n    }\n    checkIsTarget(node, expectedProdType, currRest, prevRest) {\n        if (node.idx === this.targetOccurrence &&\n            this.targetProdType === expectedProdType) {\n            this.restDef = currRest.concat(prevRest);\n            return true;\n        }\n        // performance optimization, do not iterate over the entire Grammar ast after we have found the target\n        return false;\n    }\n    walkOption(optionProd, currRest, prevRest) {\n        if (!this.checkIsTarget(optionProd, PROD_TYPE.OPTION, currRest, prevRest)) {\n            super.walkOption(optionProd, currRest, prevRest);\n        }\n    }\n    walkAtLeastOne(atLeastOneProd, currRest, prevRest) {\n        if (!this.checkIsTarget(atLeastOneProd, PROD_TYPE.REPETITION_MANDATORY, currRest, prevRest)) {\n            super.walkOption(atLeastOneProd, currRest, prevRest);\n        }\n    }\n    walkAtLeastOneSep(atLeastOneSepProd, currRest, prevRest) {\n        if (!this.checkIsTarget(atLeastOneSepProd, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR, currRest, prevRest)) {\n            super.walkOption(atLeastOneSepProd, currRest, prevRest);\n        }\n    }\n    walkMany(manyProd, currRest, prevRest) {\n        if (!this.checkIsTarget(manyProd, PROD_TYPE.REPETITION, currRest, prevRest)) {\n            super.walkOption(manyProd, currRest, prevRest);\n        }\n    }\n    walkManySep(manySepProd, currRest, prevRest) {\n        if (!this.checkIsTarget(manySepProd, PROD_TYPE.REPETITION_WITH_SEPARATOR, currRest, prevRest)) {\n            super.walkOption(manySepProd, currRest, prevRest);\n        }\n    }\n}\n/**\n * Returns the definition of a target production in a top level level rule.\n */\nclass InsideDefinitionFinderVisitor extends GAstVisitor {\n    constructor(targetOccurrence, targetProdType, targetRef) {\n        super();\n        this.targetOccurrence = targetOccurrence;\n        this.targetProdType = targetProdType;\n        this.targetRef = targetRef;\n        this.result = [];\n    }\n    checkIsTarget(node, expectedProdName) {\n        if (node.idx === this.targetOccurrence &&\n            this.targetProdType === expectedProdName &&\n            (this.targetRef === undefined || node === this.targetRef)) {\n            this.result = node.definition;\n        }\n    }\n    visitOption(node) {\n        this.checkIsTarget(node, PROD_TYPE.OPTION);\n    }\n    visitRepetition(node) {\n        this.checkIsTarget(node, PROD_TYPE.REPETITION);\n    }\n    visitRepetitionMandatory(node) {\n        this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY);\n    }\n    visitRepetitionMandatoryWithSeparator(node) {\n        this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR);\n    }\n    visitRepetitionWithSeparator(node) {\n        this.checkIsTarget(node, PROD_TYPE.REPETITION_WITH_SEPARATOR);\n    }\n    visitAlternation(node) {\n        this.checkIsTarget(node, PROD_TYPE.ALTERNATION);\n    }\n}\nfunction initializeArrayOfArrays(size) {\n    const result = new Array(size);\n    for (let i = 0; i < size; i++) {\n        result[i] = [];\n    }\n    return result;\n}\n/**\n * A sort of hash function between a Path in the grammar and a string.\n * Note that this returns multiple \"hashes\" to support the scenario of token categories.\n * -  A single path with categories may match multiple **actual** paths.\n */\nfunction pathToHashKeys(path) {\n    let keys = [\"\"];\n    for (let i = 0; i < path.length; i++) {\n        const tokType = path[i];\n        const longerKeys = [];\n        for (let j = 0; j < keys.length; j++) {\n            const currShorterKey = keys[j];\n            longerKeys.push(currShorterKey + \"_\" + tokType.tokenTypeIdx);\n            for (let t = 0; t < tokType.categoryMatches.length; t++) {\n                const categoriesKeySuffix = \"_\" + tokType.categoryMatches[t];\n                longerKeys.push(currShorterKey + categoriesKeySuffix);\n            }\n        }\n        keys = longerKeys;\n    }\n    return keys;\n}\n/**\n * Imperative style due to being called from a hot spot\n */\nfunction isUniquePrefixHash(altKnownPathsKeys, searchPathKeys, idx) {\n    for (let currAltIdx = 0; currAltIdx < altKnownPathsKeys.length; currAltIdx++) {\n        // We only want to test vs the other alternatives\n        if (currAltIdx === idx) {\n            continue;\n        }\n        const otherAltKnownPathsKeys = altKnownPathsKeys[currAltIdx];\n        for (let searchIdx = 0; searchIdx < searchPathKeys.length; searchIdx++) {\n            const searchKey = searchPathKeys[searchIdx];\n            if (otherAltKnownPathsKeys[searchKey] === true) {\n                return false;\n            }\n        }\n    }\n    // None of the SearchPathKeys were found in any of the other alternatives\n    return true;\n}\nexport function lookAheadSequenceFromAlternatives(altsDefs, k) {\n    const partialAlts = map(altsDefs, (currAlt) => possiblePathsFrom([currAlt], 1));\n    const finalResult = initializeArrayOfArrays(partialAlts.length);\n    const altsHashes = map(partialAlts, (currAltPaths) => {\n        const dict = {};\n        forEach(currAltPaths, (item) => {\n            const keys = pathToHashKeys(item.partialPath);\n            forEach(keys, (currKey) => {\n                dict[currKey] = true;\n            });\n        });\n        return dict;\n    });\n    let newData = partialAlts;\n    // maxLookahead loop\n    for (let pathLength = 1; pathLength <= k; pathLength++) {\n        const currDataset = newData;\n        newData = initializeArrayOfArrays(currDataset.length);\n        // alternatives loop\n        for (let altIdx = 0; altIdx < currDataset.length; altIdx++) {\n            const currAltPathsAndSuffixes = currDataset[altIdx];\n            // paths in current alternative loop\n            for (let currPathIdx = 0; currPathIdx < currAltPathsAndSuffixes.length; currPathIdx++) {\n                const currPathPrefix = currAltPathsAndSuffixes[currPathIdx].partialPath;\n                const suffixDef = currAltPathsAndSuffixes[currPathIdx].suffixDef;\n                const prefixKeys = pathToHashKeys(currPathPrefix);\n                const isUnique = isUniquePrefixHash(altsHashes, prefixKeys, altIdx);\n                // End of the line for this path.\n                if (isUnique || isEmpty(suffixDef) || currPathPrefix.length === k) {\n                    const currAltResult = finalResult[altIdx];\n                    // TODO: Can we implement a containsPath using Maps/Dictionaries?\n                    if (containsPath(currAltResult, currPathPrefix) === false) {\n                        currAltResult.push(currPathPrefix);\n                        // Update all new  keys for the current path.\n                        for (let j = 0; j < prefixKeys.length; j++) {\n                            const currKey = prefixKeys[j];\n                            altsHashes[altIdx][currKey] = true;\n                        }\n                    }\n                }\n                // Expand longer paths\n                else {\n                    const newPartialPathsAndSuffixes = possiblePathsFrom(suffixDef, pathLength + 1, currPathPrefix);\n                    newData[altIdx] = newData[altIdx].concat(newPartialPathsAndSuffixes);\n                    // Update keys for new known paths\n                    forEach(newPartialPathsAndSuffixes, (item) => {\n                        const prefixKeys = pathToHashKeys(item.partialPath);\n                        forEach(prefixKeys, (key) => {\n                            altsHashes[altIdx][key] = true;\n                        });\n                    });\n                }\n            }\n        }\n    }\n    return finalResult;\n}\nexport function getLookaheadPathsForOr(occurrence, ruleGrammar, k, orProd) {\n    const visitor = new InsideDefinitionFinderVisitor(occurrence, PROD_TYPE.ALTERNATION, orProd);\n    ruleGrammar.accept(visitor);\n    return lookAheadSequenceFromAlternatives(visitor.result, k);\n}\nexport function getLookaheadPathsForOptionalProd(occurrence, ruleGrammar, prodType, k) {\n    const insideDefVisitor = new InsideDefinitionFinderVisitor(occurrence, prodType);\n    ruleGrammar.accept(insideDefVisitor);\n    const insideDef = insideDefVisitor.result;\n    const afterDefWalker = new RestDefinitionFinderWalker(ruleGrammar, occurrence, prodType);\n    const afterDef = afterDefWalker.startWalking();\n    const insideFlat = new AlternativeGAST({ definition: insideDef });\n    const afterFlat = new AlternativeGAST({ definition: afterDef });\n    return lookAheadSequenceFromAlternatives([insideFlat, afterFlat], k);\n}\nexport function containsPath(alternative, searchPath) {\n    compareOtherPath: for (let i = 0; i < alternative.length; i++) {\n        const otherPath = alternative[i];\n        if (otherPath.length !== searchPath.length) {\n            continue;\n        }\n        for (let j = 0; j < otherPath.length; j++) {\n            const searchTok = searchPath[j];\n            const otherTok = otherPath[j];\n            const matchingTokens = searchTok === otherTok ||\n                otherTok.categoryMatchesMap[searchTok.tokenTypeIdx] !== undefined;\n            if (matchingTokens === false) {\n                continue compareOtherPath;\n            }\n        }\n        return true;\n    }\n    return false;\n}\nexport function isStrictPrefixOfPath(prefix, other) {\n    return (prefix.length < other.length &&\n        every(prefix, (tokType, idx) => {\n            const otherTokType = other[idx];\n            return (tokType === otherTokType ||\n                otherTokType.categoryMatchesMap[tokType.tokenTypeIdx]);\n        }));\n}\nexport function areTokenCategoriesNotUsed(lookAheadPaths) {\n    return every(lookAheadPaths, (singleAltPaths) => every(singleAltPaths, (singlePath) => every(singlePath, (token) => isEmpty(token.categoryMatches))));\n}\n//# sourceMappingURL=lookahead.js.map","import { clone, compact, difference, drop, dropRight, filter, first, flatMap, flatten, forEach, groupBy, includes, isEmpty, map, pickBy, reduce, reject, values, } from \"lodash-es\";\nimport { ParserDefinitionErrorType, } from \"../parser/parser.js\";\nimport { Alternation, Alternative as AlternativeGAST, GAstVisitor, getProductionDslName, isOptionalProd, NonTerminal, Option, Repetition, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, Terminal, } from \"@chevrotain/gast\";\nimport { containsPath, getLookaheadPathsForOptionalProd, getLookaheadPathsForOr, getProdType, isStrictPrefixOfPath, } from \"./lookahead.js\";\nimport { nextPossibleTokensAfter } from \"./interpreter.js\";\nimport { tokenStructuredMatcher } from \"../../scan/tokens.js\";\nexport function validateLookahead(options) {\n    const lookaheadValidationErrorMessages = options.lookaheadStrategy.validate({\n        rules: options.rules,\n        tokenTypes: options.tokenTypes,\n        grammarName: options.grammarName,\n    });\n    return map(lookaheadValidationErrorMessages, (errorMessage) => (Object.assign({ type: ParserDefinitionErrorType.CUSTOM_LOOKAHEAD_VALIDATION }, errorMessage)));\n}\nexport function validateGrammar(topLevels, tokenTypes, errMsgProvider, grammarName) {\n    const duplicateErrors = flatMap(topLevels, (currTopLevel) => validateDuplicateProductions(currTopLevel, errMsgProvider));\n    const termsNamespaceConflictErrors = checkTerminalAndNoneTerminalsNameSpace(topLevels, tokenTypes, errMsgProvider);\n    const tooManyAltsErrors = flatMap(topLevels, (curRule) => validateTooManyAlts(curRule, errMsgProvider));\n    const duplicateRulesError = flatMap(topLevels, (curRule) => validateRuleDoesNotAlreadyExist(curRule, topLevels, grammarName, errMsgProvider));\n    return duplicateErrors.concat(termsNamespaceConflictErrors, tooManyAltsErrors, duplicateRulesError);\n}\nfunction validateDuplicateProductions(topLevelRule, errMsgProvider) {\n    const collectorVisitor = new OccurrenceValidationCollector();\n    topLevelRule.accept(collectorVisitor);\n    const allRuleProductions = collectorVisitor.allProductions;\n    const productionGroups = groupBy(allRuleProductions, identifyProductionForDuplicates);\n    const duplicates = pickBy(productionGroups, (currGroup) => {\n        return currGroup.length > 1;\n    });\n    const errors = map(values(duplicates), (currDuplicates) => {\n        const firstProd = first(currDuplicates);\n        const msg = errMsgProvider.buildDuplicateFoundError(topLevelRule, currDuplicates);\n        const dslName = getProductionDslName(firstProd);\n        const defError = {\n            message: msg,\n            type: ParserDefinitionErrorType.DUPLICATE_PRODUCTIONS,\n            ruleName: topLevelRule.name,\n            dslName: dslName,\n            occurrence: firstProd.idx,\n        };\n        const param = getExtraProductionArgument(firstProd);\n        if (param) {\n            defError.parameter = param;\n        }\n        return defError;\n    });\n    return errors;\n}\nexport function identifyProductionForDuplicates(prod) {\n    return `${getProductionDslName(prod)}_#_${prod.idx}_#_${getExtraProductionArgument(prod)}`;\n}\nfunction getExtraProductionArgument(prod) {\n    if (prod instanceof Terminal) {\n        return prod.terminalType.name;\n    }\n    else if (prod instanceof NonTerminal) {\n        return prod.nonTerminalName;\n    }\n    else {\n        return \"\";\n    }\n}\nexport class OccurrenceValidationCollector extends GAstVisitor {\n    constructor() {\n        super(...arguments);\n        this.allProductions = [];\n    }\n    visitNonTerminal(subrule) {\n        this.allProductions.push(subrule);\n    }\n    visitOption(option) {\n        this.allProductions.push(option);\n    }\n    visitRepetitionWithSeparator(manySep) {\n        this.allProductions.push(manySep);\n    }\n    visitRepetitionMandatory(atLeastOne) {\n        this.allProductions.push(atLeastOne);\n    }\n    visitRepetitionMandatoryWithSeparator(atLeastOneSep) {\n        this.allProductions.push(atLeastOneSep);\n    }\n    visitRepetition(many) {\n        this.allProductions.push(many);\n    }\n    visitAlternation(or) {\n        this.allProductions.push(or);\n    }\n    visitTerminal(terminal) {\n        this.allProductions.push(terminal);\n    }\n}\nexport function validateRuleDoesNotAlreadyExist(rule, allRules, className, errMsgProvider) {\n    const errors = [];\n    const occurrences = reduce(allRules, (result, curRule) => {\n        if (curRule.name === rule.name) {\n            return result + 1;\n        }\n        return result;\n    }, 0);\n    if (occurrences > 1) {\n        const errMsg = errMsgProvider.buildDuplicateRuleNameError({\n            topLevelRule: rule,\n            grammarName: className,\n        });\n        errors.push({\n            message: errMsg,\n            type: ParserDefinitionErrorType.DUPLICATE_RULE_NAME,\n            ruleName: rule.name,\n        });\n    }\n    return errors;\n}\n// TODO: is there anyway to get only the rule names of rules inherited from the super grammars?\n// This is not part of the IGrammarErrorProvider because the validation cannot be performed on\n// The grammar structure, only at runtime.\nexport function validateRuleIsOverridden(ruleName, definedRulesNames, className) {\n    const errors = [];\n    let errMsg;\n    if (!includes(definedRulesNames, ruleName)) {\n        errMsg =\n            `Invalid rule override, rule: ->${ruleName}<- cannot be overridden in the grammar: ->${className}<-` +\n                `as it is not defined in any of the super grammars `;\n        errors.push({\n            message: errMsg,\n            type: ParserDefinitionErrorType.INVALID_RULE_OVERRIDE,\n            ruleName: ruleName,\n        });\n    }\n    return errors;\n}\nexport function validateNoLeftRecursion(topRule, currRule, errMsgProvider, path = []) {\n    const errors = [];\n    const nextNonTerminals = getFirstNoneTerminal(currRule.definition);\n    if (isEmpty(nextNonTerminals)) {\n        return [];\n    }\n    else {\n        const ruleName = topRule.name;\n        const foundLeftRecursion = includes(nextNonTerminals, topRule);\n        if (foundLeftRecursion) {\n            errors.push({\n                message: errMsgProvider.buildLeftRecursionError({\n                    topLevelRule: topRule,\n                    leftRecursionPath: path,\n                }),\n                type: ParserDefinitionErrorType.LEFT_RECURSION,\n                ruleName: ruleName,\n            });\n        }\n        // we are only looking for cyclic paths leading back to the specific topRule\n        // other cyclic paths are ignored, we still need this difference to avoid infinite loops...\n        const validNextSteps = difference(nextNonTerminals, path.concat([topRule]));\n        const errorsFromNextSteps = flatMap(validNextSteps, (currRefRule) => {\n            const newPath = clone(path);\n            newPath.push(currRefRule);\n            return validateNoLeftRecursion(topRule, currRefRule, errMsgProvider, newPath);\n        });\n        return errors.concat(errorsFromNextSteps);\n    }\n}\nexport function getFirstNoneTerminal(definition) {\n    let result = [];\n    if (isEmpty(definition)) {\n        return result;\n    }\n    const firstProd = first(definition);\n    /* istanbul ignore else */\n    if (firstProd instanceof NonTerminal) {\n        result.push(firstProd.referencedRule);\n    }\n    else if (firstProd instanceof AlternativeGAST ||\n        firstProd instanceof Option ||\n        firstProd instanceof RepetitionMandatory ||\n        firstProd instanceof RepetitionMandatoryWithSeparator ||\n        firstProd instanceof RepetitionWithSeparator ||\n        firstProd instanceof Repetition) {\n        result = result.concat(getFirstNoneTerminal(firstProd.definition));\n    }\n    else if (firstProd instanceof Alternation) {\n        // each sub definition in alternation is a FLAT\n        result = flatten(map(firstProd.definition, (currSubDef) => getFirstNoneTerminal(currSubDef.definition)));\n    }\n    else if (firstProd instanceof Terminal) {\n        // nothing to see, move along\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n    const isFirstOptional = isOptionalProd(firstProd);\n    const hasMore = definition.length > 1;\n    if (isFirstOptional && hasMore) {\n        const rest = drop(definition);\n        return result.concat(getFirstNoneTerminal(rest));\n    }\n    else {\n        return result;\n    }\n}\nclass OrCollector extends GAstVisitor {\n    constructor() {\n        super(...arguments);\n        this.alternations = [];\n    }\n    visitAlternation(node) {\n        this.alternations.push(node);\n    }\n}\nexport function validateEmptyOrAlternative(topLevelRule, errMsgProvider) {\n    const orCollector = new OrCollector();\n    topLevelRule.accept(orCollector);\n    const ors = orCollector.alternations;\n    const errors = flatMap(ors, (currOr) => {\n        const exceptLast = dropRight(currOr.definition);\n        return flatMap(exceptLast, (currAlternative, currAltIdx) => {\n            const possibleFirstInAlt = nextPossibleTokensAfter([currAlternative], [], tokenStructuredMatcher, 1);\n            if (isEmpty(possibleFirstInAlt)) {\n                return [\n                    {\n                        message: errMsgProvider.buildEmptyAlternationError({\n                            topLevelRule: topLevelRule,\n                            alternation: currOr,\n                            emptyChoiceIdx: currAltIdx,\n                        }),\n                        type: ParserDefinitionErrorType.NONE_LAST_EMPTY_ALT,\n                        ruleName: topLevelRule.name,\n                        occurrence: currOr.idx,\n                        alternative: currAltIdx + 1,\n                    },\n                ];\n            }\n            else {\n                return [];\n            }\n        });\n    });\n    return errors;\n}\nexport function validateAmbiguousAlternationAlternatives(topLevelRule, globalMaxLookahead, errMsgProvider) {\n    const orCollector = new OrCollector();\n    topLevelRule.accept(orCollector);\n    let ors = orCollector.alternations;\n    // New Handling of ignoring ambiguities\n    // - https://github.com/chevrotain/chevrotain/issues/869\n    ors = reject(ors, (currOr) => currOr.ignoreAmbiguities === true);\n    const errors = flatMap(ors, (currOr) => {\n        const currOccurrence = currOr.idx;\n        const actualMaxLookahead = currOr.maxLookahead || globalMaxLookahead;\n        const alternatives = getLookaheadPathsForOr(currOccurrence, topLevelRule, actualMaxLookahead, currOr);\n        const altsAmbiguityErrors = checkAlternativesAmbiguities(alternatives, currOr, topLevelRule, errMsgProvider);\n        const altsPrefixAmbiguityErrors = checkPrefixAlternativesAmbiguities(alternatives, currOr, topLevelRule, errMsgProvider);\n        return altsAmbiguityErrors.concat(altsPrefixAmbiguityErrors);\n    });\n    return errors;\n}\nexport class RepetitionCollector extends GAstVisitor {\n    constructor() {\n        super(...arguments);\n        this.allProductions = [];\n    }\n    visitRepetitionWithSeparator(manySep) {\n        this.allProductions.push(manySep);\n    }\n    visitRepetitionMandatory(atLeastOne) {\n        this.allProductions.push(atLeastOne);\n    }\n    visitRepetitionMandatoryWithSeparator(atLeastOneSep) {\n        this.allProductions.push(atLeastOneSep);\n    }\n    visitRepetition(many) {\n        this.allProductions.push(many);\n    }\n}\nexport function validateTooManyAlts(topLevelRule, errMsgProvider) {\n    const orCollector = new OrCollector();\n    topLevelRule.accept(orCollector);\n    const ors = orCollector.alternations;\n    const errors = flatMap(ors, (currOr) => {\n        if (currOr.definition.length > 255) {\n            return [\n                {\n                    message: errMsgProvider.buildTooManyAlternativesError({\n                        topLevelRule: topLevelRule,\n                        alternation: currOr,\n                    }),\n                    type: ParserDefinitionErrorType.TOO_MANY_ALTS,\n                    ruleName: topLevelRule.name,\n                    occurrence: currOr.idx,\n                },\n            ];\n        }\n        else {\n            return [];\n        }\n    });\n    return errors;\n}\nexport function validateSomeNonEmptyLookaheadPath(topLevelRules, maxLookahead, errMsgProvider) {\n    const errors = [];\n    forEach(topLevelRules, (currTopRule) => {\n        const collectorVisitor = new RepetitionCollector();\n        currTopRule.accept(collectorVisitor);\n        const allRuleProductions = collectorVisitor.allProductions;\n        forEach(allRuleProductions, (currProd) => {\n            const prodType = getProdType(currProd);\n            const actualMaxLookahead = currProd.maxLookahead || maxLookahead;\n            const currOccurrence = currProd.idx;\n            const paths = getLookaheadPathsForOptionalProd(currOccurrence, currTopRule, prodType, actualMaxLookahead);\n            const pathsInsideProduction = paths[0];\n            if (isEmpty(flatten(pathsInsideProduction))) {\n                const errMsg = errMsgProvider.buildEmptyRepetitionError({\n                    topLevelRule: currTopRule,\n                    repetition: currProd,\n                });\n                errors.push({\n                    message: errMsg,\n                    type: ParserDefinitionErrorType.NO_NON_EMPTY_LOOKAHEAD,\n                    ruleName: currTopRule.name,\n                });\n            }\n        });\n    });\n    return errors;\n}\nfunction checkAlternativesAmbiguities(alternatives, alternation, rule, errMsgProvider) {\n    const foundAmbiguousPaths = [];\n    const identicalAmbiguities = reduce(alternatives, (result, currAlt, currAltIdx) => {\n        // ignore (skip) ambiguities with this alternative\n        if (alternation.definition[currAltIdx].ignoreAmbiguities === true) {\n            return result;\n        }\n        forEach(currAlt, (currPath) => {\n            const altsCurrPathAppearsIn = [currAltIdx];\n            forEach(alternatives, (currOtherAlt, currOtherAltIdx) => {\n                if (currAltIdx !== currOtherAltIdx &&\n                    containsPath(currOtherAlt, currPath) &&\n                    // ignore (skip) ambiguities with this \"other\" alternative\n                    alternation.definition[currOtherAltIdx].ignoreAmbiguities !== true) {\n                    altsCurrPathAppearsIn.push(currOtherAltIdx);\n                }\n            });\n            if (altsCurrPathAppearsIn.length > 1 &&\n                !containsPath(foundAmbiguousPaths, currPath)) {\n                foundAmbiguousPaths.push(currPath);\n                result.push({\n                    alts: altsCurrPathAppearsIn,\n                    path: currPath,\n                });\n            }\n        });\n        return result;\n    }, []);\n    const currErrors = map(identicalAmbiguities, (currAmbDescriptor) => {\n        const ambgIndices = map(currAmbDescriptor.alts, (currAltIdx) => currAltIdx + 1);\n        const currMessage = errMsgProvider.buildAlternationAmbiguityError({\n            topLevelRule: rule,\n            alternation: alternation,\n            ambiguityIndices: ambgIndices,\n            prefixPath: currAmbDescriptor.path,\n        });\n        return {\n            message: currMessage,\n            type: ParserDefinitionErrorType.AMBIGUOUS_ALTS,\n            ruleName: rule.name,\n            occurrence: alternation.idx,\n            alternatives: currAmbDescriptor.alts,\n        };\n    });\n    return currErrors;\n}\nexport function checkPrefixAlternativesAmbiguities(alternatives, alternation, rule, errMsgProvider) {\n    // flatten\n    const pathsAndIndices = reduce(alternatives, (result, currAlt, idx) => {\n        const currPathsAndIdx = map(currAlt, (currPath) => {\n            return { idx: idx, path: currPath };\n        });\n        return result.concat(currPathsAndIdx);\n    }, []);\n    const errors = compact(flatMap(pathsAndIndices, (currPathAndIdx) => {\n        const alternativeGast = alternation.definition[currPathAndIdx.idx];\n        // ignore (skip) ambiguities with this alternative\n        if (alternativeGast.ignoreAmbiguities === true) {\n            return [];\n        }\n        const targetIdx = currPathAndIdx.idx;\n        const targetPath = currPathAndIdx.path;\n        const prefixAmbiguitiesPathsAndIndices = filter(pathsAndIndices, (searchPathAndIdx) => {\n            // prefix ambiguity can only be created from lower idx (higher priority) path\n            return (\n            // ignore (skip) ambiguities with this \"other\" alternative\n            alternation.definition[searchPathAndIdx.idx].ignoreAmbiguities !==\n                true &&\n                searchPathAndIdx.idx < targetIdx &&\n                // checking for strict prefix because identical lookaheads\n                // will be be detected using a different validation.\n                isStrictPrefixOfPath(searchPathAndIdx.path, targetPath));\n        });\n        const currPathPrefixErrors = map(prefixAmbiguitiesPathsAndIndices, (currAmbPathAndIdx) => {\n            const ambgIndices = [currAmbPathAndIdx.idx + 1, targetIdx + 1];\n            const occurrence = alternation.idx === 0 ? \"\" : alternation.idx;\n            const message = errMsgProvider.buildAlternationPrefixAmbiguityError({\n                topLevelRule: rule,\n                alternation: alternation,\n                ambiguityIndices: ambgIndices,\n                prefixPath: currAmbPathAndIdx.path,\n            });\n            return {\n                message: message,\n                type: ParserDefinitionErrorType.AMBIGUOUS_PREFIX_ALTS,\n                ruleName: rule.name,\n                occurrence: occurrence,\n                alternatives: ambgIndices,\n            };\n        });\n        return currPathPrefixErrors;\n    }));\n    return errors;\n}\nfunction checkTerminalAndNoneTerminalsNameSpace(topLevels, tokenTypes, errMsgProvider) {\n    const errors = [];\n    const tokenNames = map(tokenTypes, (currToken) => currToken.name);\n    forEach(topLevels, (currRule) => {\n        const currRuleName = currRule.name;\n        if (includes(tokenNames, currRuleName)) {\n            const errMsg = errMsgProvider.buildNamespaceConflictError(currRule);\n            errors.push({\n                message: errMsg,\n                type: ParserDefinitionErrorType.CONFLICT_TOKENS_RULES_NAMESPACE,\n                ruleName: currRuleName,\n            });\n        }\n    });\n    return errors;\n}\n//# sourceMappingURL=checks.js.map","import { defaults, forEach } from \"lodash-es\";\nimport { resolveGrammar as orgResolveGrammar } from \"../resolver.js\";\nimport { validateGrammar as orgValidateGrammar } from \"../checks.js\";\nimport { defaultGrammarResolverErrorProvider, defaultGrammarValidatorErrorProvider, } from \"../../errors_public.js\";\nexport function resolveGrammar(options) {\n    const actualOptions = defaults(options, {\n        errMsgProvider: defaultGrammarResolverErrorProvider,\n    });\n    const topRulesTable = {};\n    forEach(options.rules, (rule) => {\n        topRulesTable[rule.name] = rule;\n    });\n    return orgResolveGrammar(topRulesTable, actualOptions.errMsgProvider);\n}\nexport function validateGrammar(options) {\n    options = defaults(options, {\n        errMsgProvider: defaultGrammarValidatorErrorProvider,\n    });\n    return orgValidateGrammar(options.rules, options.tokenTypes, options.errMsgProvider, options.grammarName);\n}\n//# sourceMappingURL=gast_resolver_public.js.map","import { includes } from \"lodash-es\";\nconst MISMATCHED_TOKEN_EXCEPTION = \"MismatchedTokenException\";\nconst NO_VIABLE_ALT_EXCEPTION = \"NoViableAltException\";\nconst EARLY_EXIT_EXCEPTION = \"EarlyExitException\";\nconst NOT_ALL_INPUT_PARSED_EXCEPTION = \"NotAllInputParsedException\";\nconst RECOGNITION_EXCEPTION_NAMES = [\n    MISMATCHED_TOKEN_EXCEPTION,\n    NO_VIABLE_ALT_EXCEPTION,\n    EARLY_EXIT_EXCEPTION,\n    NOT_ALL_INPUT_PARSED_EXCEPTION,\n];\nObject.freeze(RECOGNITION_EXCEPTION_NAMES);\n// hacks to bypass no support for custom Errors in javascript/typescript\nexport function isRecognitionException(error) {\n    // can't do instanceof on hacked custom js exceptions\n    return includes(RECOGNITION_EXCEPTION_NAMES, error.name);\n}\nclass RecognitionException extends Error {\n    constructor(message, token) {\n        super(message);\n        this.token = token;\n        this.resyncedTokens = [];\n        // fix prototype chain when typescript target is ES5\n        Object.setPrototypeOf(this, new.target.prototype);\n        /* istanbul ignore next - V8 workaround to remove constructor from stacktrace when typescript target is ES5 */\n        if (Error.captureStackTrace) {\n            Error.captureStackTrace(this, this.constructor);\n        }\n    }\n}\nexport class MismatchedTokenException extends RecognitionException {\n    constructor(message, token, previousToken) {\n        super(message, token);\n        this.previousToken = previousToken;\n        this.name = MISMATCHED_TOKEN_EXCEPTION;\n    }\n}\nexport class NoViableAltException extends RecognitionException {\n    constructor(message, token, previousToken) {\n        super(message, token);\n        this.previousToken = previousToken;\n        this.name = NO_VIABLE_ALT_EXCEPTION;\n    }\n}\nexport class NotAllInputParsedException extends RecognitionException {\n    constructor(message, token) {\n        super(message, token);\n        this.name = NOT_ALL_INPUT_PARSED_EXCEPTION;\n    }\n}\nexport class EarlyExitException extends RecognitionException {\n    constructor(message, token, previousToken) {\n        super(message, token);\n        this.previousToken = previousToken;\n        this.name = EARLY_EXIT_EXCEPTION;\n    }\n}\n//# sourceMappingURL=exceptions_public.js.map","import { createTokenInstance, EOF, tokenMatcher, } from \"../../../scan/tokens_public.js\";\nimport { clone, dropRight, find, flatten, has, includes, isEmpty, map, } from \"lodash-es\";\nimport { MismatchedTokenException } from \"../../exceptions_public.js\";\nimport { IN } from \"../../constants.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\nexport const EOF_FOLLOW_KEY = {};\nexport const IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\";\nexport class InRuleRecoveryException extends Error {\n    constructor(message) {\n        super(message);\n        this.name = IN_RULE_RECOVERY_EXCEPTION;\n    }\n}\n/**\n * This trait is responsible for the error recovery and fault tolerant logic\n */\nexport class Recoverable {\n    initRecoverable(config) {\n        this.firstAfterRepMap = {};\n        this.resyncFollows = {};\n        this.recoveryEnabled = has(config, \"recoveryEnabled\")\n            ? config.recoveryEnabled // assumes end user provides the correct config value/type\n            : DEFAULT_PARSER_CONFIG.recoveryEnabled;\n        // performance optimization, NOOP will be inlined which\n        // effectively means that this optional feature does not exist\n        // when not used.\n        if (this.recoveryEnabled) {\n            this.attemptInRepetitionRecovery = attemptInRepetitionRecovery;\n        }\n    }\n    getTokenToInsert(tokType) {\n        const tokToInsert = createTokenInstance(tokType, \"\", NaN, NaN, NaN, NaN, NaN, NaN);\n        tokToInsert.isInsertedInRecovery = true;\n        return tokToInsert;\n    }\n    canTokenTypeBeInsertedInRecovery(tokType) {\n        return true;\n    }\n    canTokenTypeBeDeletedInRecovery(tokType) {\n        return true;\n    }\n    tryInRepetitionRecovery(grammarRule, grammarRuleArgs, lookAheadFunc, expectedTokType) {\n        // TODO: can the resyncTokenType be cached?\n        const reSyncTokType = this.findReSyncTokenType();\n        const savedLexerState = this.exportLexerState();\n        const resyncedTokens = [];\n        let passedResyncPoint = false;\n        const nextTokenWithoutResync = this.LA(1);\n        let currToken = this.LA(1);\n        const generateErrorMessage = () => {\n            const previousToken = this.LA(0);\n            // we are preemptively re-syncing before an error has been detected, therefor we must reproduce\n            // the error that would have been thrown\n            const msg = this.errorMessageProvider.buildMismatchTokenMessage({\n                expected: expectedTokType,\n                actual: nextTokenWithoutResync,\n                previous: previousToken,\n                ruleName: this.getCurrRuleFullName(),\n            });\n            const error = new MismatchedTokenException(msg, nextTokenWithoutResync, this.LA(0));\n            // the first token here will be the original cause of the error, this is not part of the resyncedTokens property.\n            error.resyncedTokens = dropRight(resyncedTokens);\n            this.SAVE_ERROR(error);\n        };\n        while (!passedResyncPoint) {\n            // re-synced to a point where we can safely exit the repetition/\n            if (this.tokenMatcher(currToken, expectedTokType)) {\n                generateErrorMessage();\n                return; // must return here to avoid reverting the inputIdx\n            }\n            else if (lookAheadFunc.call(this)) {\n                // we skipped enough tokens so we can resync right back into another iteration of the repetition grammar rule\n                generateErrorMessage();\n                // recursive invocation in other to support multiple re-syncs in the same top level repetition grammar rule\n                grammarRule.apply(this, grammarRuleArgs);\n                return; // must return here to avoid reverting the inputIdx\n            }\n            else if (this.tokenMatcher(currToken, reSyncTokType)) {\n                passedResyncPoint = true;\n            }\n            else {\n                currToken = this.SKIP_TOKEN();\n                this.addToResyncTokens(currToken, resyncedTokens);\n            }\n        }\n        // we were unable to find a CLOSER point to resync inside the Repetition, reset the state.\n        // The parsing exception we were trying to prevent will happen in the NEXT parsing step. it may be handled by\n        // \"between rules\" resync recovery later in the flow.\n        this.importLexerState(savedLexerState);\n    }\n    shouldInRepetitionRecoveryBeTried(expectTokAfterLastMatch, nextTokIdx, notStuck) {\n        // Edge case of arriving from a MANY repetition which is stuck\n        // Attempting recovery in this case could cause an infinite loop\n        if (notStuck === false) {\n            return false;\n        }\n        // no need to recover, next token is what we expect...\n        if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n            return false;\n        }\n        // error recovery is disabled during backtracking as it can make the parser ignore a valid grammar path\n        // and prefer some backtracking path that includes recovered errors.\n        if (this.isBackTracking()) {\n            return false;\n        }\n        // if we can perform inRule recovery (single token insertion or deletion) we always prefer that recovery algorithm\n        // because if it works, it makes the least amount of changes to the input stream (greedy algorithm)\n        //noinspection RedundantIfStatementJS\n        if (this.canPerformInRuleRecovery(expectTokAfterLastMatch, this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx))) {\n            return false;\n        }\n        return true;\n    }\n    // Error Recovery functionality\n    getFollowsForInRuleRecovery(tokType, tokIdxInRule) {\n        const grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule);\n        const follows = this.getNextPossibleTokenTypes(grammarPath);\n        return follows;\n    }\n    tryInRuleRecovery(expectedTokType, follows) {\n        if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n            const tokToInsert = this.getTokenToInsert(expectedTokType);\n            return tokToInsert;\n        }\n        if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n            const nextTok = this.SKIP_TOKEN();\n            this.consumeToken();\n            return nextTok;\n        }\n        throw new InRuleRecoveryException(\"sad sad panda\");\n    }\n    canPerformInRuleRecovery(expectedToken, follows) {\n        return (this.canRecoverWithSingleTokenInsertion(expectedToken, follows) ||\n            this.canRecoverWithSingleTokenDeletion(expectedToken));\n    }\n    canRecoverWithSingleTokenInsertion(expectedTokType, follows) {\n        if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n            return false;\n        }\n        // must know the possible following tokens to perform single token insertion\n        if (isEmpty(follows)) {\n            return false;\n        }\n        const mismatchedTok = this.LA(1);\n        const isMisMatchedTokInFollows = find(follows, (possibleFollowsTokType) => {\n            return this.tokenMatcher(mismatchedTok, possibleFollowsTokType);\n        }) !== undefined;\n        return isMisMatchedTokInFollows;\n    }\n    canRecoverWithSingleTokenDeletion(expectedTokType) {\n        if (!this.canTokenTypeBeDeletedInRecovery(expectedTokType)) {\n            return false;\n        }\n        const isNextTokenWhatIsExpected = this.tokenMatcher(this.LA(2), expectedTokType);\n        return isNextTokenWhatIsExpected;\n    }\n    isInCurrentRuleReSyncSet(tokenTypeIdx) {\n        const followKey = this.getCurrFollowKey();\n        const currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey);\n        return includes(currentRuleReSyncSet, tokenTypeIdx);\n    }\n    findReSyncTokenType() {\n        const allPossibleReSyncTokTypes = this.flattenFollowSet();\n        // this loop will always terminate as EOF is always in the follow stack and also always (virtually) in the input\n        let nextToken = this.LA(1);\n        let k = 2;\n        while (true) {\n            const foundMatch = find(allPossibleReSyncTokTypes, (resyncTokType) => {\n                const canMatch = tokenMatcher(nextToken, resyncTokType);\n                return canMatch;\n            });\n            if (foundMatch !== undefined) {\n                return foundMatch;\n            }\n            nextToken = this.LA(k);\n            k++;\n        }\n    }\n    getCurrFollowKey() {\n        // the length is at least one as we always add the ruleName to the stack before invoking the rule.\n        if (this.RULE_STACK.length === 1) {\n            return EOF_FOLLOW_KEY;\n        }\n        const currRuleShortName = this.getLastExplicitRuleShortName();\n        const currRuleIdx = this.getLastExplicitRuleOccurrenceIndex();\n        const prevRuleShortName = this.getPreviousExplicitRuleShortName();\n        return {\n            ruleName: this.shortRuleNameToFullName(currRuleShortName),\n            idxInCallingRule: currRuleIdx,\n            inRule: this.shortRuleNameToFullName(prevRuleShortName),\n        };\n    }\n    buildFullFollowKeyStack() {\n        const explicitRuleStack = this.RULE_STACK;\n        const explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK;\n        return map(explicitRuleStack, (ruleName, idx) => {\n            if (idx === 0) {\n                return EOF_FOLLOW_KEY;\n            }\n            return {\n                ruleName: this.shortRuleNameToFullName(ruleName),\n                idxInCallingRule: explicitOccurrenceStack[idx],\n                inRule: this.shortRuleNameToFullName(explicitRuleStack[idx - 1]),\n            };\n        });\n    }\n    flattenFollowSet() {\n        const followStack = map(this.buildFullFollowKeyStack(), (currKey) => {\n            return this.getFollowSetFromFollowKey(currKey);\n        });\n        return flatten(followStack);\n    }\n    getFollowSetFromFollowKey(followKey) {\n        if (followKey === EOF_FOLLOW_KEY) {\n            return [EOF];\n        }\n        const followName = followKey.ruleName + followKey.idxInCallingRule + IN + followKey.inRule;\n        return this.resyncFollows[followName];\n    }\n    // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n    // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n    addToResyncTokens(token, resyncTokens) {\n        if (!this.tokenMatcher(token, EOF)) {\n            resyncTokens.push(token);\n        }\n        return resyncTokens;\n    }\n    reSyncTo(tokType) {\n        const resyncedTokens = [];\n        let nextTok = this.LA(1);\n        while (this.tokenMatcher(nextTok, tokType) === false) {\n            nextTok = this.SKIP_TOKEN();\n            this.addToResyncTokens(nextTok, resyncedTokens);\n        }\n        // the last token is not part of the error.\n        return dropRight(resyncedTokens);\n    }\n    attemptInRepetitionRecovery(prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {\n        // by default this is a NO-OP\n        // The actual implementation is with the function(not method) below\n    }\n    getCurrentGrammarPath(tokType, tokIdxInRule) {\n        const pathRuleStack = this.getHumanReadableRuleStack();\n        const pathOccurrenceStack = clone(this.RULE_OCCURRENCE_STACK);\n        const grammarPath = {\n            ruleStack: pathRuleStack,\n            occurrenceStack: pathOccurrenceStack,\n            lastTok: tokType,\n            lastTokOccurrence: tokIdxInRule,\n        };\n        return grammarPath;\n    }\n    getHumanReadableRuleStack() {\n        return map(this.RULE_STACK, (currShortName) => this.shortRuleNameToFullName(currShortName));\n    }\n}\nexport function attemptInRepetitionRecovery(prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {\n    const key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence);\n    let firstAfterRepInfo = this.firstAfterRepMap[key];\n    if (firstAfterRepInfo === undefined) {\n        const currRuleName = this.getCurrRuleFullName();\n        const ruleGrammar = this.getGAstProductions()[currRuleName];\n        const walker = new nextToksWalker(ruleGrammar, prodOccurrence);\n        firstAfterRepInfo = walker.startWalking();\n        this.firstAfterRepMap[key] = firstAfterRepInfo;\n    }\n    let expectTokAfterLastMatch = firstAfterRepInfo.token;\n    let nextTokIdx = firstAfterRepInfo.occurrence;\n    const isEndOfRule = firstAfterRepInfo.isEndOfRule;\n    // special edge case of a TOP most repetition after which the input should END.\n    // this will force an attempt for inRule recovery in that scenario.\n    if (this.RULE_STACK.length === 1 &&\n        isEndOfRule &&\n        expectTokAfterLastMatch === undefined) {\n        expectTokAfterLastMatch = EOF;\n        nextTokIdx = 1;\n    }\n    // We don't have anything to re-sync to...\n    // this condition was extracted from `shouldInRepetitionRecoveryBeTried` to act as a type-guard\n    if (expectTokAfterLastMatch === undefined || nextTokIdx === undefined) {\n        return;\n    }\n    if (this.shouldInRepetitionRecoveryBeTried(expectTokAfterLastMatch, nextTokIdx, notStuck)) {\n        // TODO: performance optimization: instead of passing the original args here, we modify\n        // the args param (or create a new one) and make sure the lookahead func is explicitly provided\n        // to avoid searching the cache for it once more.\n        this.tryInRepetitionRecovery(prodFunc, args, lookaheadFunc, expectTokAfterLastMatch);\n    }\n}\n//# sourceMappingURL=recoverable.js.map","// Lookahead keys are 32Bit integers in the form\n// TTTTTTTT-ZZZZZZZZZZZZ-YYYY-XXXXXXXX\n// XXXX -> Occurrence Index bitmap.\n// YYYY -> DSL Method Type bitmap.\n// ZZZZZZZZZZZZZZZ -> Rule short Index bitmap.\n// TTTTTTTTT -> alternation alternative index bitmap\nexport const BITS_FOR_METHOD_TYPE = 4;\nexport const BITS_FOR_OCCURRENCE_IDX = 8;\nexport const BITS_FOR_RULE_IDX = 12;\n// TODO: validation, this means that there may at most 2^8 --> 256 alternatives for an alternation.\nexport const BITS_FOR_ALT_IDX = 8;\n// short string used as part of mapping keys.\n// being short improves the performance when composing KEYS for maps out of these\n// The 5 - 8 bits (16 possible values, are reserved for the DSL method indices)\nexport const OR_IDX = 1 << BITS_FOR_OCCURRENCE_IDX;\nexport const OPTION_IDX = 2 << BITS_FOR_OCCURRENCE_IDX;\nexport const MANY_IDX = 3 << BITS_FOR_OCCURRENCE_IDX;\nexport const AT_LEAST_ONE_IDX = 4 << BITS_FOR_OCCURRENCE_IDX;\nexport const MANY_SEP_IDX = 5 << BITS_FOR_OCCURRENCE_IDX;\nexport const AT_LEAST_ONE_SEP_IDX = 6 << BITS_FOR_OCCURRENCE_IDX;\n// this actually returns a number, but it is always used as a string (object prop key)\nexport function getKeyForAutomaticLookahead(ruleIdx, dslMethodIdx, occurrence) {\n    return occurrence | dslMethodIdx | ruleIdx;\n}\nconst BITS_START_FOR_ALT_IDX = 32 - BITS_FOR_ALT_IDX;\n//# sourceMappingURL=keys.js.map","import { flatMap, isEmpty } from \"lodash-es\";\nimport { defaultGrammarValidatorErrorProvider } from \"../errors_public.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser/parser.js\";\nimport { validateAmbiguousAlternationAlternatives, validateEmptyOrAlternative, validateNoLeftRecursion, validateSomeNonEmptyLookaheadPath, } from \"./checks.js\";\nimport { buildAlternativesLookAheadFunc, buildLookaheadFuncForOptionalProd, buildLookaheadFuncForOr, buildSingleAlternativeLookaheadFunction, getProdType, } from \"./lookahead.js\";\nexport class LLkLookaheadStrategy {\n    constructor(options) {\n        var _a;\n        this.maxLookahead =\n            (_a = options === null || options === void 0 ? void 0 : options.maxLookahead) !== null && _a !== void 0 ? _a : DEFAULT_PARSER_CONFIG.maxLookahead;\n    }\n    validate(options) {\n        const leftRecursionErrors = this.validateNoLeftRecursion(options.rules);\n        if (isEmpty(leftRecursionErrors)) {\n            const emptyAltErrors = this.validateEmptyOrAlternatives(options.rules);\n            const ambiguousAltsErrors = this.validateAmbiguousAlternationAlternatives(options.rules, this.maxLookahead);\n            const emptyRepetitionErrors = this.validateSomeNonEmptyLookaheadPath(options.rules, this.maxLookahead);\n            const allErrors = [\n                ...leftRecursionErrors,\n                ...emptyAltErrors,\n                ...ambiguousAltsErrors,\n                ...emptyRepetitionErrors,\n            ];\n            return allErrors;\n        }\n        return leftRecursionErrors;\n    }\n    validateNoLeftRecursion(rules) {\n        return flatMap(rules, (currTopRule) => validateNoLeftRecursion(currTopRule, currTopRule, defaultGrammarValidatorErrorProvider));\n    }\n    validateEmptyOrAlternatives(rules) {\n        return flatMap(rules, (currTopRule) => validateEmptyOrAlternative(currTopRule, defaultGrammarValidatorErrorProvider));\n    }\n    validateAmbiguousAlternationAlternatives(rules, maxLookahead) {\n        return flatMap(rules, (currTopRule) => validateAmbiguousAlternationAlternatives(currTopRule, maxLookahead, defaultGrammarValidatorErrorProvider));\n    }\n    validateSomeNonEmptyLookaheadPath(rules, maxLookahead) {\n        return validateSomeNonEmptyLookaheadPath(rules, maxLookahead, defaultGrammarValidatorErrorProvider);\n    }\n    buildLookaheadForAlternation(options) {\n        return buildLookaheadFuncForOr(options.prodOccurrence, options.rule, options.maxLookahead, options.hasPredicates, options.dynamicTokensEnabled, buildAlternativesLookAheadFunc);\n    }\n    buildLookaheadForOptional(options) {\n        return buildLookaheadFuncForOptionalProd(options.prodOccurrence, options.rule, options.maxLookahead, options.dynamicTokensEnabled, getProdType(options.prodType), buildSingleAlternativeLookaheadFunction);\n    }\n}\n//# sourceMappingURL=llk_lookahead.js.map","import { forEach, has } from \"lodash-es\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\nimport { AT_LEAST_ONE_IDX, AT_LEAST_ONE_SEP_IDX, getKeyForAutomaticLookahead, MANY_IDX, MANY_SEP_IDX, OPTION_IDX, OR_IDX, } from \"../../grammar/keys.js\";\nimport { GAstVisitor, getProductionDslName, } from \"@chevrotain/gast\";\nimport { LLkLookaheadStrategy } from \"../../grammar/llk_lookahead.js\";\n/**\n * Trait responsible for the lookahead related utilities and optimizations.\n */\nexport class LooksAhead {\n    initLooksAhead(config) {\n        this.dynamicTokensEnabled = has(config, \"dynamicTokensEnabled\")\n            ? config.dynamicTokensEnabled // assumes end user provides the correct config value/type\n            : DEFAULT_PARSER_CONFIG.dynamicTokensEnabled;\n        this.maxLookahead = has(config, \"maxLookahead\")\n            ? config.maxLookahead // assumes end user provides the correct config value/type\n            : DEFAULT_PARSER_CONFIG.maxLookahead;\n        this.lookaheadStrategy = has(config, \"lookaheadStrategy\")\n            ? config.lookaheadStrategy // assumes end user provides the correct config value/type\n            : new LLkLookaheadStrategy({ maxLookahead: this.maxLookahead });\n        this.lookAheadFuncsCache = new Map();\n    }\n    preComputeLookaheadFunctions(rules) {\n        forEach(rules, (currRule) => {\n            this.TRACE_INIT(`${currRule.name} Rule Lookahead`, () => {\n                const { alternation, repetition, option, repetitionMandatory, repetitionMandatoryWithSeparator, repetitionWithSeparator, } = collectMethods(currRule);\n                forEach(alternation, (currProd) => {\n                    const prodIdx = currProd.idx === 0 ? \"\" : currProd.idx;\n                    this.TRACE_INIT(`${getProductionDslName(currProd)}${prodIdx}`, () => {\n                        const laFunc = this.lookaheadStrategy.buildLookaheadForAlternation({\n                            prodOccurrence: currProd.idx,\n                            rule: currRule,\n                            maxLookahead: currProd.maxLookahead || this.maxLookahead,\n                            hasPredicates: currProd.hasPredicates,\n                            dynamicTokensEnabled: this.dynamicTokensEnabled,\n                        });\n                        const key = getKeyForAutomaticLookahead(this.fullRuleNameToShort[currRule.name], OR_IDX, currProd.idx);\n                        this.setLaFuncCache(key, laFunc);\n                    });\n                });\n                forEach(repetition, (currProd) => {\n                    this.computeLookaheadFunc(currRule, currProd.idx, MANY_IDX, \"Repetition\", currProd.maxLookahead, getProductionDslName(currProd));\n                });\n                forEach(option, (currProd) => {\n                    this.computeLookaheadFunc(currRule, currProd.idx, OPTION_IDX, \"Option\", currProd.maxLookahead, getProductionDslName(currProd));\n                });\n                forEach(repetitionMandatory, (currProd) => {\n                    this.computeLookaheadFunc(currRule, currProd.idx, AT_LEAST_ONE_IDX, \"RepetitionMandatory\", currProd.maxLookahead, getProductionDslName(currProd));\n                });\n                forEach(repetitionMandatoryWithSeparator, (currProd) => {\n                    this.computeLookaheadFunc(currRule, currProd.idx, AT_LEAST_ONE_SEP_IDX, \"RepetitionMandatoryWithSeparator\", currProd.maxLookahead, getProductionDslName(currProd));\n                });\n                forEach(repetitionWithSeparator, (currProd) => {\n                    this.computeLookaheadFunc(currRule, currProd.idx, MANY_SEP_IDX, \"RepetitionWithSeparator\", currProd.maxLookahead, getProductionDslName(currProd));\n                });\n            });\n        });\n    }\n    computeLookaheadFunc(rule, prodOccurrence, prodKey, prodType, prodMaxLookahead, dslMethodName) {\n        this.TRACE_INIT(`${dslMethodName}${prodOccurrence === 0 ? \"\" : prodOccurrence}`, () => {\n            const laFunc = this.lookaheadStrategy.buildLookaheadForOptional({\n                prodOccurrence,\n                rule,\n                maxLookahead: prodMaxLookahead || this.maxLookahead,\n                dynamicTokensEnabled: this.dynamicTokensEnabled,\n                prodType,\n            });\n            const key = getKeyForAutomaticLookahead(this.fullRuleNameToShort[rule.name], prodKey, prodOccurrence);\n            this.setLaFuncCache(key, laFunc);\n        });\n    }\n    // this actually returns a number, but it is always used as a string (object prop key)\n    getKeyForAutomaticLookahead(dslMethodIdx, occurrence) {\n        const currRuleShortName = this.getLastExplicitRuleShortName();\n        return getKeyForAutomaticLookahead(currRuleShortName, dslMethodIdx, occurrence);\n    }\n    getLaFuncFromCache(key) {\n        return this.lookAheadFuncsCache.get(key);\n    }\n    /* istanbul ignore next */\n    setLaFuncCache(key, value) {\n        this.lookAheadFuncsCache.set(key, value);\n    }\n}\nclass DslMethodsCollectorVisitor extends GAstVisitor {\n    constructor() {\n        super(...arguments);\n        this.dslMethods = {\n            option: [],\n            alternation: [],\n            repetition: [],\n            repetitionWithSeparator: [],\n            repetitionMandatory: [],\n            repetitionMandatoryWithSeparator: [],\n        };\n    }\n    reset() {\n        this.dslMethods = {\n            option: [],\n            alternation: [],\n            repetition: [],\n            repetitionWithSeparator: [],\n            repetitionMandatory: [],\n            repetitionMandatoryWithSeparator: [],\n        };\n    }\n    visitOption(option) {\n        this.dslMethods.option.push(option);\n    }\n    visitRepetitionWithSeparator(manySep) {\n        this.dslMethods.repetitionWithSeparator.push(manySep);\n    }\n    visitRepetitionMandatory(atLeastOne) {\n        this.dslMethods.repetitionMandatory.push(atLeastOne);\n    }\n    visitRepetitionMandatoryWithSeparator(atLeastOneSep) {\n        this.dslMethods.repetitionMandatoryWithSeparator.push(atLeastOneSep);\n    }\n    visitRepetition(many) {\n        this.dslMethods.repetition.push(many);\n    }\n    visitAlternation(or) {\n        this.dslMethods.alternation.push(or);\n    }\n}\nconst collectorVisitor = new DslMethodsCollectorVisitor();\nexport function collectMethods(rule) {\n    collectorVisitor.reset();\n    rule.accept(collectorVisitor);\n    const dslMethods = collectorVisitor.dslMethods;\n    // avoid uncleaned references\n    collectorVisitor.reset();\n    return dslMethods;\n}\n//# sourceMappingURL=looksahead.js.map","/**\n * This nodeLocation tracking is not efficient and should only be used\n * when error recovery is enabled or the Token Vector contains virtual Tokens\n * (e.g, Python Indent/Outdent)\n * As it executes the calculation for every single terminal/nonTerminal\n * and does not rely on the fact the token vector is **sorted**\n */\nexport function setNodeLocationOnlyOffset(currNodeLocation, newLocationInfo) {\n    // First (valid) update for this cst node\n    if (isNaN(currNodeLocation.startOffset) === true) {\n        // assumption1: Token location information is either NaN or a valid number\n        // assumption2: Token location information is fully valid if it exist\n        // (both start/end offsets exist and are numbers).\n        currNodeLocation.startOffset = newLocationInfo.startOffset;\n        currNodeLocation.endOffset = newLocationInfo.endOffset;\n    }\n    // Once the startOffset has been updated with a valid number it should never receive\n    // any farther updates as the Token vector is sorted.\n    // We still have to check this this condition for every new possible location info\n    // because with error recovery enabled we may encounter invalid tokens (NaN location props)\n    else if (currNodeLocation.endOffset < newLocationInfo.endOffset === true) {\n        currNodeLocation.endOffset = newLocationInfo.endOffset;\n    }\n}\n/**\n * This nodeLocation tracking is not efficient and should only be used\n * when error recovery is enabled or the Token Vector contains virtual Tokens\n * (e.g, Python Indent/Outdent)\n * As it executes the calculation for every single terminal/nonTerminal\n * and does not rely on the fact the token vector is **sorted**\n */\nexport function setNodeLocationFull(currNodeLocation, newLocationInfo) {\n    // First (valid) update for this cst node\n    if (isNaN(currNodeLocation.startOffset) === true) {\n        // assumption1: Token location information is either NaN or a valid number\n        // assumption2: Token location information is fully valid if it exist\n        // (all start/end props exist and are numbers).\n        currNodeLocation.startOffset = newLocationInfo.startOffset;\n        currNodeLocation.startColumn = newLocationInfo.startColumn;\n        currNodeLocation.startLine = newLocationInfo.startLine;\n        currNodeLocation.endOffset = newLocationInfo.endOffset;\n        currNodeLocation.endColumn = newLocationInfo.endColumn;\n        currNodeLocation.endLine = newLocationInfo.endLine;\n    }\n    // Once the start props has been updated with a valid number it should never receive\n    // any farther updates as the Token vector is sorted.\n    // We still have to check this this condition for every new possible location info\n    // because with error recovery enabled we may encounter invalid tokens (NaN location props)\n    else if (currNodeLocation.endOffset < newLocationInfo.endOffset === true) {\n        currNodeLocation.endOffset = newLocationInfo.endOffset;\n        currNodeLocation.endColumn = newLocationInfo.endColumn;\n        currNodeLocation.endLine = newLocationInfo.endLine;\n    }\n}\nexport function addTerminalToCst(node, token, tokenTypeName) {\n    if (node.children[tokenTypeName] === undefined) {\n        node.children[tokenTypeName] = [token];\n    }\n    else {\n        node.children[tokenTypeName].push(token);\n    }\n}\nexport function addNoneTerminalToCst(node, ruleName, ruleResult) {\n    if (node.children[ruleName] === undefined) {\n        node.children[ruleName] = [ruleResult];\n    }\n    else {\n        node.children[ruleName].push(ruleResult);\n    }\n}\n//# sourceMappingURL=cst.js.map","const NAME = \"name\";\nexport function defineNameProp(obj, nameValue) {\n    Object.defineProperty(obj, NAME, {\n        enumerable: false,\n        configurable: true,\n        writable: false,\n        value: nameValue,\n    });\n}\n//# sourceMappingURL=lang_extensions.js.map","import { compact, filter, forEach, isArray, isEmpty, isFunction, isUndefined, keys, map, } from \"lodash-es\";\nimport { defineNameProp } from \"../../lang/lang_extensions.js\";\nexport function defaultVisit(ctx, param) {\n    const childrenNames = keys(ctx);\n    const childrenNamesLength = childrenNames.length;\n    for (let i = 0; i < childrenNamesLength; i++) {\n        const currChildName = childrenNames[i];\n        const currChildArray = ctx[currChildName];\n        const currChildArrayLength = currChildArray.length;\n        for (let j = 0; j < currChildArrayLength; j++) {\n            const currChild = currChildArray[j];\n            // distinction between Tokens Children and CstNode children\n            if (currChild.tokenTypeIdx === undefined) {\n                this[currChild.name](currChild.children, param);\n            }\n        }\n    }\n    // defaultVisit does not support generic out param\n}\nexport function createBaseSemanticVisitorConstructor(grammarName, ruleNames) {\n    const derivedConstructor = function () { };\n    // can be overwritten according to:\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/\n    // name?redirectlocale=en-US&redirectslug=JavaScript%2FReference%2FGlobal_Objects%2FFunction%2Fname\n    defineNameProp(derivedConstructor, grammarName + \"BaseSemantics\");\n    const semanticProto = {\n        visit: function (cstNode, param) {\n            // enables writing more concise visitor methods when CstNode has only a single child\n            if (isArray(cstNode)) {\n                // A CST Node's children dictionary can never have empty arrays as values\n                // If a key is defined there will be at least one element in the corresponding value array.\n                cstNode = cstNode[0];\n            }\n            // enables passing optional CstNodes concisely.\n            if (isUndefined(cstNode)) {\n                return undefined;\n            }\n            return this[cstNode.name](cstNode.children, param);\n        },\n        validateVisitor: function () {\n            const semanticDefinitionErrors = validateVisitor(this, ruleNames);\n            if (!isEmpty(semanticDefinitionErrors)) {\n                const errorMessages = map(semanticDefinitionErrors, (currDefError) => currDefError.msg);\n                throw Error(`Errors Detected in CST Visitor <${this.constructor.name}>:\\n\\t` +\n                    `${errorMessages.join(\"\\n\\n\").replace(/\\n/g, \"\\n\\t\")}`);\n            }\n        },\n    };\n    derivedConstructor.prototype = semanticProto;\n    derivedConstructor.prototype.constructor = derivedConstructor;\n    derivedConstructor._RULE_NAMES = ruleNames;\n    return derivedConstructor;\n}\nexport function createBaseVisitorConstructorWithDefaults(grammarName, ruleNames, baseConstructor) {\n    const derivedConstructor = function () { };\n    // can be overwritten according to:\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/\n    // name?redirectlocale=en-US&redirectslug=JavaScript%2FReference%2FGlobal_Objects%2FFunction%2Fname\n    defineNameProp(derivedConstructor, grammarName + \"BaseSemanticsWithDefaults\");\n    const withDefaultsProto = Object.create(baseConstructor.prototype);\n    forEach(ruleNames, (ruleName) => {\n        withDefaultsProto[ruleName] = defaultVisit;\n    });\n    derivedConstructor.prototype = withDefaultsProto;\n    derivedConstructor.prototype.constructor = derivedConstructor;\n    return derivedConstructor;\n}\nexport var CstVisitorDefinitionError;\n(function (CstVisitorDefinitionError) {\n    CstVisitorDefinitionError[CstVisitorDefinitionError[\"REDUNDANT_METHOD\"] = 0] = \"REDUNDANT_METHOD\";\n    CstVisitorDefinitionError[CstVisitorDefinitionError[\"MISSING_METHOD\"] = 1] = \"MISSING_METHOD\";\n})(CstVisitorDefinitionError || (CstVisitorDefinitionError = {}));\nexport function validateVisitor(visitorInstance, ruleNames) {\n    const missingErrors = validateMissingCstMethods(visitorInstance, ruleNames);\n    return missingErrors;\n}\nexport function validateMissingCstMethods(visitorInstance, ruleNames) {\n    const missingRuleNames = filter(ruleNames, (currRuleName) => {\n        return isFunction(visitorInstance[currRuleName]) === false;\n    });\n    const errors = map(missingRuleNames, (currRuleName) => {\n        return {\n            msg: `Missing visitor method: <${currRuleName}> on ${(visitorInstance.constructor.name)} CST Visitor.`,\n            type: CstVisitorDefinitionError.MISSING_METHOD,\n            methodName: currRuleName,\n        };\n    });\n    return compact(errors);\n}\n//# sourceMappingURL=cst_visitor.js.map","import { addNoneTerminalToCst, addTerminalToCst, setNodeLocationFull, setNodeLocationOnlyOffset, } from \"../../cst/cst.js\";\nimport { has, isUndefined, keys, noop } from \"lodash-es\";\nimport { createBaseSemanticVisitorConstructor, createBaseVisitorConstructorWithDefaults, } from \"../../cst/cst_visitor.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n/**\n * This trait is responsible for the CST building logic.\n */\nexport class TreeBuilder {\n    initTreeBuilder(config) {\n        this.CST_STACK = [];\n        // outputCst is no longer exposed/defined in the pubic API\n        this.outputCst = config.outputCst;\n        this.nodeLocationTracking = has(config, \"nodeLocationTracking\")\n            ? config.nodeLocationTracking // assumes end user provides the correct config value/type\n            : DEFAULT_PARSER_CONFIG.nodeLocationTracking;\n        if (!this.outputCst) {\n            this.cstInvocationStateUpdate = noop;\n            this.cstFinallyStateUpdate = noop;\n            this.cstPostTerminal = noop;\n            this.cstPostNonTerminal = noop;\n            this.cstPostRule = noop;\n        }\n        else {\n            if (/full/i.test(this.nodeLocationTracking)) {\n                if (this.recoveryEnabled) {\n                    this.setNodeLocationFromToken = setNodeLocationFull;\n                    this.setNodeLocationFromNode = setNodeLocationFull;\n                    this.cstPostRule = noop;\n                    this.setInitialNodeLocation = this.setInitialNodeLocationFullRecovery;\n                }\n                else {\n                    this.setNodeLocationFromToken = noop;\n                    this.setNodeLocationFromNode = noop;\n                    this.cstPostRule = this.cstPostRuleFull;\n                    this.setInitialNodeLocation = this.setInitialNodeLocationFullRegular;\n                }\n            }\n            else if (/onlyOffset/i.test(this.nodeLocationTracking)) {\n                if (this.recoveryEnabled) {\n                    this.setNodeLocationFromToken = setNodeLocationOnlyOffset;\n                    this.setNodeLocationFromNode = setNodeLocationOnlyOffset;\n                    this.cstPostRule = noop;\n                    this.setInitialNodeLocation =\n                        this.setInitialNodeLocationOnlyOffsetRecovery;\n                }\n                else {\n                    this.setNodeLocationFromToken = noop;\n                    this.setNodeLocationFromNode = noop;\n                    this.cstPostRule = this.cstPostRuleOnlyOffset;\n                    this.setInitialNodeLocation =\n                        this.setInitialNodeLocationOnlyOffsetRegular;\n                }\n            }\n            else if (/none/i.test(this.nodeLocationTracking)) {\n                this.setNodeLocationFromToken = noop;\n                this.setNodeLocationFromNode = noop;\n                this.cstPostRule = noop;\n                this.setInitialNodeLocation = noop;\n            }\n            else {\n                throw Error(`Invalid <nodeLocationTracking> config option: \"${config.nodeLocationTracking}\"`);\n            }\n        }\n    }\n    setInitialNodeLocationOnlyOffsetRecovery(cstNode) {\n        cstNode.location = {\n            startOffset: NaN,\n            endOffset: NaN,\n        };\n    }\n    setInitialNodeLocationOnlyOffsetRegular(cstNode) {\n        cstNode.location = {\n            // without error recovery the starting Location of a new CstNode is guaranteed\n            // To be the next Token's startOffset (for valid inputs).\n            // For invalid inputs there won't be any CSTOutput so this potential\n            // inaccuracy does not matter\n            startOffset: this.LA(1).startOffset,\n            endOffset: NaN,\n        };\n    }\n    setInitialNodeLocationFullRecovery(cstNode) {\n        cstNode.location = {\n            startOffset: NaN,\n            startLine: NaN,\n            startColumn: NaN,\n            endOffset: NaN,\n            endLine: NaN,\n            endColumn: NaN,\n        };\n    }\n    /**\n       *  @see setInitialNodeLocationOnlyOffsetRegular for explanation why this work\n  \n       * @param cstNode\n       */\n    setInitialNodeLocationFullRegular(cstNode) {\n        const nextToken = this.LA(1);\n        cstNode.location = {\n            startOffset: nextToken.startOffset,\n            startLine: nextToken.startLine,\n            startColumn: nextToken.startColumn,\n            endOffset: NaN,\n            endLine: NaN,\n            endColumn: NaN,\n        };\n    }\n    cstInvocationStateUpdate(fullRuleName) {\n        const cstNode = {\n            name: fullRuleName,\n            children: Object.create(null),\n        };\n        this.setInitialNodeLocation(cstNode);\n        this.CST_STACK.push(cstNode);\n    }\n    cstFinallyStateUpdate() {\n        this.CST_STACK.pop();\n    }\n    cstPostRuleFull(ruleCstNode) {\n        // casts to `required<CstNodeLocation>` are safe because `cstPostRuleFull` should only be invoked when full location is enabled\n        const prevToken = this.LA(0);\n        const loc = ruleCstNode.location;\n        // If this condition is true it means we consumed at least one Token\n        // In this CstNode.\n        if (loc.startOffset <= prevToken.startOffset === true) {\n            loc.endOffset = prevToken.endOffset;\n            loc.endLine = prevToken.endLine;\n            loc.endColumn = prevToken.endColumn;\n        }\n        // \"empty\" CstNode edge case\n        else {\n            loc.startOffset = NaN;\n            loc.startLine = NaN;\n            loc.startColumn = NaN;\n        }\n    }\n    cstPostRuleOnlyOffset(ruleCstNode) {\n        const prevToken = this.LA(0);\n        // `location' is not null because `cstPostRuleOnlyOffset` will only be invoked when location tracking is enabled.\n        const loc = ruleCstNode.location;\n        // If this condition is true it means we consumed at least one Token\n        // In this CstNode.\n        if (loc.startOffset <= prevToken.startOffset === true) {\n            loc.endOffset = prevToken.endOffset;\n        }\n        // \"empty\" CstNode edge case\n        else {\n            loc.startOffset = NaN;\n        }\n    }\n    cstPostTerminal(key, consumedToken) {\n        const rootCst = this.CST_STACK[this.CST_STACK.length - 1];\n        addTerminalToCst(rootCst, consumedToken, key);\n        // This is only used when **both** error recovery and CST Output are enabled.\n        this.setNodeLocationFromToken(rootCst.location, consumedToken);\n    }\n    cstPostNonTerminal(ruleCstResult, ruleName) {\n        const preCstNode = this.CST_STACK[this.CST_STACK.length - 1];\n        addNoneTerminalToCst(preCstNode, ruleName, ruleCstResult);\n        // This is only used when **both** error recovery and CST Output are enabled.\n        this.setNodeLocationFromNode(preCstNode.location, ruleCstResult.location);\n    }\n    getBaseCstVisitorConstructor() {\n        if (isUndefined(this.baseCstVisitorConstructor)) {\n            const newBaseCstVisitorConstructor = createBaseSemanticVisitorConstructor(this.className, keys(this.gastProductionsCache));\n            this.baseCstVisitorConstructor = newBaseCstVisitorConstructor;\n            return newBaseCstVisitorConstructor;\n        }\n        return this.baseCstVisitorConstructor;\n    }\n    getBaseCstVisitorConstructorWithDefaults() {\n        if (isUndefined(this.baseCstVisitorWithDefaultsConstructor)) {\n            const newConstructor = createBaseVisitorConstructorWithDefaults(this.className, keys(this.gastProductionsCache), this.getBaseCstVisitorConstructor());\n            this.baseCstVisitorWithDefaultsConstructor = newConstructor;\n            return newConstructor;\n        }\n        return this.baseCstVisitorWithDefaultsConstructor;\n    }\n    getLastExplicitRuleShortName() {\n        const ruleStack = this.RULE_STACK;\n        return ruleStack[ruleStack.length - 1];\n    }\n    getPreviousExplicitRuleShortName() {\n        const ruleStack = this.RULE_STACK;\n        return ruleStack[ruleStack.length - 2];\n    }\n    getLastExplicitRuleOccurrenceIndex() {\n        const occurrenceStack = this.RULE_OCCURRENCE_STACK;\n        return occurrenceStack[occurrenceStack.length - 1];\n    }\n}\n//# sourceMappingURL=tree_builder.js.map","import { END_OF_FILE } from \"../parser.js\";\n/**\n * Trait responsible abstracting over the interaction with Lexer output (Token vector).\n *\n * This could be generalized to support other kinds of lexers, e.g.\n * - Just in Time Lexing / Lexer-Less parsing.\n * - Streaming Lexer.\n */\nexport class LexerAdapter {\n    initLexerAdapter() {\n        this.tokVector = [];\n        this.tokVectorLength = 0;\n        this.currIdx = -1;\n    }\n    set input(newInput) {\n        // @ts-ignore - `this parameter` not supported in setters/getters\n        //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n        if (this.selfAnalysisDone !== true) {\n            throw Error(`Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.`);\n        }\n        // @ts-ignore - `this parameter` not supported in setters/getters\n        //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n        this.reset();\n        this.tokVector = newInput;\n        this.tokVectorLength = newInput.length;\n    }\n    get input() {\n        return this.tokVector;\n    }\n    // skips a token and returns the next token\n    SKIP_TOKEN() {\n        if (this.currIdx <= this.tokVector.length - 2) {\n            this.consumeToken();\n            return this.LA(1);\n        }\n        else {\n            return END_OF_FILE;\n        }\n    }\n    // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n    // or lexers dependent on parser context.\n    LA(howMuch) {\n        const soughtIdx = this.currIdx + howMuch;\n        if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\n            return END_OF_FILE;\n        }\n        else {\n            return this.tokVector[soughtIdx];\n        }\n    }\n    consumeToken() {\n        this.currIdx++;\n    }\n    exportLexerState() {\n        return this.currIdx;\n    }\n    importLexerState(newState) {\n        this.currIdx = newState;\n    }\n    resetLexerState() {\n        this.currIdx = -1;\n    }\n    moveToTerminatedState() {\n        this.currIdx = this.tokVector.length - 1;\n    }\n    getLexerPosition() {\n        return this.exportLexerState();\n    }\n}\n//# sourceMappingURL=lexer_adapter.js.map","import { includes, values } from \"lodash-es\";\nimport { isRecognitionException } from \"../../exceptions_public.js\";\nimport { DEFAULT_RULE_CONFIG, ParserDefinitionErrorType } from \"../parser.js\";\nimport { defaultGrammarValidatorErrorProvider } from \"../../errors_public.js\";\nimport { validateRuleIsOverridden } from \"../../grammar/checks.js\";\nimport { serializeGrammar } from \"@chevrotain/gast\";\n/**\n * This trait is responsible for implementing the public API\n * for defining Chevrotain parsers, i.e:\n * - CONSUME\n * - RULE\n * - OPTION\n * - ...\n */\nexport class RecognizerApi {\n    ACTION(impl) {\n        return impl.call(this);\n    }\n    consume(idx, tokType, options) {\n        return this.consumeInternal(tokType, idx, options);\n    }\n    subrule(idx, ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, idx, options);\n    }\n    option(idx, actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, idx);\n    }\n    or(idx, altsOrOpts) {\n        return this.orInternal(altsOrOpts, idx);\n    }\n    many(idx, actionORMethodDef) {\n        return this.manyInternal(idx, actionORMethodDef);\n    }\n    atLeastOne(idx, actionORMethodDef) {\n        return this.atLeastOneInternal(idx, actionORMethodDef);\n    }\n    CONSUME(tokType, options) {\n        return this.consumeInternal(tokType, 0, options);\n    }\n    CONSUME1(tokType, options) {\n        return this.consumeInternal(tokType, 1, options);\n    }\n    CONSUME2(tokType, options) {\n        return this.consumeInternal(tokType, 2, options);\n    }\n    CONSUME3(tokType, options) {\n        return this.consumeInternal(tokType, 3, options);\n    }\n    CONSUME4(tokType, options) {\n        return this.consumeInternal(tokType, 4, options);\n    }\n    CONSUME5(tokType, options) {\n        return this.consumeInternal(tokType, 5, options);\n    }\n    CONSUME6(tokType, options) {\n        return this.consumeInternal(tokType, 6, options);\n    }\n    CONSUME7(tokType, options) {\n        return this.consumeInternal(tokType, 7, options);\n    }\n    CONSUME8(tokType, options) {\n        return this.consumeInternal(tokType, 8, options);\n    }\n    CONSUME9(tokType, options) {\n        return this.consumeInternal(tokType, 9, options);\n    }\n    SUBRULE(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 0, options);\n    }\n    SUBRULE1(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 1, options);\n    }\n    SUBRULE2(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 2, options);\n    }\n    SUBRULE3(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 3, options);\n    }\n    SUBRULE4(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 4, options);\n    }\n    SUBRULE5(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 5, options);\n    }\n    SUBRULE6(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 6, options);\n    }\n    SUBRULE7(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 7, options);\n    }\n    SUBRULE8(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 8, options);\n    }\n    SUBRULE9(ruleToCall, options) {\n        return this.subruleInternal(ruleToCall, 9, options);\n    }\n    OPTION(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 0);\n    }\n    OPTION1(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 1);\n    }\n    OPTION2(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 2);\n    }\n    OPTION3(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 3);\n    }\n    OPTION4(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 4);\n    }\n    OPTION5(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 5);\n    }\n    OPTION6(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 6);\n    }\n    OPTION7(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 7);\n    }\n    OPTION8(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 8);\n    }\n    OPTION9(actionORMethodDef) {\n        return this.optionInternal(actionORMethodDef, 9);\n    }\n    OR(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 0);\n    }\n    OR1(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 1);\n    }\n    OR2(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 2);\n    }\n    OR3(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 3);\n    }\n    OR4(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 4);\n    }\n    OR5(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 5);\n    }\n    OR6(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 6);\n    }\n    OR7(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 7);\n    }\n    OR8(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 8);\n    }\n    OR9(altsOrOpts) {\n        return this.orInternal(altsOrOpts, 9);\n    }\n    MANY(actionORMethodDef) {\n        this.manyInternal(0, actionORMethodDef);\n    }\n    MANY1(actionORMethodDef) {\n        this.manyInternal(1, actionORMethodDef);\n    }\n    MANY2(actionORMethodDef) {\n        this.manyInternal(2, actionORMethodDef);\n    }\n    MANY3(actionORMethodDef) {\n        this.manyInternal(3, actionORMethodDef);\n    }\n    MANY4(actionORMethodDef) {\n        this.manyInternal(4, actionORMethodDef);\n    }\n    MANY5(actionORMethodDef) {\n        this.manyInternal(5, actionORMethodDef);\n    }\n    MANY6(actionORMethodDef) {\n        this.manyInternal(6, actionORMethodDef);\n    }\n    MANY7(actionORMethodDef) {\n        this.manyInternal(7, actionORMethodDef);\n    }\n    MANY8(actionORMethodDef) {\n        this.manyInternal(8, actionORMethodDef);\n    }\n    MANY9(actionORMethodDef) {\n        this.manyInternal(9, actionORMethodDef);\n    }\n    MANY_SEP(options) {\n        this.manySepFirstInternal(0, options);\n    }\n    MANY_SEP1(options) {\n        this.manySepFirstInternal(1, options);\n    }\n    MANY_SEP2(options) {\n        this.manySepFirstInternal(2, options);\n    }\n    MANY_SEP3(options) {\n        this.manySepFirstInternal(3, options);\n    }\n    MANY_SEP4(options) {\n        this.manySepFirstInternal(4, options);\n    }\n    MANY_SEP5(options) {\n        this.manySepFirstInternal(5, options);\n    }\n    MANY_SEP6(options) {\n        this.manySepFirstInternal(6, options);\n    }\n    MANY_SEP7(options) {\n        this.manySepFirstInternal(7, options);\n    }\n    MANY_SEP8(options) {\n        this.manySepFirstInternal(8, options);\n    }\n    MANY_SEP9(options) {\n        this.manySepFirstInternal(9, options);\n    }\n    AT_LEAST_ONE(actionORMethodDef) {\n        this.atLeastOneInternal(0, actionORMethodDef);\n    }\n    AT_LEAST_ONE1(actionORMethodDef) {\n        return this.atLeastOneInternal(1, actionORMethodDef);\n    }\n    AT_LEAST_ONE2(actionORMethodDef) {\n        this.atLeastOneInternal(2, actionORMethodDef);\n    }\n    AT_LEAST_ONE3(actionORMethodDef) {\n        this.atLeastOneInternal(3, actionORMethodDef);\n    }\n    AT_LEAST_ONE4(actionORMethodDef) {\n        this.atLeastOneInternal(4, actionORMethodDef);\n    }\n    AT_LEAST_ONE5(actionORMethodDef) {\n        this.atLeastOneInternal(5, actionORMethodDef);\n    }\n    AT_LEAST_ONE6(actionORMethodDef) {\n        this.atLeastOneInternal(6, actionORMethodDef);\n    }\n    AT_LEAST_ONE7(actionORMethodDef) {\n        this.atLeastOneInternal(7, actionORMethodDef);\n    }\n    AT_LEAST_ONE8(actionORMethodDef) {\n        this.atLeastOneInternal(8, actionORMethodDef);\n    }\n    AT_LEAST_ONE9(actionORMethodDef) {\n        this.atLeastOneInternal(9, actionORMethodDef);\n    }\n    AT_LEAST_ONE_SEP(options) {\n        this.atLeastOneSepFirstInternal(0, options);\n    }\n    AT_LEAST_ONE_SEP1(options) {\n        this.atLeastOneSepFirstInternal(1, options);\n    }\n    AT_LEAST_ONE_SEP2(options) {\n        this.atLeastOneSepFirstInternal(2, options);\n    }\n    AT_LEAST_ONE_SEP3(options) {\n        this.atLeastOneSepFirstInternal(3, options);\n    }\n    AT_LEAST_ONE_SEP4(options) {\n        this.atLeastOneSepFirstInternal(4, options);\n    }\n    AT_LEAST_ONE_SEP5(options) {\n        this.atLeastOneSepFirstInternal(5, options);\n    }\n    AT_LEAST_ONE_SEP6(options) {\n        this.atLeastOneSepFirstInternal(6, options);\n    }\n    AT_LEAST_ONE_SEP7(options) {\n        this.atLeastOneSepFirstInternal(7, options);\n    }\n    AT_LEAST_ONE_SEP8(options) {\n        this.atLeastOneSepFirstInternal(8, options);\n    }\n    AT_LEAST_ONE_SEP9(options) {\n        this.atLeastOneSepFirstInternal(9, options);\n    }\n    RULE(name, implementation, config = DEFAULT_RULE_CONFIG) {\n        if (includes(this.definedRulesNames, name)) {\n            const errMsg = defaultGrammarValidatorErrorProvider.buildDuplicateRuleNameError({\n                topLevelRule: name,\n                grammarName: this.className,\n            });\n            const error = {\n                message: errMsg,\n                type: ParserDefinitionErrorType.DUPLICATE_RULE_NAME,\n                ruleName: name,\n            };\n            this.definitionErrors.push(error);\n        }\n        this.definedRulesNames.push(name);\n        const ruleImplementation = this.defineRule(name, implementation, config);\n        this[name] = ruleImplementation;\n        return ruleImplementation;\n    }\n    OVERRIDE_RULE(name, impl, config = DEFAULT_RULE_CONFIG) {\n        const ruleErrors = validateRuleIsOverridden(name, this.definedRulesNames, this.className);\n        this.definitionErrors = this.definitionErrors.concat(ruleErrors);\n        const ruleImplementation = this.defineRule(name, impl, config);\n        this[name] = ruleImplementation;\n        return ruleImplementation;\n    }\n    BACKTRACK(grammarRule, args) {\n        return function () {\n            // save org state\n            this.isBackTrackingStack.push(1);\n            const orgState = this.saveRecogState();\n            try {\n                grammarRule.apply(this, args);\n                // if no exception was thrown we have succeed parsing the rule.\n                return true;\n            }\n            catch (e) {\n                if (isRecognitionException(e)) {\n                    return false;\n                }\n                else {\n                    throw e;\n                }\n            }\n            finally {\n                this.reloadRecogState(orgState);\n                this.isBackTrackingStack.pop();\n            }\n        };\n    }\n    // GAST export APIs\n    getGAstProductions() {\n        return this.gastProductionsCache;\n    }\n    getSerializedGastProductions() {\n        return serializeGrammar(values(this.gastProductionsCache));\n    }\n}\n//# sourceMappingURL=recognizer_api.js.map","import { clone, every, flatten, has, isArray, isEmpty, isObject, reduce, uniq, values, } from \"lodash-es\";\nimport { AT_LEAST_ONE_IDX, AT_LEAST_ONE_SEP_IDX, BITS_FOR_METHOD_TYPE, BITS_FOR_OCCURRENCE_IDX, MANY_IDX, MANY_SEP_IDX, OPTION_IDX, OR_IDX, } from \"../../grammar/keys.js\";\nimport { isRecognitionException, MismatchedTokenException, NotAllInputParsedException, } from \"../../exceptions_public.js\";\nimport { PROD_TYPE } from \"../../grammar/lookahead.js\";\nimport { NextTerminalAfterAtLeastOneSepWalker, NextTerminalAfterAtLeastOneWalker, NextTerminalAfterManySepWalker, NextTerminalAfterManyWalker, } from \"../../grammar/interpreter.js\";\nimport { DEFAULT_RULE_CONFIG } from \"../parser.js\";\nimport { IN_RULE_RECOVERY_EXCEPTION } from \"./recoverable.js\";\nimport { EOF } from \"../../../scan/tokens_public.js\";\nimport { augmentTokenTypes, isTokenType, tokenStructuredMatcher, tokenStructuredMatcherNoCategories, } from \"../../../scan/tokens.js\";\n/**\n * This trait is responsible for the runtime parsing engine\n * Used by the official API (recognizer_api.ts)\n */\nexport class RecognizerEngine {\n    initRecognizerEngine(tokenVocabulary, config) {\n        this.className = this.constructor.name;\n        // TODO: would using an ES6 Map or plain object be faster (CST building scenario)\n        this.shortRuleNameToFull = {};\n        this.fullRuleNameToShort = {};\n        this.ruleShortNameIdx = 256;\n        this.tokenMatcher = tokenStructuredMatcherNoCategories;\n        this.subruleIdx = 0;\n        this.definedRulesNames = [];\n        this.tokensMap = {};\n        this.isBackTrackingStack = [];\n        this.RULE_STACK = [];\n        this.RULE_OCCURRENCE_STACK = [];\n        this.gastProductionsCache = {};\n        if (has(config, \"serializedGrammar\")) {\n            throw Error(\"The Parser's configuration can no longer contain a <serializedGrammar> property.\\n\" +\n                \"\\tSee: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_6-0-0\\n\" +\n                \"\\tFor Further details.\");\n        }\n        if (isArray(tokenVocabulary)) {\n            // This only checks for Token vocabularies provided as arrays.\n            // That is good enough because the main objective is to detect users of pre-V4.0 APIs\n            // rather than all edge cases of empty Token vocabularies.\n            if (isEmpty(tokenVocabulary)) {\n                throw Error(\"A Token Vocabulary cannot be empty.\\n\" +\n                    \"\\tNote that the first argument for the parser constructor\\n\" +\n                    \"\\tis no longer a Token vector (since v4.0).\");\n            }\n            if (typeof tokenVocabulary[0].startOffset === \"number\") {\n                throw Error(\"The Parser constructor no longer accepts a token vector as the first argument.\\n\" +\n                    \"\\tSee: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_4-0-0\\n\" +\n                    \"\\tFor Further details.\");\n            }\n        }\n        if (isArray(tokenVocabulary)) {\n            this.tokensMap = reduce(tokenVocabulary, (acc, tokType) => {\n                acc[tokType.name] = tokType;\n                return acc;\n            }, {});\n        }\n        else if (has(tokenVocabulary, \"modes\") &&\n            every(flatten(values(tokenVocabulary.modes)), isTokenType)) {\n            const allTokenTypes = flatten(values(tokenVocabulary.modes));\n            const uniqueTokens = uniq(allTokenTypes);\n            this.tokensMap = reduce(uniqueTokens, (acc, tokType) => {\n                acc[tokType.name] = tokType;\n                return acc;\n            }, {});\n        }\n        else if (isObject(tokenVocabulary)) {\n            this.tokensMap = clone(tokenVocabulary);\n        }\n        else {\n            throw new Error(\"<tokensDictionary> argument must be An Array of Token constructors,\" +\n                \" A dictionary of Token constructors or an IMultiModeLexerDefinition\");\n        }\n        // always add EOF to the tokenNames -> constructors map. it is useful to assure all the input has been\n        // parsed with a clear error message (\"expecting EOF but found ...\")\n        this.tokensMap[\"EOF\"] = EOF;\n        const allTokenTypes = has(tokenVocabulary, \"modes\")\n            ? flatten(values(tokenVocabulary.modes))\n            : values(tokenVocabulary);\n        const noTokenCategoriesUsed = every(allTokenTypes, (tokenConstructor) => isEmpty(tokenConstructor.categoryMatches));\n        this.tokenMatcher = noTokenCategoriesUsed\n            ? tokenStructuredMatcherNoCategories\n            : tokenStructuredMatcher;\n        // Because ES2015+ syntax should be supported for creating Token classes\n        // We cannot assume that the Token classes were created using the \"extendToken\" utilities\n        // Therefore we must augment the Token classes both on Lexer initialization and on Parser initialization\n        augmentTokenTypes(values(this.tokensMap));\n    }\n    defineRule(ruleName, impl, config) {\n        if (this.selfAnalysisDone) {\n            throw Error(`Grammar rule <${ruleName}> may not be defined after the 'performSelfAnalysis' method has been called'\\n` +\n                `Make sure that all grammar rule definitions are done before 'performSelfAnalysis' is called.`);\n        }\n        const resyncEnabled = has(config, \"resyncEnabled\")\n            ? config.resyncEnabled // assumes end user provides the correct config value/type\n            : DEFAULT_RULE_CONFIG.resyncEnabled;\n        const recoveryValueFunc = has(config, \"recoveryValueFunc\")\n            ? config.recoveryValueFunc // assumes end user provides the correct config value/type\n            : DEFAULT_RULE_CONFIG.recoveryValueFunc;\n        // performance optimization: Use small integers as keys for the longer human readable \"full\" rule names.\n        // this greatly improves Map access time (as much as 8% for some performance benchmarks).\n        const shortName = this.ruleShortNameIdx << (BITS_FOR_METHOD_TYPE + BITS_FOR_OCCURRENCE_IDX);\n        this.ruleShortNameIdx++;\n        this.shortRuleNameToFull[shortName] = ruleName;\n        this.fullRuleNameToShort[ruleName] = shortName;\n        let invokeRuleWithTry;\n        // Micro optimization, only check the condition **once** on rule definition\n        // instead of **every single** rule invocation.\n        if (this.outputCst === true) {\n            invokeRuleWithTry = function invokeRuleWithTry(...args) {\n                try {\n                    this.ruleInvocationStateUpdate(shortName, ruleName, this.subruleIdx);\n                    impl.apply(this, args);\n                    const cst = this.CST_STACK[this.CST_STACK.length - 1];\n                    this.cstPostRule(cst);\n                    return cst;\n                }\n                catch (e) {\n                    return this.invokeRuleCatch(e, resyncEnabled, recoveryValueFunc);\n                }\n                finally {\n                    this.ruleFinallyStateUpdate();\n                }\n            };\n        }\n        else {\n            invokeRuleWithTry = function invokeRuleWithTryCst(...args) {\n                try {\n                    this.ruleInvocationStateUpdate(shortName, ruleName, this.subruleIdx);\n                    return impl.apply(this, args);\n                }\n                catch (e) {\n                    return this.invokeRuleCatch(e, resyncEnabled, recoveryValueFunc);\n                }\n                finally {\n                    this.ruleFinallyStateUpdate();\n                }\n            };\n        }\n        const wrappedGrammarRule = Object.assign(invokeRuleWithTry, { ruleName, originalGrammarAction: impl });\n        return wrappedGrammarRule;\n    }\n    invokeRuleCatch(e, resyncEnabledConfig, recoveryValueFunc) {\n        const isFirstInvokedRule = this.RULE_STACK.length === 1;\n        // note the reSync is always enabled for the first rule invocation, because we must always be able to\n        // reSync with EOF and just output some INVALID ParseTree\n        // during backtracking reSync recovery is disabled, otherwise we can't be certain the backtracking\n        // path is really the most valid one\n        const reSyncEnabled = resyncEnabledConfig && !this.isBackTracking() && this.recoveryEnabled;\n        if (isRecognitionException(e)) {\n            const recogError = e;\n            if (reSyncEnabled) {\n                const reSyncTokType = this.findReSyncTokenType();\n                if (this.isInCurrentRuleReSyncSet(reSyncTokType)) {\n                    recogError.resyncedTokens = this.reSyncTo(reSyncTokType);\n                    if (this.outputCst) {\n                        const partialCstResult = this.CST_STACK[this.CST_STACK.length - 1];\n                        partialCstResult.recoveredNode = true;\n                        return partialCstResult;\n                    }\n                    else {\n                        return recoveryValueFunc(e);\n                    }\n                }\n                else {\n                    if (this.outputCst) {\n                        const partialCstResult = this.CST_STACK[this.CST_STACK.length - 1];\n                        partialCstResult.recoveredNode = true;\n                        recogError.partialCstResult = partialCstResult;\n                    }\n                    // to be handled Further up the call stack\n                    throw recogError;\n                }\n            }\n            else if (isFirstInvokedRule) {\n                // otherwise a Redundant input error will be created as well and we cannot guarantee that this is indeed the case\n                this.moveToTerminatedState();\n                // the parser should never throw one of its own errors outside its flow.\n                // even if error recovery is disabled\n                return recoveryValueFunc(e);\n            }\n            else {\n                // to be recovered Further up the call stack\n                throw recogError;\n            }\n        }\n        else {\n            // some other Error type which we don't know how to handle (for example a built in JavaScript Error)\n            throw e;\n        }\n    }\n    // Implementation of parsing DSL\n    optionInternal(actionORMethodDef, occurrence) {\n        const key = this.getKeyForAutomaticLookahead(OPTION_IDX, occurrence);\n        return this.optionInternalLogic(actionORMethodDef, occurrence, key);\n    }\n    optionInternalLogic(actionORMethodDef, occurrence, key) {\n        let lookAheadFunc = this.getLaFuncFromCache(key);\n        let action;\n        if (typeof actionORMethodDef !== \"function\") {\n            action = actionORMethodDef.DEF;\n            const predicate = actionORMethodDef.GATE;\n            // predicate present\n            if (predicate !== undefined) {\n                const orgLookaheadFunction = lookAheadFunc;\n                lookAheadFunc = () => {\n                    return predicate.call(this) && orgLookaheadFunction.call(this);\n                };\n            }\n        }\n        else {\n            action = actionORMethodDef;\n        }\n        if (lookAheadFunc.call(this) === true) {\n            return action.call(this);\n        }\n        return undefined;\n    }\n    atLeastOneInternal(prodOccurrence, actionORMethodDef) {\n        const laKey = this.getKeyForAutomaticLookahead(AT_LEAST_ONE_IDX, prodOccurrence);\n        return this.atLeastOneInternalLogic(prodOccurrence, actionORMethodDef, laKey);\n    }\n    atLeastOneInternalLogic(prodOccurrence, actionORMethodDef, key) {\n        let lookAheadFunc = this.getLaFuncFromCache(key);\n        let action;\n        if (typeof actionORMethodDef !== \"function\") {\n            action = actionORMethodDef.DEF;\n            const predicate = actionORMethodDef.GATE;\n            // predicate present\n            if (predicate !== undefined) {\n                const orgLookaheadFunction = lookAheadFunc;\n                lookAheadFunc = () => {\n                    return predicate.call(this) && orgLookaheadFunction.call(this);\n                };\n            }\n        }\n        else {\n            action = actionORMethodDef;\n        }\n        if (lookAheadFunc.call(this) === true) {\n            let notStuck = this.doSingleRepetition(action);\n            while (lookAheadFunc.call(this) === true &&\n                notStuck === true) {\n                notStuck = this.doSingleRepetition(action);\n            }\n        }\n        else {\n            throw this.raiseEarlyExitException(prodOccurrence, PROD_TYPE.REPETITION_MANDATORY, actionORMethodDef.ERR_MSG);\n        }\n        // note that while it may seem that this can cause an error because by using a recursive call to\n        // AT_LEAST_ONE we change the grammar to AT_LEAST_TWO, AT_LEAST_THREE ... , the possible recursive call\n        // from the tryInRepetitionRecovery(...) will only happen IFF there really are TWO/THREE/.... items.\n        // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n        this.attemptInRepetitionRecovery(this.atLeastOneInternal, [prodOccurrence, actionORMethodDef], lookAheadFunc, AT_LEAST_ONE_IDX, prodOccurrence, NextTerminalAfterAtLeastOneWalker);\n    }\n    atLeastOneSepFirstInternal(prodOccurrence, options) {\n        const laKey = this.getKeyForAutomaticLookahead(AT_LEAST_ONE_SEP_IDX, prodOccurrence);\n        this.atLeastOneSepFirstInternalLogic(prodOccurrence, options, laKey);\n    }\n    atLeastOneSepFirstInternalLogic(prodOccurrence, options, key) {\n        const action = options.DEF;\n        const separator = options.SEP;\n        const firstIterationLookaheadFunc = this.getLaFuncFromCache(key);\n        // 1st iteration\n        if (firstIterationLookaheadFunc.call(this) === true) {\n            action.call(this);\n            //  TODO: Optimization can move this function construction into \"attemptInRepetitionRecovery\"\n            //  because it is only needed in error recovery scenarios.\n            const separatorLookAheadFunc = () => {\n                return this.tokenMatcher(this.LA(1), separator);\n            };\n            // 2nd..nth iterations\n            while (this.tokenMatcher(this.LA(1), separator) === true) {\n                // note that this CONSUME will never enter recovery because\n                // the separatorLookAheadFunc checks that the separator really does exist.\n                this.CONSUME(separator);\n                // No need for checking infinite loop here due to consuming the separator.\n                action.call(this);\n            }\n            // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n            this.attemptInRepetitionRecovery(this.repetitionSepSecondInternal, [\n                prodOccurrence,\n                separator,\n                separatorLookAheadFunc,\n                action,\n                NextTerminalAfterAtLeastOneSepWalker,\n            ], separatorLookAheadFunc, AT_LEAST_ONE_SEP_IDX, prodOccurrence, NextTerminalAfterAtLeastOneSepWalker);\n        }\n        else {\n            throw this.raiseEarlyExitException(prodOccurrence, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR, options.ERR_MSG);\n        }\n    }\n    manyInternal(prodOccurrence, actionORMethodDef) {\n        const laKey = this.getKeyForAutomaticLookahead(MANY_IDX, prodOccurrence);\n        return this.manyInternalLogic(prodOccurrence, actionORMethodDef, laKey);\n    }\n    manyInternalLogic(prodOccurrence, actionORMethodDef, key) {\n        let lookaheadFunction = this.getLaFuncFromCache(key);\n        let action;\n        if (typeof actionORMethodDef !== \"function\") {\n            action = actionORMethodDef.DEF;\n            const predicate = actionORMethodDef.GATE;\n            // predicate present\n            if (predicate !== undefined) {\n                const orgLookaheadFunction = lookaheadFunction;\n                lookaheadFunction = () => {\n                    return predicate.call(this) && orgLookaheadFunction.call(this);\n                };\n            }\n        }\n        else {\n            action = actionORMethodDef;\n        }\n        let notStuck = true;\n        while (lookaheadFunction.call(this) === true && notStuck === true) {\n            notStuck = this.doSingleRepetition(action);\n        }\n        // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n        this.attemptInRepetitionRecovery(this.manyInternal, [prodOccurrence, actionORMethodDef], lookaheadFunction, MANY_IDX, prodOccurrence, NextTerminalAfterManyWalker, \n        // The notStuck parameter is only relevant when \"attemptInRepetitionRecovery\"\n        // is invoked from manyInternal, in the MANY_SEP case and AT_LEAST_ONE[_SEP]\n        // An infinite loop cannot occur as:\n        // - Either the lookahead is guaranteed to consume something (Single Token Separator)\n        // - AT_LEAST_ONE by definition is guaranteed to consume something (or error out).\n        notStuck);\n    }\n    manySepFirstInternal(prodOccurrence, options) {\n        const laKey = this.getKeyForAutomaticLookahead(MANY_SEP_IDX, prodOccurrence);\n        this.manySepFirstInternalLogic(prodOccurrence, options, laKey);\n    }\n    manySepFirstInternalLogic(prodOccurrence, options, key) {\n        const action = options.DEF;\n        const separator = options.SEP;\n        const firstIterationLaFunc = this.getLaFuncFromCache(key);\n        // 1st iteration\n        if (firstIterationLaFunc.call(this) === true) {\n            action.call(this);\n            const separatorLookAheadFunc = () => {\n                return this.tokenMatcher(this.LA(1), separator);\n            };\n            // 2nd..nth iterations\n            while (this.tokenMatcher(this.LA(1), separator) === true) {\n                // note that this CONSUME will never enter recovery because\n                // the separatorLookAheadFunc checks that the separator really does exist.\n                this.CONSUME(separator);\n                // No need for checking infinite loop here due to consuming the separator.\n                action.call(this);\n            }\n            // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n            this.attemptInRepetitionRecovery(this.repetitionSepSecondInternal, [\n                prodOccurrence,\n                separator,\n                separatorLookAheadFunc,\n                action,\n                NextTerminalAfterManySepWalker,\n            ], separatorLookAheadFunc, MANY_SEP_IDX, prodOccurrence, NextTerminalAfterManySepWalker);\n        }\n    }\n    repetitionSepSecondInternal(prodOccurrence, separator, separatorLookAheadFunc, action, nextTerminalAfterWalker) {\n        while (separatorLookAheadFunc()) {\n            // note that this CONSUME will never enter recovery because\n            // the separatorLookAheadFunc checks that the separator really does exist.\n            this.CONSUME(separator);\n            action.call(this);\n        }\n        // we can only arrive to this function after an error\n        // has occurred (hence the name 'second') so the following\n        // IF will always be entered, its possible to remove it...\n        // however it is kept to avoid confusion and be consistent.\n        // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n        /* istanbul ignore else */\n        this.attemptInRepetitionRecovery(this.repetitionSepSecondInternal, [\n            prodOccurrence,\n            separator,\n            separatorLookAheadFunc,\n            action,\n            nextTerminalAfterWalker,\n        ], separatorLookAheadFunc, AT_LEAST_ONE_SEP_IDX, prodOccurrence, nextTerminalAfterWalker);\n    }\n    doSingleRepetition(action) {\n        const beforeIteration = this.getLexerPosition();\n        action.call(this);\n        const afterIteration = this.getLexerPosition();\n        // This boolean will indicate if this repetition progressed\n        // or if we are \"stuck\" (potential infinite loop in the repetition).\n        return afterIteration > beforeIteration;\n    }\n    orInternal(altsOrOpts, occurrence) {\n        const laKey = this.getKeyForAutomaticLookahead(OR_IDX, occurrence);\n        const alts = isArray(altsOrOpts) ? altsOrOpts : altsOrOpts.DEF;\n        const laFunc = this.getLaFuncFromCache(laKey);\n        const altIdxToTake = laFunc.call(this, alts);\n        if (altIdxToTake !== undefined) {\n            const chosenAlternative = alts[altIdxToTake];\n            return chosenAlternative.ALT.call(this);\n        }\n        this.raiseNoAltException(occurrence, altsOrOpts.ERR_MSG);\n    }\n    ruleFinallyStateUpdate() {\n        this.RULE_STACK.pop();\n        this.RULE_OCCURRENCE_STACK.pop();\n        // NOOP when cst is disabled\n        this.cstFinallyStateUpdate();\n        if (this.RULE_STACK.length === 0 && this.isAtEndOfInput() === false) {\n            const firstRedundantTok = this.LA(1);\n            const errMsg = this.errorMessageProvider.buildNotAllInputParsedMessage({\n                firstRedundant: firstRedundantTok,\n                ruleName: this.getCurrRuleFullName(),\n            });\n            this.SAVE_ERROR(new NotAllInputParsedException(errMsg, firstRedundantTok));\n        }\n    }\n    subruleInternal(ruleToCall, idx, options) {\n        let ruleResult;\n        try {\n            const args = options !== undefined ? options.ARGS : undefined;\n            this.subruleIdx = idx;\n            ruleResult = ruleToCall.apply(this, args);\n            this.cstPostNonTerminal(ruleResult, options !== undefined && options.LABEL !== undefined\n                ? options.LABEL\n                : ruleToCall.ruleName);\n            return ruleResult;\n        }\n        catch (e) {\n            throw this.subruleInternalError(e, options, ruleToCall.ruleName);\n        }\n    }\n    subruleInternalError(e, options, ruleName) {\n        if (isRecognitionException(e) && e.partialCstResult !== undefined) {\n            this.cstPostNonTerminal(e.partialCstResult, options !== undefined && options.LABEL !== undefined\n                ? options.LABEL\n                : ruleName);\n            delete e.partialCstResult;\n        }\n        throw e;\n    }\n    consumeInternal(tokType, idx, options) {\n        let consumedToken;\n        try {\n            const nextToken = this.LA(1);\n            if (this.tokenMatcher(nextToken, tokType) === true) {\n                this.consumeToken();\n                consumedToken = nextToken;\n            }\n            else {\n                this.consumeInternalError(tokType, nextToken, options);\n            }\n        }\n        catch (eFromConsumption) {\n            consumedToken = this.consumeInternalRecovery(tokType, idx, eFromConsumption);\n        }\n        this.cstPostTerminal(options !== undefined && options.LABEL !== undefined\n            ? options.LABEL\n            : tokType.name, consumedToken);\n        return consumedToken;\n    }\n    consumeInternalError(tokType, nextToken, options) {\n        let msg;\n        const previousToken = this.LA(0);\n        if (options !== undefined && options.ERR_MSG) {\n            msg = options.ERR_MSG;\n        }\n        else {\n            msg = this.errorMessageProvider.buildMismatchTokenMessage({\n                expected: tokType,\n                actual: nextToken,\n                previous: previousToken,\n                ruleName: this.getCurrRuleFullName(),\n            });\n        }\n        throw this.SAVE_ERROR(new MismatchedTokenException(msg, nextToken, previousToken));\n    }\n    consumeInternalRecovery(tokType, idx, eFromConsumption) {\n        // no recovery allowed during backtracking, otherwise backtracking may recover invalid syntax and accept it\n        // but the original syntax could have been parsed successfully without any backtracking + recovery\n        if (this.recoveryEnabled &&\n            // TODO: more robust checking of the exception type. Perhaps Typescript extending expressions?\n            eFromConsumption.name === \"MismatchedTokenException\" &&\n            !this.isBackTracking()) {\n            const follows = this.getFollowsForInRuleRecovery(tokType, idx);\n            try {\n                return this.tryInRuleRecovery(tokType, follows);\n            }\n            catch (eFromInRuleRecovery) {\n                if (eFromInRuleRecovery.name === IN_RULE_RECOVERY_EXCEPTION) {\n                    // failed in RuleRecovery.\n                    // throw the original error in order to trigger reSync error recovery\n                    throw eFromConsumption;\n                }\n                else {\n                    throw eFromInRuleRecovery;\n                }\n            }\n        }\n        else {\n            throw eFromConsumption;\n        }\n    }\n    saveRecogState() {\n        // errors is a getter which will clone the errors array\n        const savedErrors = this.errors;\n        const savedRuleStack = clone(this.RULE_STACK);\n        return {\n            errors: savedErrors,\n            lexerState: this.exportLexerState(),\n            RULE_STACK: savedRuleStack,\n            CST_STACK: this.CST_STACK,\n        };\n    }\n    reloadRecogState(newState) {\n        this.errors = newState.errors;\n        this.importLexerState(newState.lexerState);\n        this.RULE_STACK = newState.RULE_STACK;\n    }\n    ruleInvocationStateUpdate(shortName, fullName, idxInCallingRule) {\n        this.RULE_OCCURRENCE_STACK.push(idxInCallingRule);\n        this.RULE_STACK.push(shortName);\n        // NOOP when cst is disabled\n        this.cstInvocationStateUpdate(fullName);\n    }\n    isBackTracking() {\n        return this.isBackTrackingStack.length !== 0;\n    }\n    getCurrRuleFullName() {\n        const shortName = this.getLastExplicitRuleShortName();\n        return this.shortRuleNameToFull[shortName];\n    }\n    shortRuleNameToFullName(shortName) {\n        return this.shortRuleNameToFull[shortName];\n    }\n    isAtEndOfInput() {\n        return this.tokenMatcher(this.LA(1), EOF);\n    }\n    reset() {\n        this.resetLexerState();\n        this.subruleIdx = 0;\n        this.isBackTrackingStack = [];\n        this.errors = [];\n        this.RULE_STACK = [];\n        // TODO: extract a specific reset for TreeBuilder trait\n        this.CST_STACK = [];\n        this.RULE_OCCURRENCE_STACK = [];\n    }\n}\n//# sourceMappingURL=recognizer_engine.js.map","import { EarlyExitException, isRecognitionException, NoViableAltException, } from \"../../exceptions_public.js\";\nimport { clone, has } from \"lodash-es\";\nimport { getLookaheadPathsForOptionalProd, getLookaheadPathsForOr, } from \"../../grammar/lookahead.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n/**\n * Trait responsible for runtime parsing errors.\n */\nexport class ErrorHandler {\n    initErrorHandler(config) {\n        this._errors = [];\n        this.errorMessageProvider = has(config, \"errorMessageProvider\")\n            ? config.errorMessageProvider // assumes end user provides the correct config value/type\n            : DEFAULT_PARSER_CONFIG.errorMessageProvider;\n    }\n    SAVE_ERROR(error) {\n        if (isRecognitionException(error)) {\n            error.context = {\n                ruleStack: this.getHumanReadableRuleStack(),\n                ruleOccurrenceStack: clone(this.RULE_OCCURRENCE_STACK),\n            };\n            this._errors.push(error);\n            return error;\n        }\n        else {\n            throw Error(\"Trying to save an Error which is not a RecognitionException\");\n        }\n    }\n    get errors() {\n        return clone(this._errors);\n    }\n    set errors(newErrors) {\n        this._errors = newErrors;\n    }\n    // TODO: consider caching the error message computed information\n    raiseEarlyExitException(occurrence, prodType, userDefinedErrMsg) {\n        const ruleName = this.getCurrRuleFullName();\n        const ruleGrammar = this.getGAstProductions()[ruleName];\n        const lookAheadPathsPerAlternative = getLookaheadPathsForOptionalProd(occurrence, ruleGrammar, prodType, this.maxLookahead);\n        const insideProdPaths = lookAheadPathsPerAlternative[0];\n        const actualTokens = [];\n        for (let i = 1; i <= this.maxLookahead; i++) {\n            actualTokens.push(this.LA(i));\n        }\n        const msg = this.errorMessageProvider.buildEarlyExitMessage({\n            expectedIterationPaths: insideProdPaths,\n            actual: actualTokens,\n            previous: this.LA(0),\n            customUserDescription: userDefinedErrMsg,\n            ruleName: ruleName,\n        });\n        throw this.SAVE_ERROR(new EarlyExitException(msg, this.LA(1), this.LA(0)));\n    }\n    // TODO: consider caching the error message computed information\n    raiseNoAltException(occurrence, errMsgTypes) {\n        const ruleName = this.getCurrRuleFullName();\n        const ruleGrammar = this.getGAstProductions()[ruleName];\n        // TODO: getLookaheadPathsForOr can be slow for large enough maxLookahead and certain grammars, consider caching ?\n        const lookAheadPathsPerAlternative = getLookaheadPathsForOr(occurrence, ruleGrammar, this.maxLookahead);\n        const actualTokens = [];\n        for (let i = 1; i <= this.maxLookahead; i++) {\n            actualTokens.push(this.LA(i));\n        }\n        const previousToken = this.LA(0);\n        const errMsg = this.errorMessageProvider.buildNoViableAltMessage({\n            expectedPathsPerAlt: lookAheadPathsPerAlternative,\n            actual: actualTokens,\n            previous: previousToken,\n            customUserDescription: errMsgTypes,\n            ruleName: this.getCurrRuleFullName(),\n        });\n        throw this.SAVE_ERROR(new NoViableAltException(errMsg, this.LA(1), previousToken));\n    }\n}\n//# sourceMappingURL=error_handler.js.map","import { NextAfterTokenWalker, nextPossibleTokensAfter, } from \"../../grammar/interpreter.js\";\nimport { first, isUndefined } from \"lodash-es\";\nexport class ContentAssist {\n    initContentAssist() { }\n    computeContentAssist(startRuleName, precedingInput) {\n        const startRuleGast = this.gastProductionsCache[startRuleName];\n        if (isUndefined(startRuleGast)) {\n            throw Error(`Rule ->${startRuleName}<- does not exist in this grammar.`);\n        }\n        return nextPossibleTokensAfter([startRuleGast], precedingInput, this.tokenMatcher, this.maxLookahead);\n    }\n    // TODO: should this be a member method or a utility? it does not have any state or usage of 'this'...\n    // TODO: should this be more explicitly part of the public API?\n    getNextPossibleTokenTypes(grammarPath) {\n        const topRuleName = first(grammarPath.ruleStack);\n        const gastProductions = this.getGAstProductions();\n        const topProduction = gastProductions[topRuleName];\n        const nextPossibleTokenTypes = new NextAfterTokenWalker(topProduction, grammarPath).startWalking();\n        return nextPossibleTokenTypes;\n    }\n}\n//# sourceMappingURL=context_assist.js.map","import { forEach, has, isArray, isFunction, last as peek, some, } from \"lodash-es\";\nimport { Alternation, Alternative, NonTerminal, Option, Repetition, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, Rule, Terminal, } from \"@chevrotain/gast\";\nimport { Lexer } from \"../../../scan/lexer_public.js\";\nimport { augmentTokenTypes, hasShortKeyProperty, } from \"../../../scan/tokens.js\";\nimport { createToken, createTokenInstance, } from \"../../../scan/tokens_public.js\";\nimport { END_OF_FILE } from \"../parser.js\";\nimport { BITS_FOR_OCCURRENCE_IDX } from \"../../grammar/keys.js\";\nconst RECORDING_NULL_OBJECT = {\n    description: \"This Object indicates the Parser is during Recording Phase\",\n};\nObject.freeze(RECORDING_NULL_OBJECT);\nconst HANDLE_SEPARATOR = true;\nconst MAX_METHOD_IDX = Math.pow(2, BITS_FOR_OCCURRENCE_IDX) - 1;\nconst RFT = createToken({ name: \"RECORDING_PHASE_TOKEN\", pattern: Lexer.NA });\naugmentTokenTypes([RFT]);\nconst RECORDING_PHASE_TOKEN = createTokenInstance(RFT, \"This IToken indicates the Parser is in Recording Phase\\n\\t\" +\n    \"\" +\n    \"See: https://chevrotain.io/docs/guide/internals.html#grammar-recording for details\", \n// Using \"-1\" instead of NaN (as in EOF) because an actual number is less likely to\n// cause errors if the output of LA or CONSUME would be (incorrectly) used during the recording phase.\n-1, -1, -1, -1, -1, -1);\nObject.freeze(RECORDING_PHASE_TOKEN);\nconst RECORDING_PHASE_CSTNODE = {\n    name: \"This CSTNode indicates the Parser is in Recording Phase\\n\\t\" +\n        \"See: https://chevrotain.io/docs/guide/internals.html#grammar-recording for details\",\n    children: {},\n};\n/**\n * This trait handles the creation of the GAST structure for Chevrotain Grammars\n */\nexport class GastRecorder {\n    initGastRecorder(config) {\n        this.recordingProdStack = [];\n        this.RECORDING_PHASE = false;\n    }\n    enableRecording() {\n        this.RECORDING_PHASE = true;\n        this.TRACE_INIT(\"Enable Recording\", () => {\n            /**\n             * Warning Dark Voodoo Magic upcoming!\n             * We are \"replacing\" the public parsing DSL methods API\n             * With **new** alternative implementations on the Parser **instance**\n             *\n             * So far this is the only way I've found to avoid performance regressions during parsing time.\n             * - Approx 30% performance regression was measured on Chrome 75 Canary when attempting to replace the \"internal\"\n             *   implementations directly instead.\n             */\n            for (let i = 0; i < 10; i++) {\n                const idx = i > 0 ? i : \"\";\n                this[`CONSUME${idx}`] = function (arg1, arg2) {\n                    return this.consumeInternalRecord(arg1, i, arg2);\n                };\n                this[`SUBRULE${idx}`] = function (arg1, arg2) {\n                    return this.subruleInternalRecord(arg1, i, arg2);\n                };\n                this[`OPTION${idx}`] = function (arg1) {\n                    return this.optionInternalRecord(arg1, i);\n                };\n                this[`OR${idx}`] = function (arg1) {\n                    return this.orInternalRecord(arg1, i);\n                };\n                this[`MANY${idx}`] = function (arg1) {\n                    this.manyInternalRecord(i, arg1);\n                };\n                this[`MANY_SEP${idx}`] = function (arg1) {\n                    this.manySepFirstInternalRecord(i, arg1);\n                };\n                this[`AT_LEAST_ONE${idx}`] = function (arg1) {\n                    this.atLeastOneInternalRecord(i, arg1);\n                };\n                this[`AT_LEAST_ONE_SEP${idx}`] = function (arg1) {\n                    this.atLeastOneSepFirstInternalRecord(i, arg1);\n                };\n            }\n            // DSL methods with the idx(suffix) as an argument\n            this[`consume`] = function (idx, arg1, arg2) {\n                return this.consumeInternalRecord(arg1, idx, arg2);\n            };\n            this[`subrule`] = function (idx, arg1, arg2) {\n                return this.subruleInternalRecord(arg1, idx, arg2);\n            };\n            this[`option`] = function (idx, arg1) {\n                return this.optionInternalRecord(arg1, idx);\n            };\n            this[`or`] = function (idx, arg1) {\n                return this.orInternalRecord(arg1, idx);\n            };\n            this[`many`] = function (idx, arg1) {\n                this.manyInternalRecord(idx, arg1);\n            };\n            this[`atLeastOne`] = function (idx, arg1) {\n                this.atLeastOneInternalRecord(idx, arg1);\n            };\n            this.ACTION = this.ACTION_RECORD;\n            this.BACKTRACK = this.BACKTRACK_RECORD;\n            this.LA = this.LA_RECORD;\n        });\n    }\n    disableRecording() {\n        this.RECORDING_PHASE = false;\n        // By deleting these **instance** properties, any future invocation\n        // will be deferred to the original methods on the **prototype** object\n        // This seems to get rid of any incorrect optimizations that V8 may\n        // do during the recording phase.\n        this.TRACE_INIT(\"Deleting Recording methods\", () => {\n            const that = this;\n            for (let i = 0; i < 10; i++) {\n                const idx = i > 0 ? i : \"\";\n                delete that[`CONSUME${idx}`];\n                delete that[`SUBRULE${idx}`];\n                delete that[`OPTION${idx}`];\n                delete that[`OR${idx}`];\n                delete that[`MANY${idx}`];\n                delete that[`MANY_SEP${idx}`];\n                delete that[`AT_LEAST_ONE${idx}`];\n                delete that[`AT_LEAST_ONE_SEP${idx}`];\n            }\n            delete that[`consume`];\n            delete that[`subrule`];\n            delete that[`option`];\n            delete that[`or`];\n            delete that[`many`];\n            delete that[`atLeastOne`];\n            delete that.ACTION;\n            delete that.BACKTRACK;\n            delete that.LA;\n        });\n    }\n    //   Parser methods are called inside an ACTION?\n    //   Maybe try/catch/finally on ACTIONS while disabling the recorders state changes?\n    // @ts-expect-error -- noop place holder\n    ACTION_RECORD(impl) {\n        // NO-OP during recording\n    }\n    // Executing backtracking logic will break our recording logic assumptions\n    BACKTRACK_RECORD(grammarRule, args) {\n        return () => true;\n    }\n    // LA is part of the official API and may be used for custom lookahead logic\n    // by end users who may forget to wrap it in ACTION or inside a GATE\n    LA_RECORD(howMuch) {\n        // We cannot use the RECORD_PHASE_TOKEN here because someone may depend\n        // On LA return EOF at the end of the input so an infinite loop may occur.\n        return END_OF_FILE;\n    }\n    topLevelRuleRecord(name, def) {\n        try {\n            const newTopLevelRule = new Rule({ definition: [], name: name });\n            newTopLevelRule.name = name;\n            this.recordingProdStack.push(newTopLevelRule);\n            def.call(this);\n            this.recordingProdStack.pop();\n            return newTopLevelRule;\n        }\n        catch (originalError) {\n            if (originalError.KNOWN_RECORDER_ERROR !== true) {\n                try {\n                    originalError.message =\n                        originalError.message +\n                            '\\n\\t This error was thrown during the \"grammar recording phase\" For more info see:\\n\\t' +\n                            \"https://chevrotain.io/docs/guide/internals.html#grammar-recording\";\n                }\n                catch (mutabilityError) {\n                    // We may not be able to modify the original error object\n                    throw originalError;\n                }\n            }\n            throw originalError;\n        }\n    }\n    // Implementation of parsing DSL\n    optionInternalRecord(actionORMethodDef, occurrence) {\n        return recordProd.call(this, Option, actionORMethodDef, occurrence);\n    }\n    atLeastOneInternalRecord(occurrence, actionORMethodDef) {\n        recordProd.call(this, RepetitionMandatory, actionORMethodDef, occurrence);\n    }\n    atLeastOneSepFirstInternalRecord(occurrence, options) {\n        recordProd.call(this, RepetitionMandatoryWithSeparator, options, occurrence, HANDLE_SEPARATOR);\n    }\n    manyInternalRecord(occurrence, actionORMethodDef) {\n        recordProd.call(this, Repetition, actionORMethodDef, occurrence);\n    }\n    manySepFirstInternalRecord(occurrence, options) {\n        recordProd.call(this, RepetitionWithSeparator, options, occurrence, HANDLE_SEPARATOR);\n    }\n    orInternalRecord(altsOrOpts, occurrence) {\n        return recordOrProd.call(this, altsOrOpts, occurrence);\n    }\n    subruleInternalRecord(ruleToCall, occurrence, options) {\n        assertMethodIdxIsValid(occurrence);\n        if (!ruleToCall || has(ruleToCall, \"ruleName\") === false) {\n            const error = new Error(`<SUBRULE${getIdxSuffix(occurrence)}> argument is invalid` +\n                ` expecting a Parser method reference but got: <${JSON.stringify(ruleToCall)}>` +\n                `\\n inside top level rule: <${this.recordingProdStack[0].name}>`);\n            error.KNOWN_RECORDER_ERROR = true;\n            throw error;\n        }\n        const prevProd = peek(this.recordingProdStack);\n        const ruleName = ruleToCall.ruleName;\n        const newNoneTerminal = new NonTerminal({\n            idx: occurrence,\n            nonTerminalName: ruleName,\n            label: options === null || options === void 0 ? void 0 : options.LABEL,\n            // The resolving of the `referencedRule` property will be done once all the Rule's GASTs have been created\n            referencedRule: undefined,\n        });\n        prevProd.definition.push(newNoneTerminal);\n        return this.outputCst\n            ? RECORDING_PHASE_CSTNODE\n            : RECORDING_NULL_OBJECT;\n    }\n    consumeInternalRecord(tokType, occurrence, options) {\n        assertMethodIdxIsValid(occurrence);\n        if (!hasShortKeyProperty(tokType)) {\n            const error = new Error(`<CONSUME${getIdxSuffix(occurrence)}> argument is invalid` +\n                ` expecting a TokenType reference but got: <${JSON.stringify(tokType)}>` +\n                `\\n inside top level rule: <${this.recordingProdStack[0].name}>`);\n            error.KNOWN_RECORDER_ERROR = true;\n            throw error;\n        }\n        const prevProd = peek(this.recordingProdStack);\n        const newNoneTerminal = new Terminal({\n            idx: occurrence,\n            terminalType: tokType,\n            label: options === null || options === void 0 ? void 0 : options.LABEL,\n        });\n        prevProd.definition.push(newNoneTerminal);\n        return RECORDING_PHASE_TOKEN;\n    }\n}\nfunction recordProd(prodConstructor, mainProdArg, occurrence, handleSep = false) {\n    assertMethodIdxIsValid(occurrence);\n    const prevProd = peek(this.recordingProdStack);\n    const grammarAction = isFunction(mainProdArg) ? mainProdArg : mainProdArg.DEF;\n    const newProd = new prodConstructor({ definition: [], idx: occurrence });\n    if (handleSep) {\n        newProd.separator = mainProdArg.SEP;\n    }\n    if (has(mainProdArg, \"MAX_LOOKAHEAD\")) {\n        newProd.maxLookahead = mainProdArg.MAX_LOOKAHEAD;\n    }\n    this.recordingProdStack.push(newProd);\n    grammarAction.call(this);\n    prevProd.definition.push(newProd);\n    this.recordingProdStack.pop();\n    return RECORDING_NULL_OBJECT;\n}\nfunction recordOrProd(mainProdArg, occurrence) {\n    assertMethodIdxIsValid(occurrence);\n    const prevProd = peek(this.recordingProdStack);\n    // Only an array of alternatives\n    const hasOptions = isArray(mainProdArg) === false;\n    const alts = hasOptions === false ? mainProdArg : mainProdArg.DEF;\n    const newOrProd = new Alternation({\n        definition: [],\n        idx: occurrence,\n        ignoreAmbiguities: hasOptions && mainProdArg.IGNORE_AMBIGUITIES === true,\n    });\n    if (has(mainProdArg, \"MAX_LOOKAHEAD\")) {\n        newOrProd.maxLookahead = mainProdArg.MAX_LOOKAHEAD;\n    }\n    const hasPredicates = some(alts, (currAlt) => isFunction(currAlt.GATE));\n    newOrProd.hasPredicates = hasPredicates;\n    prevProd.definition.push(newOrProd);\n    forEach(alts, (currAlt) => {\n        const currAltFlat = new Alternative({ definition: [] });\n        newOrProd.definition.push(currAltFlat);\n        if (has(currAlt, \"IGNORE_AMBIGUITIES\")) {\n            currAltFlat.ignoreAmbiguities = currAlt.IGNORE_AMBIGUITIES; // assumes end user provides the correct config value/type\n        }\n        // **implicit** ignoreAmbiguities due to usage of gate\n        else if (has(currAlt, \"GATE\")) {\n            currAltFlat.ignoreAmbiguities = true;\n        }\n        this.recordingProdStack.push(currAltFlat);\n        currAlt.ALT.call(this);\n        this.recordingProdStack.pop();\n    });\n    return RECORDING_NULL_OBJECT;\n}\nfunction getIdxSuffix(idx) {\n    return idx === 0 ? \"\" : `${idx}`;\n}\nfunction assertMethodIdxIsValid(idx) {\n    if (idx < 0 || idx > MAX_METHOD_IDX) {\n        const error = new Error(\n        // The stack trace will contain all the needed details\n        `Invalid DSL Method idx value: <${idx}>\\n\\t` +\n            `Idx value must be a none negative value smaller than ${MAX_METHOD_IDX + 1}`);\n        error.KNOWN_RECORDER_ERROR = true;\n        throw error;\n    }\n}\n//# sourceMappingURL=gast_recorder.js.map","import { has } from \"lodash-es\";\nimport { timer } from \"@chevrotain/utils\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n/**\n * Trait responsible for runtime parsing errors.\n */\nexport class PerformanceTracer {\n    initPerformanceTracer(config) {\n        if (has(config, \"traceInitPerf\")) {\n            const userTraceInitPerf = config.traceInitPerf;\n            const traceIsNumber = typeof userTraceInitPerf === \"number\";\n            this.traceInitMaxIdent = traceIsNumber\n                ? userTraceInitPerf\n                : Infinity;\n            this.traceInitPerf = traceIsNumber\n                ? userTraceInitPerf > 0\n                : userTraceInitPerf; // assumes end user provides the correct config value/type\n        }\n        else {\n            this.traceInitMaxIdent = 0;\n            this.traceInitPerf = DEFAULT_PARSER_CONFIG.traceInitPerf;\n        }\n        this.traceInitIndent = -1;\n    }\n    TRACE_INIT(phaseDesc, phaseImpl) {\n        // No need to optimize this using NOOP pattern because\n        // It is not called in a hot spot...\n        if (this.traceInitPerf === true) {\n            this.traceInitIndent++;\n            const indent = new Array(this.traceInitIndent + 1).join(\"\\t\");\n            if (this.traceInitIndent < this.traceInitMaxIdent) {\n                console.log(`${indent}--> <${phaseDesc}>`);\n            }\n            const { time, value } = timer(phaseImpl);\n            /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n            const traceMethod = time > 10 ? console.warn : console.log;\n            if (this.traceInitIndent < this.traceInitMaxIdent) {\n                traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n            }\n            this.traceInitIndent--;\n            return value;\n        }\n        else {\n            return phaseImpl();\n        }\n    }\n}\n//# sourceMappingURL=perf_tracer.js.map","export function applyMixins(derivedCtor, baseCtors) {\n    baseCtors.forEach((baseCtor) => {\n        const baseProto = baseCtor.prototype;\n        Object.getOwnPropertyNames(baseProto).forEach((propName) => {\n            if (propName === \"constructor\") {\n                return;\n            }\n            const basePropDescriptor = Object.getOwnPropertyDescriptor(baseProto, propName);\n            // Handle Accessors\n            if (basePropDescriptor &&\n                (basePropDescriptor.get || basePropDescriptor.set)) {\n                Object.defineProperty(derivedCtor.prototype, propName, basePropDescriptor);\n            }\n            else {\n                derivedCtor.prototype[propName] = baseCtor.prototype[propName];\n            }\n        });\n    });\n}\n//# sourceMappingURL=apply_mixins.js.map","import { clone, forEach, has, isEmpty, map, values } from \"lodash-es\";\nimport { toFastProperties } from \"@chevrotain/utils\";\nimport { computeAllProdsFollows } from \"../grammar/follow.js\";\nimport { createTokenInstance, EOF } from \"../../scan/tokens_public.js\";\nimport { defaultGrammarValidatorErrorProvider, defaultParserErrorProvider, } from \"../errors_public.js\";\nimport { resolveGrammar, validateGrammar, } from \"../grammar/gast/gast_resolver_public.js\";\nimport { Recoverable } from \"./traits/recoverable.js\";\nimport { LooksAhead } from \"./traits/looksahead.js\";\nimport { TreeBuilder } from \"./traits/tree_builder.js\";\nimport { LexerAdapter } from \"./traits/lexer_adapter.js\";\nimport { RecognizerApi } from \"./traits/recognizer_api.js\";\nimport { RecognizerEngine } from \"./traits/recognizer_engine.js\";\nimport { ErrorHandler } from \"./traits/error_handler.js\";\nimport { ContentAssist } from \"./traits/context_assist.js\";\nimport { GastRecorder } from \"./traits/gast_recorder.js\";\nimport { PerformanceTracer } from \"./traits/perf_tracer.js\";\nimport { applyMixins } from \"./utils/apply_mixins.js\";\nimport { validateLookahead } from \"../grammar/checks.js\";\nexport const END_OF_FILE = createTokenInstance(EOF, \"\", NaN, NaN, NaN, NaN, NaN, NaN);\nObject.freeze(END_OF_FILE);\nexport const DEFAULT_PARSER_CONFIG = Object.freeze({\n    recoveryEnabled: false,\n    maxLookahead: 3,\n    dynamicTokensEnabled: false,\n    outputCst: true,\n    errorMessageProvider: defaultParserErrorProvider,\n    nodeLocationTracking: \"none\",\n    traceInitPerf: false,\n    skipValidations: false,\n});\nexport const DEFAULT_RULE_CONFIG = Object.freeze({\n    recoveryValueFunc: () => undefined,\n    resyncEnabled: true,\n});\nexport var ParserDefinitionErrorType;\n(function (ParserDefinitionErrorType) {\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"INVALID_RULE_NAME\"] = 0] = \"INVALID_RULE_NAME\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"DUPLICATE_RULE_NAME\"] = 1] = \"DUPLICATE_RULE_NAME\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"INVALID_RULE_OVERRIDE\"] = 2] = \"INVALID_RULE_OVERRIDE\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"DUPLICATE_PRODUCTIONS\"] = 3] = \"DUPLICATE_PRODUCTIONS\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"UNRESOLVED_SUBRULE_REF\"] = 4] = \"UNRESOLVED_SUBRULE_REF\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"LEFT_RECURSION\"] = 5] = \"LEFT_RECURSION\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"NONE_LAST_EMPTY_ALT\"] = 6] = \"NONE_LAST_EMPTY_ALT\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"AMBIGUOUS_ALTS\"] = 7] = \"AMBIGUOUS_ALTS\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"CONFLICT_TOKENS_RULES_NAMESPACE\"] = 8] = \"CONFLICT_TOKENS_RULES_NAMESPACE\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"INVALID_TOKEN_NAME\"] = 9] = \"INVALID_TOKEN_NAME\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"NO_NON_EMPTY_LOOKAHEAD\"] = 10] = \"NO_NON_EMPTY_LOOKAHEAD\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"AMBIGUOUS_PREFIX_ALTS\"] = 11] = \"AMBIGUOUS_PREFIX_ALTS\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"TOO_MANY_ALTS\"] = 12] = \"TOO_MANY_ALTS\";\n    ParserDefinitionErrorType[ParserDefinitionErrorType[\"CUSTOM_LOOKAHEAD_VALIDATION\"] = 13] = \"CUSTOM_LOOKAHEAD_VALIDATION\";\n})(ParserDefinitionErrorType || (ParserDefinitionErrorType = {}));\nexport function EMPTY_ALT(value = undefined) {\n    return function () {\n        return value;\n    };\n}\nexport class Parser {\n    /**\n     *  @deprecated use the **instance** method with the same name instead\n     */\n    static performSelfAnalysis(parserInstance) {\n        throw Error(\"The **static** `performSelfAnalysis` method has been deprecated.\" +\n            \"\\t\\nUse the **instance** method with the same name instead.\");\n    }\n    performSelfAnalysis() {\n        this.TRACE_INIT(\"performSelfAnalysis\", () => {\n            let defErrorsMsgs;\n            this.selfAnalysisDone = true;\n            const className = this.className;\n            this.TRACE_INIT(\"toFastProps\", () => {\n                // Without this voodoo magic the parser would be x3-x4 slower\n                // It seems it is better to invoke `toFastProperties` **before**\n                // Any manipulations of the `this` object done during the recording phase.\n                toFastProperties(this);\n            });\n            this.TRACE_INIT(\"Grammar Recording\", () => {\n                try {\n                    this.enableRecording();\n                    // Building the GAST\n                    forEach(this.definedRulesNames, (currRuleName) => {\n                        const wrappedRule = this[currRuleName];\n                        const originalGrammarAction = wrappedRule[\"originalGrammarAction\"];\n                        let recordedRuleGast;\n                        this.TRACE_INIT(`${currRuleName} Rule`, () => {\n                            recordedRuleGast = this.topLevelRuleRecord(currRuleName, originalGrammarAction);\n                        });\n                        this.gastProductionsCache[currRuleName] = recordedRuleGast;\n                    });\n                }\n                finally {\n                    this.disableRecording();\n                }\n            });\n            let resolverErrors = [];\n            this.TRACE_INIT(\"Grammar Resolving\", () => {\n                resolverErrors = resolveGrammar({\n                    rules: values(this.gastProductionsCache),\n                });\n                this.definitionErrors = this.definitionErrors.concat(resolverErrors);\n            });\n            this.TRACE_INIT(\"Grammar Validations\", () => {\n                // only perform additional grammar validations IFF no resolving errors have occurred.\n                // as unresolved grammar may lead to unhandled runtime exceptions in the follow up validations.\n                if (isEmpty(resolverErrors) && this.skipValidations === false) {\n                    const validationErrors = validateGrammar({\n                        rules: values(this.gastProductionsCache),\n                        tokenTypes: values(this.tokensMap),\n                        errMsgProvider: defaultGrammarValidatorErrorProvider,\n                        grammarName: className,\n                    });\n                    const lookaheadValidationErrors = validateLookahead({\n                        lookaheadStrategy: this.lookaheadStrategy,\n                        rules: values(this.gastProductionsCache),\n                        tokenTypes: values(this.tokensMap),\n                        grammarName: className,\n                    });\n                    this.definitionErrors = this.definitionErrors.concat(validationErrors, lookaheadValidationErrors);\n                }\n            });\n            // this analysis may fail if the grammar is not perfectly valid\n            if (isEmpty(this.definitionErrors)) {\n                // The results of these computations are not needed unless error recovery is enabled.\n                if (this.recoveryEnabled) {\n                    this.TRACE_INIT(\"computeAllProdsFollows\", () => {\n                        const allFollows = computeAllProdsFollows(values(this.gastProductionsCache));\n                        this.resyncFollows = allFollows;\n                    });\n                }\n                this.TRACE_INIT(\"ComputeLookaheadFunctions\", () => {\n                    var _a, _b;\n                    (_b = (_a = this.lookaheadStrategy).initialize) === null || _b === void 0 ? void 0 : _b.call(_a, {\n                        rules: values(this.gastProductionsCache),\n                    });\n                    this.preComputeLookaheadFunctions(values(this.gastProductionsCache));\n                });\n            }\n            if (!Parser.DEFER_DEFINITION_ERRORS_HANDLING &&\n                !isEmpty(this.definitionErrors)) {\n                defErrorsMsgs = map(this.definitionErrors, (defError) => defError.message);\n                throw new Error(`Parser Definition Errors detected:\\n ${defErrorsMsgs.join(\"\\n-------------------------------\\n\")}`);\n            }\n        });\n    }\n    constructor(tokenVocabulary, config) {\n        this.definitionErrors = [];\n        this.selfAnalysisDone = false;\n        const that = this;\n        that.initErrorHandler(config);\n        that.initLexerAdapter();\n        that.initLooksAhead(config);\n        that.initRecognizerEngine(tokenVocabulary, config);\n        that.initRecoverable(config);\n        that.initTreeBuilder(config);\n        that.initContentAssist();\n        that.initGastRecorder(config);\n        that.initPerformanceTracer(config);\n        if (has(config, \"ignoredIssues\")) {\n            throw new Error(\"The <ignoredIssues> IParserConfig property has been deprecated.\\n\\t\" +\n                \"Please use the <IGNORE_AMBIGUITIES> flag on the relevant DSL method instead.\\n\\t\" +\n                \"See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#IGNORING_AMBIGUITIES\\n\\t\" +\n                \"For further details.\");\n        }\n        this.skipValidations = has(config, \"skipValidations\")\n            ? config.skipValidations // casting assumes the end user passing the correct type\n            : DEFAULT_PARSER_CONFIG.skipValidations;\n    }\n}\n// Set this flag to true if you don't want the Parser to throw error when problems in it's definition are detected.\n// (normally during the parser's constructor).\n// This is a design time flag, it will not affect the runtime error handling of the parser, just design time errors,\n// for example: duplicate rule names, referencing an unresolved subrule, etc...\n// This flag should not be enabled during normal usage, it is used in special situations, for example when\n// needing to display the parser definition errors in some GUI(online playground).\nParser.DEFER_DEFINITION_ERRORS_HANDLING = false;\napplyMixins(Parser, [\n    Recoverable,\n    LooksAhead,\n    TreeBuilder,\n    LexerAdapter,\n    RecognizerEngine,\n    RecognizerApi,\n    ErrorHandler,\n    ContentAssist,\n    GastRecorder,\n    PerformanceTracer,\n]);\nexport class CstParser extends Parser {\n    constructor(tokenVocabulary, config = DEFAULT_PARSER_CONFIG) {\n        const configClone = clone(config);\n        configClone.outputCst = true;\n        super(tokenVocabulary, configClone);\n    }\n}\nexport class EmbeddedActionsParser extends Parser {\n    constructor(tokenVocabulary, config = DEFAULT_PARSER_CONFIG) {\n        const configClone = clone(config);\n        configClone.outputCst = false;\n        super(tokenVocabulary, configClone);\n    }\n}\n//# sourceMappingURL=parser.js.map","import { buildModel } from \"./model.js\";\nimport { genDts } from \"./generate.js\";\nconst defaultOptions = {\n    includeVisitorInterface: true,\n    visitorInterfaceName: \"ICstNodeVisitor\",\n};\nexport function generateCstDts(productions, options) {\n    const effectiveOptions = Object.assign(Object.assign({}, defaultOptions), options);\n    const model = buildModel(productions);\n    return genDts(model, effectiveOptions);\n}\n//# sourceMappingURL=api.js.map","/* istanbul ignore file - tricky to import some things from this module during testing */\n// semantic version\nexport { VERSION } from \"./version.js\";\nexport { CstParser, EmbeddedActionsParser, ParserDefinitionErrorType, EMPTY_ALT, } from \"./parse/parser/parser.js\";\nexport { Lexer, LexerDefinitionErrorType } from \"./scan/lexer_public.js\";\n// Tokens utilities\nexport { createToken, createTokenInstance, EOF, tokenLabel, tokenMatcher, tokenName, } from \"./scan/tokens_public.js\";\n// Lookahead\nexport { getLookaheadPaths } from \"./parse/grammar/lookahead.js\";\nexport { LLkLookaheadStrategy } from \"./parse/grammar/llk_lookahead.js\";\n// Other Utilities\nexport { defaultParserErrorProvider } from \"./parse/errors_public.js\";\nexport { EarlyExitException, isRecognitionException, MismatchedTokenException, NotAllInputParsedException, NoViableAltException, } from \"./parse/exceptions_public.js\";\nexport { defaultLexerErrorProvider } from \"./scan/lexer_errors_public.js\";\n// grammar reflection API\nexport { Alternation, Alternative, NonTerminal, Option, Repetition, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, Rule, Terminal, } from \"@chevrotain/gast\";\n// GAST Utilities\nexport { serializeGrammar, serializeProduction, GAstVisitor, } from \"@chevrotain/gast\";\nexport { generateCstDts } from \"@chevrotain/cst-dts-gen\";\n/* istanbul ignore next */\nexport function clearCache() {\n    console.warn(\"The clearCache function was 'soft' removed from the Chevrotain API.\" +\n        \"\\n\\t It performs no action other than printing this message.\" +\n        \"\\n\\t Please avoid using it as it will be completely removed in the future\");\n}\nexport { createSyntaxDiagramsCode } from \"./diagrams/render_public.js\";\nexport class Parser {\n    constructor() {\n        throw new Error(\"The Parser class has been deprecated, use CstParser or EmbeddedActionsParser instead.\\t\\n\" +\n            \"See: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_7-0-0\");\n    }\n}\n//# sourceMappingURL=api.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { DefaultNameRegexp } from '../utils/cst-utils.js';\nimport { isCommentTerminal, terminalRegex } from '../utils/grammar-utils.js';\nimport { isMultilineComment } from '../utils/regexp-utils.js';\nimport { isTerminalRule } from './generated/ast.js';\n/**\n * Create the default grammar configuration (used by `createDefaultModule`). This can be overridden in a\n * language-specific module.\n */\nexport function createGrammarConfig(services) {\n    const rules = [];\n    const grammar = services.Grammar;\n    for (const rule of grammar.rules) {\n        if (isTerminalRule(rule) && isCommentTerminal(rule) && isMultilineComment(terminalRegex(rule))) {\n            rules.push(rule.name);\n        }\n    }\n    return {\n        multilineCommentRules: rules,\n        nameRegexp: DefaultNameRegexp\n    };\n}\n//# sourceMappingURL=grammar-config.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport map from \"lodash-es/map.js\";\nimport filter from \"lodash-es/filter.js\";\nimport { Alternation, NonTerminal, Option, RepetitionMandatory, Repetition, Terminal, RepetitionWithSeparator, RepetitionMandatoryWithSeparator } from \"chevrotain\";\nexport function buildATNKey(rule, type, occurrence) {\n    return `${rule.name}_${type}_${occurrence}`;\n}\nexport const ATN_INVALID_TYPE = 0;\nexport const ATN_BASIC = 1;\nexport const ATN_RULE_START = 2;\nexport const ATN_PLUS_BLOCK_START = 4;\nexport const ATN_STAR_BLOCK_START = 5;\n// Currently unused as the ATN is not used for lexing\nexport const ATN_TOKEN_START = 6;\nexport const ATN_RULE_STOP = 7;\nexport const ATN_BLOCK_END = 8;\nexport const ATN_STAR_LOOP_BACK = 9;\nexport const ATN_STAR_LOOP_ENTRY = 10;\nexport const ATN_PLUS_LOOP_BACK = 11;\nexport const ATN_LOOP_END = 12;\nexport class AbstractTransition {\n    constructor(target) {\n        this.target = target;\n    }\n    isEpsilon() {\n        return false;\n    }\n}\nexport class AtomTransition extends AbstractTransition {\n    constructor(target, tokenType) {\n        super(target);\n        this.tokenType = tokenType;\n    }\n}\nexport class EpsilonTransition extends AbstractTransition {\n    constructor(target) {\n        super(target);\n    }\n    isEpsilon() {\n        return true;\n    }\n}\nexport class RuleTransition extends AbstractTransition {\n    constructor(ruleStart, rule, followState) {\n        super(ruleStart);\n        this.rule = rule;\n        this.followState = followState;\n    }\n    isEpsilon() {\n        return true;\n    }\n}\nexport function createATN(rules) {\n    const atn = {\n        decisionMap: {},\n        decisionStates: [],\n        ruleToStartState: new Map(),\n        ruleToStopState: new Map(),\n        states: []\n    };\n    createRuleStartAndStopATNStates(atn, rules);\n    const ruleLength = rules.length;\n    for (let i = 0; i < ruleLength; i++) {\n        const rule = rules[i];\n        const ruleBlock = block(atn, rule, rule);\n        if (ruleBlock === undefined) {\n            continue;\n        }\n        buildRuleHandle(atn, rule, ruleBlock);\n    }\n    return atn;\n}\nfunction createRuleStartAndStopATNStates(atn, rules) {\n    const ruleLength = rules.length;\n    for (let i = 0; i < ruleLength; i++) {\n        const rule = rules[i];\n        const start = newState(atn, rule, undefined, {\n            type: ATN_RULE_START\n        });\n        const stop = newState(atn, rule, undefined, {\n            type: ATN_RULE_STOP\n        });\n        start.stop = stop;\n        atn.ruleToStartState.set(rule, start);\n        atn.ruleToStopState.set(rule, stop);\n    }\n}\nfunction atom(atn, rule, production) {\n    if (production instanceof Terminal) {\n        return tokenRef(atn, rule, production.terminalType, production);\n    }\n    else if (production instanceof NonTerminal) {\n        return ruleRef(atn, rule, production);\n    }\n    else if (production instanceof Alternation) {\n        return alternation(atn, rule, production);\n    }\n    else if (production instanceof Option) {\n        return option(atn, rule, production);\n    }\n    else if (production instanceof Repetition) {\n        return repetition(atn, rule, production);\n    }\n    else if (production instanceof RepetitionWithSeparator) {\n        return repetitionSep(atn, rule, production);\n    }\n    else if (production instanceof RepetitionMandatory) {\n        return repetitionMandatory(atn, rule, production);\n    }\n    else if (production instanceof RepetitionMandatoryWithSeparator) {\n        return repetitionMandatorySep(atn, rule, production);\n    }\n    else {\n        return block(atn, rule, production);\n    }\n}\nfunction repetition(atn, rule, repetition) {\n    const starState = newState(atn, rule, repetition, {\n        type: ATN_STAR_BLOCK_START\n    });\n    defineDecisionState(atn, starState);\n    const handle = makeAlts(atn, rule, starState, repetition, block(atn, rule, repetition));\n    return star(atn, rule, repetition, handle);\n}\nfunction repetitionSep(atn, rule, repetition) {\n    const starState = newState(atn, rule, repetition, {\n        type: ATN_STAR_BLOCK_START\n    });\n    defineDecisionState(atn, starState);\n    const handle = makeAlts(atn, rule, starState, repetition, block(atn, rule, repetition));\n    const sep = tokenRef(atn, rule, repetition.separator, repetition);\n    return star(atn, rule, repetition, handle, sep);\n}\nfunction repetitionMandatory(atn, rule, repetition) {\n    const plusState = newState(atn, rule, repetition, {\n        type: ATN_PLUS_BLOCK_START\n    });\n    defineDecisionState(atn, plusState);\n    const handle = makeAlts(atn, rule, plusState, repetition, block(atn, rule, repetition));\n    return plus(atn, rule, repetition, handle);\n}\nfunction repetitionMandatorySep(atn, rule, repetition) {\n    const plusState = newState(atn, rule, repetition, {\n        type: ATN_PLUS_BLOCK_START\n    });\n    defineDecisionState(atn, plusState);\n    const handle = makeAlts(atn, rule, plusState, repetition, block(atn, rule, repetition));\n    const sep = tokenRef(atn, rule, repetition.separator, repetition);\n    return plus(atn, rule, repetition, handle, sep);\n}\nfunction alternation(atn, rule, alternation) {\n    const start = newState(atn, rule, alternation, {\n        type: ATN_BASIC\n    });\n    defineDecisionState(atn, start);\n    const alts = map(alternation.definition, (e) => atom(atn, rule, e));\n    const handle = makeAlts(atn, rule, start, alternation, ...alts);\n    return handle;\n}\nfunction option(atn, rule, option) {\n    const start = newState(atn, rule, option, {\n        type: ATN_BASIC\n    });\n    defineDecisionState(atn, start);\n    const handle = makeAlts(atn, rule, start, option, block(atn, rule, option));\n    return optional(atn, rule, option, handle);\n}\nfunction block(atn, rule, block) {\n    const handles = filter(map(block.definition, (e) => atom(atn, rule, e)), (e) => e !== undefined);\n    if (handles.length === 1) {\n        return handles[0];\n    }\n    else if (handles.length === 0) {\n        return undefined;\n    }\n    else {\n        return makeBlock(atn, handles);\n    }\n}\nfunction plus(atn, rule, plus, handle, sep) {\n    const blkStart = handle.left;\n    const blkEnd = handle.right;\n    const loop = newState(atn, rule, plus, {\n        type: ATN_PLUS_LOOP_BACK\n    });\n    defineDecisionState(atn, loop);\n    const end = newState(atn, rule, plus, {\n        type: ATN_LOOP_END\n    });\n    blkStart.loopback = loop;\n    end.loopback = loop;\n    atn.decisionMap[buildATNKey(rule, sep ? 'RepetitionMandatoryWithSeparator' : 'RepetitionMandatory', plus.idx)] = loop;\n    epsilon(blkEnd, loop); // block can see loop back\n    // Depending on whether we have a separator we put the exit transition at index 1 or 0\n    // This influences the chosen option in the lookahead DFA\n    if (sep === undefined) {\n        epsilon(loop, blkStart); // loop back to start\n        epsilon(loop, end); // exit\n    }\n    else {\n        epsilon(loop, end); // exit\n        // loop back to start with separator\n        epsilon(loop, sep.left);\n        epsilon(sep.right, blkStart);\n    }\n    return {\n        left: blkStart,\n        right: end\n    };\n}\nfunction star(atn, rule, star, handle, sep) {\n    const start = handle.left;\n    const end = handle.right;\n    const entry = newState(atn, rule, star, {\n        type: ATN_STAR_LOOP_ENTRY\n    });\n    defineDecisionState(atn, entry);\n    const loopEnd = newState(atn, rule, star, {\n        type: ATN_LOOP_END\n    });\n    const loop = newState(atn, rule, star, {\n        type: ATN_STAR_LOOP_BACK\n    });\n    entry.loopback = loop;\n    loopEnd.loopback = loop;\n    epsilon(entry, start); // loop enter edge (alt 2)\n    epsilon(entry, loopEnd); // bypass loop edge (alt 1)\n    epsilon(end, loop); // block end hits loop back\n    if (sep !== undefined) {\n        epsilon(loop, loopEnd); // end loop\n        // loop back to start of handle using separator\n        epsilon(loop, sep.left);\n        epsilon(sep.right, start);\n    }\n    else {\n        epsilon(loop, entry); // loop back to entry/exit decision\n    }\n    atn.decisionMap[buildATNKey(rule, sep ? 'RepetitionWithSeparator' : 'Repetition', star.idx)] = entry;\n    return {\n        left: entry,\n        right: loopEnd\n    };\n}\nfunction optional(atn, rule, optional, handle) {\n    const start = handle.left;\n    const end = handle.right;\n    epsilon(start, end);\n    atn.decisionMap[buildATNKey(rule, 'Option', optional.idx)] = start;\n    return handle;\n}\nfunction defineDecisionState(atn, state) {\n    atn.decisionStates.push(state);\n    state.decision = atn.decisionStates.length - 1;\n    return state.decision;\n}\nfunction makeAlts(atn, rule, start, production, ...alts) {\n    const end = newState(atn, rule, production, {\n        type: ATN_BLOCK_END,\n        start\n    });\n    start.end = end;\n    for (const alt of alts) {\n        if (alt !== undefined) {\n            // hook alts up to decision block\n            epsilon(start, alt.left);\n            epsilon(alt.right, end);\n        }\n        else {\n            epsilon(start, end);\n        }\n    }\n    const handle = {\n        left: start,\n        right: end\n    };\n    atn.decisionMap[buildATNKey(rule, getProdType(production), production.idx)] = start;\n    return handle;\n}\nfunction getProdType(production) {\n    if (production instanceof Alternation) {\n        return 'Alternation';\n    }\n    else if (production instanceof Option) {\n        return 'Option';\n    }\n    else if (production instanceof Repetition) {\n        return 'Repetition';\n    }\n    else if (production instanceof RepetitionWithSeparator) {\n        return 'RepetitionWithSeparator';\n    }\n    else if (production instanceof RepetitionMandatory) {\n        return 'RepetitionMandatory';\n    }\n    else if (production instanceof RepetitionMandatoryWithSeparator) {\n        return 'RepetitionMandatoryWithSeparator';\n    }\n    else {\n        throw new Error('Invalid production type encountered');\n    }\n}\nfunction makeBlock(atn, alts) {\n    const altsLength = alts.length;\n    for (let i = 0; i < altsLength - 1; i++) {\n        const handle = alts[i];\n        let transition;\n        if (handle.left.transitions.length === 1) {\n            transition = handle.left.transitions[0];\n        }\n        const isRuleTransition = transition instanceof RuleTransition;\n        const ruleTransition = transition;\n        const next = alts[i + 1].left;\n        if (handle.left.type === ATN_BASIC &&\n            handle.right.type === ATN_BASIC &&\n            transition !== undefined &&\n            ((isRuleTransition && ruleTransition.followState === handle.right) ||\n                transition.target === handle.right)) {\n            // we can avoid epsilon edge to next element\n            if (isRuleTransition) {\n                ruleTransition.followState = next;\n            }\n            else {\n                transition.target = next;\n            }\n            removeState(atn, handle.right); // we skipped over this state\n        }\n        else {\n            // need epsilon if previous block's right end node is complex\n            epsilon(handle.right, next);\n        }\n    }\n    const first = alts[0];\n    const last = alts[altsLength - 1];\n    return {\n        left: first.left,\n        right: last.right\n    };\n}\nfunction tokenRef(atn, rule, tokenType, production) {\n    const left = newState(atn, rule, production, {\n        type: ATN_BASIC\n    });\n    const right = newState(atn, rule, production, {\n        type: ATN_BASIC\n    });\n    addTransition(left, new AtomTransition(right, tokenType));\n    return {\n        left,\n        right\n    };\n}\nfunction ruleRef(atn, currentRule, nonTerminal) {\n    const rule = nonTerminal.referencedRule;\n    const start = atn.ruleToStartState.get(rule);\n    const left = newState(atn, currentRule, nonTerminal, {\n        type: ATN_BASIC\n    });\n    const right = newState(atn, currentRule, nonTerminal, {\n        type: ATN_BASIC\n    });\n    const call = new RuleTransition(start, rule, right);\n    addTransition(left, call);\n    return {\n        left,\n        right\n    };\n}\nfunction buildRuleHandle(atn, rule, block) {\n    const start = atn.ruleToStartState.get(rule);\n    epsilon(start, block.left);\n    const stop = atn.ruleToStopState.get(rule);\n    epsilon(block.right, stop);\n    const handle = {\n        left: start,\n        right: stop\n    };\n    return handle;\n}\nfunction epsilon(a, b) {\n    const transition = new EpsilonTransition(b);\n    addTransition(a, transition);\n}\nfunction newState(atn, rule, production, partial) {\n    const t = Object.assign({ atn,\n        production, epsilonOnlyTransitions: false, rule, transitions: [], nextTokenWithinRule: [], stateNumber: atn.states.length }, partial);\n    atn.states.push(t);\n    return t;\n}\nfunction addTransition(state, transition) {\n    // A single ATN state can only contain epsilon transitions or non-epsilon transitions\n    // Because they are never mixed, only setting the property for the first transition is fine\n    if (state.transitions.length === 0) {\n        state.epsilonOnlyTransitions = transition.isEpsilon();\n    }\n    state.transitions.push(transition);\n}\nfunction removeState(atn, state) {\n    atn.states.splice(atn.states.indexOf(state), 1);\n}\n//# sourceMappingURL=atn.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport map from \"lodash-es/map.js\";\nexport const DFA_ERROR = {};\nexport class ATNConfigSet {\n    constructor() {\n        this.map = {};\n        this.configs = [];\n    }\n    get size() {\n        return this.configs.length;\n    }\n    finalize() {\n        // Empties the map to free up memory\n        this.map = {};\n    }\n    add(config) {\n        const key = getATNConfigKey(config);\n        // Only add configs which don't exist in our map already\n        // While this does not influence the actual algorithm, adding them anyway would massively increase memory consumption\n        if (!(key in this.map)) {\n            this.map[key] = this.configs.length;\n            this.configs.push(config);\n        }\n    }\n    get elements() {\n        return this.configs;\n    }\n    get alts() {\n        return map(this.configs, (e) => e.alt);\n    }\n    get key() {\n        let value = \"\";\n        for (const k in this.map) {\n            value += k + \":\";\n        }\n        return value;\n    }\n}\nexport function getATNConfigKey(config, alt = true) {\n    return `${alt ? `a${config.alt}` : \"\"}s${config.state.stateNumber}:${config.stack.map((e) => e.stateNumber.toString()).join(\"_\")}`;\n}\n//# sourceMappingURL=dfa.js.map","import baseIteratee from './_baseIteratee.js';\nimport baseUniq from './_baseUniq.js';\n\n/**\n * This method is like `_.uniq` except that it accepts `iteratee` which is\n * invoked for each element in `array` to generate the criterion by which\n * uniqueness is computed. The order of result values is determined by the\n * order they occur in the array. The iteratee is invoked with one argument:\n * (value).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {Function} [iteratee=_.identity] The iteratee invoked per element.\n * @returns {Array} Returns the new duplicate free array.\n * @example\n *\n * _.uniqBy([2.1, 1.2, 2.3], Math.floor);\n * // => [2.1, 1.2]\n *\n * // The `_.property` iteratee shorthand.\n * _.uniqBy([{ 'x': 1 }, { 'x': 2 }, { 'x': 1 }], 'x');\n * // => [{ 'x': 1 }, { 'x': 2 }]\n */\nfunction uniqBy(array, iteratee) {\n  return (array && array.length) ? baseUniq(array, baseIteratee(iteratee, 2)) : [];\n}\n\nexport default uniqBy;\n","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { tokenMatcher, tokenLabel, NonTerminal, Alternation, Option, RepetitionMandatory, RepetitionMandatoryWithSeparator, RepetitionWithSeparator, Repetition, Terminal, LLkLookaheadStrategy, getLookaheadPaths } from \"chevrotain\";\nimport { ATN_RULE_STOP, AtomTransition, buildATNKey, createATN, EpsilonTransition, RuleTransition } from \"./atn.js\";\nimport { ATNConfigSet, DFA_ERROR, getATNConfigKey } from \"./dfa.js\";\nimport min from \"lodash-es/min.js\";\nimport flatMap from \"lodash-es/flatMap.js\";\nimport uniqBy from \"lodash-es/uniqBy.js\";\nimport map from \"lodash-es/map.js\";\nimport flatten from \"lodash-es/flatten.js\";\nimport forEach from \"lodash-es/forEach.js\";\nimport isEmpty from \"lodash-es/isEmpty.js\";\nimport reduce from \"lodash-es/reduce.js\";\nfunction createDFACache(startState, decision) {\n    const map = {};\n    return (predicateSet) => {\n        const key = predicateSet.toString();\n        let existing = map[key];\n        if (existing !== undefined) {\n            return existing;\n        }\n        else {\n            existing = {\n                atnStartState: startState,\n                decision,\n                states: {}\n            };\n            map[key] = existing;\n            return existing;\n        }\n    };\n}\nclass PredicateSet {\n    constructor() {\n        this.predicates = [];\n    }\n    is(index) {\n        return index >= this.predicates.length || this.predicates[index];\n    }\n    set(index, value) {\n        this.predicates[index] = value;\n    }\n    toString() {\n        let value = \"\";\n        const size = this.predicates.length;\n        for (let i = 0; i < size; i++) {\n            value += this.predicates[i] === true ? \"1\" : \"0\";\n        }\n        return value;\n    }\n}\nconst EMPTY_PREDICATES = new PredicateSet();\nexport class LLStarLookaheadStrategy extends LLkLookaheadStrategy {\n    constructor(options) {\n        var _a;\n        super();\n        this.logging = (_a = options === null || options === void 0 ? void 0 : options.logging) !== null && _a !== void 0 ? _a : ((message) => console.log(message));\n    }\n    initialize(options) {\n        this.atn = createATN(options.rules);\n        this.dfas = initATNSimulator(this.atn);\n    }\n    validateAmbiguousAlternationAlternatives() {\n        return [];\n    }\n    validateEmptyOrAlternatives() {\n        return [];\n    }\n    buildLookaheadForAlternation(options) {\n        const { prodOccurrence, rule, hasPredicates, dynamicTokensEnabled } = options;\n        const dfas = this.dfas;\n        const logging = this.logging;\n        const key = buildATNKey(rule, 'Alternation', prodOccurrence);\n        const decisionState = this.atn.decisionMap[key];\n        const decisionIndex = decisionState.decision;\n        const partialAlts = map(getLookaheadPaths({\n            maxLookahead: 1,\n            occurrence: prodOccurrence,\n            prodType: \"Alternation\",\n            rule: rule\n        }), (currAlt) => map(currAlt, (path) => path[0]));\n        if (isLL1Sequence(partialAlts, false) && !dynamicTokensEnabled) {\n            const choiceToAlt = reduce(partialAlts, (result, currAlt, idx) => {\n                forEach(currAlt, (currTokType) => {\n                    if (currTokType) {\n                        result[currTokType.tokenTypeIdx] = idx;\n                        forEach(currTokType.categoryMatches, (currExtendingType) => {\n                            result[currExtendingType] = idx;\n                        });\n                    }\n                });\n                return result;\n            }, {});\n            if (hasPredicates) {\n                return function (orAlts) {\n                    var _a;\n                    const nextToken = this.LA(1);\n                    const prediction = choiceToAlt[nextToken.tokenTypeIdx];\n                    if (orAlts !== undefined && prediction !== undefined) {\n                        const gate = (_a = orAlts[prediction]) === null || _a === void 0 ? void 0 : _a.GATE;\n                        if (gate !== undefined && gate.call(this) === false) {\n                            return undefined;\n                        }\n                    }\n                    return prediction;\n                };\n            }\n            else {\n                return function () {\n                    const nextToken = this.LA(1);\n                    return choiceToAlt[nextToken.tokenTypeIdx];\n                };\n            }\n        }\n        else if (hasPredicates) {\n            return function (orAlts) {\n                const predicates = new PredicateSet();\n                const length = orAlts === undefined ? 0 : orAlts.length;\n                for (let i = 0; i < length; i++) {\n                    const gate = orAlts === null || orAlts === void 0 ? void 0 : orAlts[i].GATE;\n                    predicates.set(i, gate === undefined || gate.call(this));\n                }\n                const result = adaptivePredict.call(this, dfas, decisionIndex, predicates, logging);\n                return typeof result === 'number' ? result : undefined;\n            };\n        }\n        else {\n            return function () {\n                const result = adaptivePredict.call(this, dfas, decisionIndex, EMPTY_PREDICATES, logging);\n                return typeof result === 'number' ? result : undefined;\n            };\n        }\n    }\n    buildLookaheadForOptional(options) {\n        const { prodOccurrence, rule, prodType, dynamicTokensEnabled } = options;\n        const dfas = this.dfas;\n        const logging = this.logging;\n        const key = buildATNKey(rule, prodType, prodOccurrence);\n        const decisionState = this.atn.decisionMap[key];\n        const decisionIndex = decisionState.decision;\n        const alts = map(getLookaheadPaths({\n            maxLookahead: 1,\n            occurrence: prodOccurrence,\n            prodType,\n            rule\n        }), (e) => {\n            return map(e, (g) => g[0]);\n        });\n        if (isLL1Sequence(alts) && alts[0][0] && !dynamicTokensEnabled) {\n            const alt = alts[0];\n            const singleTokensTypes = flatten(alt);\n            if (singleTokensTypes.length === 1 &&\n                isEmpty(singleTokensTypes[0].categoryMatches)) {\n                const expectedTokenType = singleTokensTypes[0];\n                const expectedTokenUniqueKey = expectedTokenType.tokenTypeIdx;\n                return function () {\n                    return this.LA(1).tokenTypeIdx === expectedTokenUniqueKey;\n                };\n            }\n            else {\n                const choiceToAlt = reduce(singleTokensTypes, (result, currTokType) => {\n                    if (currTokType !== undefined) {\n                        result[currTokType.tokenTypeIdx] = true;\n                        forEach(currTokType.categoryMatches, (currExtendingType) => {\n                            result[currExtendingType] = true;\n                        });\n                    }\n                    return result;\n                }, {});\n                return function () {\n                    const nextToken = this.LA(1);\n                    return choiceToAlt[nextToken.tokenTypeIdx] === true;\n                };\n            }\n        }\n        return function () {\n            const result = adaptivePredict.call(this, dfas, decisionIndex, EMPTY_PREDICATES, logging);\n            return typeof result === \"object\" ? false : result === 0;\n        };\n    }\n}\nfunction isLL1Sequence(sequences, allowEmpty = true) {\n    const fullSet = new Set();\n    for (const alt of sequences) {\n        const altSet = new Set();\n        for (const tokType of alt) {\n            if (tokType === undefined) {\n                if (allowEmpty) {\n                    // Epsilon production encountered\n                    break;\n                }\n                else {\n                    return false;\n                }\n            }\n            const indices = [tokType.tokenTypeIdx].concat(tokType.categoryMatches);\n            for (const index of indices) {\n                if (fullSet.has(index)) {\n                    if (!altSet.has(index)) {\n                        return false;\n                    }\n                }\n                else {\n                    fullSet.add(index);\n                    altSet.add(index);\n                }\n            }\n        }\n    }\n    return true;\n}\nfunction initATNSimulator(atn) {\n    const decisionLength = atn.decisionStates.length;\n    const decisionToDFA = Array(decisionLength);\n    for (let i = 0; i < decisionLength; i++) {\n        decisionToDFA[i] = createDFACache(atn.decisionStates[i], i);\n    }\n    return decisionToDFA;\n}\nfunction adaptivePredict(dfaCaches, decision, predicateSet, logging) {\n    const dfa = dfaCaches[decision](predicateSet);\n    let start = dfa.start;\n    if (start === undefined) {\n        const closure = computeStartState(dfa.atnStartState);\n        start = addDFAState(dfa, newDFAState(closure));\n        dfa.start = start;\n    }\n    const alt = performLookahead.apply(this, [dfa, start, predicateSet, logging]);\n    return alt;\n}\nfunction performLookahead(dfa, s0, predicateSet, logging) {\n    let previousD = s0;\n    let i = 1;\n    const path = [];\n    let t = this.LA(i++);\n    while (true) {\n        let d = getExistingTargetState(previousD, t);\n        if (d === undefined) {\n            d = computeLookaheadTarget.apply(this, [dfa, previousD, t, i, predicateSet, logging]);\n        }\n        if (d === DFA_ERROR) {\n            return buildAdaptivePredictError(path, previousD, t);\n        }\n        if (d.isAcceptState === true) {\n            return d.prediction;\n        }\n        previousD = d;\n        path.push(t);\n        t = this.LA(i++);\n    }\n}\nfunction computeLookaheadTarget(dfa, previousD, token, lookahead, predicateSet, logging) {\n    const reach = computeReachSet(previousD.configs, token, predicateSet);\n    if (reach.size === 0) {\n        addDFAEdge(dfa, previousD, token, DFA_ERROR);\n        return DFA_ERROR;\n    }\n    let newState = newDFAState(reach);\n    const predictedAlt = getUniqueAlt(reach, predicateSet);\n    if (predictedAlt !== undefined) {\n        newState.isAcceptState = true;\n        newState.prediction = predictedAlt;\n        newState.configs.uniqueAlt = predictedAlt;\n    }\n    else if (hasConflictTerminatingPrediction(reach)) {\n        const prediction = min(reach.alts);\n        newState.isAcceptState = true;\n        newState.prediction = prediction;\n        newState.configs.uniqueAlt = prediction;\n        reportLookaheadAmbiguity.apply(this, [dfa, lookahead, reach.alts, logging]);\n    }\n    newState = addDFAEdge(dfa, previousD, token, newState);\n    return newState;\n}\nfunction reportLookaheadAmbiguity(dfa, lookahead, ambiguityIndices, logging) {\n    const prefixPath = [];\n    for (let i = 1; i <= lookahead; i++) {\n        prefixPath.push(this.LA(i).tokenType);\n    }\n    const atnState = dfa.atnStartState;\n    const topLevelRule = atnState.rule;\n    const production = atnState.production;\n    const message = buildAmbiguityError({\n        topLevelRule,\n        ambiguityIndices,\n        production,\n        prefixPath\n    });\n    logging(message);\n}\nfunction buildAmbiguityError(options) {\n    const pathMsg = map(options.prefixPath, (currtok) => tokenLabel(currtok)).join(\", \");\n    const occurrence = options.production.idx === 0 ? \"\" : options.production.idx;\n    let currMessage = `Ambiguous Alternatives Detected: <${options.ambiguityIndices.join(\", \")}> in <${getProductionDslName(options.production)}${occurrence}>` +\n        ` inside <${options.topLevelRule.name}> Rule,\\n` +\n        `<${pathMsg}> may appears as a prefix path in all these alternatives.\\n`;\n    currMessage =\n        currMessage +\n            `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#AMBIGUOUS_ALTERNATIVES\\n` +\n            `For Further details.`;\n    return currMessage;\n}\nfunction getProductionDslName(prod) {\n    if (prod instanceof NonTerminal) {\n        return \"SUBRULE\";\n    }\n    else if (prod instanceof Option) {\n        return \"OPTION\";\n    }\n    else if (prod instanceof Alternation) {\n        return \"OR\";\n    }\n    else if (prod instanceof RepetitionMandatory) {\n        return \"AT_LEAST_ONE\";\n    }\n    else if (prod instanceof RepetitionMandatoryWithSeparator) {\n        return \"AT_LEAST_ONE_SEP\";\n    }\n    else if (prod instanceof RepetitionWithSeparator) {\n        return \"MANY_SEP\";\n    }\n    else if (prod instanceof Repetition) {\n        return \"MANY\";\n    }\n    else if (prod instanceof Terminal) {\n        return \"CONSUME\";\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nfunction buildAdaptivePredictError(path, previous, current) {\n    const nextTransitions = flatMap(previous.configs.elements, (e) => e.state.transitions);\n    const nextTokenTypes = uniqBy(nextTransitions\n        .filter((e) => e instanceof AtomTransition)\n        .map((e) => e.tokenType), (e) => e.tokenTypeIdx);\n    return {\n        actualToken: current,\n        possibleTokenTypes: nextTokenTypes,\n        tokenPath: path\n    };\n}\nfunction getExistingTargetState(state, token) {\n    return state.edges[token.tokenTypeIdx];\n}\nfunction computeReachSet(configs, token, predicateSet) {\n    const intermediate = new ATNConfigSet();\n    const skippedStopStates = [];\n    for (const c of configs.elements) {\n        if (predicateSet.is(c.alt) === false) {\n            continue;\n        }\n        if (c.state.type === ATN_RULE_STOP) {\n            skippedStopStates.push(c);\n            continue;\n        }\n        const transitionLength = c.state.transitions.length;\n        for (let i = 0; i < transitionLength; i++) {\n            const transition = c.state.transitions[i];\n            const target = getReachableTarget(transition, token);\n            if (target !== undefined) {\n                intermediate.add({\n                    state: target,\n                    alt: c.alt,\n                    stack: c.stack\n                });\n            }\n        }\n    }\n    let reach;\n    if (skippedStopStates.length === 0 && intermediate.size === 1) {\n        reach = intermediate;\n    }\n    if (reach === undefined) {\n        reach = new ATNConfigSet();\n        for (const c of intermediate.elements) {\n            closure(c, reach);\n        }\n    }\n    if (skippedStopStates.length > 0 && !hasConfigInRuleStopState(reach)) {\n        for (const c of skippedStopStates) {\n            reach.add(c);\n        }\n    }\n    return reach;\n}\nfunction getReachableTarget(transition, token) {\n    if (transition instanceof AtomTransition &&\n        tokenMatcher(token, transition.tokenType)) {\n        return transition.target;\n    }\n    return undefined;\n}\nfunction getUniqueAlt(configs, predicateSet) {\n    let alt;\n    for (const c of configs.elements) {\n        if (predicateSet.is(c.alt) === true) {\n            if (alt === undefined) {\n                alt = c.alt;\n            }\n            else if (alt !== c.alt) {\n                return undefined;\n            }\n        }\n    }\n    return alt;\n}\nfunction newDFAState(closure) {\n    return {\n        configs: closure,\n        edges: {},\n        isAcceptState: false,\n        prediction: -1\n    };\n}\nfunction addDFAEdge(dfa, from, token, to) {\n    to = addDFAState(dfa, to);\n    from.edges[token.tokenTypeIdx] = to;\n    return to;\n}\nfunction addDFAState(dfa, state) {\n    if (state === DFA_ERROR) {\n        return state;\n    }\n    // Repetitions have the same config set\n    // Therefore, storing the key of the config in a map allows us to create a loop in our DFA\n    const mapKey = state.configs.key;\n    const existing = dfa.states[mapKey];\n    if (existing !== undefined) {\n        return existing;\n    }\n    state.configs.finalize();\n    dfa.states[mapKey] = state;\n    return state;\n}\nfunction computeStartState(atnState) {\n    const configs = new ATNConfigSet();\n    const numberOfTransitions = atnState.transitions.length;\n    for (let i = 0; i < numberOfTransitions; i++) {\n        const target = atnState.transitions[i].target;\n        const config = {\n            state: target,\n            alt: i,\n            stack: []\n        };\n        closure(config, configs);\n    }\n    return configs;\n}\nfunction closure(config, configs) {\n    const p = config.state;\n    if (p.type === ATN_RULE_STOP) {\n        if (config.stack.length > 0) {\n            const atnStack = [...config.stack];\n            const followState = atnStack.pop();\n            const followConfig = {\n                state: followState,\n                alt: config.alt,\n                stack: atnStack\n            };\n            closure(followConfig, configs);\n        }\n        else {\n            // Dipping into outer context, simply add the config\n            // This will stop computation once every config is at the rule stop state\n            configs.add(config);\n        }\n        return;\n    }\n    if (!p.epsilonOnlyTransitions) {\n        configs.add(config);\n    }\n    const transitionLength = p.transitions.length;\n    for (let i = 0; i < transitionLength; i++) {\n        const transition = p.transitions[i];\n        const c = getEpsilonTarget(config, transition);\n        if (c !== undefined) {\n            closure(c, configs);\n        }\n    }\n}\nfunction getEpsilonTarget(config, transition) {\n    if (transition instanceof EpsilonTransition) {\n        return {\n            state: transition.target,\n            alt: config.alt,\n            stack: config.stack\n        };\n    }\n    else if (transition instanceof RuleTransition) {\n        const stack = [...config.stack, transition.followState];\n        return {\n            state: transition.target,\n            alt: config.alt,\n            stack\n        };\n    }\n    return undefined;\n}\nfunction hasConfigInRuleStopState(configs) {\n    for (const c of configs.elements) {\n        if (c.state.type === ATN_RULE_STOP) {\n            return true;\n        }\n    }\n    return false;\n}\nfunction allConfigsInRuleStopStates(configs) {\n    for (const c of configs.elements) {\n        if (c.state.type !== ATN_RULE_STOP) {\n            return false;\n        }\n    }\n    return true;\n}\nfunction hasConflictTerminatingPrediction(configs) {\n    if (allConfigsInRuleStopStates(configs)) {\n        return true;\n    }\n    const altSets = getConflictingAltSets(configs.elements);\n    const heuristic = hasConflictingAltSet(altSets) && !hasStateAssociatedWithOneAlt(altSets);\n    return heuristic;\n}\nfunction getConflictingAltSets(configs) {\n    const configToAlts = new Map();\n    for (const c of configs) {\n        const key = getATNConfigKey(c, false);\n        let alts = configToAlts.get(key);\n        if (alts === undefined) {\n            alts = {};\n            configToAlts.set(key, alts);\n        }\n        alts[c.alt] = true;\n    }\n    return configToAlts;\n}\nfunction hasConflictingAltSet(altSets) {\n    for (const value of Array.from(altSets.values())) {\n        if (Object.keys(value).length > 1) {\n            return true;\n        }\n    }\n    return false;\n}\nfunction hasStateAssociatedWithOneAlt(altSets) {\n    for (const value of Array.from(altSets.values())) {\n        if (Object.keys(value).length === 1) {\n            return true;\n        }\n    }\n    return false;\n}\n//# sourceMappingURL=all-star-lookahead.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nexport { LLStarLookaheadStrategy } from './all-star-lookahead.js';\n//# sourceMappingURL=index.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { Position } from 'vscode-languageserver-types';\nimport { tokenToRange } from '../utils/cst-utils.js';\nexport class CstNodeBuilder {\n    constructor() {\n        this.nodeStack = [];\n    }\n    get current() {\n        return this.nodeStack[this.nodeStack.length - 1] ?? this.rootNode;\n    }\n    buildRootNode(input) {\n        this.rootNode = new RootCstNodeImpl(input);\n        this.rootNode.root = this.rootNode;\n        this.nodeStack = [this.rootNode];\n        return this.rootNode;\n    }\n    buildCompositeNode(feature) {\n        const compositeNode = new CompositeCstNodeImpl();\n        compositeNode.grammarSource = feature;\n        compositeNode.root = this.rootNode;\n        this.current.content.push(compositeNode);\n        this.nodeStack.push(compositeNode);\n        return compositeNode;\n    }\n    buildLeafNode(token, feature) {\n        const leafNode = new LeafCstNodeImpl(token.startOffset, token.image.length, tokenToRange(token), token.tokenType, !feature);\n        leafNode.grammarSource = feature;\n        leafNode.root = this.rootNode;\n        this.current.content.push(leafNode);\n        return leafNode;\n    }\n    removeNode(node) {\n        const parent = node.container;\n        if (parent) {\n            const index = parent.content.indexOf(node);\n            if (index >= 0) {\n                parent.content.splice(index, 1);\n            }\n        }\n    }\n    addHiddenNodes(tokens) {\n        const nodes = [];\n        for (const token of tokens) {\n            const leafNode = new LeafCstNodeImpl(token.startOffset, token.image.length, tokenToRange(token), token.tokenType, true);\n            leafNode.root = this.rootNode;\n            nodes.push(leafNode);\n        }\n        let current = this.current;\n        let added = false;\n        // If we are within a composite node, we add the hidden nodes to the content\n        if (current.content.length > 0) {\n            current.content.push(...nodes);\n            return;\n        }\n        // Otherwise we are at a newly created node\n        // Instead of adding the hidden nodes here, we search for the first parent node with content\n        while (current.container) {\n            const index = current.container.content.indexOf(current);\n            if (index > 0) {\n                // Add the hidden nodes before the current node\n                current.container.content.splice(index, 0, ...nodes);\n                added = true;\n                break;\n            }\n            current = current.container;\n        }\n        // If we arrive at the root node, we add the hidden nodes at the beginning\n        // This is the case if the hidden nodes are the first nodes in the tree\n        if (!added) {\n            this.rootNode.content.unshift(...nodes);\n        }\n    }\n    construct(item) {\n        const current = this.current;\n        // The specified item could be a datatype ($type is symbol), fragment ($type is undefined) or infix rule ($infix is true)\n        // Only if the $type is a string, we actually assign the element\n        if (typeof item.$type === 'string' && !item.$infixName) {\n            this.current.astNode = item;\n        }\n        item.$cstNode = current;\n        const node = this.nodeStack.pop();\n        // Empty composite nodes are not valid\n        // Simply remove the node from the tree\n        if (node?.content.length === 0) {\n            this.removeNode(node);\n        }\n    }\n}\nexport class AbstractCstNode {\n    get hidden() {\n        return false;\n    }\n    get astNode() {\n        const node = typeof this._astNode?.$type === 'string' ? this._astNode : this.container?.astNode;\n        if (!node) {\n            throw new Error('This node has no associated AST element');\n        }\n        return node;\n    }\n    set astNode(value) {\n        this._astNode = value;\n    }\n    get text() {\n        return this.root.fullText.substring(this.offset, this.end);\n    }\n}\nexport class LeafCstNodeImpl extends AbstractCstNode {\n    get offset() {\n        return this._offset;\n    }\n    get length() {\n        return this._length;\n    }\n    get end() {\n        return this._offset + this._length;\n    }\n    get hidden() {\n        return this._hidden;\n    }\n    get tokenType() {\n        return this._tokenType;\n    }\n    get range() {\n        return this._range;\n    }\n    constructor(offset, length, range, tokenType, hidden = false) {\n        super();\n        this._hidden = hidden;\n        this._offset = offset;\n        this._tokenType = tokenType;\n        this._length = length;\n        this._range = range;\n    }\n}\nexport class CompositeCstNodeImpl extends AbstractCstNode {\n    constructor() {\n        super(...arguments);\n        this.content = new CstNodeContainer(this);\n    }\n    get offset() {\n        return this.firstNonHiddenNode?.offset ?? 0;\n    }\n    get length() {\n        return this.end - this.offset;\n    }\n    get end() {\n        return this.lastNonHiddenNode?.end ?? 0;\n    }\n    get range() {\n        const firstNode = this.firstNonHiddenNode;\n        const lastNode = this.lastNonHiddenNode;\n        if (firstNode && lastNode) {\n            if (this._rangeCache === undefined) {\n                const { range: firstRange } = firstNode;\n                const { range: lastRange } = lastNode;\n                this._rangeCache = { start: firstRange.start, end: lastRange.end.line < firstRange.start.line ? firstRange.start : lastRange.end };\n            }\n            return this._rangeCache;\n        }\n        else {\n            return { start: Position.create(0, 0), end: Position.create(0, 0) };\n        }\n    }\n    get firstNonHiddenNode() {\n        for (const child of this.content) {\n            if (!child.hidden) {\n                return child;\n            }\n        }\n        return this.content[0];\n    }\n    get lastNonHiddenNode() {\n        for (let i = this.content.length - 1; i >= 0; i--) {\n            const child = this.content[i];\n            if (!child.hidden) {\n                return child;\n            }\n        }\n        return this.content[this.content.length - 1];\n    }\n}\nclass CstNodeContainer extends Array {\n    constructor(parent) {\n        super();\n        this.parent = parent;\n        Object.setPrototypeOf(this, CstNodeContainer.prototype);\n    }\n    push(...items) {\n        this.addParents(items);\n        return super.push(...items);\n    }\n    unshift(...items) {\n        this.addParents(items);\n        return super.unshift(...items);\n    }\n    splice(start, count, ...items) {\n        this.addParents(items);\n        return super.splice(start, count, ...items);\n    }\n    addParents(items) {\n        for (const item of items) {\n            item.container = this.parent;\n        }\n    }\n}\nexport class RootCstNodeImpl extends CompositeCstNodeImpl {\n    get text() {\n        return this._text.substring(this.offset, this.end);\n    }\n    get fullText() {\n        return this._text;\n    }\n    constructor(input) {\n        super();\n        this._text = '';\n        this._text = input ?? '';\n    }\n}\n//# sourceMappingURL=cst-node-builder.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n/* eslint-disable @typescript-eslint/no-explicit-any */\nimport { isInfixRule } from '../languages/generated/ast.js';\nimport { defaultParserErrorProvider, EmbeddedActionsParser, LLkLookaheadStrategy } from 'chevrotain';\nimport { LLStarLookaheadStrategy } from 'chevrotain-allstar';\nimport { isAssignment, isCrossReference, isKeyword, isParserRule } from '../languages/generated/ast.js';\nimport { getTypeName, isDataTypeRule } from '../utils/grammar-utils.js';\nimport { assignMandatoryProperties, getContainerOfType, linkContentToContainer } from '../utils/ast-utils.js';\nimport { CstNodeBuilder } from './cst-node-builder.js';\nexport const DatatypeSymbol = Symbol('Datatype');\nfunction isDataTypeNode(node) {\n    return node.$type === DatatypeSymbol;\n}\nconst ruleSuffix = '\\u200B';\nconst withRuleSuffix = (name) => name.endsWith(ruleSuffix) ? name : name + ruleSuffix;\nexport class AbstractLangiumParser {\n    constructor(services) {\n        this._unorderedGroups = new Map();\n        this.allRules = new Map();\n        this.lexer = services.parser.Lexer;\n        const tokens = this.lexer.definition;\n        const production = services.LanguageMetaData.mode === 'production';\n        if (services.shared.profilers.LangiumProfiler?.isActive('parsing')) {\n            this.wrapper = new ProfilerWrapper(tokens, {\n                ...services.parser.ParserConfig,\n                skipValidations: production,\n                errorMessageProvider: services.parser.ParserErrorMessageProvider\n            }, services.shared.profilers.LangiumProfiler.createTask('parsing', services.LanguageMetaData.languageId));\n        }\n        else {\n            this.wrapper = new ChevrotainWrapper(tokens, {\n                ...services.parser.ParserConfig,\n                skipValidations: production,\n                errorMessageProvider: services.parser.ParserErrorMessageProvider\n            });\n        }\n    }\n    alternatives(idx, choices) {\n        this.wrapper.wrapOr(idx, choices);\n    }\n    optional(idx, callback) {\n        this.wrapper.wrapOption(idx, callback);\n    }\n    many(idx, callback) {\n        this.wrapper.wrapMany(idx, callback);\n    }\n    atLeastOne(idx, callback) {\n        this.wrapper.wrapAtLeastOne(idx, callback);\n    }\n    getRule(name) {\n        return this.allRules.get(name);\n    }\n    isRecording() {\n        return this.wrapper.IS_RECORDING;\n    }\n    get unorderedGroups() {\n        return this._unorderedGroups;\n    }\n    getRuleStack() {\n        return this.wrapper.RULE_STACK;\n    }\n    finalize() {\n        this.wrapper.wrapSelfAnalysis();\n    }\n}\nexport class LangiumParser extends AbstractLangiumParser {\n    get current() {\n        return this.stack[this.stack.length - 1];\n    }\n    constructor(services) {\n        super(services);\n        this.nodeBuilder = new CstNodeBuilder();\n        this.stack = [];\n        this.assignmentMap = new Map();\n        this.operatorPrecedence = new Map();\n        this.linker = services.references.Linker;\n        this.converter = services.parser.ValueConverter;\n        this.astReflection = services.shared.AstReflection;\n    }\n    rule(rule, impl) {\n        const type = this.computeRuleType(rule);\n        let infixName = undefined;\n        if (isInfixRule(rule)) {\n            infixName = rule.name;\n            this.registerPrecedenceMap(rule);\n        }\n        const ruleMethod = this.wrapper.DEFINE_RULE(withRuleSuffix(rule.name), this.startImplementation(type, infixName, impl).bind(this));\n        this.allRules.set(rule.name, ruleMethod);\n        if (isParserRule(rule) && rule.entry) {\n            this.mainRule = ruleMethod;\n        }\n        return ruleMethod;\n    }\n    registerPrecedenceMap(rule) {\n        const name = rule.name;\n        const map = new Map();\n        for (let i = 0; i < rule.operators.precedences.length; i++) {\n            const precedence = rule.operators.precedences[i];\n            for (const keyword of precedence.operators) {\n                map.set(keyword.value, {\n                    precedence: i,\n                    rightAssoc: precedence.associativity === 'right'\n                });\n            }\n        }\n        this.operatorPrecedence.set(name, map);\n    }\n    computeRuleType(rule) {\n        if (isInfixRule(rule)) {\n            return getTypeName(rule);\n        }\n        else if (rule.fragment) {\n            return undefined;\n        }\n        else if (isDataTypeRule(rule)) {\n            return DatatypeSymbol;\n        }\n        else {\n            return getTypeName(rule);\n        }\n    }\n    parse(input, options = {}) {\n        this.nodeBuilder.buildRootNode(input);\n        const lexerResult = this.lexerResult = this.lexer.tokenize(input);\n        this.wrapper.input = lexerResult.tokens;\n        const ruleMethod = options.rule ? this.allRules.get(options.rule) : this.mainRule;\n        if (!ruleMethod) {\n            throw new Error(options.rule ? `No rule found with name '${options.rule}'` : 'No main rule available.');\n        }\n        const result = this.doParse(ruleMethod);\n        this.nodeBuilder.addHiddenNodes(lexerResult.hidden);\n        this.unorderedGroups.clear();\n        this.lexerResult = undefined;\n        linkContentToContainer(result, { deep: true });\n        return {\n            value: result,\n            lexerErrors: lexerResult.errors,\n            lexerReport: lexerResult.report,\n            parserErrors: this.wrapper.errors\n        };\n    }\n    doParse(rule) {\n        let result = this.wrapper.rule(rule);\n        if (this.stack.length > 0) {\n            // In case the parser throws on the entry rule, `construct` is not called\n            // We need to call it manually here\n            result = this.construct();\n        }\n        // Perform some sanity checking\n        if (result === undefined) {\n            throw new Error('No result from parser');\n        }\n        else if (this.stack.length > 0) {\n            throw new Error('Parser stack is not empty after parsing');\n        }\n        return result;\n    }\n    startImplementation($type, infixName, implementation) {\n        return (args) => {\n            // Only create a new AST node in case the calling rule is not a fragment rule\n            const createNode = !this.isRecording() && $type !== undefined;\n            if (createNode) {\n                const node = { $type };\n                this.stack.push(node);\n                if ($type === DatatypeSymbol) {\n                    node.value = '';\n                }\n                else if (infixName !== undefined) {\n                    node.$infixName = infixName;\n                }\n            }\n            // Execute the actual rule implementation\n            // The `implementation` never returns anything and only manipulates the parser state.\n            implementation(args);\n            // Once the rule implementation is done, we need to construct the AST node\n            // If the implementation throws (likely a recognition error), we relay the construction to the `subrule` method\n            return createNode ? this.construct() : undefined;\n        };\n    }\n    extractHiddenTokens(token) {\n        const hiddenTokens = this.lexerResult.hidden;\n        if (!hiddenTokens.length) {\n            return [];\n        }\n        const offset = token.startOffset;\n        for (let i = 0; i < hiddenTokens.length; i++) {\n            const token = hiddenTokens[i];\n            if (token.startOffset > offset) {\n                return hiddenTokens.splice(0, i);\n            }\n        }\n        return hiddenTokens.splice(0, hiddenTokens.length);\n    }\n    consume(idx, tokenType, feature) {\n        const token = this.wrapper.wrapConsume(idx, tokenType);\n        if (!this.isRecording() && this.isValidToken(token)) {\n            // Before inserting the current token into the CST, we want add the hidden tokens (i.e. comments)\n            // These are located directly before the current token, but are not part of the token stream.\n            // Adding the hidden tokens to the CST requires searching through the CST and finding the correct position.\n            // Performing this work here is more efficient than doing it later on.\n            const hiddenTokens = this.extractHiddenTokens(token);\n            this.nodeBuilder.addHiddenNodes(hiddenTokens);\n            const leafNode = this.nodeBuilder.buildLeafNode(token, feature);\n            const { assignment, crossRef } = this.getAssignment(feature);\n            const current = this.current;\n            if (assignment) {\n                const convertedValue = isKeyword(feature) ? token.image : this.converter.convert(token.image, leafNode);\n                this.assign(assignment.operator, assignment.feature, convertedValue, leafNode, crossRef);\n            }\n            else if (isDataTypeNode(current)) {\n                let text = token.image;\n                if (!isKeyword(feature)) {\n                    text = this.converter.convert(text, leafNode).toString();\n                }\n                current.value += text;\n            }\n        }\n    }\n    /**\n     * Most consumed parser tokens are valid. However there are two cases in which they are not valid:\n     *\n     * 1. They were inserted during error recovery by the parser. These tokens don't really exist and should not be further processed\n     * 2. They contain invalid token ranges. This might include the special EOF token, or other tokens produced by invalid token builders.\n     */\n    isValidToken(token) {\n        return !token.isInsertedInRecovery && !isNaN(token.startOffset) && typeof token.endOffset === 'number' && !isNaN(token.endOffset);\n    }\n    subrule(idx, rule, fragment, feature, args) {\n        let cstNode;\n        if (!this.isRecording() && !fragment) {\n            // We only want to create a new CST node if the subrule actually creates a new AST node.\n            // In other cases like calls of fragment rules the current CST/AST is populated further.\n            // Note that skipping this initialization and leaving cstNode unassigned also skips the subrule assignment later on.\n            // This is intended, as fragment rules only enrich the current AST node\n            cstNode = this.nodeBuilder.buildCompositeNode(feature);\n        }\n        let result;\n        try {\n            result = this.wrapper.wrapSubrule(idx, rule, args);\n        }\n        finally {\n            if (!this.isRecording()) {\n                // Calling `subrule` on chevrotain parsers can result in a recognition error\n                // This likely means that we encounter a syntax error in the input.\n                // In this case, the result of the subrule is `undefined` and we need to call `construct` manually.\n                if (result === undefined && !fragment) {\n                    result = this.construct();\n                }\n                // We want to perform the subrule assignment regardless of the recognition error\n                // But only if the subrule call actually consumed any tokens\n                if (result !== undefined && cstNode && cstNode.length > 0) {\n                    this.performSubruleAssignment(result, feature, cstNode);\n                }\n            }\n            // We don't have a catch block in here because we want to propagate the recognition error to the caller\n            // This results in much better error recovery and error messages from chevrotain\n        }\n    }\n    performSubruleAssignment(result, feature, cstNode) {\n        const { assignment, crossRef } = this.getAssignment(feature);\n        if (assignment) {\n            this.assign(assignment.operator, assignment.feature, result, cstNode, crossRef);\n        }\n        else if (!assignment) {\n            // If we call a subrule without an assignment we either:\n            // 1. append the result of the subrule (data type rule)\n            // 2. override the current object with the newly parsed object\n            // If the current element is an AST node and the result of the subrule\n            // is a data type rule, we can safely discard the results.\n            const current = this.current;\n            if (isDataTypeNode(current)) {\n                current.value += result.toString();\n            }\n            else if (typeof result === 'object' && result) {\n                const object = this.assignWithoutOverride(result, current);\n                const newItem = object;\n                this.stack.pop();\n                this.stack.push(newItem);\n            }\n        }\n    }\n    action($type, action) {\n        if (!this.isRecording()) {\n            let last = this.current;\n            if (action.feature && action.operator) {\n                last = this.construct();\n                this.nodeBuilder.removeNode(last.$cstNode);\n                const node = this.nodeBuilder.buildCompositeNode(action);\n                node.content.push(last.$cstNode);\n                const newItem = { $type };\n                this.stack.push(newItem);\n                this.assign(action.operator, action.feature, last, last.$cstNode);\n            }\n            else {\n                last.$type = $type;\n            }\n        }\n    }\n    construct() {\n        if (this.isRecording()) {\n            return undefined;\n        }\n        const obj = this.stack.pop();\n        this.nodeBuilder.construct(obj);\n        if ('$infixName' in obj) {\n            return this.constructInfix(obj, this.operatorPrecedence.get(obj.$infixName));\n        }\n        else if (isDataTypeNode(obj)) {\n            return this.converter.convert(obj.value, obj.$cstNode);\n        }\n        else {\n            assignMandatoryProperties(this.astReflection, obj);\n        }\n        return obj;\n    }\n    constructInfix(obj, precedence) {\n        const parts = obj.parts;\n        if (!Array.isArray(parts) || parts.length === 0) {\n            // Likely the result of a syntax error, simply return undefined\n            return undefined;\n        }\n        const operators = obj.operators;\n        if (!Array.isArray(operators) || parts.length < 2) {\n            // Captured just a single, non-binary expression\n            // Simply return the expression as is.\n            return parts[0];\n        }\n        // Find the operator with the lowest precedence (highest value in precedence map)\n        let lowestPrecedenceIdx = 0;\n        let lowestPrecedenceValue = -1;\n        for (let i = 0; i < operators.length; i++) {\n            const operator = operators[i];\n            const opPrecedence = precedence.get(operator) ?? {\n                precedence: Infinity,\n                rightAssoc: false\n            };\n            // For equal precedence, use associativity to determine which operator to pick\n            if (opPrecedence.precedence > lowestPrecedenceValue) {\n                // Always pick operators with lower precedence (higher precedence value)\n                lowestPrecedenceValue = opPrecedence.precedence;\n                lowestPrecedenceIdx = i;\n            }\n            else if (opPrecedence.precedence === lowestPrecedenceValue) {\n                // Check associativity when precedence is equal\n                if (!opPrecedence.rightAssoc) {\n                    // For left associative operators (default), pick the leftmost one\n                    // This means choosing the rightmost equal-precedence operator when working backwards\n                    lowestPrecedenceIdx = i;\n                }\n                // For right associative operators with equal precedence,\n                // we keep the previous (rightmost) index\n            }\n        }\n        // Split the expression at the lowest precedence operator\n        const leftOperators = operators.slice(0, lowestPrecedenceIdx);\n        const rightOperators = operators.slice(lowestPrecedenceIdx + 1);\n        const leftParts = parts.slice(0, lowestPrecedenceIdx + 1);\n        const rightParts = parts.slice(lowestPrecedenceIdx + 1);\n        // Create sub-expressions\n        const leftInfix = {\n            $infixName: obj.$infixName,\n            $type: obj.$type,\n            $cstNode: obj.$cstNode,\n            parts: leftParts,\n            operators: leftOperators\n        };\n        const rightInfix = {\n            $infixName: obj.$infixName,\n            $type: obj.$type,\n            $cstNode: obj.$cstNode,\n            parts: rightParts,\n            operators: rightOperators\n        };\n        // Recursively build the left and right subtrees\n        const leftTree = this.constructInfix(leftInfix, precedence);\n        const rightTree = this.constructInfix(rightInfix, precedence);\n        // Create the final binary expression\n        return {\n            $type: obj.$type,\n            $cstNode: obj.$cstNode,\n            left: leftTree,\n            operator: operators[lowestPrecedenceIdx],\n            right: rightTree\n        };\n    }\n    getAssignment(feature) {\n        if (!this.assignmentMap.has(feature)) {\n            const assignment = getContainerOfType(feature, isAssignment);\n            this.assignmentMap.set(feature, {\n                assignment: assignment,\n                crossRef: assignment && isCrossReference(assignment.terminal) ? (assignment.terminal.isMulti ? 'multi' : 'single') : undefined\n            });\n        }\n        return this.assignmentMap.get(feature);\n    }\n    assign(operator, feature, value, cstNode, crossRef) {\n        const obj = this.current;\n        let item;\n        if (crossRef === 'single' && typeof value === 'string') {\n            item = this.linker.buildReference(obj, feature, cstNode, value);\n        }\n        else if (crossRef === 'multi' && typeof value === 'string') {\n            item = this.linker.buildMultiReference(obj, feature, cstNode, value);\n        }\n        else {\n            item = value;\n        }\n        switch (operator) {\n            case '=': {\n                obj[feature] = item;\n                break;\n            }\n            case '?=': {\n                obj[feature] = true;\n                break;\n            }\n            case '+=': {\n                if (!Array.isArray(obj[feature])) {\n                    obj[feature] = [];\n                }\n                obj[feature].push(item);\n            }\n        }\n    }\n    assignWithoutOverride(target, source) {\n        for (const [name, existingValue] of Object.entries(source)) {\n            const newValue = target[name];\n            if (newValue === undefined) {\n                target[name] = existingValue;\n            }\n            else if (Array.isArray(newValue) && Array.isArray(existingValue)) {\n                existingValue.push(...newValue);\n                target[name] = existingValue;\n            }\n        }\n        // The target was parsed from a unassigned subrule\n        // After the subrule construction, it received a cst node\n        // This CST node will later be overriden by the cst node builder\n        // To prevent references to stale AST nodes in the CST,\n        // we need to remove the reference here\n        const targetCstNode = target.$cstNode;\n        if (targetCstNode) {\n            targetCstNode.astNode = undefined;\n            target.$cstNode = undefined;\n        }\n        return target;\n    }\n    get definitionErrors() {\n        return this.wrapper.definitionErrors;\n    }\n}\nexport class AbstractParserErrorMessageProvider {\n    buildMismatchTokenMessage(options) {\n        return defaultParserErrorProvider.buildMismatchTokenMessage(options);\n    }\n    buildNotAllInputParsedMessage(options) {\n        return defaultParserErrorProvider.buildNotAllInputParsedMessage(options);\n    }\n    buildNoViableAltMessage(options) {\n        return defaultParserErrorProvider.buildNoViableAltMessage(options);\n    }\n    buildEarlyExitMessage(options) {\n        return defaultParserErrorProvider.buildEarlyExitMessage(options);\n    }\n}\nexport class LangiumParserErrorMessageProvider extends AbstractParserErrorMessageProvider {\n    buildMismatchTokenMessage({ expected, actual }) {\n        const expectedMsg = expected.LABEL\n            ? '`' + expected.LABEL + '`'\n            : expected.name.endsWith(':KW')\n                ? `keyword '${expected.name.substring(0, expected.name.length - 3)}'`\n                : `token of type '${expected.name}'`;\n        return `Expecting ${expectedMsg} but found \\`${actual.image}\\`.`;\n    }\n    buildNotAllInputParsedMessage({ firstRedundant }) {\n        return `Expecting end of file but found \\`${firstRedundant.image}\\`.`;\n    }\n}\nexport class LangiumCompletionParser extends AbstractLangiumParser {\n    constructor() {\n        super(...arguments);\n        this.tokens = [];\n        this.elementStack = [];\n        this.lastElementStack = [];\n        this.nextTokenIndex = 0;\n        this.stackSize = 0;\n    }\n    action() {\n        // NOOP\n    }\n    construct() {\n        // NOOP\n        return undefined;\n    }\n    parse(input) {\n        this.resetState();\n        const tokens = this.lexer.tokenize(input, { mode: 'partial' });\n        this.tokens = tokens.tokens;\n        this.wrapper.input = [...this.tokens];\n        this.mainRule.call(this.wrapper, {});\n        this.unorderedGroups.clear();\n        return {\n            tokens: this.tokens,\n            elementStack: [...this.lastElementStack],\n            tokenIndex: this.nextTokenIndex\n        };\n    }\n    rule(rule, impl) {\n        const ruleMethod = this.wrapper.DEFINE_RULE(withRuleSuffix(rule.name), this.startImplementation(impl).bind(this));\n        this.allRules.set(rule.name, ruleMethod);\n        if (rule.entry) {\n            this.mainRule = ruleMethod;\n        }\n        return ruleMethod;\n    }\n    resetState() {\n        this.elementStack = [];\n        this.lastElementStack = [];\n        this.nextTokenIndex = 0;\n        this.stackSize = 0;\n    }\n    startImplementation(implementation) {\n        return (args) => {\n            const size = this.keepStackSize();\n            try {\n                implementation(args);\n            }\n            finally {\n                this.resetStackSize(size);\n            }\n        };\n    }\n    removeUnexpectedElements() {\n        this.elementStack.splice(this.stackSize);\n    }\n    keepStackSize() {\n        const size = this.elementStack.length;\n        this.stackSize = size;\n        return size;\n    }\n    resetStackSize(size) {\n        this.removeUnexpectedElements();\n        this.stackSize = size;\n    }\n    consume(idx, tokenType, feature) {\n        this.wrapper.wrapConsume(idx, tokenType);\n        if (!this.isRecording()) {\n            this.lastElementStack = [...this.elementStack, feature];\n            this.nextTokenIndex = this.currIdx + 1;\n        }\n    }\n    subrule(idx, rule, fragment, feature, args) {\n        this.before(feature);\n        this.wrapper.wrapSubrule(idx, rule, args);\n        this.after(feature);\n    }\n    before(element) {\n        if (!this.isRecording()) {\n            this.elementStack.push(element);\n        }\n    }\n    after(element) {\n        if (!this.isRecording()) {\n            const index = this.elementStack.lastIndexOf(element);\n            if (index >= 0) {\n                this.elementStack.splice(index);\n            }\n        }\n    }\n    get currIdx() {\n        return this.wrapper.currIdx;\n    }\n}\nconst defaultConfig = {\n    recoveryEnabled: true,\n    nodeLocationTracking: 'full',\n    skipValidations: true,\n    errorMessageProvider: new LangiumParserErrorMessageProvider()\n};\n/**\n * This class wraps the embedded actions parser of chevrotain and exposes protected methods.\n * This way, we can build the `LangiumParser` as a composition.\n */\nclass ChevrotainWrapper extends EmbeddedActionsParser {\n    constructor(tokens, config) {\n        const useDefaultLookahead = config && 'maxLookahead' in config;\n        super(tokens, {\n            ...defaultConfig,\n            lookaheadStrategy: useDefaultLookahead\n                ? new LLkLookaheadStrategy({ maxLookahead: config.maxLookahead })\n                : new LLStarLookaheadStrategy({\n                    // If validations are skipped, don't log the lookahead warnings\n                    logging: config.skipValidations ? () => { } : undefined\n                }),\n            ...config,\n        });\n    }\n    get IS_RECORDING() {\n        return this.RECORDING_PHASE;\n    }\n    DEFINE_RULE(name, impl, config) {\n        return this.RULE(name, impl, config);\n    }\n    wrapSelfAnalysis() {\n        this.performSelfAnalysis();\n    }\n    wrapConsume(idx, tokenType) {\n        return this.consume(idx, tokenType, undefined);\n    }\n    wrapSubrule(idx, rule, args) {\n        return this.subrule(idx, rule, {\n            ARGS: [args]\n        });\n    }\n    wrapOr(idx, choices) {\n        this.or(idx, choices);\n    }\n    wrapOption(idx, callback) {\n        this.option(idx, callback);\n    }\n    wrapMany(idx, callback) {\n        this.many(idx, callback);\n    }\n    wrapAtLeastOne(idx, callback) {\n        this.atLeastOne(idx, callback);\n    }\n    rule(rule) {\n        return rule.call(this, {});\n    }\n}\nclass ProfilerWrapper extends ChevrotainWrapper {\n    constructor(tokens, config, task) {\n        super(tokens, config);\n        this.task = task;\n    }\n    rule(rule) {\n        this.task.start();\n        this.task.startSubTask(this.ruleName(rule));\n        try {\n            return super.rule(rule);\n        }\n        finally {\n            this.task.stopSubTask(this.ruleName(rule));\n            this.task.stop();\n        }\n    }\n    ruleName(rule) {\n        return rule.ruleName;\n    }\n    subrule(idx, ruleToCall, options) {\n        this.task.startSubTask(this.ruleName(ruleToCall));\n        try {\n            return super.subrule(idx, ruleToCall, options);\n        }\n        finally {\n            this.task.stopSubTask(this.ruleName(ruleToCall));\n        }\n    }\n}\n//# sourceMappingURL=langium-parser.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { EMPTY_ALT, EOF } from 'chevrotain';\nimport { isAction, isAlternatives, isEndOfFile, isAssignment, isConjunction, isCrossReference, isDisjunction, isGroup, isKeyword, isNegation, isParameterReference, isParserRule, isRuleCall, isTerminalRule, isUnorderedGroup, isBooleanLiteral, isInfixRule, isAbstractParserRule } from '../languages/generated/ast.js';\nimport { assertUnreachable, ErrorWithLocation } from '../utils/errors.js';\nimport { stream } from '../utils/stream.js';\nimport { findNameAssignment, getAllReachableRules, getTypeName } from '../utils/grammar-utils.js';\nexport function createParser(grammar, parser, tokens) {\n    const parserContext = {\n        parser,\n        tokens,\n        ruleNames: new Map()\n    };\n    buildRules(parserContext, grammar);\n    return parser;\n}\nfunction buildRules(parserContext, grammar) {\n    const reachable = getAllReachableRules(grammar, false);\n    const parserRules = stream(grammar.rules).filter(isParserRule).filter(rule => reachable.has(rule));\n    for (const rule of parserRules) {\n        const ctx = {\n            ...parserContext,\n            consume: 1,\n            optional: 1,\n            subrule: 1,\n            many: 1,\n            or: 1\n        };\n        parserContext.parser.rule(rule, buildElement(ctx, rule.definition));\n    }\n    const infixRules = stream(grammar.rules).filter(isInfixRule).filter(rule => reachable.has(rule));\n    for (const rule of infixRules) {\n        parserContext.parser.rule(rule, buildInfixRule(parserContext, rule));\n    }\n}\nfunction buildInfixRule(ctx, rule) {\n    const expressionRule = rule.call.rule.ref;\n    if (!expressionRule) {\n        throw new Error('Could not resolve reference to infix operator rule: ' + rule.call.rule.$refText);\n    }\n    if (isTerminalRule(expressionRule)) {\n        throw new Error('Cannot use terminal rule in infix expression');\n    }\n    // We need to construct a bunch of synthetic grammar AST nodes here\n    // This ensures that the CST and completion engine get populated as expected\n    const allKeywords = rule.operators.precedences.flatMap(e => e.operators);\n    // The outer group represents the first expression call and the whole (optional) loop\n    const outerGroup = {\n        $type: 'Group',\n        elements: []\n    };\n    const part1Assignment = {\n        $container: outerGroup,\n        $type: 'Assignment',\n        feature: 'parts',\n        operator: '+=',\n        terminal: rule.call\n    };\n    // The inner group represents the loop that contains the operator and expression call\n    // It can be infinitely repeated\n    const innerGroup = {\n        $container: outerGroup,\n        $type: 'Group',\n        elements: [],\n        cardinality: '*'\n    };\n    outerGroup.elements.push(part1Assignment, innerGroup);\n    // Store all operator keywords in one alternative/assignment\n    const alternatives = {\n        $type: 'Alternatives',\n        elements: allKeywords\n    };\n    const operatorAssignment = {\n        $container: innerGroup,\n        $type: 'Assignment',\n        feature: 'operators',\n        operator: '+=',\n        terminal: alternatives\n    };\n    // We need a second assignment of the called expression here\n    const part2Assignment = {\n        ...part1Assignment,\n        $container: innerGroup\n    };\n    innerGroup.elements.push(operatorAssignment, part2Assignment);\n    const tokens = allKeywords.map(e => ctx.tokens[e.value]);\n    const orAlts = tokens.map((token, index) => ({\n        ALT: () => ctx.parser.consume(index, token, operatorAssignment)\n    }));\n    let subrule;\n    return (args) => {\n        subrule ?? (subrule = getRule(ctx, expressionRule));\n        ctx.parser.subrule(0, subrule, false, part1Assignment, args);\n        ctx.parser.many(0, {\n            DEF: () => {\n                ctx.parser.alternatives(0, orAlts);\n                ctx.parser.subrule(1, subrule, false, part2Assignment, args);\n            }\n        });\n    };\n}\nfunction buildElement(ctx, element, ignoreGuard = false) {\n    let method;\n    if (isKeyword(element)) {\n        method = buildKeyword(ctx, element);\n    }\n    else if (isAction(element)) {\n        method = buildAction(ctx, element);\n    }\n    else if (isAssignment(element)) {\n        method = buildElement(ctx, element.terminal);\n    }\n    else if (isCrossReference(element)) {\n        method = buildCrossReference(ctx, element);\n    }\n    else if (isRuleCall(element)) {\n        method = buildRuleCall(ctx, element);\n    }\n    else if (isAlternatives(element)) {\n        method = buildAlternatives(ctx, element);\n    }\n    else if (isUnorderedGroup(element)) {\n        method = buildUnorderedGroup(ctx, element);\n    }\n    else if (isGroup(element)) {\n        method = buildGroup(ctx, element);\n    }\n    else if (isEndOfFile(element)) {\n        const idx = ctx.consume++;\n        method = () => ctx.parser.consume(idx, EOF, element);\n    }\n    else {\n        throw new ErrorWithLocation(element.$cstNode, `Unexpected element type: ${element.$type}`);\n    }\n    return wrap(ctx, ignoreGuard ? undefined : getGuardCondition(element), method, element.cardinality);\n}\nfunction buildAction(ctx, action) {\n    const actionType = getTypeName(action);\n    return () => ctx.parser.action(actionType, action);\n}\nfunction buildRuleCall(ctx, ruleCall) {\n    const rule = ruleCall.rule.ref;\n    if (isAbstractParserRule(rule)) {\n        const idx = ctx.subrule++;\n        const fragment = isParserRule(rule) && rule.fragment;\n        const predicate = ruleCall.arguments.length > 0 ? buildRuleCallPredicate(rule, ruleCall.arguments) : () => ({});\n        let subrule;\n        return (args) => {\n            subrule ?? (subrule = getRule(ctx, rule));\n            ctx.parser.subrule(idx, subrule, fragment, ruleCall, predicate(args));\n        };\n    }\n    else if (isTerminalRule(rule)) {\n        const idx = ctx.consume++;\n        const method = getToken(ctx, rule.name);\n        return () => ctx.parser.consume(idx, method, ruleCall);\n    }\n    else if (!rule) {\n        throw new ErrorWithLocation(ruleCall.$cstNode, `Undefined rule: ${ruleCall.rule.$refText}`);\n    }\n    else {\n        assertUnreachable(rule);\n    }\n}\nfunction buildRuleCallPredicate(rule, namedArgs) {\n    const hasNamedArguments = namedArgs.some(arg => arg.calledByName);\n    if (hasNamedArguments) {\n        const namedPredicates = namedArgs.map(arg => ({\n            parameterName: arg.parameter?.ref?.name,\n            predicate: buildPredicate(arg.value)\n        }));\n        return (args) => {\n            const ruleArgs = {};\n            for (const { parameterName, predicate } of namedPredicates) {\n                if (parameterName) {\n                    ruleArgs[parameterName] = predicate(args);\n                }\n            }\n            return ruleArgs;\n        };\n    }\n    else {\n        const predicates = namedArgs.map(arg => buildPredicate(arg.value));\n        return (args) => {\n            const ruleArgs = {};\n            for (let i = 0; i < predicates.length; i++) {\n                if (i < rule.parameters.length) {\n                    const parameterName = rule.parameters[i].name;\n                    const predicate = predicates[i];\n                    ruleArgs[parameterName] = predicate(args);\n                }\n            }\n            return ruleArgs;\n        };\n    }\n}\nfunction buildPredicate(condition) {\n    if (isDisjunction(condition)) {\n        const left = buildPredicate(condition.left);\n        const right = buildPredicate(condition.right);\n        return (args) => (left(args) || right(args));\n    }\n    else if (isConjunction(condition)) {\n        const left = buildPredicate(condition.left);\n        const right = buildPredicate(condition.right);\n        return (args) => (left(args) && right(args));\n    }\n    else if (isNegation(condition)) {\n        const value = buildPredicate(condition.value);\n        return (args) => !value(args);\n    }\n    else if (isParameterReference(condition)) {\n        const name = condition.parameter.ref.name;\n        return (args) => args !== undefined && args[name] === true;\n    }\n    else if (isBooleanLiteral(condition)) {\n        const value = Boolean(condition.true);\n        return () => value;\n    }\n    assertUnreachable(condition);\n}\nfunction buildAlternatives(ctx, alternatives) {\n    if (alternatives.elements.length === 1) {\n        return buildElement(ctx, alternatives.elements[0]);\n    }\n    else {\n        const methods = [];\n        for (const element of alternatives.elements) {\n            const predicatedMethod = {\n                // Since we handle the guard condition in the alternative already\n                // We can ignore the group guard condition inside\n                ALT: buildElement(ctx, element, true)\n            };\n            const guard = getGuardCondition(element);\n            if (guard) {\n                predicatedMethod.GATE = buildPredicate(guard);\n            }\n            methods.push(predicatedMethod);\n        }\n        const idx = ctx.or++;\n        return (args) => ctx.parser.alternatives(idx, methods.map(method => {\n            const alt = {\n                ALT: () => method.ALT(args)\n            };\n            const gate = method.GATE;\n            if (gate) {\n                alt.GATE = () => gate(args);\n            }\n            return alt;\n        }));\n    }\n}\nfunction buildUnorderedGroup(ctx, group) {\n    if (group.elements.length === 1) {\n        return buildElement(ctx, group.elements[0]);\n    }\n    const methods = [];\n    for (const element of group.elements) {\n        const predicatedMethod = {\n            // Since we handle the guard condition in the alternative already\n            // We can ignore the group guard condition inside\n            ALT: buildElement(ctx, element, true)\n        };\n        const guard = getGuardCondition(element);\n        if (guard) {\n            predicatedMethod.GATE = buildPredicate(guard);\n        }\n        methods.push(predicatedMethod);\n    }\n    const orIdx = ctx.or++;\n    const idFunc = (groupIdx, lParser) => {\n        const stackId = lParser.getRuleStack().join('-');\n        return `uGroup_${groupIdx}_${stackId}`;\n    };\n    const alternatives = (args) => ctx.parser.alternatives(orIdx, methods.map((method, idx) => {\n        const alt = { ALT: () => true };\n        const parser = ctx.parser;\n        alt.ALT = () => {\n            method.ALT(args);\n            if (!parser.isRecording()) {\n                const key = idFunc(orIdx, parser);\n                if (!parser.unorderedGroups.get(key)) {\n                    // init after clear state\n                    parser.unorderedGroups.set(key, []);\n                }\n                const groupState = parser.unorderedGroups.get(key);\n                if (typeof groupState?.[idx] === 'undefined') {\n                    // Not accessed yet\n                    groupState[idx] = true;\n                }\n            }\n        };\n        const gate = method.GATE;\n        if (gate) {\n            alt.GATE = () => gate(args);\n        }\n        else {\n            alt.GATE = () => {\n                const trackedAlternatives = parser.unorderedGroups.get(idFunc(orIdx, parser));\n                const allow = !trackedAlternatives?.[idx];\n                return allow;\n            };\n        }\n        return alt;\n    }));\n    const wrapped = wrap(ctx, getGuardCondition(group), alternatives, '*');\n    return (args) => {\n        wrapped(args);\n        if (!ctx.parser.isRecording()) {\n            ctx.parser.unorderedGroups.delete(idFunc(orIdx, ctx.parser));\n        }\n    };\n}\nfunction buildGroup(ctx, group) {\n    const methods = group.elements.map(e => buildElement(ctx, e));\n    return (args) => methods.forEach(method => method(args));\n}\nfunction getGuardCondition(element) {\n    if (isGroup(element)) {\n        return element.guardCondition;\n    }\n    return undefined;\n}\nfunction buildCrossReference(ctx, crossRef, terminal = crossRef.terminal) {\n    if (!terminal) {\n        if (!crossRef.type.ref) {\n            throw new Error('Could not resolve reference to type: ' + crossRef.type.$refText);\n        }\n        const assignment = findNameAssignment(crossRef.type.ref);\n        const assignTerminal = assignment?.terminal;\n        if (!assignTerminal) {\n            throw new Error('Could not find name assignment for type: ' + getTypeName(crossRef.type.ref));\n        }\n        return buildCrossReference(ctx, crossRef, assignTerminal);\n    }\n    else if (isRuleCall(terminal) && isParserRule(terminal.rule.ref)) {\n        // The terminal is a data type rule here. Everything else will result in a validation error.\n        const rule = terminal.rule.ref;\n        const idx = ctx.subrule++;\n        let subrule;\n        return (args) => {\n            subrule ?? (subrule = getRule(ctx, rule));\n            ctx.parser.subrule(idx, subrule, false, crossRef, args);\n        };\n    }\n    else if (isRuleCall(terminal) && isTerminalRule(terminal.rule.ref)) {\n        const idx = ctx.consume++;\n        const terminalRule = getToken(ctx, terminal.rule.ref.name);\n        return () => ctx.parser.consume(idx, terminalRule, crossRef);\n    }\n    else if (isKeyword(terminal)) {\n        const idx = ctx.consume++;\n        const keyword = getToken(ctx, terminal.value);\n        return () => ctx.parser.consume(idx, keyword, crossRef);\n    }\n    else {\n        throw new Error('Could not build cross reference parser');\n    }\n}\nfunction buildKeyword(ctx, keyword) {\n    const idx = ctx.consume++;\n    const token = ctx.tokens[keyword.value];\n    if (!token) {\n        throw new Error('Could not find token for keyword: ' + keyword.value);\n    }\n    return () => ctx.parser.consume(idx, token, keyword);\n}\nfunction wrap(ctx, guard, method, cardinality) {\n    const gate = guard && buildPredicate(guard);\n    if (!cardinality) {\n        if (gate) {\n            const idx = ctx.or++;\n            return (args) => ctx.parser.alternatives(idx, [\n                {\n                    ALT: () => method(args),\n                    GATE: () => gate(args)\n                },\n                {\n                    ALT: EMPTY_ALT(),\n                    GATE: () => !gate(args)\n                }\n            ]);\n        }\n        else {\n            return method;\n        }\n    }\n    if (cardinality === '*') {\n        const idx = ctx.many++;\n        return (args) => ctx.parser.many(idx, {\n            DEF: () => method(args),\n            GATE: gate ? () => gate(args) : undefined\n        });\n    }\n    else if (cardinality === '+') {\n        const idx = ctx.many++;\n        if (gate) {\n            const orIdx = ctx.or++;\n            // In the case of a guard condition for the `+` group\n            // We combine it with an empty alternative\n            // If the condition returns true, it needs to parse at least a single iteration\n            // If its false, it is not allowed to parse anything\n            return (args) => ctx.parser.alternatives(orIdx, [\n                {\n                    ALT: () => ctx.parser.atLeastOne(idx, {\n                        DEF: () => method(args)\n                    }),\n                    GATE: () => gate(args)\n                },\n                {\n                    ALT: EMPTY_ALT(),\n                    GATE: () => !gate(args)\n                }\n            ]);\n        }\n        else {\n            return (args) => ctx.parser.atLeastOne(idx, {\n                DEF: () => method(args),\n            });\n        }\n    }\n    else if (cardinality === '?') {\n        const idx = ctx.optional++;\n        return (args) => ctx.parser.optional(idx, {\n            DEF: () => method(args),\n            GATE: gate ? () => gate(args) : undefined\n        });\n    }\n    else {\n        assertUnreachable(cardinality);\n    }\n}\nfunction getRule(ctx, element) {\n    const name = getRuleName(ctx, element);\n    const rule = ctx.parser.getRule(name);\n    if (!rule)\n        throw new Error(`Rule \"${name}\" not found.\"`);\n    return rule;\n}\nfunction getRuleName(ctx, element) {\n    if (isAbstractParserRule(element)) {\n        return element.name;\n    }\n    else if (ctx.ruleNames.has(element)) {\n        return ctx.ruleNames.get(element);\n    }\n    else {\n        let item = element;\n        let parent = item.$container;\n        let ruleName = element.$type;\n        while (!isParserRule(parent)) {\n            if (isGroup(parent) || isAlternatives(parent) || isUnorderedGroup(parent)) {\n                const index = parent.elements.indexOf(item);\n                ruleName = index.toString() + ':' + ruleName;\n            }\n            item = parent;\n            parent = parent.$container;\n        }\n        const rule = parent;\n        ruleName = rule.name + ':' + ruleName;\n        ctx.ruleNames.set(element, ruleName);\n        return ruleName;\n    }\n}\nfunction getToken(ctx, name) {\n    const token = ctx.tokens[name];\n    if (!token)\n        throw new Error(`Token \"${name}\" not found.\"`);\n    return token;\n}\n//# sourceMappingURL=parser-builder-base.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { LangiumCompletionParser } from './langium-parser.js';\nimport { createParser } from './parser-builder-base.js';\nexport function createCompletionParser(services) {\n    const grammar = services.Grammar;\n    const lexer = services.parser.Lexer;\n    const parser = new LangiumCompletionParser(services);\n    createParser(grammar, parser, lexer.definition);\n    parser.finalize();\n    return parser;\n}\n//# sourceMappingURL=completion-parser-builder.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { LangiumParser } from './langium-parser.js';\nimport { createParser } from './parser-builder-base.js';\n/**\n * Create and finalize a Langium parser. The parser rules are derived from the grammar, which is\n * available at `services.Grammar`.\n */\nexport function createLangiumParser(services) {\n    const parser = prepareLangiumParser(services);\n    parser.finalize();\n    return parser;\n}\n/**\n * Create a Langium parser without finalizing it. This is used to extract more detailed error\n * information when the parser is initially validated.\n */\nexport function prepareLangiumParser(services) {\n    const grammar = services.Grammar;\n    const lexer = services.parser.Lexer;\n    const parser = new LangiumParser(services);\n    return createParser(grammar, parser, lexer.definition);\n}\n//# sourceMappingURL=langium-parser-builder.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { CancellationToken, CancellationTokenSource } from '../utils/cancellation.js';\n/**\n * Delays the execution of the current code to the next tick of the event loop.\n * Don't call this method directly in a tight loop to prevent too many promises from being created.\n */\nexport function delayNextTick() {\n    return new Promise(resolve => {\n        // In case we are running in a non-node environment, `setImmediate` isn't available.\n        // Using `setTimeout` of the browser API accomplishes the same result.\n        if (typeof setImmediate === 'undefined') {\n            setTimeout(resolve, 0);\n        }\n        else {\n            setImmediate(resolve);\n        }\n    });\n}\nlet lastTick = 0;\nlet globalInterruptionPeriod = 10;\n/**\n * Reset the global interruption period and create a cancellation token source.\n */\nexport function startCancelableOperation() {\n    lastTick = performance.now();\n    return new CancellationTokenSource();\n}\n/**\n * Change the period duration for `interruptAndCheck` to the given number of milliseconds.\n * The default value is 10ms.\n */\nexport function setInterruptionPeriod(period) {\n    globalInterruptionPeriod = period;\n}\n/**\n * This symbol may be thrown in an asynchronous context by any Langium service that receives\n * a `CancellationToken`. This means that the promise returned by such a service is rejected with\n * this symbol as rejection reason.\n */\nexport const OperationCancelled = Symbol('OperationCancelled');\n/**\n * Use this in a `catch` block to check whether the thrown object indicates that the operation\n * has been cancelled.\n */\nexport function isOperationCancelled(err) {\n    return err === OperationCancelled;\n}\n/**\n * This function does two things:\n *  1. Check the elapsed time since the last call to this function or to `startCancelableOperation`. If the predefined\n *     period (configured with `setInterruptionPeriod`) is exceeded, execution is delayed with `delayNextTick`.\n *  2. If the predefined period is not met yet or execution is resumed after an interruption, the given cancellation\n *     token is checked, and if cancellation is requested, `OperationCanceled` is thrown.\n *\n * All services in Langium that receive a `CancellationToken` may potentially call this function, so the\n * `CancellationToken` must be caught (with an `async` try-catch block or a `catch` callback attached to\n * the promise) to avoid that event being exposed as an error.\n */\nexport async function interruptAndCheck(token) {\n    if (token === CancellationToken.None) {\n        // Early exit in case cancellation was disabled by the caller\n        return;\n    }\n    const current = performance.now();\n    if (current - lastTick >= globalInterruptionPeriod) {\n        lastTick = current;\n        await delayNextTick();\n        // prevent calling delayNextTick every iteration of loop\n        // where delayNextTick takes up the majority or all of the\n        // globalInterruptionPeriod itself\n        lastTick = performance.now();\n    }\n    if (token.isCancellationRequested) {\n        throw OperationCancelled;\n    }\n}\n/**\n * Simple implementation of the deferred pattern.\n * An object that exposes a promise and functions to resolve and reject it.\n */\nexport class Deferred {\n    constructor() {\n        this.promise = new Promise((resolve, reject) => {\n            this.resolve = (arg) => {\n                resolve(arg);\n                return this;\n            };\n            this.reject = (err) => {\n                reject(err);\n                return this;\n            };\n        });\n    }\n}\n//# sourceMappingURL=promise-utils.js.map","/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\n'use strict';\nclass FullTextDocument {\n    constructor(uri, languageId, version, content) {\n        this._uri = uri;\n        this._languageId = languageId;\n        this._version = version;\n        this._content = content;\n        this._lineOffsets = undefined;\n    }\n    get uri() {\n        return this._uri;\n    }\n    get languageId() {\n        return this._languageId;\n    }\n    get version() {\n        return this._version;\n    }\n    getText(range) {\n        if (range) {\n            const start = this.offsetAt(range.start);\n            const end = this.offsetAt(range.end);\n            return this._content.substring(start, end);\n        }\n        return this._content;\n    }\n    update(changes, version) {\n        for (const change of changes) {\n            if (FullTextDocument.isIncremental(change)) {\n                // makes sure start is before end\n                const range = getWellformedRange(change.range);\n                // update content\n                const startOffset = this.offsetAt(range.start);\n                const endOffset = this.offsetAt(range.end);\n                this._content = this._content.substring(0, startOffset) + change.text + this._content.substring(endOffset, this._content.length);\n                // update the offsets\n                const startLine = Math.max(range.start.line, 0);\n                const endLine = Math.max(range.end.line, 0);\n                let lineOffsets = this._lineOffsets;\n                const addedLineOffsets = computeLineOffsets(change.text, false, startOffset);\n                if (endLine - startLine === addedLineOffsets.length) {\n                    for (let i = 0, len = addedLineOffsets.length; i < len; i++) {\n                        lineOffsets[i + startLine + 1] = addedLineOffsets[i];\n                    }\n                }\n                else {\n                    if (addedLineOffsets.length < 10000) {\n                        lineOffsets.splice(startLine + 1, endLine - startLine, ...addedLineOffsets);\n                    }\n                    else { // avoid too many arguments for splice\n                        this._lineOffsets = lineOffsets = lineOffsets.slice(0, startLine + 1).concat(addedLineOffsets, lineOffsets.slice(endLine + 1));\n                    }\n                }\n                const diff = change.text.length - (endOffset - startOffset);\n                if (diff !== 0) {\n                    for (let i = startLine + 1 + addedLineOffsets.length, len = lineOffsets.length; i < len; i++) {\n                        lineOffsets[i] = lineOffsets[i] + diff;\n                    }\n                }\n            }\n            else if (FullTextDocument.isFull(change)) {\n                this._content = change.text;\n                this._lineOffsets = undefined;\n            }\n            else {\n                throw new Error('Unknown change event received');\n            }\n        }\n        this._version = version;\n    }\n    getLineOffsets() {\n        if (this._lineOffsets === undefined) {\n            this._lineOffsets = computeLineOffsets(this._content, true);\n        }\n        return this._lineOffsets;\n    }\n    positionAt(offset) {\n        offset = Math.max(Math.min(offset, this._content.length), 0);\n        const lineOffsets = this.getLineOffsets();\n        let low = 0, high = lineOffsets.length;\n        if (high === 0) {\n            return { line: 0, character: offset };\n        }\n        while (low < high) {\n            const mid = Math.floor((low + high) / 2);\n            if (lineOffsets[mid] > offset) {\n                high = mid;\n            }\n            else {\n                low = mid + 1;\n            }\n        }\n        // low is the least x for which the line offset is larger than the current offset\n        // or array.length if no line offset is larger than the current offset\n        const line = low - 1;\n        offset = this.ensureBeforeEOL(offset, lineOffsets[line]);\n        return { line, character: offset - lineOffsets[line] };\n    }\n    offsetAt(position) {\n        const lineOffsets = this.getLineOffsets();\n        if (position.line >= lineOffsets.length) {\n            return this._content.length;\n        }\n        else if (position.line < 0) {\n            return 0;\n        }\n        const lineOffset = lineOffsets[position.line];\n        if (position.character <= 0) {\n            return lineOffset;\n        }\n        const nextLineOffset = (position.line + 1 < lineOffsets.length) ? lineOffsets[position.line + 1] : this._content.length;\n        const offset = Math.min(lineOffset + position.character, nextLineOffset);\n        return this.ensureBeforeEOL(offset, lineOffset);\n    }\n    ensureBeforeEOL(offset, lineOffset) {\n        while (offset > lineOffset && isEOL(this._content.charCodeAt(offset - 1))) {\n            offset--;\n        }\n        return offset;\n    }\n    get lineCount() {\n        return this.getLineOffsets().length;\n    }\n    static isIncremental(event) {\n        const candidate = event;\n        return candidate !== undefined && candidate !== null &&\n            typeof candidate.text === 'string' && candidate.range !== undefined &&\n            (candidate.rangeLength === undefined || typeof candidate.rangeLength === 'number');\n    }\n    static isFull(event) {\n        const candidate = event;\n        return candidate !== undefined && candidate !== null &&\n            typeof candidate.text === 'string' && candidate.range === undefined && candidate.rangeLength === undefined;\n    }\n}\nexport var TextDocument;\n(function (TextDocument) {\n    /**\n     * Creates a new text document.\n     *\n     * @param uri The document's uri.\n     * @param languageId  The document's language Id.\n     * @param version The document's initial version number.\n     * @param content The document's content.\n     */\n    function create(uri, languageId, version, content) {\n        return new FullTextDocument(uri, languageId, version, content);\n    }\n    TextDocument.create = create;\n    /**\n     * Updates a TextDocument by modifying its content.\n     *\n     * @param document the document to update. Only documents created by TextDocument.create are valid inputs.\n     * @param changes the changes to apply to the document.\n     * @param version the changes version for the document.\n     * @returns The updated TextDocument. Note: That's the same document instance passed in as first parameter.\n     *\n     */\n    function update(document, changes, version) {\n        if (document instanceof FullTextDocument) {\n            document.update(changes, version);\n            return document;\n        }\n        else {\n            throw new Error('TextDocument.update: document must be created by TextDocument.create');\n        }\n    }\n    TextDocument.update = update;\n    function applyEdits(document, edits) {\n        const text = document.getText();\n        const sortedEdits = mergeSort(edits.map(getWellformedEdit), (a, b) => {\n            const diff = a.range.start.line - b.range.start.line;\n            if (diff === 0) {\n                return a.range.start.character - b.range.start.character;\n            }\n            return diff;\n        });\n        let lastModifiedOffset = 0;\n        const spans = [];\n        for (const e of sortedEdits) {\n            const startOffset = document.offsetAt(e.range.start);\n            if (startOffset < lastModifiedOffset) {\n                throw new Error('Overlapping edit');\n            }\n            else if (startOffset > lastModifiedOffset) {\n                spans.push(text.substring(lastModifiedOffset, startOffset));\n            }\n            if (e.newText.length) {\n                spans.push(e.newText);\n            }\n            lastModifiedOffset = document.offsetAt(e.range.end);\n        }\n        spans.push(text.substr(lastModifiedOffset));\n        return spans.join('');\n    }\n    TextDocument.applyEdits = applyEdits;\n})(TextDocument || (TextDocument = {}));\nfunction mergeSort(data, compare) {\n    if (data.length <= 1) {\n        // sorted\n        return data;\n    }\n    const p = (data.length / 2) | 0;\n    const left = data.slice(0, p);\n    const right = data.slice(p);\n    mergeSort(left, compare);\n    mergeSort(right, compare);\n    let leftIdx = 0;\n    let rightIdx = 0;\n    let i = 0;\n    while (leftIdx < left.length && rightIdx < right.length) {\n        const ret = compare(left[leftIdx], right[rightIdx]);\n        if (ret <= 0) {\n            // smaller_equal -> take left to preserve order\n            data[i++] = left[leftIdx++];\n        }\n        else {\n            // greater -> take right\n            data[i++] = right[rightIdx++];\n        }\n    }\n    while (leftIdx < left.length) {\n        data[i++] = left[leftIdx++];\n    }\n    while (rightIdx < right.length) {\n        data[i++] = right[rightIdx++];\n    }\n    return data;\n}\nfunction computeLineOffsets(text, isAtLineStart, textOffset = 0) {\n    const result = isAtLineStart ? [textOffset] : [];\n    for (let i = 0; i < text.length; i++) {\n        const ch = text.charCodeAt(i);\n        if (isEOL(ch)) {\n            if (ch === 13 /* CharCode.CarriageReturn */ && i + 1 < text.length && text.charCodeAt(i + 1) === 10 /* CharCode.LineFeed */) {\n                i++;\n            }\n            result.push(textOffset + i + 1);\n        }\n    }\n    return result;\n}\nfunction isEOL(char) {\n    return char === 13 /* CharCode.CarriageReturn */ || char === 10 /* CharCode.LineFeed */;\n}\nfunction getWellformedRange(range) {\n    const start = range.start;\n    const end = range.end;\n    if (start.line > end.line || (start.line === end.line && start.character > end.character)) {\n        return { start: end, end: start };\n    }\n    return range;\n}\nfunction getWellformedEdit(textEdit) {\n    const range = getWellformedRange(textEdit.range);\n    if (range !== textEdit.range) {\n        return { newText: textEdit.newText, range };\n    }\n    return textEdit;\n}\n","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { URI, Utils } from 'vscode-uri';\nexport { URI };\nexport var UriUtils;\n(function (UriUtils) {\n    UriUtils.basename = Utils.basename;\n    UriUtils.dirname = Utils.dirname;\n    UriUtils.extname = Utils.extname;\n    UriUtils.joinPath = Utils.joinPath;\n    UriUtils.resolvePath = Utils.resolvePath;\n    const isWindows = typeof process === 'object' && process?.platform === 'win32';\n    function equals(a, b) {\n        return a?.toString() === b?.toString();\n    }\n    UriUtils.equals = equals;\n    function relative(from, to) {\n        const fromPath = typeof from === 'string' ? URI.parse(from).path : from.path;\n        const toPath = typeof to === 'string' ? URI.parse(to).path : to.path;\n        const fromParts = fromPath.split('/').filter(e => e.length > 0);\n        const toParts = toPath.split('/').filter(e => e.length > 0);\n        if (isWindows) {\n            const upperCaseDriveLetter = /^[A-Z]:$/;\n            if (fromParts[0] && upperCaseDriveLetter.test(fromParts[0])) {\n                fromParts[0] = fromParts[0].toLowerCase();\n            }\n            if (toParts[0] && upperCaseDriveLetter.test(toParts[0])) {\n                toParts[0] = toParts[0].toLowerCase();\n            }\n            if (fromParts[0] !== toParts[0]) {\n                // in case of different drive letters, we cannot compute a relative path, so...\n                return toPath.substring(1); // fall back to full 'to' path, drop the leading '/', keep everything else as is for good comparability\n            }\n        }\n        let i = 0;\n        for (; i < fromParts.length; i++) {\n            if (fromParts[i] !== toParts[i]) {\n                break;\n            }\n        }\n        const backPart = '../'.repeat(fromParts.length - i);\n        const toPart = toParts.slice(i).join('/');\n        return backPart + toPart;\n    }\n    UriUtils.relative = relative;\n    function normalize(uri) {\n        return URI.parse(uri.toString()).toString();\n    }\n    UriUtils.normalize = normalize;\n    function contains(parent, child) {\n        let parentPath = typeof parent === 'string' ? parent : parent.path;\n        let childPath = typeof child === 'string' ? child : child.path;\n        // Trim trailing slashes\n        if (childPath.charAt(childPath.length - 1) === '/') {\n            childPath = childPath.slice(0, -1);\n        }\n        if (parentPath.charAt(parentPath.length - 1) === '/') {\n            parentPath = parentPath.slice(0, -1);\n        }\n        // If the paths are equal, simply return true\n        if (childPath === parentPath) {\n            return true;\n        }\n        // If the child path is shorter than the parent path, it can't be a child\n        if (childPath.length < parentPath.length) {\n            return false;\n        }\n        // If the path does not feature a slash after the parent path, it can't be a child\n        if (childPath.charAt(parentPath.length) !== '/') {\n            return false;\n        }\n        // Check if the child path starts with the parent path\n        return childPath.startsWith(parentPath);\n    }\n    UriUtils.contains = contains;\n})(UriUtils || (UriUtils = {}));\n/**\n * A trie structure for URIs. It allows to insert, delete and find elements by their URI.\n * More specifically, it allows to efficiently find all elements that are children of a given URI.\n *\n * Unlike a regular trie, this implementation uses the name of the URI segments as keys.\n *\n * @see {@link https://en.wikipedia.org/wiki/Trie}\n */\nexport class UriTrie {\n    constructor() {\n        this.root = { name: '', children: new Map() };\n    }\n    normalizeUri(uri) {\n        return UriUtils.normalize(uri);\n    }\n    clear() {\n        this.root.children.clear();\n    }\n    insert(uri, element) {\n        const node = this.getNode(this.normalizeUri(uri), true);\n        node.element = element;\n    }\n    delete(uri) {\n        const nodeToDelete = this.getNode(this.normalizeUri(uri), false);\n        if (nodeToDelete?.parent) {\n            nodeToDelete.parent.children.delete(nodeToDelete.name);\n        }\n    }\n    has(uri) {\n        return this.getNode(this.normalizeUri(uri), false)?.element !== undefined;\n    }\n    hasNode(uri) {\n        return this.getNode(this.normalizeUri(uri), false) !== undefined;\n    }\n    find(uri) {\n        return this.getNode(this.normalizeUri(uri), false)?.element;\n    }\n    findNode(uri) {\n        const uriString = this.normalizeUri(uri);\n        const node = this.getNode(uriString, false);\n        if (!node) {\n            return undefined;\n        }\n        return {\n            name: node.name,\n            uri: UriUtils.joinPath(URI.parse(uriString), node.name).toString(),\n            element: node.element\n        };\n    }\n    findChildren(uri) {\n        const uriString = this.normalizeUri(uri);\n        const node = this.getNode(uriString, false);\n        if (!node) {\n            return [];\n        }\n        return Array.from(node.children.values()).map(child => ({\n            name: child.name,\n            uri: UriUtils.joinPath(URI.parse(uriString), child.name).toString(),\n            element: child.element\n        }));\n    }\n    all() {\n        return this.collectValues(this.root);\n    }\n    findAll(prefix) {\n        const node = this.getNode(UriUtils.normalize(prefix), false);\n        if (!node) {\n            return [];\n        }\n        return this.collectValues(node);\n    }\n    getNode(uri, create) {\n        const parts = uri.split('/');\n        if (uri.charAt(uri.length - 1) === '/') {\n            // Remove the last part if the URI ends with a slash\n            parts.pop();\n        }\n        let current = this.root;\n        for (const part of parts) {\n            let child = current.children.get(part);\n            if (!child) {\n                if (create) {\n                    child = {\n                        name: part,\n                        children: new Map(),\n                        parent: current\n                    };\n                    current.children.set(part, child);\n                }\n                else {\n                    return undefined;\n                }\n            }\n            current = child;\n        }\n        return current;\n    }\n    collectValues(node) {\n        const result = [];\n        if (node.element) {\n            result.push(node.element);\n        }\n        for (const child of node.children.values()) {\n            result.push(...this.collectValues(child));\n        }\n        return result;\n    }\n}\n//# sourceMappingURL=uri-utils.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n/**\n * Re-export 'TextDocument' from 'vscode-languageserver-textdocument' for convenience,\n *  including both type _and_ symbol (namespace), as we here and there also refer to the symbol,\n *  the overhead is very small, just a few kilobytes.\n * Everything else of that package (at the time contributing) is also defined\n *  in 'vscode-languageserver-protocol' or 'vscode-languageserver-types'.\n */\nexport { TextDocument } from 'vscode-languageserver-textdocument';\nimport { TextDocument } from './documents.js';\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { stream } from '../utils/stream.js';\nimport { URI, UriTrie } from '../utils/uri-utils.js';\n/**\n * A document is subject to several phases that are run in predefined order. Any state value implies that\n * smaller state values are finished as well.\n */\nexport var DocumentState;\n(function (DocumentState) {\n    /**\n     * The text content has changed and needs to be parsed again. The AST held by this outdated\n     * document instance is no longer valid.\n     */\n    DocumentState[DocumentState[\"Changed\"] = 0] = \"Changed\";\n    /**\n     * An AST has been created from the text content. The document structure can be traversed,\n     * but cross-references cannot be resolved yet. If necessary, the structure can be manipulated\n     * at this stage as a preprocessing step.\n     */\n    DocumentState[DocumentState[\"Parsed\"] = 1] = \"Parsed\";\n    /**\n     * The `IndexManager` service has processed AST nodes of this document. This means the\n     * exported symbols are available in the global scope and can be resolved from other documents.\n     */\n    DocumentState[DocumentState[\"IndexedContent\"] = 2] = \"IndexedContent\";\n    /**\n     * The `ScopeComputation` service has processed this document. This means the document's locally accessible\n     * symbols are captured in a `DocumentSymbols` table and can be looked up by the `ScopeProvider` service.\n     * Once a document has reached this state, you may follow every reference - it will lazily\n     * resolve its `ref` property and yield either the target AST node or `undefined` in case\n     * the target is not in scope.\n     */\n    DocumentState[DocumentState[\"ComputedScopes\"] = 3] = \"ComputedScopes\";\n    /**\n     * The `Linker` service has processed this document. All outgoing references have been\n     * resolved or marked as erroneous.\n     */\n    DocumentState[DocumentState[\"Linked\"] = 4] = \"Linked\";\n    /**\n     * The `IndexManager` service has processed AST node references of this document. This is\n     * necessary to determine which documents are affected by a change in one of the workspace\n     * documents.\n     */\n    DocumentState[DocumentState[\"IndexedReferences\"] = 5] = \"IndexedReferences\";\n    /**\n     * The `DocumentValidator` service has processed this document. The language server listens\n     * to the results of this phase and sends diagnostics to the client.\n     */\n    DocumentState[DocumentState[\"Validated\"] = 6] = \"Validated\";\n})(DocumentState || (DocumentState = {}));\nexport class DefaultLangiumDocumentFactory {\n    constructor(services) {\n        this.serviceRegistry = services.ServiceRegistry;\n        this.textDocuments = services.workspace.TextDocuments;\n        this.fileSystemProvider = services.workspace.FileSystemProvider;\n    }\n    async fromUri(uri, cancellationToken = CancellationToken.None) {\n        const content = await this.fileSystemProvider.readFile(uri);\n        return this.createAsync(uri, content, cancellationToken);\n    }\n    fromTextDocument(textDocument, uri, token) {\n        uri = uri ?? URI.parse(textDocument.uri);\n        if (CancellationToken.is(token)) {\n            return this.createAsync(uri, textDocument, token);\n        }\n        else {\n            return this.create(uri, textDocument, token);\n        }\n    }\n    fromString(text, uri, token) {\n        if (CancellationToken.is(token)) {\n            return this.createAsync(uri, text, token);\n        }\n        else {\n            return this.create(uri, text, token);\n        }\n    }\n    fromModel(model, uri) {\n        return this.create(uri, { $model: model });\n    }\n    create(uri, content, options) {\n        if (typeof content === 'string') {\n            const parseResult = this.parse(uri, content, options);\n            return this.createLangiumDocument(parseResult, uri, undefined, content);\n        }\n        else if ('$model' in content) {\n            const parseResult = { value: content.$model, parserErrors: [], lexerErrors: [] };\n            return this.createLangiumDocument(parseResult, uri);\n        }\n        else {\n            const parseResult = this.parse(uri, content.getText(), options);\n            return this.createLangiumDocument(parseResult, uri, content);\n        }\n    }\n    async createAsync(uri, content, cancelToken) {\n        if (typeof content === 'string') {\n            const parseResult = await this.parseAsync(uri, content, cancelToken);\n            return this.createLangiumDocument(parseResult, uri, undefined, content);\n        }\n        else {\n            const parseResult = await this.parseAsync(uri, content.getText(), cancelToken);\n            return this.createLangiumDocument(parseResult, uri, content);\n        }\n    }\n    /**\n     * Create a LangiumDocument from a given parse result.\n     *\n     * A TextDocument is created on demand if it is not provided as argument here. Usually this\n     * should not be necessary because the main purpose of the TextDocument is to convert between\n     * text ranges and offsets, which is done solely in LSP request handling.\n     *\n     * With the introduction of {@link update} below this method is supposed to be mainly called\n     * during workspace initialization and on addition/recognition of new files, while changes in\n     * existing documents are processed via {@link update}.\n     */\n    createLangiumDocument(parseResult, uri, textDocument, text) {\n        let document;\n        if (textDocument) {\n            document = {\n                parseResult,\n                uri,\n                state: DocumentState.Parsed,\n                references: [],\n                textDocument\n            };\n        }\n        else {\n            const textDocumentGetter = this.createTextDocumentGetter(uri, text);\n            document = {\n                parseResult,\n                uri,\n                state: DocumentState.Parsed,\n                references: [],\n                get textDocument() {\n                    return textDocumentGetter();\n                }\n            };\n        }\n        parseResult.value.$document = document;\n        return document;\n    }\n    async update(document, cancellationToken) {\n        // The CST full text property contains the original text that was used to create the AST.\n        const oldText = document.parseResult.value.$cstNode?.root.fullText;\n        const textDocument = this.textDocuments?.get(document.uri.toString());\n        const text = textDocument ? textDocument.getText() : await this.fileSystemProvider.readFile(document.uri);\n        if (textDocument) {\n            Object.defineProperty(document, 'textDocument', {\n                value: textDocument\n            });\n        }\n        else {\n            const textDocumentGetter = this.createTextDocumentGetter(document.uri, text);\n            Object.defineProperty(document, 'textDocument', {\n                get: textDocumentGetter\n            });\n        }\n        // Some of these documents can be pretty large, so parsing them again can be quite expensive.\n        // Therefore, we only parse if the text has actually changed.\n        if (oldText !== text) {\n            document.parseResult = await this.parseAsync(document.uri, text, cancellationToken);\n            document.parseResult.value.$document = document;\n        }\n        document.state = DocumentState.Parsed;\n        return document;\n    }\n    parse(uri, text, options) {\n        const services = this.serviceRegistry.getServices(uri);\n        return services.parser.LangiumParser.parse(text, options);\n    }\n    parseAsync(uri, text, cancellationToken) {\n        const services = this.serviceRegistry.getServices(uri);\n        return services.parser.AsyncParser.parse(text, cancellationToken);\n    }\n    createTextDocumentGetter(uri, text) {\n        const serviceRegistry = this.serviceRegistry;\n        let textDoc = undefined;\n        return () => {\n            return textDoc ?? (textDoc = TextDocument.create(uri.toString(), serviceRegistry.getServices(uri).LanguageMetaData.languageId, 0, text ?? ''));\n        };\n    }\n}\nexport class DefaultLangiumDocuments {\n    constructor(services) {\n        this.documentTrie = new UriTrie();\n        this.services = services;\n        this.langiumDocumentFactory = services.workspace.LangiumDocumentFactory;\n        this.documentBuilder = () => services.workspace.DocumentBuilder;\n    }\n    get all() {\n        return stream(this.documentTrie.all());\n    }\n    addDocument(document) {\n        const uriString = document.uri.toString();\n        if (this.documentTrie.has(uriString)) {\n            throw new Error(`A document with the URI '${uriString}' is already present.`);\n        }\n        this.documentTrie.insert(uriString, document);\n    }\n    getDocument(uri) {\n        const uriString = uri.toString();\n        return this.documentTrie.find(uriString);\n    }\n    getDocuments(folder) {\n        const uriString = folder.toString();\n        return this.documentTrie.findAll(uriString);\n    }\n    async getOrCreateDocument(uri, cancellationToken) {\n        let document = this.getDocument(uri);\n        if (document) {\n            return document;\n        }\n        document = await this.langiumDocumentFactory.fromUri(uri, cancellationToken);\n        this.addDocument(document);\n        return document;\n    }\n    createDocument(uri, text, cancellationToken) {\n        if (cancellationToken) {\n            return this.langiumDocumentFactory.fromString(text, uri, cancellationToken).then(document => {\n                this.addDocument(document);\n                return document;\n            });\n        }\n        else {\n            const document = this.langiumDocumentFactory.fromString(text, uri);\n            this.addDocument(document);\n            return document;\n        }\n    }\n    hasDocument(uri) {\n        return this.documentTrie.has(uri.toString());\n    }\n    /**\n     * @deprecated Since 4.2 use `DocumentBuilder.resetToState(DocumentState.Changed)` instead\n     * TODO remove this for the next major release\n     */\n    invalidateDocument(uri) {\n        const uriString = uri.toString();\n        const langiumDoc = this.documentTrie.find(uriString);\n        if (langiumDoc) {\n            this.documentBuilder().resetToState(langiumDoc, DocumentState.Changed);\n        }\n        return langiumDoc;\n    }\n    deleteDocument(uri) {\n        const uriString = uri.toString();\n        const langiumDoc = this.documentTrie.find(uriString);\n        if (langiumDoc) {\n            langiumDoc.state = DocumentState.Changed;\n            this.documentTrie.delete(uriString);\n        }\n        return langiumDoc;\n    }\n    deleteDocuments(folder) {\n        const uriString = folder.toString();\n        const langiumDocs = this.documentTrie.findAll(uriString);\n        for (const langiumDoc of langiumDocs) {\n            langiumDoc.state = DocumentState.Changed;\n        }\n        this.documentTrie.delete(uriString);\n        return langiumDocs;\n    }\n}\n//# sourceMappingURL=documents.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { isAstNode, isAstNodeDescription, isLinkingError } from '../syntax-tree.js';\nimport { findRootNode, streamAst, streamReferences } from '../utils/ast-utils.js';\nimport { interruptAndCheck } from '../utils/promise-utils.js';\nimport { DocumentState } from '../workspace/documents.js';\nexport const RefResolving = Symbol('RefResolving');\nexport class DefaultLinker {\n    constructor(services) {\n        this.reflection = services.shared.AstReflection;\n        this.langiumDocuments = () => services.shared.workspace.LangiumDocuments;\n        this.scopeProvider = services.references.ScopeProvider;\n        this.astNodeLocator = services.workspace.AstNodeLocator;\n        this.profiler = services.shared.profilers.LangiumProfiler;\n        this.languageId = services.LanguageMetaData.languageId;\n    }\n    async link(document, cancelToken = CancellationToken.None) {\n        if (this.profiler?.isActive('linking')) {\n            const task = this.profiler.createTask('linking', this.languageId);\n            task.start();\n            try {\n                for (const node of streamAst(document.parseResult.value)) {\n                    await interruptAndCheck(cancelToken);\n                    streamReferences(node).forEach(ref => {\n                        const name = `${node.$type}:${ref.property}`;\n                        task.startSubTask(name);\n                        try {\n                            this.doLink(ref, document);\n                        }\n                        finally {\n                            task.stopSubTask(name);\n                        }\n                    });\n                }\n            }\n            finally {\n                task.stop();\n            }\n        }\n        else {\n            for (const node of streamAst(document.parseResult.value)) {\n                await interruptAndCheck(cancelToken);\n                streamReferences(node).forEach(ref => this.doLink(ref, document));\n            }\n        }\n    }\n    doLink(refInfo, document) {\n        const ref = refInfo.reference;\n        // The reference may already have been resolved lazily by accessing its `ref` property.\n        if ('_ref' in ref && ref._ref === undefined) {\n            ref._ref = RefResolving;\n            try {\n                const description = this.getCandidate(refInfo);\n                if (isLinkingError(description)) {\n                    ref._ref = description;\n                }\n                else {\n                    ref._nodeDescription = description;\n                    const linkedNode = this.loadAstNode(description);\n                    ref._ref = linkedNode ?? this.createLinkingError(refInfo, description);\n                }\n            }\n            catch (err) {\n                console.error(`An error occurred while resolving reference to '${ref.$refText}':`, err);\n                const errorMessage = err.message ?? String(err);\n                ref._ref = {\n                    info: refInfo,\n                    message: `An error occurred while resolving reference to '${ref.$refText}': ${errorMessage}`\n                };\n            }\n            document.references.push(ref);\n        }\n        else if ('_items' in ref && ref._items === undefined) {\n            ref._items = RefResolving;\n            try {\n                const descriptions = this.getCandidates(refInfo);\n                const items = [];\n                if (isLinkingError(descriptions)) {\n                    ref._linkingError = descriptions;\n                }\n                else {\n                    for (const description of descriptions) {\n                        const linkedNode = this.loadAstNode(description);\n                        if (linkedNode) {\n                            items.push({ ref: linkedNode, $nodeDescription: description });\n                        }\n                    }\n                }\n                ref._items = items;\n            }\n            catch (err) {\n                ref._linkingError = {\n                    info: refInfo,\n                    message: `An error occurred while resolving reference to '${ref.$refText}': ${err}`\n                };\n                ref._items = [];\n            }\n            document.references.push(ref);\n        }\n    }\n    unlink(document) {\n        for (const ref of document.references) {\n            if ('_ref' in ref) {\n                ref._ref = undefined;\n                delete ref._nodeDescription;\n            }\n            else if ('_items' in ref) {\n                ref._items = undefined;\n                delete ref._linkingError;\n            }\n        }\n        document.references = [];\n    }\n    getCandidate(refInfo) {\n        const scope = this.scopeProvider.getScope(refInfo);\n        const description = scope.getElement(refInfo.reference.$refText);\n        return description ?? this.createLinkingError(refInfo);\n    }\n    getCandidates(refInfo) {\n        const scope = this.scopeProvider.getScope(refInfo);\n        const descriptions = scope.getElements(refInfo.reference.$refText).distinct(desc => `${desc.documentUri}#${desc.path}`).toArray();\n        return descriptions.length > 0 ? descriptions : this.createLinkingError(refInfo);\n    }\n    buildReference(node, property, refNode, refText) {\n        // See behavior description in doc of Linker, update that on changes in here.\n        // eslint-disable-next-line @typescript-eslint/no-this-alias\n        const linker = this;\n        const reference = {\n            $refNode: refNode,\n            $refText: refText,\n            _ref: undefined,\n            get ref() {\n                if (isAstNode(this._ref)) {\n                    // Most frequent case: the target is already resolved.\n                    return this._ref;\n                }\n                else if (isAstNodeDescription(this._nodeDescription)) {\n                    // A candidate has been found before, but it is not loaded yet.\n                    const linkedNode = linker.loadAstNode(this._nodeDescription);\n                    this._ref = linkedNode ??\n                        linker.createLinkingError({ reference, container: node, property }, this._nodeDescription);\n                }\n                else if (this._ref === undefined) {\n                    // The reference has not been linked yet, so do that now.\n                    this._ref = RefResolving;\n                    const document = findRootNode(node).$document;\n                    const refData = linker.getLinkedNode({ reference, container: node, property });\n                    if (refData.error && document && document.state < DocumentState.ComputedScopes) {\n                        // Document scope is not ready, don't set `this._ref` so linker can retry later.\n                        return this._ref = undefined;\n                    }\n                    this._ref = refData.node ?? refData.error;\n                    this._nodeDescription = refData.descr;\n                    document?.references.push(this);\n                }\n                else if (this._ref === RefResolving) {\n                    linker.throwCyclicReferenceError(node, property, refText);\n                }\n                return isAstNode(this._ref) ? this._ref : undefined;\n            },\n            get $nodeDescription() {\n                return this._nodeDescription;\n            },\n            get error() {\n                return isLinkingError(this._ref) ? this._ref : undefined;\n            }\n        };\n        return reference;\n    }\n    buildMultiReference(node, property, refNode, refText) {\n        // See behavior description in doc of Linker, update that on changes in here.\n        // eslint-disable-next-line @typescript-eslint/no-this-alias\n        const linker = this;\n        const reference = {\n            $refNode: refNode,\n            $refText: refText,\n            _items: undefined,\n            get items() {\n                if (Array.isArray(this._items)) {\n                    return this._items;\n                }\n                else if (this._items === undefined) {\n                    this._items = RefResolving;\n                    const document = findRootNode(node).$document;\n                    const descriptions = linker.getCandidates({\n                        reference,\n                        container: node,\n                        property\n                    });\n                    const items = [];\n                    if (isLinkingError(descriptions)) {\n                        this._linkingError = descriptions;\n                    }\n                    else {\n                        for (const description of descriptions) {\n                            const linkedNode = linker.loadAstNode(description);\n                            if (linkedNode) {\n                                items.push({ ref: linkedNode, $nodeDescription: description });\n                            }\n                        }\n                    }\n                    this._items = items;\n                    document?.references.push(this);\n                }\n                else if (this._items === RefResolving) {\n                    linker.throwCyclicReferenceError(node, property, refText);\n                }\n                return Array.isArray(this._items) ? this._items : [];\n            },\n            get error() {\n                if (this._linkingError) {\n                    return this._linkingError;\n                }\n                const refs = this.items;\n                if (refs.length > 0) {\n                    return undefined;\n                }\n                else {\n                    return (this._linkingError = linker.createLinkingError({ reference, container: node, property }));\n                }\n            }\n        };\n        return reference;\n    }\n    throwCyclicReferenceError(node, property, refText) {\n        throw new Error(`Cyclic reference resolution detected: ${this.astNodeLocator.getAstNodePath(node)}/${property} (symbol '${refText}')`);\n    }\n    getLinkedNode(refInfo) {\n        try {\n            const description = this.getCandidate(refInfo);\n            if (isLinkingError(description)) {\n                return { error: description };\n            }\n            const linkedNode = this.loadAstNode(description);\n            if (linkedNode) {\n                return { node: linkedNode, descr: description };\n            }\n            else {\n                return {\n                    descr: description,\n                    error: this.createLinkingError(refInfo, description)\n                };\n            }\n        }\n        catch (err) {\n            console.error(`An error occurred while resolving reference to '${refInfo.reference.$refText}':`, err);\n            const errorMessage = err.message ?? String(err);\n            return {\n                error: {\n                    info: refInfo,\n                    message: `An error occurred while resolving reference to '${refInfo.reference.$refText}': ${errorMessage}`\n                }\n            };\n        }\n    }\n    loadAstNode(nodeDescription) {\n        if (nodeDescription.node) {\n            return nodeDescription.node;\n        }\n        const doc = this.langiumDocuments().getDocument(nodeDescription.documentUri);\n        if (!doc) {\n            return undefined;\n        }\n        return this.astNodeLocator.getAstNode(doc.parseResult.value, nodeDescription.path);\n    }\n    createLinkingError(refInfo, targetDescription) {\n        // Check whether the document is sufficiently processed by the DocumentBuilder. If not, this is a hint for a bug\n        // in the language implementation.\n        const document = findRootNode(refInfo.container).$document;\n        if (document && document.state < DocumentState.ComputedScopes) {\n            console.warn(`Attempted reference resolution before document reached ComputedScopes state (${document.uri}).`);\n        }\n        const referenceType = this.reflection.getReferenceType(refInfo);\n        return {\n            info: refInfo,\n            message: `Could not resolve reference to ${referenceType} named '${refInfo.reference.$refText}'.`,\n            targetDescription\n        };\n    }\n}\n//# sourceMappingURL=linker.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { findNodeForProperty } from '../utils/grammar-utils.js';\nexport function isNamed(node) {\n    return typeof node.name === 'string';\n}\nexport class DefaultNameProvider {\n    getName(node) {\n        if (isNamed(node)) {\n            return node.name;\n        }\n        return undefined;\n    }\n    getNameNode(node) {\n        return findNodeForProperty(node.$cstNode, 'name');\n    }\n}\n//# sourceMappingURL=name-provider.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { findAssignment } from '../utils/grammar-utils.js';\nimport { isMultiReference, isReference } from '../syntax-tree.js';\nimport { getDocument, getReferenceNodes, streamAst, streamReferences } from '../utils/ast-utils.js';\nimport { isChildNode, toDocumentSegment } from '../utils/cst-utils.js';\nimport { stream } from '../utils/stream.js';\nimport { UriUtils } from '../utils/uri-utils.js';\nimport { isCrossReference } from '../languages/generated/ast.js';\nexport class DefaultReferences {\n    constructor(services) {\n        this.nameProvider = services.references.NameProvider;\n        this.index = services.shared.workspace.IndexManager;\n        this.nodeLocator = services.workspace.AstNodeLocator;\n        this.documents = services.shared.workspace.LangiumDocuments;\n        this.hasMultiReference = streamAst(services.Grammar).some(node => isCrossReference(node) && node.isMulti);\n    }\n    findDeclarations(sourceCstNode) {\n        if (sourceCstNode) {\n            const assignment = findAssignment(sourceCstNode);\n            const nodeElem = sourceCstNode.astNode;\n            if (assignment && nodeElem) {\n                const reference = nodeElem[assignment.feature];\n                if (isReference(reference) || isMultiReference(reference)) {\n                    return getReferenceNodes(reference);\n                }\n                else if (Array.isArray(reference)) {\n                    for (const ref of reference) {\n                        if ((isReference(ref) || isMultiReference(ref)) && ref.$refNode\n                            && ref.$refNode.offset <= sourceCstNode.offset\n                            && ref.$refNode.end >= sourceCstNode.end) {\n                            return getReferenceNodes(ref);\n                        }\n                    }\n                }\n            }\n            if (nodeElem) {\n                const nameNode = this.nameProvider.getNameNode(nodeElem);\n                // Only return the targeted node in case the targeted cst node is the name node or part of it\n                if (nameNode && (nameNode === sourceCstNode || isChildNode(sourceCstNode, nameNode))) {\n                    return this.getSelfNodes(nodeElem);\n                }\n            }\n        }\n        return [];\n    }\n    /**\n     * Returns all self-references for the specified node.\n     * Since the node can be part of a multi-reference, this method returns all nodes that are part of the same multi-reference.\n     */\n    getSelfNodes(node) {\n        if (!this.hasMultiReference) {\n            return [node];\n        }\n        else {\n            // In order to find all nodes that are part of the same multi-reference,\n            // we need to find a reference that points to the node.\n            // It will also point to the logical siblings of the node.\n            const references = this.index.findAllReferences(node, this.nodeLocator.getAstNodePath(node));\n            // We can simply use the first reference to find all logical siblings.\n            // Looking through all references is not necessary and very inefficient.\n            const headNode = this.getNodeFromReferenceDescription(references.head());\n            if (headNode) {\n                // We need to iterate over all references to find the one that points to the node.\n                for (const ref of streamReferences(headNode)) {\n                    if (isMultiReference(ref.reference) && ref.reference.items.some(item => item.ref === node)) {\n                        // Once we found the reference, simply return all items of the multi-reference.\n                        return ref.reference.items.map(item => item.ref);\n                    }\n                }\n            }\n            return [node];\n        }\n    }\n    getNodeFromReferenceDescription(ref) {\n        if (!ref) {\n            return undefined;\n        }\n        const doc = this.documents.getDocument(ref.sourceUri);\n        if (doc) {\n            return this.nodeLocator.getAstNode(doc.parseResult.value, ref.sourcePath);\n        }\n        return undefined;\n    }\n    findDeclarationNodes(sourceCstNode) {\n        const astNodes = this.findDeclarations(sourceCstNode);\n        const cstNodes = [];\n        for (const astNode of astNodes) {\n            const cstNode = this.nameProvider.getNameNode(astNode) ?? astNode.$cstNode;\n            if (cstNode) {\n                cstNodes.push(cstNode);\n            }\n        }\n        return cstNodes;\n    }\n    findReferences(targetNode, options) {\n        const refs = [];\n        if (options.includeDeclaration) {\n            refs.push(...this.getSelfReferences(targetNode));\n        }\n        let indexReferences = this.index.findAllReferences(targetNode, this.nodeLocator.getAstNodePath(targetNode));\n        if (options.documentUri) {\n            indexReferences = indexReferences.filter(ref => UriUtils.equals(ref.sourceUri, options.documentUri));\n        }\n        refs.push(...indexReferences);\n        return stream(refs);\n    }\n    getSelfReferences(targetNode) {\n        const selfNodes = this.getSelfNodes(targetNode);\n        const references = [];\n        for (const selfNode of selfNodes) {\n            const nameNode = this.nameProvider.getNameNode(selfNode);\n            if (nameNode) {\n                const doc = getDocument(selfNode);\n                const path = this.nodeLocator.getAstNodePath(selfNode);\n                references.push({\n                    sourceUri: doc.uri,\n                    sourcePath: path,\n                    targetUri: doc.uri,\n                    targetPath: path,\n                    segment: toDocumentSegment(nameNode),\n                    local: true\n                });\n            }\n        }\n        return references;\n    }\n}\n//# sourceMappingURL=references.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { EMPTY_STREAM, Reduction, stream } from './stream.js';\n/**\n * A multimap is a variation of a Map that has potentially multiple values for every key.\n */\nexport class MultiMap {\n    constructor(elements) {\n        this.map = new Map();\n        if (elements) {\n            for (const [key, value] of elements) {\n                this.add(key, value);\n            }\n        }\n    }\n    /**\n     * The total number of values in the multimap.\n     */\n    get size() {\n        return Reduction.sum(stream(this.map.values()).map(a => a.length));\n    }\n    /**\n     * Clear all entries in the multimap.\n     */\n    clear() {\n        this.map.clear();\n    }\n    /**\n     * Operates differently depending on whether a `value` is given:\n     *  * With a value, this method deletes the specific key / value pair from the multimap.\n     *  * Without a value, all values associated with the given key are deleted.\n     *\n     * @returns `true` if a value existed and has been removed, or `false` if the specified\n     *     key / value does not exist.\n     */\n    delete(key, value) {\n        if (value === undefined) {\n            return this.map.delete(key);\n        }\n        else {\n            const values = this.map.get(key);\n            if (values) {\n                const index = values.indexOf(value);\n                if (index >= 0) {\n                    if (values.length === 1) {\n                        this.map.delete(key);\n                    }\n                    else {\n                        values.splice(index, 1);\n                    }\n                    return true;\n                }\n            }\n            return false;\n        }\n    }\n    /**\n     * Returns an array of all values associated with the given key. If no value exists,\n     * an empty array is returned.\n     *\n     * _Note:_ The returned array is assumed not to be modified. Use the `set` method to add a\n     * value and `delete` to remove a value from the multimap.\n     */\n    get(key) {\n        return this.map.get(key) ?? [];\n    }\n    /**\n     * Returns a stream of all values associated with the given key. If no value exists,\n     * {@link EMPTY_STREAM} is returned.\n     */\n    getStream(key) {\n        const values = this.map.get(key);\n        return values ? stream(values) : EMPTY_STREAM;\n    }\n    /**\n     * Operates differently depending on whether a `value` is given:\n     *  * With a value, this method returns `true` if the specific key / value pair is present in the multimap.\n     *  * Without a value, this method returns `true` if the given key is present in the multimap.\n     */\n    has(key, value) {\n        if (value === undefined) {\n            return this.map.has(key);\n        }\n        else {\n            const values = this.map.get(key);\n            if (values) {\n                return values.indexOf(value) >= 0;\n            }\n            return false;\n        }\n    }\n    /**\n     * Add the given key / value pair to the multimap.\n     */\n    add(key, value) {\n        if (this.map.has(key)) {\n            this.map.get(key).push(value);\n        }\n        else {\n            this.map.set(key, [value]);\n        }\n        return this;\n    }\n    /**\n     * Add the given set of key / value pairs to the multimap.\n     */\n    addAll(key, values) {\n        if (this.map.has(key)) {\n            this.map.get(key).push(...values);\n        }\n        else {\n            this.map.set(key, Array.from(values));\n        }\n        return this;\n    }\n    /**\n     * Invokes the given callback function for every key / value pair in the multimap.\n     */\n    forEach(callbackfn) {\n        this.map.forEach((array, key) => array.forEach(value => callbackfn(value, key, this)));\n    }\n    /**\n     * Returns an iterator of key, value pairs for every entry in the map.\n     */\n    [Symbol.iterator]() {\n        return this.entries().iterator();\n    }\n    /**\n     * Returns a stream of key, value pairs for every entry in the map.\n     */\n    entries() {\n        return stream(this.map.entries())\n            .flatMap(([key, array]) => array.map(value => [key, value]));\n    }\n    /**\n     * Returns a stream of keys in the map.\n     */\n    keys() {\n        return stream(this.map.keys());\n    }\n    /**\n     * Returns a stream of values in the map.\n     */\n    values() {\n        return stream(this.map.values()).flat();\n    }\n    /**\n     * Returns a stream of key, value set pairs for every key in the map.\n     */\n    entriesGroupedByKey() {\n        return stream(this.map.entries());\n    }\n}\nexport class BiMap {\n    get size() {\n        return this.map.size;\n    }\n    constructor(elements) {\n        this.map = new Map();\n        this.inverse = new Map();\n        if (elements) {\n            for (const [key, value] of elements) {\n                this.set(key, value);\n            }\n        }\n    }\n    clear() {\n        this.map.clear();\n        this.inverse.clear();\n    }\n    set(key, value) {\n        this.map.set(key, value);\n        this.inverse.set(value, key);\n        return this;\n    }\n    get(key) {\n        return this.map.get(key);\n    }\n    getKey(value) {\n        return this.inverse.get(value);\n    }\n    delete(key) {\n        const value = this.map.get(key);\n        if (value !== undefined) {\n            this.map.delete(key);\n            this.inverse.delete(value);\n            return true;\n        }\n        return false;\n    }\n}\n//# sourceMappingURL=collections.js.map","/******************************************************************************\n * Copyright 2021-2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { streamAllContents, streamContents } from '../utils/ast-utils.js';\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { MultiMap } from '../utils/collections.js';\nimport { interruptAndCheck } from '../utils/promise-utils.js';\n/**\n * The default scope computation creates and collects descriptions of the AST nodes to be exported into the\n * _global_ scope from the given document. By default those are the document's root AST node and its directly\n * contained child nodes.\n *\n * Besides, it gathers all AST nodes that have a name (according to the `NameProvider` service) and that are to be\n * included in the local scope of their particular container nodes. They are collected in a `DocumentSymbols` table.\n * As a result, for every cross-reference in the AST, target elements from the same level (siblings) and further up\n * towards the root (parents and siblings of parents) are visible.\n * Elements being nested inside lower levels (children, children of siblings and parents' siblings)\n * are _invisible_ by default, but that can be changed by customizing this service.\n */\nexport class DefaultScopeComputation {\n    constructor(services) {\n        this.nameProvider = services.references.NameProvider;\n        this.descriptions = services.workspace.AstNodeDescriptionProvider;\n    }\n    async collectExportedSymbols(document, cancelToken = CancellationToken.None) {\n        return this.collectExportedSymbolsForNode(document.parseResult.value, document, undefined, cancelToken);\n    }\n    /**\n     * Creates {@link AstNodeDescription AstNodeDescriptions} for the given {@link AstNode parentNode} and its children.\n     * The list of children to be considered is determined by the function parameter {@link children}.\n     * By default only the direct children of {@link parentNode} are visited, nested nodes are not exported.\n     *\n     * @param parentNode AST node to be exported, i.e., of which an {@link AstNodeDescription} shall be added to the returned list.\n     * @param document The document containing the AST node to be exported.\n     * @param children A function called with {@link parentNode} as single argument and returning an {@link Iterable} supplying the children to be visited, which must be directly or transitively contained in {@link parentNode}.\n     * @param cancelToken Indicates when to cancel the current operation.\n     * @throws `OperationCancelled` if a user action occurs during execution.\n     * @returns A list of {@link AstNodeDescription AstNodeDescriptions} to be published to index.\n     */\n    async collectExportedSymbolsForNode(parentNode, document, children = streamContents, cancelToken = CancellationToken.None) {\n        const exports = [];\n        this.addExportedSymbol(parentNode, exports, document);\n        for (const node of children(parentNode)) {\n            await interruptAndCheck(cancelToken);\n            this.addExportedSymbol(node, exports, document);\n        }\n        return exports;\n    }\n    /**\n     * Adds a single node to the list of exports if it has a name. Override this method to change how\n     * symbols are exported, e.g. by modifying their exported name.\n     */\n    addExportedSymbol(node, exports, document) {\n        const name = this.nameProvider.getName(node);\n        if (name) {\n            exports.push(this.descriptions.createDescription(node, name, document));\n        }\n    }\n    // --- local symbols gathering ---\n    async collectLocalSymbols(document, cancelToken = CancellationToken.None) {\n        const rootNode = document.parseResult.value;\n        const symbols = new MultiMap();\n        // Here we navigate the full AST - local scopes shall be available in the whole document\n        for (const node of streamAllContents(rootNode)) {\n            await interruptAndCheck(cancelToken);\n            this.addLocalSymbol(node, document, symbols);\n        }\n        return symbols;\n    }\n    /**\n     * Adds a single node to the local symbols of its containing document if it has a name.\n     * The default implementation makes the node visible in the subtree of its container if it does have a container.\n     * Override this method to change this, e.g. by increasing the visibility to a higher level in the AST.\n     */\n    addLocalSymbol(node, document, symbols) {\n        const container = node.$container;\n        if (container) {\n            const name = this.nameProvider.getName(node);\n            if (name) {\n                symbols.add(container, this.descriptions.createDescription(node, name, document));\n            }\n        }\n    }\n}\n//# sourceMappingURL=scope-computation.js.map","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { MultiMap } from '../utils/collections.js';\nimport { EMPTY_STREAM, stream } from '../utils/stream.js';\n/**\n * The default scope implementation is based on a `Stream`. It has an optional _outer scope_ describing\n * the next level of elements, which are queried when a target element is not found in the stream provided\n * to this scope.\n */\nexport class StreamScope {\n    constructor(elements, outerScope, options) {\n        this.elements = elements;\n        this.outerScope = outerScope;\n        this.caseInsensitive = options?.caseInsensitive ?? false;\n        this.concatOuterScope = options?.concatOuterScope ?? true;\n    }\n    getAllElements() {\n        if (this.outerScope) {\n            return this.elements.concat(this.outerScope.getAllElements());\n        }\n        else {\n            return this.elements;\n        }\n    }\n    getElement(name) {\n        const lowerCaseName = this.caseInsensitive ? name.toLowerCase() : name;\n        const local = this.caseInsensitive\n            ? this.elements.find(e => e.name.toLowerCase() === lowerCaseName)\n            : this.elements.find(e => e.name === name);\n        if (local) {\n            return local;\n        }\n        if (this.outerScope) {\n            return this.outerScope.getElement(name);\n        }\n        return undefined;\n    }\n    getElements(name) {\n        const lowerCaseName = this.caseInsensitive ? name.toLowerCase() : name;\n        const local = this.caseInsensitive\n            ? this.elements.filter(e => e.name.toLowerCase() === lowerCaseName)\n            : this.elements.filter(e => e.name === name);\n        if ((this.concatOuterScope || local.isEmpty()) && this.outerScope) {\n            return local.concat(this.outerScope.getElements(name));\n        }\n        else {\n            return local;\n        }\n    }\n}\nexport class MapScope {\n    constructor(elements, outerScope, options) {\n        this.elements = new Map();\n        this.caseInsensitive = options?.caseInsensitive ?? false;\n        this.concatOuterScope = options?.concatOuterScope ?? true;\n        for (const element of elements) {\n            const name = this.caseInsensitive\n                ? element.name.toLowerCase()\n                : element.name;\n            this.elements.set(name, element);\n        }\n        this.outerScope = outerScope;\n    }\n    getElement(name) {\n        const localName = this.caseInsensitive ? name.toLowerCase() : name;\n        const local = this.elements.get(localName);\n        if (local) {\n            return local;\n        }\n        if (this.outerScope) {\n            return this.outerScope.getElement(name);\n        }\n        return undefined;\n    }\n    getElements(name) {\n        const localName = this.caseInsensitive ? name.toLowerCase() : name;\n        const local = this.elements.get(localName);\n        const arr = local ? [local] : [];\n        if ((this.concatOuterScope || arr.length > 0) && this.outerScope) {\n            return stream(arr).concat(this.outerScope.getElements(name));\n        }\n        else {\n            return stream(arr);\n        }\n    }\n    getAllElements() {\n        let elementStream = stream(this.elements.values());\n        if (this.outerScope) {\n            elementStream = elementStream.concat(this.outerScope.getAllElements());\n        }\n        return elementStream;\n    }\n}\nexport class MultiMapScope {\n    constructor(elements, outerScope, options) {\n        this.elements = new MultiMap();\n        this.caseInsensitive = options?.caseInsensitive ?? false;\n        this.concatOuterScope = options?.concatOuterScope ?? true;\n        for (const element of elements) {\n            const name = this.caseInsensitive\n                ? element.name.toLowerCase()\n                : element.name;\n            this.elements.add(name, element);\n        }\n        this.outerScope = outerScope;\n    }\n    getElement(name) {\n        const localName = this.caseInsensitive ? name.toLowerCase() : name;\n        const local = this.elements.get(localName)[0];\n        if (local) {\n            return local;\n        }\n        if (this.outerScope) {\n            return this.outerScope.getElement(name);\n        }\n        return undefined;\n    }\n    getElements(name) {\n        const localName = this.caseInsensitive ? name.toLowerCase() : name;\n        const local = this.elements.get(localName);\n        if ((this.concatOuterScope || local.length === 0) && this.outerScope) {\n            return stream(local).concat(this.outerScope.getElements(name));\n        }\n        else {\n            return stream(local);\n        }\n    }\n    getAllElements() {\n        let elementStream = stream(this.elements.values());\n        if (this.outerScope) {\n            elementStream = elementStream.concat(this.outerScope.getAllElements());\n        }\n        return elementStream;\n    }\n}\nexport const EMPTY_SCOPE = {\n    getElement() {\n        return undefined;\n    },\n    getElements() {\n        return EMPTY_STREAM;\n    },\n    getAllElements() {\n        return EMPTY_STREAM;\n    }\n};\n//# sourceMappingURL=scope.js.map","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nexport class DisposableCache {\n    constructor() {\n        this.toDispose = [];\n        this.isDisposed = false;\n    }\n    onDispose(disposable) {\n        this.toDispose.push(disposable);\n    }\n    dispose() {\n        this.throwIfDisposed();\n        this.clear();\n        this.isDisposed = true;\n        this.toDispose.forEach(disposable => disposable.dispose());\n    }\n    throwIfDisposed() {\n        if (this.isDisposed) {\n            throw new Error('This cache has already been disposed');\n        }\n    }\n}\nexport class SimpleCache extends DisposableCache {\n    constructor() {\n        super(...arguments);\n        this.cache = new Map();\n    }\n    has(key) {\n        this.throwIfDisposed();\n        return this.cache.has(key);\n    }\n    set(key, value) {\n        this.throwIfDisposed();\n        this.cache.set(key, value);\n    }\n    get(key, provider) {\n        this.throwIfDisposed();\n        if (this.cache.has(key)) {\n            return this.cache.get(key);\n        }\n        else if (provider) {\n            const value = provider();\n            this.cache.set(key, value);\n            return value;\n        }\n        else {\n            return undefined;\n        }\n    }\n    delete(key) {\n        this.throwIfDisposed();\n        return this.cache.delete(key);\n    }\n    clear() {\n        this.throwIfDisposed();\n        this.cache.clear();\n    }\n}\nexport class ContextCache extends DisposableCache {\n    constructor(converter) {\n        super();\n        this.cache = new Map();\n        this.converter = converter ?? (value => value);\n    }\n    has(contextKey, key) {\n        this.throwIfDisposed();\n        return this.cacheForContext(contextKey).has(key);\n    }\n    set(contextKey, key, value) {\n        this.throwIfDisposed();\n        this.cacheForContext(contextKey).set(key, value);\n    }\n    get(contextKey, key, provider) {\n        this.throwIfDisposed();\n        const contextCache = this.cacheForContext(contextKey);\n        if (contextCache.has(key)) {\n            return contextCache.get(key);\n        }\n        else if (provider) {\n            const value = provider();\n            contextCache.set(key, value);\n            return value;\n        }\n        else {\n            return undefined;\n        }\n    }\n    delete(contextKey, key) {\n        this.throwIfDisposed();\n        return this.cacheForContext(contextKey).delete(key);\n    }\n    clear(contextKey) {\n        this.throwIfDisposed();\n        if (contextKey) {\n            const mapKey = this.converter(contextKey);\n            this.cache.delete(mapKey);\n        }\n        else {\n            this.cache.clear();\n        }\n    }\n    cacheForContext(contextKey) {\n        const mapKey = this.converter(contextKey);\n        let documentCache = this.cache.get(mapKey);\n        if (!documentCache) {\n            documentCache = new Map();\n            this.cache.set(mapKey, documentCache);\n        }\n        return documentCache;\n    }\n}\n/**\n * Every key/value pair in this cache is scoped to a document.\n * If this document is changed or deleted, all associated key/value pairs are deleted.\n */\nexport class DocumentCache extends ContextCache {\n    /**\n     * Creates a new document cache.\n     *\n     * @param sharedServices Service container instance to hook into document lifecycle events.\n     * @param state Optional document state on which the cache should evict.\n     * If not provided, the cache will evict on `DocumentBuilder#onUpdate`.\n     * *Deleted* documents are considered in both cases.\n     *\n     * Providing a state here will use `DocumentBuilder#onDocumentPhase` instead,\n     * which triggers on all documents that have been affected by this change, assuming that the\n     * state is `DocumentState.Linked` or a later state.\n     */\n    constructor(sharedServices, state) {\n        super(uri => uri.toString());\n        if (state) {\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onDocumentPhase(state, document => {\n                this.clear(document.uri.toString());\n            }));\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate((_changed, deleted) => {\n                for (const uri of deleted) { // react only on deleted documents\n                    this.clear(uri);\n                }\n            }));\n        }\n        else {\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate((changed, deleted) => {\n                const allUris = changed.concat(deleted); // react on both changed and deleted documents\n                for (const uri of allUris) {\n                    this.clear(uri);\n                }\n            }));\n        }\n    }\n}\n/**\n * Every key/value pair in this cache is scoped to the whole workspace.\n * If any document in the workspace is added, changed or deleted, the whole cache is evicted.\n */\nexport class WorkspaceCache extends SimpleCache {\n    /**\n     * Creates a new workspace cache.\n     *\n     * @param sharedServices Service container instance to hook into document lifecycle events.\n     * @param state Optional document state on which the cache should evict.\n     * If not provided, the cache will evict on `DocumentBuilder#onUpdate`.\n     * *Deleted* documents are considered in both cases.\n     */\n    constructor(sharedServices, state) {\n        super();\n        if (state) {\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onBuildPhase(state, () => {\n                this.clear();\n            }));\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate((_changed, deleted) => {\n                if (deleted.length > 0) { // react only on deleted documents\n                    this.clear();\n                }\n            }));\n        }\n        else {\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate(() => {\n                this.clear();\n            }));\n        }\n    }\n}\n//# sourceMappingURL=caching.js.map","/******************************************************************************\n * Copyright 2021-2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { MultiMapScope, StreamScope } from './scope.js';\nimport { getDocument } from '../utils/ast-utils.js';\nimport { stream } from '../utils/stream.js';\nimport { WorkspaceCache } from '../utils/caching.js';\nexport class DefaultScopeProvider {\n    constructor(services) {\n        this.reflection = services.shared.AstReflection;\n        this.nameProvider = services.references.NameProvider;\n        this.descriptions = services.workspace.AstNodeDescriptionProvider;\n        this.indexManager = services.shared.workspace.IndexManager;\n        this.globalScopeCache = new WorkspaceCache(services.shared);\n    }\n    getScope(context) {\n        const scopes = [];\n        const referenceType = this.reflection.getReferenceType(context);\n        const localSymbols = getDocument(context.container).localSymbols;\n        if (localSymbols) {\n            let currentNode = context.container;\n            do {\n                if (localSymbols.has(currentNode)) {\n                    scopes.push(localSymbols.getStream(currentNode).filter(desc => this.reflection.isSubtype(desc.type, referenceType)));\n                }\n                currentNode = currentNode.$container;\n            } while (currentNode);\n        }\n        let result = this.getGlobalScope(referenceType, context);\n        for (let i = scopes.length - 1; i >= 0; i--) {\n            result = this.createScope(scopes[i], result);\n        }\n        return result;\n    }\n    /**\n     * Create a scope for the given collection of AST node descriptions.\n     */\n    createScope(elements, outerScope, options) {\n        return new StreamScope(stream(elements), outerScope, options);\n    }\n    /**\n     * Create a scope for the given collection of AST nodes, which need to be transformed into respective\n     * descriptions first. This is done using the `NameProvider` and `AstNodeDescriptionProvider` services.\n     */\n    createScopeForNodes(elements, outerScope, options) {\n        const s = stream(elements).map(e => {\n            const name = this.nameProvider.getName(e);\n            if (name) {\n                return this.descriptions.createDescription(e, name);\n            }\n            return undefined;\n        }).nonNullable();\n        return new StreamScope(s, outerScope, options);\n    }\n    /**\n     * Create a global scope filtered for the given reference type.\n     */\n    getGlobalScope(referenceType, _context) {\n        return this.globalScopeCache.get(referenceType, () => new MultiMapScope(this.indexManager.allElements(referenceType)));\n    }\n}\n//# sourceMappingURL=scope-provider.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { URI } from 'vscode-uri';\nimport { isAstNode, isMultiReference, isReference } from '../syntax-tree.js';\nimport { getDocument } from '../utils/ast-utils.js';\nimport { findNodesForProperty } from '../utils/grammar-utils.js';\nexport function isAstNodeWithComment(node) {\n    return typeof node.$comment === 'string';\n}\nfunction isIntermediateReference(obj) {\n    return typeof obj === 'object' && !!obj && ('$ref' in obj || '$error' in obj);\n}\nexport class DefaultJsonSerializer {\n    constructor(services) {\n        /** The set of AstNode properties to be ignored by the serializer. */\n        this.ignoreProperties = new Set(['$container', '$containerProperty', '$containerIndex', '$document', '$cstNode']);\n        this.langiumDocuments = services.shared.workspace.LangiumDocuments;\n        this.astNodeLocator = services.workspace.AstNodeLocator;\n        this.nameProvider = services.references.NameProvider;\n        this.commentProvider = services.documentation.CommentProvider;\n    }\n    serialize(node, options) {\n        const serializeOptions = options ?? {};\n        const specificReplacer = options?.replacer;\n        const defaultReplacer = (key, value) => this.replacer(key, value, serializeOptions);\n        const replacer = specificReplacer ? (key, value) => specificReplacer(key, value, defaultReplacer) : defaultReplacer;\n        try {\n            this.currentDocument = getDocument(node);\n            return JSON.stringify(node, replacer, options?.space);\n        }\n        finally {\n            this.currentDocument = undefined;\n        }\n    }\n    deserialize(content, options) {\n        const deserializeOptions = options ?? {};\n        const root = JSON.parse(content);\n        this.linkNode(root, root, deserializeOptions);\n        return root;\n    }\n    replacer(key, value, { refText, sourceText, textRegions, comments, uriConverter }) {\n        if (this.ignoreProperties.has(key)) {\n            return undefined;\n        }\n        else if (isReference(value)) {\n            const refValue = value.ref;\n            const $refText = refText ? value.$refText : undefined;\n            if (refValue) {\n                const targetDocument = getDocument(refValue);\n                let targetUri = '';\n                if (this.currentDocument && this.currentDocument !== targetDocument) {\n                    if (uriConverter) {\n                        targetUri = uriConverter(targetDocument.uri, refValue);\n                    }\n                    else {\n                        targetUri = targetDocument.uri.toString();\n                    }\n                }\n                const targetPath = this.astNodeLocator.getAstNodePath(refValue);\n                return {\n                    $ref: `${targetUri}#${targetPath}`,\n                    $refText\n                };\n            }\n            else {\n                return {\n                    $error: value.error?.message ?? 'Could not resolve reference',\n                    $refText\n                };\n            }\n        }\n        else if (isMultiReference(value)) {\n            const $refText = refText ? value.$refText : undefined;\n            const $refs = [];\n            for (const item of value.items) {\n                const refValue = item.ref;\n                const targetDocument = getDocument(item.ref);\n                let targetUri = '';\n                if (this.currentDocument && this.currentDocument !== targetDocument) {\n                    if (uriConverter) {\n                        targetUri = uriConverter(targetDocument.uri, refValue);\n                    }\n                    else {\n                        targetUri = targetDocument.uri.toString();\n                    }\n                }\n                const targetPath = this.astNodeLocator.getAstNodePath(refValue);\n                $refs.push(`${targetUri}#${targetPath}`);\n            }\n            return {\n                $refs,\n                $refText\n            };\n        }\n        else if (isAstNode(value)) {\n            let astNode = undefined;\n            if (textRegions) {\n                astNode = this.addAstNodeRegionWithAssignmentsTo({ ...value });\n                if ((!key || value.$document) && astNode?.$textRegion) {\n                    // The document URI is added to the root node of the resulting JSON tree\n                    astNode.$textRegion.documentURI = this.currentDocument?.uri.toString();\n                }\n            }\n            if (sourceText && !key) {\n                astNode ?? (astNode = { ...value });\n                astNode.$sourceText = value.$cstNode?.text;\n            }\n            if (comments) {\n                astNode ?? (astNode = { ...value });\n                const comment = this.commentProvider.getComment(value);\n                if (comment) {\n                    astNode.$comment = comment.replace(/\\r/g, '');\n                }\n            }\n            return astNode ?? value;\n        }\n        else {\n            return value;\n        }\n    }\n    addAstNodeRegionWithAssignmentsTo(node) {\n        const createDocumentSegment = cstNode => ({\n            offset: cstNode.offset,\n            end: cstNode.end,\n            length: cstNode.length,\n            range: cstNode.range,\n        });\n        if (node.$cstNode) {\n            const textRegion = node.$textRegion = createDocumentSegment(node.$cstNode);\n            const assignments = textRegion.assignments = {};\n            Object.keys(node).filter(key => !key.startsWith('$')).forEach(key => {\n                const propertyAssignments = findNodesForProperty(node.$cstNode, key).map(createDocumentSegment);\n                if (propertyAssignments.length !== 0) {\n                    assignments[key] = propertyAssignments;\n                }\n            });\n            return node;\n        }\n        return undefined;\n    }\n    linkNode(node, root, options, container, containerProperty, containerIndex) {\n        for (const [propertyName, item] of Object.entries(node)) {\n            if (Array.isArray(item)) {\n                for (let index = 0; index < item.length; index++) {\n                    const element = item[index];\n                    if (isIntermediateReference(element)) {\n                        item[index] = this.reviveReference(node, propertyName, root, element, options);\n                    }\n                    else if (isAstNode(element)) {\n                        this.linkNode(element, root, options, node, propertyName, index);\n                    }\n                }\n            }\n            else if (isIntermediateReference(item)) {\n                node[propertyName] = this.reviveReference(node, propertyName, root, item, options);\n            }\n            else if (isAstNode(item)) {\n                this.linkNode(item, root, options, node, propertyName);\n            }\n        }\n        const mutable = node;\n        mutable.$container = container;\n        mutable.$containerProperty = containerProperty;\n        mutable.$containerIndex = containerIndex;\n    }\n    reviveReference(container, property, root, reference, options) {\n        let refText = reference.$refText;\n        let error = reference.$error;\n        let ref;\n        if (reference.$ref) {\n            const refNode = this.getRefNode(root, reference.$ref, options.uriConverter);\n            if (isAstNode(refNode)) {\n                if (!refText) {\n                    refText = this.nameProvider.getName(refNode);\n                }\n                return {\n                    $refText: refText ?? '',\n                    ref: refNode\n                };\n            }\n            else {\n                error = refNode;\n            }\n        }\n        else if (reference.$refs) {\n            const refs = [];\n            for (const refUri of reference.$refs) {\n                const refNode = this.getRefNode(root, refUri, options.uriConverter);\n                if (isAstNode(refNode)) {\n                    refs.push({ ref: refNode });\n                }\n            }\n            if (refs.length === 0) {\n                ref = {\n                    $refText: refText ?? '',\n                    items: refs\n                };\n                error ?? (error = 'Could not resolve multi-reference');\n            }\n            else {\n                return {\n                    $refText: refText ?? '',\n                    items: refs\n                };\n            }\n        }\n        if (error) {\n            ref ?? (ref = {\n                $refText: refText ?? '',\n                ref: undefined\n            });\n            ref.error = {\n                info: {\n                    container,\n                    property,\n                    reference: ref\n                },\n                message: error\n            };\n            return ref;\n        }\n        else {\n            return undefined;\n        }\n    }\n    getRefNode(root, uri, uriConverter) {\n        try {\n            const fragmentIndex = uri.indexOf('#');\n            if (fragmentIndex === 0) {\n                const node = this.astNodeLocator.getAstNode(root, uri.substring(1));\n                if (!node) {\n                    return 'Could not resolve path: ' + uri;\n                }\n                return node;\n            }\n            if (fragmentIndex < 0) {\n                const documentUri = uriConverter ? uriConverter(uri) : URI.parse(uri);\n                const document = this.langiumDocuments.getDocument(documentUri);\n                if (!document) {\n                    return 'Could not find document for URI: ' + uri;\n                }\n                return document.parseResult.value;\n            }\n            const documentUri = uriConverter ? uriConverter(uri.substring(0, fragmentIndex)) : URI.parse(uri.substring(0, fragmentIndex));\n            const document = this.langiumDocuments.getDocument(documentUri);\n            if (!document) {\n                return 'Could not find document for URI: ' + uri;\n            }\n            if (fragmentIndex === uri.length - 1) {\n                return document.parseResult.value;\n            }\n            const node = this.astNodeLocator.getAstNode(document.parseResult.value, uri.substring(fragmentIndex + 1));\n            if (!node) {\n                return 'Could not resolve URI: ' + uri;\n            }\n            return node;\n        }\n        catch (err) {\n            return String(err);\n        }\n    }\n}\n//# sourceMappingURL=json-serializer.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { UriUtils } from './utils/uri-utils.js';\n/**\n * Generic registry for Langium services, but capable of being used with extending service sets as well (such as the lsp-complete LangiumCoreServices set)\n */\nexport class DefaultServiceRegistry {\n    /**\n     * @deprecated Since 3.1.0. Use the new `fileExtensionMap` (or `languageIdMap`) property instead.\n     */\n    get map() {\n        return this.fileExtensionMap;\n    }\n    constructor(services) {\n        this.languageIdMap = new Map();\n        this.fileExtensionMap = new Map();\n        this.fileNameMap = new Map();\n        this.textDocuments = services?.workspace.TextDocuments;\n    }\n    register(language) {\n        const data = language.LanguageMetaData;\n        for (const ext of data.fileExtensions) {\n            if (this.fileExtensionMap.has(ext)) {\n                console.warn(`The file extension ${ext} is used by multiple languages. It is now assigned to '${data.languageId}'.`);\n            }\n            this.fileExtensionMap.set(ext, language);\n        }\n        if (data.fileNames) {\n            for (const name of data.fileNames) {\n                if (this.fileNameMap.has(name)) {\n                    console.warn(`The file name ${name} is used by multiple languages. It is now assigned to '${data.languageId}'.`);\n                }\n                this.fileNameMap.set(name, language);\n            }\n        }\n        this.languageIdMap.set(data.languageId, language);\n    }\n    getServices(uri) {\n        if (this.languageIdMap.size === 0) {\n            throw new Error('The service registry is empty. Use `register` to register the services of a language.');\n        }\n        const languageId = this.textDocuments?.get(uri)?.languageId;\n        if (languageId !== undefined) {\n            const services = this.languageIdMap.get(languageId);\n            if (services) {\n                return services;\n            }\n        }\n        const ext = UriUtils.extname(uri);\n        const name = UriUtils.basename(uri);\n        const services = this.fileNameMap.get(name) ?? this.fileExtensionMap.get(ext);\n        if (!services) {\n            if (languageId) {\n                throw new Error(`The service registry contains no services for the extension '${ext}' for language '${languageId}'.`);\n            }\n            else {\n                throw new Error(`The service registry contains no services for the extension '${ext}'.`);\n            }\n        }\n        return services;\n    }\n    hasServices(uri) {\n        try {\n            this.getServices(uri);\n            return true;\n        }\n        catch {\n            return false;\n        }\n    }\n    get all() {\n        return Array.from(this.languageIdMap.values());\n    }\n}\n//# sourceMappingURL=service-registry.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { assertUnreachable } from '../index.js';\nimport { MultiMap } from '../utils/collections.js';\nimport { isOperationCancelled } from '../utils/promise-utils.js';\nimport { stream } from '../utils/stream.js';\n/**\n * Create DiagnosticData for a given diagnostic code. The result can be put into the `data` field of a DiagnosticInfo.\n */\nexport function diagnosticData(code) {\n    return { code };\n}\nexport var ValidationCategory;\n(function (ValidationCategory) {\n    ValidationCategory.defaults = ['fast', 'slow', 'built-in'];\n    /**\n     * @deprecated since 4.2 Use `ValidationCategory.defaults` instead,\n     * since \"all\" does not include user-defined, custom validation categories.\n     */\n    ValidationCategory.all = ValidationCategory.defaults;\n})(ValidationCategory || (ValidationCategory = {}));\n/**\n * Manages a set of `ValidationCheck`s to be applied when documents are validated.\n */\nexport class ValidationRegistry {\n    constructor(services) {\n        this.entries = new MultiMap();\n        this.knownCategories = new Set(ValidationCategory.defaults);\n        this.entriesBefore = [];\n        this.entriesAfter = [];\n        this.reflection = services.shared.AstReflection;\n    }\n    /**\n     * Register a set of validation checks. Each value in the record can be either a single validation check (i.e. a function)\n     * or an array of validation checks.\n     *\n     * @param checksRecord Set of validation checks to register.\n     * @param thisObj Optional object to be used as `this` when calling the validation check functions.\n     * @param category Optional category for the validation checks (defaults to `'fast'`).\n     */\n    register(checksRecord, thisObj = this, category = 'fast') {\n        if (category === 'built-in') {\n            throw new Error(\"The 'built-in' category is reserved for lexer, parser, and linker errors.\");\n        }\n        this.knownCategories.add(category); // remember custom/user-defined categories\n        for (const [type, ch] of Object.entries(checksRecord)) {\n            const callbacks = ch;\n            if (Array.isArray(callbacks)) {\n                for (const check of callbacks) {\n                    const entry = {\n                        check: this.wrapValidationException(check, thisObj),\n                        category\n                    };\n                    this.addEntry(type, entry);\n                }\n            }\n            else if (typeof callbacks === 'function') {\n                const entry = {\n                    check: this.wrapValidationException(callbacks, thisObj),\n                    category\n                };\n                this.addEntry(type, entry);\n            }\n            else {\n                assertUnreachable(callbacks);\n            }\n        }\n    }\n    wrapValidationException(check, thisObj) {\n        return async (node, accept, cancelToken) => {\n            await this.handleException(() => check.call(thisObj, node, accept, cancelToken), 'An error occurred during validation', accept, node);\n        };\n    }\n    async handleException(functionality, messageContext, accept, node) {\n        try {\n            await functionality();\n        }\n        catch (err) {\n            if (isOperationCancelled(err)) {\n                throw err;\n            }\n            console.error(`${messageContext}:`, err);\n            if (err instanceof Error && err.stack) {\n                console.error(err.stack);\n            }\n            const messageDetails = err instanceof Error ? err.message : String(err);\n            accept('error', `${messageContext}: ${messageDetails}`, { node });\n        }\n    }\n    addEntry(type, entry) {\n        if (type === 'AstNode') {\n            this.entries.add('AstNode', entry);\n            return;\n        }\n        for (const subtype of this.reflection.getAllSubTypes(type)) {\n            this.entries.add(subtype, entry);\n        }\n    }\n    getChecks(type, categories) {\n        let checks = stream(this.entries.get(type))\n            .concat(this.entries.get('AstNode'));\n        if (categories) {\n            checks = checks.filter(entry => categories.includes(entry.category));\n        }\n        return checks.map(entry => entry.check);\n    }\n    /**\n     * Register logic which will be executed once before validating all the nodes of an AST/Langium document.\n     * This helps to prepare or initialize some information which are required or reusable for the following checks on the AstNodes.\n     *\n     * As an example, for validating unique fully-qualified names of nodes in the AST,\n     * here the map for mapping names to nodes could be established.\n     * During the usual checks on the nodes, they are put into this map with their name.\n     *\n     * Note that this approach makes validations stateful, which is relevant e.g. when cancelling the validation.\n     * Therefore it is recommended to clear stored information\n     * _before_ validating an AST to validate each AST unaffected from other ASTs\n     * AND _after_ validating the AST to free memory by information which are no longer used.\n     *\n     * @param checkBefore a set-up function which will be called once before actually validating an AST\n     * @param thisObj Optional object to be used as `this` when calling the validation check functions.\n     */\n    registerBeforeDocument(checkBefore, thisObj = this) {\n        this.entriesBefore.push(this.wrapPreparationException(checkBefore, 'An error occurred during set-up of the validation', thisObj));\n    }\n    /**\n     * Register logic which will be executed once after validating all the nodes of an AST/Langium document.\n     * This helps to finally evaluate information which are collected during the checks on the AstNodes.\n     *\n     * As an example, for validating unique fully-qualified names of nodes in the AST,\n     * here the map with all the collected nodes and their names is checked\n     * and validation hints are created for all nodes with the same name.\n     *\n     * Note that this approach makes validations stateful, which is relevant e.g. when cancelling the validation.\n     * Therefore it is recommended to clear stored information\n     * _before_ validating an AST to validate each AST unaffected from other ASTs\n     * AND _after_ validating the AST to free memory by information which are no longer used.\n     *\n     * @param checkBefore a set-up function which will be called once before actually validating an AST\n     * @param thisObj Optional object to be used as `this` when calling the validation check functions.\n     */\n    registerAfterDocument(checkAfter, thisObj = this) {\n        this.entriesAfter.push(this.wrapPreparationException(checkAfter, 'An error occurred during tear-down of the validation', thisObj));\n    }\n    wrapPreparationException(check, messageContext, thisObj) {\n        return async (rootNode, accept, categories, cancelToken) => {\n            await this.handleException(() => check.call(thisObj, rootNode, accept, categories, cancelToken), messageContext, accept, rootNode);\n        };\n    }\n    get checksBefore() {\n        return this.entriesBefore;\n    }\n    get checksAfter() {\n        return this.entriesAfter;\n    }\n    getAllValidationCategories(_document) {\n        return this.knownCategories;\n    }\n}\n//# sourceMappingURL=validation-registry.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { findNodeForKeyword, findNodeForProperty } from '../utils/grammar-utils.js';\nimport { streamAst } from '../utils/ast-utils.js';\nimport { tokenToRange } from '../utils/cst-utils.js';\nimport { interruptAndCheck, isOperationCancelled } from '../utils/promise-utils.js';\nimport { diagnosticData } from './validation-registry.js';\nexport const VALIDATE_EACH_NODE = Object.freeze({\n    validateNode: true,\n    validateChildren: true,\n});\nexport class DefaultDocumentValidator {\n    constructor(services) {\n        this.validationRegistry = services.validation.ValidationRegistry;\n        this.metadata = services.LanguageMetaData;\n        this.profiler = services.shared.profilers.LangiumProfiler;\n        this.languageId = services.LanguageMetaData.languageId;\n    }\n    async validateDocument(document, options = {}, cancelToken = CancellationToken.None) {\n        const parseResult = document.parseResult;\n        const diagnostics = [];\n        await interruptAndCheck(cancelToken);\n        if (!options.categories || options.categories.includes('built-in')) {\n            this.processLexingErrors(parseResult, diagnostics, options);\n            if (options.stopAfterLexingErrors && diagnostics.some(d => d.data?.code === DocumentValidator.LexingError)) {\n                return diagnostics;\n            }\n            this.processParsingErrors(parseResult, diagnostics, options);\n            if (options.stopAfterParsingErrors && diagnostics.some(d => d.data?.code === DocumentValidator.ParsingError)) {\n                return diagnostics;\n            }\n            this.processLinkingErrors(document, diagnostics, options);\n            if (options.stopAfterLinkingErrors && diagnostics.some(d => d.data?.code === DocumentValidator.LinkingError)) {\n                return diagnostics;\n            }\n        }\n        // Process custom validations\n        try {\n            diagnostics.push(...await this.validateAst(parseResult.value, options, cancelToken));\n        }\n        catch (err) {\n            if (isOperationCancelled(err)) {\n                throw err;\n            }\n            console.error('An error occurred during validation:', err);\n        }\n        await interruptAndCheck(cancelToken);\n        return diagnostics;\n    }\n    processLexingErrors(parseResult, diagnostics, _options) {\n        const lexerDiagnostics = [...parseResult.lexerErrors, ...parseResult.lexerReport?.diagnostics ?? []];\n        for (const lexerDiagnostic of lexerDiagnostics) {\n            const severity = lexerDiagnostic.severity ?? 'error';\n            const diagnostic = {\n                severity: toDiagnosticSeverity(severity),\n                range: {\n                    start: {\n                        line: lexerDiagnostic.line - 1,\n                        character: lexerDiagnostic.column - 1\n                    },\n                    end: {\n                        line: lexerDiagnostic.line - 1,\n                        character: lexerDiagnostic.column + lexerDiagnostic.length - 1\n                    }\n                },\n                message: lexerDiagnostic.message,\n                data: toDiagnosticData(severity),\n                source: this.getSource()\n            };\n            diagnostics.push(diagnostic);\n        }\n    }\n    processParsingErrors(parseResult, diagnostics, _options) {\n        for (const parserError of parseResult.parserErrors) {\n            let range = undefined;\n            // We can run into the chevrotain error recovery here\n            // The token contained in the parser error might be automatically inserted\n            // In this case every position value will be `NaN`\n            if (isNaN(parserError.token.startOffset)) {\n                // Some special parser error types contain a `previousToken`\n                // We can simply append our diagnostic to that token\n                if ('previousToken' in parserError) {\n                    const token = parserError.previousToken;\n                    if (!isNaN(token.startOffset)) {\n                        const position = { line: token.endLine - 1, character: token.endColumn };\n                        range = { start: position, end: position };\n                    }\n                    else {\n                        // No valid prev token. Might be empty document or containing only hidden tokens.\n                        // Point to document start\n                        const position = { line: 0, character: 0 };\n                        range = { start: position, end: position };\n                    }\n                }\n            }\n            else {\n                range = tokenToRange(parserError.token);\n            }\n            if (range) {\n                const diagnostic = {\n                    severity: toDiagnosticSeverity('error'),\n                    range,\n                    message: parserError.message,\n                    data: diagnosticData(DocumentValidator.ParsingError),\n                    source: this.getSource()\n                };\n                diagnostics.push(diagnostic);\n            }\n        }\n    }\n    processLinkingErrors(document, diagnostics, _options) {\n        for (const reference of document.references) {\n            const linkingError = reference.error;\n            if (linkingError) {\n                const info = {\n                    node: linkingError.info.container,\n                    range: reference.$refNode?.range,\n                    property: linkingError.info.property,\n                    index: linkingError.info.index,\n                    data: {\n                        code: DocumentValidator.LinkingError,\n                        containerType: linkingError.info.container.$type,\n                        property: linkingError.info.property,\n                        refText: linkingError.info.reference.$refText\n                    }\n                };\n                diagnostics.push(this.toDiagnostic('error', linkingError.message, info));\n            }\n        }\n    }\n    async validateAst(rootNode, options, cancelToken = CancellationToken.None) {\n        const validationItems = [];\n        const acceptor = (severity, message, info) => {\n            validationItems.push(this.toDiagnostic(severity, message, info));\n        };\n        await this.validateAstBefore(rootNode, options, acceptor, cancelToken);\n        await this.validateAstNodes(rootNode, options, acceptor, cancelToken);\n        await this.validateAstAfter(rootNode, options, acceptor, cancelToken);\n        return validationItems;\n    }\n    async validateAstBefore(rootNode, options, acceptor, cancelToken = CancellationToken.None) {\n        const checksBefore = this.validationRegistry.checksBefore;\n        for (const checkBefore of checksBefore) {\n            await interruptAndCheck(cancelToken);\n            await checkBefore(rootNode, acceptor, options.categories ?? [], cancelToken);\n        }\n    }\n    async validateAstNodes(rootNode, options, acceptor, cancelToken = CancellationToken.None) {\n        if (this.profiler?.isActive('validating')) {\n            const task = this.profiler.createTask('validating', this.languageId);\n            task.start();\n            try {\n                const nodes = streamAst(rootNode).iterator();\n                for (const node of nodes) {\n                    task.startSubTask(node.$type);\n                    const nodeOptions = this.validateSingleNodeOptions(node, options);\n                    if (nodeOptions.validateNode) {\n                        try {\n                            const checks = this.validationRegistry.getChecks(node.$type, options.categories);\n                            for (const check of checks) {\n                                await check(node, acceptor, cancelToken);\n                            }\n                        }\n                        finally {\n                            task.stopSubTask(node.$type);\n                        }\n                    }\n                    if (!nodeOptions.validateChildren) {\n                        nodes.prune();\n                    }\n                }\n            }\n            finally {\n                task.stop();\n            }\n        }\n        else {\n            const nodes = streamAst(rootNode).iterator();\n            for (const node of nodes) {\n                await interruptAndCheck(cancelToken);\n                const nodeOptions = this.validateSingleNodeOptions(node, options);\n                if (nodeOptions.validateNode) {\n                    const checks = this.validationRegistry.getChecks(node.$type, options.categories);\n                    for (const check of checks) {\n                        await check(node, acceptor, cancelToken);\n                    }\n                }\n                if (!nodeOptions.validateChildren) {\n                    nodes.prune();\n                }\n            }\n        }\n    }\n    validateSingleNodeOptions(_node, _options) {\n        return VALIDATE_EACH_NODE;\n    }\n    async validateAstAfter(rootNode, options, acceptor, cancelToken = CancellationToken.None) {\n        const checksAfter = this.validationRegistry.checksAfter;\n        for (const checkAfter of checksAfter) {\n            await interruptAndCheck(cancelToken);\n            await checkAfter(rootNode, acceptor, options.categories ?? [], cancelToken);\n        }\n    }\n    toDiagnostic(severity, message, info) {\n        return {\n            message,\n            range: getDiagnosticRange(info),\n            severity: toDiagnosticSeverity(severity),\n            code: info.code,\n            codeDescription: info.codeDescription,\n            tags: info.tags,\n            relatedInformation: info.relatedInformation,\n            data: info.data,\n            source: this.getSource()\n        };\n    }\n    getSource() {\n        return this.metadata.languageId;\n    }\n}\nexport function getDiagnosticRange(info) {\n    if (info.range) {\n        return info.range;\n    }\n    let cstNode;\n    if (typeof info.property === 'string') {\n        cstNode = findNodeForProperty(info.node.$cstNode, info.property, info.index);\n    }\n    else if (typeof info.keyword === 'string') {\n        cstNode = findNodeForKeyword(info.node.$cstNode, info.keyword, info.index);\n    }\n    cstNode ?? (cstNode = info.node.$cstNode);\n    if (!cstNode) {\n        return {\n            start: { line: 0, character: 0 },\n            end: { line: 0, character: 0 }\n        };\n    }\n    return cstNode.range;\n}\n/**\n * Transforms the diagnostic severity from the {@link LexingDiagnosticSeverity} format to LSP's `DiagnosticSeverity` format.\n *\n * @param severity The lexing diagnostic severity\n * @returns Diagnostic severity according to `vscode-languageserver-types/lib/esm/main.js#DiagnosticSeverity`\n */\nexport function toDiagnosticSeverity(severity) {\n    switch (severity) {\n        case 'error':\n            return 1;\n        case 'warning':\n            return 2;\n        case 'info':\n            return 3;\n        case 'hint':\n            return 4;\n        default:\n            throw new Error('Invalid diagnostic severity: ' + severity);\n    }\n}\nexport function toDiagnosticData(severity) {\n    switch (severity) {\n        case 'error':\n            return diagnosticData(DocumentValidator.LexingError);\n        case 'warning':\n            return diagnosticData(DocumentValidator.LexingWarning);\n        case 'info':\n            return diagnosticData(DocumentValidator.LexingInfo);\n        case 'hint':\n            return diagnosticData(DocumentValidator.LexingHint);\n        default:\n            throw new Error('Invalid diagnostic severity: ' + severity);\n    }\n}\nexport var DocumentValidator;\n(function (DocumentValidator) {\n    DocumentValidator.LexingError = 'lexing-error';\n    DocumentValidator.LexingWarning = 'lexing-warning';\n    DocumentValidator.LexingInfo = 'lexing-info';\n    DocumentValidator.LexingHint = 'lexing-hint';\n    DocumentValidator.ParsingError = 'parsing-error';\n    DocumentValidator.LinkingError = 'linking-error';\n})(DocumentValidator || (DocumentValidator = {}));\n//# sourceMappingURL=document-validator.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { isMultiReference, isReference } from '../syntax-tree.js';\nimport { getDocument, streamAst, streamReferences } from '../utils/ast-utils.js';\nimport { toDocumentSegment } from '../utils/cst-utils.js';\nimport { interruptAndCheck } from '../utils/promise-utils.js';\nimport { UriUtils } from '../utils/uri-utils.js';\nexport class DefaultAstNodeDescriptionProvider {\n    constructor(services) {\n        this.astNodeLocator = services.workspace.AstNodeLocator;\n        this.nameProvider = services.references.NameProvider;\n    }\n    createDescription(node, name, document) {\n        const doc = document ?? getDocument(node);\n        name ?? (name = this.nameProvider.getName(node));\n        const path = this.astNodeLocator.getAstNodePath(node);\n        if (!name) {\n            throw new Error(`Node at path ${path} has no name.`);\n        }\n        let nameNodeSegment;\n        const nameSegmentGetter = () => nameNodeSegment ?? (nameNodeSegment = toDocumentSegment(this.nameProvider.getNameNode(node) ?? node.$cstNode));\n        return {\n            node,\n            name,\n            get nameSegment() {\n                return nameSegmentGetter();\n            },\n            selectionSegment: toDocumentSegment(node.$cstNode),\n            type: node.$type,\n            documentUri: doc.uri,\n            path\n        };\n    }\n}\nexport class DefaultReferenceDescriptionProvider {\n    constructor(services) {\n        this.nodeLocator = services.workspace.AstNodeLocator;\n    }\n    async createDescriptions(document, cancelToken = CancellationToken.None) {\n        const descr = [];\n        const rootNode = document.parseResult.value;\n        for (const astNode of streamAst(rootNode)) {\n            await interruptAndCheck(cancelToken);\n            streamReferences(astNode).forEach(refInfo => {\n                if (!refInfo.reference.error) {\n                    descr.push(...this.createInfoDescriptions(refInfo));\n                }\n            });\n        }\n        return descr;\n    }\n    createInfoDescriptions(refInfo) {\n        const reference = refInfo.reference;\n        if (reference.error || !reference.$refNode) {\n            return [];\n        }\n        let items = [];\n        if (isReference(reference) && reference.$nodeDescription) {\n            items = [reference.$nodeDescription];\n        }\n        else if (isMultiReference(reference)) {\n            items = reference.items.map(e => e.$nodeDescription).filter(e => e !== undefined);\n        }\n        const sourceUri = getDocument(refInfo.container).uri;\n        const sourcePath = this.nodeLocator.getAstNodePath(refInfo.container);\n        const descriptions = [];\n        const segment = toDocumentSegment(reference.$refNode);\n        for (const item of items) {\n            descriptions.push({\n                sourceUri,\n                sourcePath,\n                targetUri: item.documentUri,\n                targetPath: item.path,\n                segment,\n                local: UriUtils.equals(item.documentUri, sourceUri)\n            });\n        }\n        return descriptions;\n    }\n}\n//# sourceMappingURL=ast-descriptions.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nexport class DefaultAstNodeLocator {\n    constructor() {\n        this.segmentSeparator = '/';\n        this.indexSeparator = '@';\n    }\n    getAstNodePath(node) {\n        if (node.$container) {\n            const containerPath = this.getAstNodePath(node.$container);\n            const newSegment = this.getPathSegment(node);\n            const nodePath = containerPath + this.segmentSeparator + newSegment;\n            return nodePath;\n        }\n        return '';\n    }\n    getPathSegment({ $containerProperty, $containerIndex }) {\n        if (!$containerProperty) {\n            throw new Error(\"Missing '$containerProperty' in AST node.\");\n        }\n        if ($containerIndex !== undefined) {\n            return $containerProperty + this.indexSeparator + $containerIndex;\n        }\n        return $containerProperty;\n    }\n    getAstNode(node, path) {\n        const segments = path.split(this.segmentSeparator);\n        return segments.reduce((previousValue, currentValue) => {\n            if (!previousValue || currentValue.length === 0) {\n                return previousValue;\n            }\n            const propertyIndex = currentValue.indexOf(this.indexSeparator);\n            if (propertyIndex > 0) {\n                const property = currentValue.substring(0, propertyIndex);\n                const arrayIndex = parseInt(currentValue.substring(propertyIndex + 1));\n                const array = previousValue[property];\n                return array?.[arrayIndex];\n            }\n            return previousValue[currentValue];\n        }, node);\n    }\n}\n//# sourceMappingURL=ast-node-locator.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { Emitter } from '../utils/event.js';\nimport { Deferred } from '../utils/promise-utils.js';\n/**\n * Base configuration provider for building up other configuration providers\n */\nexport class DefaultConfigurationProvider {\n    constructor(services) {\n        this._ready = new Deferred();\n        this.onConfigurationSectionUpdateEmitter = new Emitter();\n        this.settings = {};\n        this.workspaceConfig = false;\n        this.serviceRegistry = services.ServiceRegistry;\n    }\n    get ready() {\n        return this._ready.promise;\n    }\n    initialize(params) {\n        this.workspaceConfig = params.capabilities.workspace?.configuration ?? false;\n    }\n    async initialized(params) {\n        if (this.workspaceConfig) {\n            if (params.register) {\n                // params.register(...) is a function to be provided by the calling language server for the sake of\n                //  decoupling this implementation from the concrete LSP implementations, specifically the LSP Connection\n                const languages = this.serviceRegistry.all;\n                params.register({\n                    // Listen to configuration changes for all languages\n                    section: languages.map(lang => this.toSectionName(lang.LanguageMetaData.languageId))\n                });\n            }\n            if (params.fetchConfiguration) {\n                // params.fetchConfiguration(...) is a function to be provided by the calling language server for the sake of\n                //  decoupling this implementation from the concrete LSP implementations, specifically the LSP Connection\n                const configToUpdate = this.serviceRegistry.all.map(lang => ({\n                    // Fetch the configuration changes for all languages\n                    section: this.toSectionName(lang.LanguageMetaData.languageId)\n                }));\n                // get workspace configurations (default scope URI)\n                const configs = await params.fetchConfiguration(configToUpdate);\n                configToUpdate.forEach((conf, idx) => {\n                    this.updateSectionConfiguration(conf.section, configs[idx]);\n                });\n            }\n        }\n        this._ready.resolve();\n    }\n    /**\n     *  Updates the cached configurations using the `change` notification parameters.\n     *\n     * @param change The parameters of a change configuration notification.\n     * `settings` property of the change object could be expressed as `Record<string, Record<string, any>>`\n     */\n    updateConfiguration(change) {\n        if (typeof change.settings !== 'object' || change.settings === null) {\n            return;\n        }\n        Object.entries(change.settings).forEach(([section, configuration]) => {\n            this.updateSectionConfiguration(section, configuration);\n            this.onConfigurationSectionUpdateEmitter.fire({ section, configuration });\n        });\n    }\n    updateSectionConfiguration(section, configuration) {\n        this.settings[section] = configuration;\n    }\n    /**\n    * Returns a configuration value stored for the given language.\n    *\n    * @param language The language id\n    * @param configuration Configuration name\n    */\n    async getConfiguration(language, configuration) {\n        await this.ready;\n        const sectionName = this.toSectionName(language);\n        if (this.settings[sectionName]) {\n            return this.settings[sectionName][configuration];\n        }\n    }\n    toSectionName(languageId) {\n        return `${languageId}`;\n    }\n    get onConfigurationSectionUpdate() {\n        return this.onConfigurationSectionUpdateEmitter.event;\n    }\n}\n//# sourceMappingURL=configuration.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nexport var Disposable;\n(function (Disposable) {\n    function create(callback) {\n        return {\n            dispose: async () => await callback()\n        };\n    }\n    Disposable.create = create;\n})(Disposable || (Disposable = {}));\n//# sourceMappingURL=disposable.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { LSPErrorCodes, ResponseError } from 'vscode-languageserver-protocol';\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { Disposable } from '../utils/disposable.js';\nimport { MultiMap } from '../utils/collections.js';\nimport { OperationCancelled, interruptAndCheck, isOperationCancelled } from '../utils/promise-utils.js';\nimport { stream } from '../utils/stream.js';\nimport { UriUtils } from '../utils/uri-utils.js';\nimport { DocumentState } from './documents.js';\nexport class DefaultDocumentBuilder {\n    constructor(services) {\n        this.updateBuildOptions = {\n            // Default: run only the built-in validation checks and those in the _fast_ category (includes those without category)\n            validation: {\n                categories: ['built-in', 'fast']\n            }\n        };\n        this.updateListeners = [];\n        this.buildPhaseListeners = new MultiMap();\n        this.documentPhaseListeners = new MultiMap();\n        this.buildState = new Map();\n        this.documentBuildWaiters = new Map();\n        this.currentState = DocumentState.Changed;\n        this.langiumDocuments = services.workspace.LangiumDocuments;\n        this.langiumDocumentFactory = services.workspace.LangiumDocumentFactory;\n        this.textDocuments = services.workspace.TextDocuments;\n        this.indexManager = services.workspace.IndexManager;\n        this.fileSystemProvider = services.workspace.FileSystemProvider;\n        this.workspaceManager = () => services.workspace.WorkspaceManager;\n        this.serviceRegistry = services.ServiceRegistry;\n    }\n    async build(documents, options = {}, cancelToken = CancellationToken.None) {\n        for (const document of documents) {\n            const key = document.uri.toString();\n            if (document.state === DocumentState.Validated) {\n                if (typeof options.validation === 'boolean' && options.validation) {\n                    // Force re-running all validation checks\n                    this.resetToState(document, DocumentState.IndexedReferences);\n                }\n                else if (typeof options.validation === 'object') {\n                    // Validation with explicit options was requested for a document that has already been partly validated.\n                    // In this case, we need to execute only the missing validation categories.\n                    const categories = this.findMissingValidationCategories(document, options);\n                    if (categories.length > 0) {\n                        // Validate this document, since some of the requested validation categories are not executed yet.\n                        //  In all other cases/else-branches, the document is not build at all.\n                        this.buildState.set(key, {\n                            completed: false,\n                            options: {\n                                validation: {\n                                    categories\n                                }\n                            },\n                            result: this.buildState.get(key)?.result,\n                        });\n                        // Reset the state, but keep the existing validation markers of the already completed validation categories.\n                        document.state = DocumentState.IndexedReferences;\n                    }\n                }\n            }\n            else {\n                // Default: forget any previous build options\n                this.buildState.delete(key);\n            }\n        }\n        this.currentState = DocumentState.Changed;\n        await this.emitUpdate(documents.map(e => e.uri), []);\n        await this.buildDocuments(documents, options, cancelToken);\n    }\n    async update(changed, deleted, cancelToken = CancellationToken.None) {\n        this.currentState = DocumentState.Changed;\n        // Remove all metadata of documents that are reported as deleted\n        const deletedUris = [];\n        for (const deletedUri of deleted) {\n            // Since the deleted URI might point to a directory, we delete all documents within\n            const deletedDocs = this.langiumDocuments.deleteDocuments(deletedUri);\n            for (const doc of deletedDocs) {\n                deletedUris.push(doc.uri);\n                this.cleanUpDeleted(doc);\n            }\n        }\n        // Since the changed URI might point to a directory, we need to check all (nested) documents in that directory\n        const changedUris = (await Promise.all(changed.map(uri => this.findChangedUris(uri)))).flat();\n        // Set the state of all changed documents to `Changed` so they are completely rebuilt\n        for (const changedUri of changedUris) {\n            let changedDocument = this.langiumDocuments.getDocument(changedUri);\n            if (changedDocument === undefined) {\n                // We create an unparsed, invalid document.\n                // This will be parsed as soon as we reach the first document builder phase.\n                // This allows to cancel the parsing process later in case we need it.\n                changedDocument = this.langiumDocumentFactory.fromModel({ $type: 'INVALID' }, changedUri);\n                changedDocument.state = DocumentState.Changed; // required, since `langiumDocumentFactory.fromModel` marks the new document as `DocumentState.Parsed`\n                this.langiumDocuments.addDocument(changedDocument);\n            }\n            this.resetToState(changedDocument, DocumentState.Changed);\n        }\n        // Set the state of all documents that should be relinked to `ComputedScopes` (if not already lower)\n        const allChangedUris = stream(changedUris).concat(deletedUris).map(uri => uri.toString()).toSet();\n        this.langiumDocuments.all\n            .filter(doc => !allChangedUris.has(doc.uri.toString()) && this.shouldRelink(doc, allChangedUris))\n            .forEach(doc => this.resetToState(doc, DocumentState.ComputedScopes));\n        // Notify listeners of the update\n        await this.emitUpdate(changedUris, deletedUris);\n        // Only allow interrupting the execution after all state changes are done\n        await interruptAndCheck(cancelToken);\n        // Collect and sort all documents that we should rebuild\n        const rebuildDocuments = this.sortDocuments(this.langiumDocuments.all\n            .filter(doc => \n        // This includes those that were reported as changed and those that we selected for relinking\n        doc.state < DocumentState.Validated\n            // This includes those for which a previous build has been cancelled\n            || !this.buildState.get(doc.uri.toString())?.completed\n            // `updateBuildOptions` changed between the last build (which is completed) and the current build,\n            //  leading to incomplete results, e.g. some validation categories are requested, which are not executed during the last build\n            || this.resultsAreIncomplete(doc, this.updateBuildOptions))\n            .toArray());\n        await this.buildDocuments(rebuildDocuments, this.updateBuildOptions, cancelToken);\n    }\n    resultsAreIncomplete(document, options) {\n        return this.findMissingValidationCategories(document, options).length >= 1;\n    }\n    findMissingValidationCategories(document, options) {\n        const state = this.buildState.get(document.uri.toString());\n        const allCategories = this.serviceRegistry.getServices(document.uri).validation.ValidationRegistry.getAllValidationCategories(document);\n        const executedCategories = state?.result?.validationChecks ? new Set(state?.result?.validationChecks) : state?.completed ? allCategories : new Set();\n        const requestedCategories = (options === undefined || options.validation === true) ? allCategories\n            : typeof options.validation === 'object' ? (options.validation.categories ?? allCategories) : [];\n        return stream(requestedCategories).filter(requested => !executedCategories.has(requested)).toArray();\n    }\n    async findChangedUris(changed) {\n        // Most common case is that the document/textDocument at the specified URI has changed\n        const document = this.langiumDocuments.getDocument(changed) ?? this.textDocuments?.get(changed);\n        if (document) {\n            return [changed];\n        }\n        // If the document doesn't exist yet, we need to check what kind of file has changed\n        try {\n            const stat = await this.fileSystemProvider.stat(changed);\n            if (stat.isDirectory) {\n                // If a directory has changed, we need to check all documents in that directory\n                const uris = await this.workspaceManager().searchFolder(changed);\n                return uris;\n            }\n            else if (this.workspaceManager().shouldIncludeEntry(stat)) {\n                // Return the changed URI if it's a file that we can handle\n                return [changed];\n            }\n        }\n        catch {\n            // If we can't determine the file type, we discard the change\n        }\n        return [];\n    }\n    async emitUpdate(changed, deleted) {\n        await Promise.all(this.updateListeners.map(listener => listener(changed, deleted)));\n    }\n    /**\n     * Sort the given documents by priority. By default, documents with an open text document are prioritized.\n     * This is useful to ensure that visible documents show their diagnostics before all other documents.\n     *\n     * This improves the responsiveness in large workspaces as users usually don't care about diagnostics\n     * in files that are currently not opened in the editor.\n     */\n    sortDocuments(documents) {\n        let left = 0;\n        let right = documents.length - 1;\n        while (left < right) {\n            while (left < documents.length && this.hasTextDocument(documents[left])) {\n                left++;\n            }\n            while (right >= 0 && !this.hasTextDocument(documents[right])) {\n                right--;\n            }\n            if (left < right) {\n                [documents[left], documents[right]] = [documents[right], documents[left]];\n            }\n        }\n        return documents;\n    }\n    hasTextDocument(doc) {\n        return Boolean(this.textDocuments?.get(doc.uri));\n    }\n    /**\n     * Check whether the given document should be relinked after changes were found in the given URIs.\n     */\n    shouldRelink(document, changedUris) {\n        // Relink documents with linking errors -- maybe those references can be resolved now\n        if (document.references.some(ref => ref.error !== undefined)) {\n            return true;\n        }\n        // Check whether the document is affected by any of the changed URIs\n        return this.indexManager.isAffected(document, changedUris);\n    }\n    onUpdate(callback) {\n        this.updateListeners.push(callback);\n        return Disposable.create(() => {\n            const index = this.updateListeners.indexOf(callback);\n            if (index >= 0) {\n                this.updateListeners.splice(index, 1);\n            }\n        });\n    }\n    resetToState(document, state) {\n        switch (state) {\n            case DocumentState.Changed: {\n                // Fall through\n            }\n            case DocumentState.Parsed:\n                this.indexManager.removeContent(document.uri);\n            // Fall through\n            case DocumentState.IndexedContent:\n                document.localSymbols = undefined;\n            // Fall through\n            case DocumentState.ComputedScopes: {\n                const linker = this.serviceRegistry.getServices(document.uri).references.Linker;\n                linker.unlink(document);\n                // Fall through\n            }\n            case DocumentState.Linked:\n                this.indexManager.removeReferences(document.uri);\n            // Fall through\n            case DocumentState.IndexedReferences:\n                document.diagnostics = undefined;\n                this.buildState.delete(document.uri.toString());\n            // Fall through\n            case DocumentState.Validated:\n            // do nothing and keep the buildState\n        }\n        if (document.state > state) {\n            document.state = state;\n        }\n    }\n    cleanUpDeleted(document) {\n        this.buildState.delete(document.uri.toString());\n        this.indexManager.remove(document.uri);\n        // Since this method `cleanUpDeleted` is not available from outside, the following line is not necessary, since the state is already set before.\n        //  This line does not hurt and makes the code to be in sync with `resetToState`.\n        //  If `cleanUpDeleted` is called in custom document builders at some more places, this line becomes necessary.\n        document.state = DocumentState.Changed;\n    }\n    /**\n     * Build the given documents by stepping through all build phases. If a document's state indicates\n     * that a certain build phase is already done, the phase is skipped for that document.\n     *\n     * @param documents The documents to build.\n     * @param options the {@link BuildOptions} to use.\n     * @param cancelToken A cancellation token that can be used to cancel the build.\n     * @returns A promise that resolves when the build is done.\n     */\n    async buildDocuments(documents, options, cancelToken) {\n        this.prepareBuild(documents, options);\n        // 0. Parse content\n        await this.runCancelable(documents, DocumentState.Parsed, cancelToken, doc => this.langiumDocumentFactory.update(doc, cancelToken));\n        // 1. Index content: collect the documents' symbols being accessible by other documents\n        await this.runCancelable(documents, DocumentState.IndexedContent, cancelToken, doc => this.indexManager.updateContent(doc, cancelToken));\n        // 2. Local symbols: collect each documents' symbols being accessible within the document (only)\n        await this.runCancelable(documents, DocumentState.ComputedScopes, cancelToken, async (doc) => {\n            const scopeComputation = this.serviceRegistry.getServices(doc.uri).references.ScopeComputation;\n            doc.localSymbols = await scopeComputation.collectLocalSymbols(doc, cancelToken);\n        });\n        // 3. Linking\n        const toBeLinked = documents.filter(doc => this.shouldLink(doc));\n        await this.runCancelable(toBeLinked, DocumentState.Linked, cancelToken, doc => {\n            const linker = this.serviceRegistry.getServices(doc.uri).references.Linker;\n            return linker.link(doc, cancelToken);\n        });\n        // 4. Index references\n        await this.runCancelable(toBeLinked, DocumentState.IndexedReferences, cancelToken, doc => this.indexManager.updateReferences(doc, cancelToken));\n        // 5. Validation\n        const toBeValidated = documents.filter(doc => {\n            if (this.shouldValidate(doc)) {\n                return true; // the build state is marked as completed after finishing the validation for the current document\n            }\n            else {\n                this.markAsCompleted(doc); // since the validation is skipped for this document, it is already completed now\n                return false;\n            }\n        });\n        await this.runCancelable(toBeValidated, DocumentState.Validated, cancelToken, async (doc) => {\n            await this.validate(doc, cancelToken);\n            this.markAsCompleted(doc);\n        });\n    }\n    markAsCompleted(document) {\n        const state = this.buildState.get(document.uri.toString());\n        if (state) {\n            state.completed = true;\n        }\n    }\n    /**\n     * Runs prior to beginning the build process to update the {@link DocumentBuildState} for each document\n     *\n     * @param documents collection of documents to be built\n     * @param options the {@link BuildOptions} to use\n     */\n    prepareBuild(documents, options) {\n        for (const doc of documents) {\n            const key = doc.uri.toString();\n            const state = this.buildState.get(key);\n            if (!state // If the document has no previous build state, we set it.\n                || state.completed // If it has one, but it's already marked as completed, we overwrite it.\n            ) {\n                this.buildState.set(key, {\n                    completed: false,\n                    options,\n                    result: state?.result\n                });\n            }\n            else {\n                // If the previous build was not completed, we keep its DocumentState and continue from the DocumentState where it was cancelled,\n                //  e.g. the previous build options are used, including the previously requested validation categories.\n            }\n        }\n    }\n    /**\n     * Runs a cancelable operation on a set of documents to bring them to a specified {@link DocumentState}.\n     *\n     * @param documents The array of documents to process.\n     * @param targetState The target {@link DocumentState} to bring the documents to.\n     * @param cancelToken A token that can be used to cancel the operation.\n     * @param callback A function to be called for each document.\n     * @returns A promise that resolves when all documents have been processed or the operation is canceled.\n     * @throws Will throw `OperationCancelled` if the operation is canceled via a `CancellationToken`.\n     */\n    async runCancelable(documents, targetState, cancelToken, callback) {\n        for (const document of documents) {\n            if (document.state < targetState) {\n                await interruptAndCheck(cancelToken);\n                await callback(document);\n                document.state = targetState;\n                await this.notifyDocumentPhase(document, targetState, cancelToken);\n            }\n        }\n        // Do not use `filtered` here, as that will miss documents that have previously reached the current target state.\n        // For example, this happens in case the cancellation triggers between the processing of two documents\n        // or files that were picked up during the workspace initialization.\n        const targetStateDocs = documents.filter(doc => doc.state === targetState);\n        await this.notifyBuildPhase(targetStateDocs, targetState, cancelToken);\n        this.currentState = targetState;\n    }\n    onBuildPhase(targetState, callback) {\n        this.buildPhaseListeners.add(targetState, callback);\n        return Disposable.create(() => {\n            this.buildPhaseListeners.delete(targetState, callback);\n        });\n    }\n    onDocumentPhase(targetState, callback) {\n        this.documentPhaseListeners.add(targetState, callback);\n        return Disposable.create(() => {\n            this.documentPhaseListeners.delete(targetState, callback);\n        });\n    }\n    waitUntil(state, uriOrToken, cancelToken) {\n        let uri = undefined;\n        if (uriOrToken && 'path' in uriOrToken) {\n            uri = uriOrToken;\n        }\n        else {\n            cancelToken = uriOrToken;\n        }\n        cancelToken ?? (cancelToken = CancellationToken.None);\n        if (uri) {\n            return this.awaitDocumentState(state, uri, cancelToken);\n        }\n        else {\n            return this.awaitBuilderState(state, cancelToken);\n        }\n    }\n    awaitDocumentState(state, uri, cancelToken) {\n        const document = this.langiumDocuments.getDocument(uri);\n        if (!document) {\n            return Promise.reject(new ResponseError(LSPErrorCodes.ServerCancelled, `No document found for URI: ${uri.toString()}`));\n        }\n        else if (document.state >= state) {\n            return Promise.resolve(uri);\n        }\n        else if (cancelToken.isCancellationRequested) {\n            return Promise.reject(OperationCancelled);\n        }\n        else if (this.currentState >= state && state > document.state) {\n            // this would imply that the document has been excluded from linking or validation, for example;\n            // this should never occur, the LS need to make sure that the affected document is properly built,\n            //  alternatively, the build state requirement need to be relaxed.\n            return Promise.reject(new ResponseError(LSPErrorCodes.RequestFailed, `Document state of ${uri.toString()} is ${DocumentState[document.state]}, requiring ${DocumentState[state]}, but workspace state is already ${DocumentState[this.currentState]}. Returning undefined.`));\n        }\n        return new Promise((resolve, reject) => {\n            const buildDisposable = this.onDocumentPhase(state, (doc) => {\n                if (UriUtils.equals(doc.uri, uri)) {\n                    buildDisposable.dispose();\n                    cancelDisposable.dispose();\n                    resolve(doc.uri);\n                }\n            });\n            const cancelDisposable = cancelToken.onCancellationRequested(() => {\n                buildDisposable.dispose();\n                cancelDisposable.dispose();\n                reject(OperationCancelled);\n            });\n        });\n    }\n    awaitBuilderState(state, cancelToken) {\n        if (this.currentState >= state) {\n            return Promise.resolve();\n        }\n        else if (cancelToken.isCancellationRequested) {\n            return Promise.reject(OperationCancelled);\n        }\n        return new Promise((resolve, reject) => {\n            const buildDisposable = this.onBuildPhase(state, () => {\n                buildDisposable.dispose();\n                cancelDisposable.dispose();\n                resolve();\n            });\n            const cancelDisposable = cancelToken.onCancellationRequested(() => {\n                buildDisposable.dispose();\n                cancelDisposable.dispose();\n                reject(OperationCancelled);\n            });\n        });\n    }\n    async notifyDocumentPhase(document, state, cancelToken) {\n        const listeners = this.documentPhaseListeners.get(state);\n        const listenersCopy = listeners.slice();\n        for (const listener of listenersCopy) {\n            try {\n                await interruptAndCheck(cancelToken);\n                await listener(document, cancelToken);\n            }\n            catch (err) {\n                // Ignore cancellation errors\n                // We want to finish the listeners before throwing\n                if (!isOperationCancelled(err)) {\n                    throw err;\n                }\n            }\n        }\n    }\n    async notifyBuildPhase(documents, state, cancelToken) {\n        if (documents.length === 0) {\n            // Don't notify when no document has been processed\n            return;\n        }\n        const listeners = this.buildPhaseListeners.get(state);\n        const listenersCopy = listeners.slice();\n        for (const listener of listenersCopy) {\n            await interruptAndCheck(cancelToken);\n            await listener(documents, cancelToken);\n        }\n    }\n    /**\n     * Determine whether the given document should be linked during a build. The default\n     * implementation checks the `eagerLinking` property of the build options. If it's set to `true`\n     * or `undefined`, the document is included in the linking phase. This also affects the\n     * references indexing phase, which depends on eager linking.\n     */\n    shouldLink(document) {\n        return this.getBuildOptions(document).eagerLinking ?? true;\n    }\n    /**\n     * Determine whether the given document should be validated during a build. The default\n     * implementation checks the `validation` property of the build options. If it's set to `true`\n     * or a `ValidationOptions` object, the document is included in the validation phase.\n     */\n    shouldValidate(document) {\n        return Boolean(this.getBuildOptions(document).validation);\n    }\n    /**\n     * Run validation checks on the given document and store the resulting diagnostics in the document.\n     * If the document already contains diagnostics, the new ones are added to the list.\n     */\n    async validate(document, cancelToken) {\n        const validator = this.serviceRegistry.getServices(document.uri).validation.DocumentValidator;\n        const options = this.getBuildOptions(document);\n        const validationOptions = typeof options.validation === 'object' ? { ...options.validation } : {};\n        validationOptions.categories = this.findMissingValidationCategories(document, options); // execute only not-yet-executed categories\n        const diagnostics = await validator.validateDocument(document, validationOptions, cancelToken);\n        if (document.diagnostics) {\n            document.diagnostics.push(...diagnostics); // keep diagnostics of previously executed categories\n        }\n        else {\n            document.diagnostics = diagnostics;\n        }\n        // Store information about the executed validation in the build state\n        const state = this.buildState.get(document.uri.toString());\n        if (state) {\n            state.result ?? (state.result = {});\n            if (state.result.validationChecks) {\n                state.result.validationChecks = stream(state.result.validationChecks).concat(validationOptions.categories).distinct().toArray();\n            }\n            else {\n                state.result.validationChecks = [...validationOptions.categories];\n            }\n        }\n    }\n    getBuildOptions(document) {\n        return this.buildState.get(document.uri.toString())?.options ?? {};\n    }\n}\n//# sourceMappingURL=document-builder.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { getDocument } from '../utils/ast-utils.js';\nimport { ContextCache } from '../utils/caching.js';\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { stream } from '../utils/stream.js';\nimport { UriUtils } from '../utils/uri-utils.js';\nexport class DefaultIndexManager {\n    constructor(services) {\n        /**\n         * The symbol index stores all `AstNodeDescription` items exported by a document.\n         * The key used in this map is the string representation of the specific document URI.\n         */\n        this.symbolIndex = new Map();\n        /**\n         * This is a cache for the `allElements()` method.\n         * It caches the descriptions from `symbolIndex` grouped by types.\n         */\n        this.symbolByTypeIndex = new ContextCache();\n        /**\n         * This index keeps track of all `ReferenceDescription` items exported by a document.\n         * This is used to compute which elements are affected by a document change\n         * and for finding references to an AST node.\n         */\n        this.referenceIndex = new Map();\n        this.documents = services.workspace.LangiumDocuments;\n        this.serviceRegistry = services.ServiceRegistry;\n        this.astReflection = services.AstReflection;\n    }\n    findAllReferences(targetNode, astNodePath) {\n        const targetDocUri = getDocument(targetNode).uri;\n        const result = [];\n        this.referenceIndex.forEach(docRefs => {\n            docRefs.forEach(refDescr => {\n                if (UriUtils.equals(refDescr.targetUri, targetDocUri) && refDescr.targetPath === astNodePath) {\n                    result.push(refDescr);\n                }\n            });\n        });\n        return stream(result);\n    }\n    allElements(nodeType, uris) {\n        let documentUris = stream(this.symbolIndex.keys());\n        if (uris) {\n            documentUris = documentUris.filter(uri => !uris || uris.has(uri));\n        }\n        return documentUris\n            .map(uri => this.getFileDescriptions(uri, nodeType))\n            .flat();\n    }\n    getFileDescriptions(uri, nodeType) {\n        if (!nodeType) {\n            return this.symbolIndex.get(uri) ?? [];\n        }\n        const descriptions = this.symbolByTypeIndex.get(uri, nodeType, () => {\n            const allFileDescriptions = this.symbolIndex.get(uri) ?? [];\n            return allFileDescriptions.filter(e => this.astReflection.isSubtype(e.type, nodeType));\n        });\n        return descriptions;\n    }\n    remove(uri) {\n        this.removeContent(uri);\n        this.removeReferences(uri);\n    }\n    removeContent(uri) {\n        const uriString = uri.toString();\n        this.symbolIndex.delete(uriString);\n        this.symbolByTypeIndex.clear(uriString);\n    }\n    removeReferences(uri) {\n        const uriString = uri.toString();\n        this.referenceIndex.delete(uriString);\n    }\n    async updateContent(document, cancelToken = CancellationToken.None) {\n        const services = this.serviceRegistry.getServices(document.uri);\n        const exports = await services.references.ScopeComputation.collectExportedSymbols(document, cancelToken);\n        const uri = document.uri.toString();\n        this.symbolIndex.set(uri, exports);\n        this.symbolByTypeIndex.clear(uri);\n    }\n    async updateReferences(document, cancelToken = CancellationToken.None) {\n        const services = this.serviceRegistry.getServices(document.uri);\n        const indexData = await services.workspace.ReferenceDescriptionProvider.createDescriptions(document, cancelToken);\n        this.referenceIndex.set(document.uri.toString(), indexData);\n    }\n    isAffected(document, changedUris) {\n        const references = this.referenceIndex.get(document.uri.toString());\n        if (!references) {\n            return false;\n        }\n        return references.some(ref => !ref.local && changedUris.has(ref.targetUri.toString()));\n    }\n}\n//# sourceMappingURL=index-manager.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { CancellationToken } from '../utils/cancellation.js';\nimport { Deferred, interruptAndCheck } from '../utils/promise-utils.js';\nimport { URI, UriUtils } from '../utils/uri-utils.js';\nimport { stream } from '../utils/stream.js';\nexport class DefaultWorkspaceManager {\n    constructor(services) {\n        this.initialBuildOptions = {};\n        this._ready = new Deferred();\n        this.serviceRegistry = services.ServiceRegistry;\n        this.langiumDocuments = services.workspace.LangiumDocuments;\n        this.documentBuilder = services.workspace.DocumentBuilder;\n        this.fileSystemProvider = services.workspace.FileSystemProvider;\n        this.mutex = services.workspace.WorkspaceLock;\n    }\n    get ready() {\n        return this._ready.promise;\n    }\n    get workspaceFolders() {\n        return this.folders;\n    }\n    initialize(params) {\n        this.folders = params.workspaceFolders ?? undefined;\n    }\n    initialized(_params) {\n        // Initialize the workspace even if there are no workspace folders\n        // We still want to load additional documents (language library or similar) during initialization\n        return this.mutex.write(token => this.initializeWorkspace(this.folders ?? [], token));\n    }\n    async initializeWorkspace(folders, cancelToken = CancellationToken.None) {\n        const documents = await this.performStartup(folders);\n        // Only after creating all documents do we check whether we need to cancel the initialization\n        // The document builder will later pick up on all unprocessed documents\n        await interruptAndCheck(cancelToken);\n        await this.documentBuilder.build(documents, this.initialBuildOptions, cancelToken);\n    }\n    /**\n     * Performs the uninterruptable startup sequence of the workspace manager.\n     * This methods loads all documents in the workspace and other documents and returns them.\n     */\n    async performStartup(folders) {\n        const documents = [];\n        const collector = (document) => {\n            documents.push(document);\n            if (!this.langiumDocuments.hasDocument(document.uri)) {\n                this.langiumDocuments.addDocument(document);\n            }\n        };\n        // Even though we don't await the initialization of the workspace manager,\n        // we can still assume that all library documents and file documents are loaded by the time we start building documents.\n        // The mutex prevents anything from performing a workspace build until we check the cancellation token\n        await this.loadAdditionalDocuments(folders, collector);\n        const uris = [];\n        await Promise.all(folders.map(wf => this.getRootFolder(wf))\n            .map(async (entry) => this.traverseFolder(entry, uris)));\n        const uniqueUris = stream(uris)\n            // Ensure that we only create one document per URI/file\n            .distinct(uri => uri.toString())\n            // Also ensure that the documents don't already exist\n            .filter(uri => !this.langiumDocuments.hasDocument(uri));\n        await this.loadWorkspaceDocuments(uniqueUris, collector);\n        this._ready.resolve();\n        return documents;\n    }\n    async loadWorkspaceDocuments(uris, collector) {\n        await Promise.all(uris.map(async (uri) => {\n            const document = await this.langiumDocuments.getOrCreateDocument(uri);\n            collector(document);\n        }));\n    }\n    /**\n     * Load all additional documents that shall be visible in the context of the given workspace\n     * folders and add them to the collector. This can be used to include built-in libraries of\n     * your language, which can be either loaded from provided files or constructed in memory.\n     */\n    loadAdditionalDocuments(_folders, _collector) {\n        return Promise.resolve();\n    }\n    /**\n     * Determine the root folder of the source documents in the given workspace folder.\n     * The default implementation returns the URI of the workspace folder, but you can override\n     * this to return a subfolder like `src` instead.\n     */\n    getRootFolder(workspaceFolder) {\n        return URI.parse(workspaceFolder.uri);\n    }\n    /**\n     * Traverse the file system folder identified by the given URI and its subfolders. All\n     * contained files that match the file extensions are added to the `uris` array.\n     */\n    async traverseFolder(folderPath, uris) {\n        try {\n            const content = await this.fileSystemProvider.readDirectory(folderPath);\n            await Promise.all(content.map(async (entry) => {\n                if (this.shouldIncludeEntry(entry)) {\n                    if (entry.isDirectory) {\n                        await this.traverseFolder(entry.uri, uris);\n                    }\n                    else if (entry.isFile) {\n                        uris.push(entry.uri);\n                    }\n                }\n            }));\n        }\n        catch (e) {\n            console.error('Failure to read directory content of ' + folderPath.toString(true), e);\n        }\n    }\n    async searchFolder(uri) {\n        const uris = [];\n        await this.traverseFolder(uri, uris);\n        return uris;\n    }\n    /**\n     * Determine whether the given folder entry shall be included while indexing the workspace.\n     */\n    shouldIncludeEntry(entry) {\n        const name = UriUtils.basename(entry.uri);\n        if (name.startsWith('.')) {\n            return false;\n        }\n        if (entry.isDirectory) {\n            return name !== 'node_modules' && name !== 'out';\n        }\n        else if (entry.isFile) {\n            return this.serviceRegistry.hasServices(entry.uri);\n        }\n        return false;\n    }\n}\n//# sourceMappingURL=workspace-manager.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { Lexer as ChevrotainLexer, defaultLexerErrorProvider } from 'chevrotain';\nexport class DefaultLexerErrorMessageProvider {\n    buildUnexpectedCharactersMessage(fullText, startOffset, length, line, column) {\n        return defaultLexerErrorProvider.buildUnexpectedCharactersMessage(fullText, startOffset, length, line, column);\n    }\n    buildUnableToPopLexerModeMessage(token) {\n        return defaultLexerErrorProvider.buildUnableToPopLexerModeMessage(token);\n    }\n}\nexport const DEFAULT_TOKENIZE_OPTIONS = { mode: 'full' };\nexport class DefaultLexer {\n    constructor(services) {\n        this.errorMessageProvider = services.parser.LexerErrorMessageProvider;\n        this.tokenBuilder = services.parser.TokenBuilder;\n        const tokens = this.tokenBuilder.buildTokens(services.Grammar, {\n            caseInsensitive: services.LanguageMetaData.caseInsensitive\n        });\n        this.tokenTypes = this.toTokenTypeDictionary(tokens);\n        const lexerTokens = isTokenTypeDictionary(tokens) ? Object.values(tokens) : tokens;\n        const production = services.LanguageMetaData.mode === 'production';\n        this.chevrotainLexer = new ChevrotainLexer(lexerTokens, {\n            positionTracking: 'full',\n            skipValidations: production,\n            errorMessageProvider: this.errorMessageProvider\n        });\n    }\n    get definition() {\n        return this.tokenTypes;\n    }\n    tokenize(text, _options = DEFAULT_TOKENIZE_OPTIONS) {\n        const chevrotainResult = this.chevrotainLexer.tokenize(text);\n        return {\n            tokens: chevrotainResult.tokens,\n            errors: chevrotainResult.errors,\n            hidden: chevrotainResult.groups.hidden ?? [],\n            report: this.tokenBuilder.flushLexingReport?.(text)\n        };\n    }\n    toTokenTypeDictionary(buildTokens) {\n        if (isTokenTypeDictionary(buildTokens))\n            return buildTokens;\n        const tokens = isIMultiModeLexerDefinition(buildTokens) ? Object.values(buildTokens.modes).flat() : buildTokens;\n        const res = {};\n        tokens.forEach(token => res[token.name] = token);\n        return res;\n    }\n}\n/**\n * Returns a check whether the given TokenVocabulary is TokenType array\n */\nexport function isTokenTypeArray(tokenVocabulary) {\n    return Array.isArray(tokenVocabulary) && (tokenVocabulary.length === 0 || 'name' in tokenVocabulary[0]);\n}\n/**\n * Returns a check whether the given TokenVocabulary is IMultiModeLexerDefinition\n */\nexport function isIMultiModeLexerDefinition(tokenVocabulary) {\n    return tokenVocabulary && 'modes' in tokenVocabulary && 'defaultMode' in tokenVocabulary;\n}\n/**\n * Returns a check whether the given TokenVocabulary is TokenTypeDictionary\n */\nexport function isTokenTypeDictionary(tokenVocabulary) {\n    return !isTokenTypeArray(tokenVocabulary) && !isIMultiModeLexerDefinition(tokenVocabulary);\n}\n//# sourceMappingURL=lexer.js.map","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { Position, Range } from 'vscode-languageserver-types';\nimport { NEWLINE_REGEXP, escapeRegExp } from '../utils/regexp-utils.js';\nimport { URI } from '../utils/uri-utils.js';\nexport function parseJSDoc(node, start, options) {\n    let opts;\n    let position;\n    if (typeof node === 'string') {\n        position = start;\n        opts = options;\n    }\n    else {\n        position = node.range.start;\n        opts = start;\n    }\n    if (!position) {\n        position = Position.create(0, 0);\n    }\n    const lines = getLines(node);\n    const normalizedOptions = normalizeOptions(opts);\n    const tokens = tokenize({\n        lines,\n        position,\n        options: normalizedOptions\n    });\n    return parseJSDocComment({\n        index: 0,\n        tokens,\n        position\n    });\n}\nexport function isJSDoc(node, options) {\n    const normalizedOptions = normalizeOptions(options);\n    const lines = getLines(node);\n    if (lines.length === 0) {\n        return false;\n    }\n    const first = lines[0];\n    const last = lines[lines.length - 1];\n    const firstRegex = normalizedOptions.start;\n    const lastRegex = normalizedOptions.end;\n    return Boolean(firstRegex?.exec(first)) && Boolean(lastRegex?.exec(last));\n}\nfunction getLines(node) {\n    let content = '';\n    if (typeof node === 'string') {\n        content = node;\n    }\n    else {\n        content = node.text;\n    }\n    const lines = content.split(NEWLINE_REGEXP);\n    return lines;\n}\nconst tagRegex = /\\s*(@([\\p{L}][\\p{L}\\p{N}]*)?)/uy;\nconst inlineTagRegex = /\\{(@[\\p{L}][\\p{L}\\p{N}]*)(\\s*)([^\\r\\n}]+)?\\}/gu;\nfunction tokenize(context) {\n    const tokens = [];\n    let currentLine = context.position.line;\n    let currentCharacter = context.position.character;\n    for (let i = 0; i < context.lines.length; i++) {\n        const first = i === 0;\n        const last = i === context.lines.length - 1;\n        let line = context.lines[i];\n        let index = 0;\n        if (first && context.options.start) {\n            const match = context.options.start?.exec(line);\n            if (match) {\n                index = match.index + match[0].length;\n            }\n        }\n        else {\n            const match = context.options.line?.exec(line);\n            if (match) {\n                index = match.index + match[0].length;\n            }\n        }\n        if (last) {\n            const match = context.options.end?.exec(line);\n            if (match) {\n                line = line.substring(0, match.index);\n            }\n        }\n        line = line.substring(0, lastCharacter(line));\n        const whitespaceEnd = skipWhitespace(line, index);\n        if (whitespaceEnd >= line.length) {\n            // Only create a break token when we already have previous tokens\n            if (tokens.length > 0) {\n                const position = Position.create(currentLine, currentCharacter);\n                tokens.push({\n                    type: 'break',\n                    content: '',\n                    range: Range.create(position, position)\n                });\n            }\n        }\n        else {\n            tagRegex.lastIndex = index;\n            const tagMatch = tagRegex.exec(line);\n            if (tagMatch) {\n                const fullMatch = tagMatch[0];\n                const value = tagMatch[1];\n                const start = Position.create(currentLine, currentCharacter + index);\n                const end = Position.create(currentLine, currentCharacter + index + fullMatch.length);\n                tokens.push({\n                    type: 'tag',\n                    content: value,\n                    range: Range.create(start, end)\n                });\n                index += fullMatch.length;\n                index = skipWhitespace(line, index);\n            }\n            if (index < line.length) {\n                const rest = line.substring(index);\n                const inlineTagMatches = Array.from(rest.matchAll(inlineTagRegex));\n                tokens.push(...buildInlineTokens(inlineTagMatches, rest, currentLine, currentCharacter + index));\n            }\n        }\n        currentLine++;\n        currentCharacter = 0;\n    }\n    // Remove last break token if there is one\n    if (tokens.length > 0 && tokens[tokens.length - 1].type === 'break') {\n        return tokens.slice(0, -1);\n    }\n    return tokens;\n}\nfunction buildInlineTokens(tags, line, lineIndex, characterIndex) {\n    const tokens = [];\n    if (tags.length === 0) {\n        const start = Position.create(lineIndex, characterIndex);\n        const end = Position.create(lineIndex, characterIndex + line.length);\n        tokens.push({\n            type: 'text',\n            content: line,\n            range: Range.create(start, end)\n        });\n    }\n    else {\n        let lastIndex = 0;\n        for (const match of tags) {\n            const matchIndex = match.index;\n            const startContent = line.substring(lastIndex, matchIndex);\n            if (startContent.length > 0) {\n                tokens.push({\n                    type: 'text',\n                    content: line.substring(lastIndex, matchIndex),\n                    range: Range.create(Position.create(lineIndex, lastIndex + characterIndex), Position.create(lineIndex, matchIndex + characterIndex))\n                });\n            }\n            let offset = startContent.length + 1;\n            const tagName = match[1];\n            tokens.push({\n                type: 'inline-tag',\n                content: tagName,\n                range: Range.create(Position.create(lineIndex, lastIndex + offset + characterIndex), Position.create(lineIndex, lastIndex + offset + tagName.length + characterIndex))\n            });\n            offset += tagName.length;\n            if (match.length === 4) {\n                offset += match[2].length;\n                const value = match[3];\n                tokens.push({\n                    type: 'text',\n                    content: value,\n                    range: Range.create(Position.create(lineIndex, lastIndex + offset + characterIndex), Position.create(lineIndex, lastIndex + offset + value.length + characterIndex))\n                });\n            }\n            else {\n                tokens.push({\n                    type: 'text',\n                    content: '',\n                    range: Range.create(Position.create(lineIndex, lastIndex + offset + characterIndex), Position.create(lineIndex, lastIndex + offset + characterIndex))\n                });\n            }\n            lastIndex = matchIndex + match[0].length;\n        }\n        const endContent = line.substring(lastIndex);\n        if (endContent.length > 0) {\n            tokens.push({\n                type: 'text',\n                content: endContent,\n                range: Range.create(Position.create(lineIndex, lastIndex + characterIndex), Position.create(lineIndex, lastIndex + characterIndex + endContent.length))\n            });\n        }\n    }\n    return tokens;\n}\nconst nonWhitespaceRegex = /\\S/;\nconst whitespaceEndRegex = /\\s*$/;\nfunction skipWhitespace(line, index) {\n    const match = line.substring(index).match(nonWhitespaceRegex);\n    if (match) {\n        return index + match.index;\n    }\n    else {\n        return line.length;\n    }\n}\nfunction lastCharacter(line) {\n    const match = line.match(whitespaceEndRegex);\n    if (match && typeof match.index === 'number') {\n        return match.index;\n    }\n    return undefined;\n}\n// Parsing\nfunction parseJSDocComment(context) {\n    const startPosition = Position.create(context.position.line, context.position.character);\n    if (context.tokens.length === 0) {\n        return new JSDocCommentImpl([], Range.create(startPosition, startPosition));\n    }\n    const elements = [];\n    while (context.index < context.tokens.length) {\n        const element = parseJSDocElement(context, elements[elements.length - 1]);\n        if (element) {\n            elements.push(element);\n        }\n    }\n    const start = elements[0]?.range.start ?? startPosition;\n    const end = elements[elements.length - 1]?.range.end ?? startPosition;\n    return new JSDocCommentImpl(elements, Range.create(start, end));\n}\nfunction parseJSDocElement(context, last) {\n    const next = context.tokens[context.index];\n    if (next.type === 'tag') {\n        return parseJSDocTag(context, false);\n    }\n    else if (next.type === 'text' || next.type === 'inline-tag') {\n        return parseJSDocText(context);\n    }\n    else {\n        appendEmptyLine(next, last);\n        context.index++;\n        return undefined;\n    }\n}\nfunction appendEmptyLine(token, element) {\n    if (element) {\n        const line = new JSDocLineImpl('', token.range);\n        if ('inlines' in element) {\n            element.inlines.push(line);\n        }\n        else {\n            element.content.inlines.push(line);\n        }\n    }\n}\nfunction parseJSDocText(context) {\n    let token = context.tokens[context.index];\n    const firstToken = token;\n    let lastToken = token;\n    const lines = [];\n    while (token && token.type !== 'break' && token.type !== 'tag') {\n        lines.push(parseJSDocInline(context));\n        lastToken = token;\n        token = context.tokens[context.index];\n    }\n    return new JSDocTextImpl(lines, Range.create(firstToken.range.start, lastToken.range.end));\n}\nfunction parseJSDocInline(context) {\n    const token = context.tokens[context.index];\n    if (token.type === 'inline-tag') {\n        return parseJSDocTag(context, true);\n    }\n    else {\n        return parseJSDocLine(context);\n    }\n}\nfunction parseJSDocTag(context, inline) {\n    const tagToken = context.tokens[context.index++];\n    const name = tagToken.content.substring(1);\n    const nextToken = context.tokens[context.index];\n    if (nextToken?.type === 'text') {\n        if (inline) {\n            const docLine = parseJSDocLine(context);\n            return new JSDocTagImpl(name, new JSDocTextImpl([docLine], docLine.range), inline, Range.create(tagToken.range.start, docLine.range.end));\n        }\n        else {\n            const textDoc = parseJSDocText(context);\n            return new JSDocTagImpl(name, textDoc, inline, Range.create(tagToken.range.start, textDoc.range.end));\n        }\n    }\n    else {\n        const range = tagToken.range;\n        return new JSDocTagImpl(name, new JSDocTextImpl([], range), inline, range);\n    }\n}\nfunction parseJSDocLine(context) {\n    const token = context.tokens[context.index++];\n    return new JSDocLineImpl(token.content, token.range);\n}\nfunction normalizeOptions(options) {\n    if (!options) {\n        return normalizeOptions({\n            start: '/**',\n            end: '*/',\n            line: '*'\n        });\n    }\n    const { start, end, line } = options;\n    return {\n        start: normalizeOption(start, true),\n        end: normalizeOption(end, false),\n        line: normalizeOption(line, true)\n    };\n}\nfunction normalizeOption(option, start) {\n    if (typeof option === 'string' || typeof option === 'object') {\n        const escaped = typeof option === 'string' ? escapeRegExp(option) : option.source;\n        if (start) {\n            return new RegExp(`^\\\\s*${escaped}`);\n        }\n        else {\n            return new RegExp(`\\\\s*${escaped}\\\\s*$`);\n        }\n    }\n    else {\n        return option;\n    }\n}\nclass JSDocCommentImpl {\n    constructor(elements, range) {\n        this.elements = elements;\n        this.range = range;\n    }\n    getTag(name) {\n        return this.getAllTags().find(e => e.name === name);\n    }\n    getTags(name) {\n        return this.getAllTags().filter(e => e.name === name);\n    }\n    getAllTags() {\n        return this.elements.filter(e => 'name' in e);\n    }\n    toString() {\n        let value = '';\n        for (const element of this.elements) {\n            if (value.length === 0) {\n                value = element.toString();\n            }\n            else {\n                const text = element.toString();\n                value += fillNewlines(value) + text;\n            }\n        }\n        return value.trim();\n    }\n    toMarkdown(options) {\n        let value = '';\n        for (const element of this.elements) {\n            if (value.length === 0) {\n                value = element.toMarkdown(options);\n            }\n            else {\n                const text = element.toMarkdown(options);\n                value += fillNewlines(value) + text;\n            }\n        }\n        return value.trim();\n    }\n}\nclass JSDocTagImpl {\n    constructor(name, content, inline, range) {\n        this.name = name;\n        this.content = content;\n        this.inline = inline;\n        this.range = range;\n    }\n    toString() {\n        let text = `@${this.name}`;\n        const content = this.content.toString();\n        if (this.content.inlines.length === 1) {\n            text = `${text} ${content}`;\n        }\n        else if (this.content.inlines.length > 1) {\n            text = `${text}\\n${content}`;\n        }\n        if (this.inline) {\n            // Inline tags are surrounded by curly braces\n            return `{${text}}`;\n        }\n        else {\n            return text;\n        }\n    }\n    toMarkdown(options) {\n        return options?.renderTag?.(this) ?? this.toMarkdownDefault(options);\n    }\n    toMarkdownDefault(options) {\n        const content = this.content.toMarkdown(options);\n        if (this.inline) {\n            const rendered = renderInlineTag(this.name, content, options ?? {});\n            if (typeof rendered === 'string') {\n                return rendered;\n            }\n        }\n        let marker = '';\n        if (options?.tag === 'italic' || options?.tag === undefined) {\n            marker = '*';\n        }\n        else if (options?.tag === 'bold') {\n            marker = '**';\n        }\n        else if (options?.tag === 'bold-italic') {\n            marker = '***';\n        }\n        let text = `${marker}@${this.name}${marker}`;\n        if (this.content.inlines.length === 1) {\n            text = `${text}  ${content}`;\n        }\n        else if (this.content.inlines.length > 1) {\n            text = `${text}\\n${content}`;\n        }\n        if (this.inline) {\n            // Inline tags are surrounded by curly braces\n            return `{${text}}`;\n        }\n        else {\n            return text;\n        }\n    }\n}\nfunction renderInlineTag(tag, content, options) {\n    if (tag === 'linkplain' || tag === 'linkcode' || tag === 'link') {\n        const index = content.indexOf(' ');\n        let display = content;\n        if (index > 0) {\n            const displayStart = skipWhitespace(content, index);\n            display = content.substring(displayStart);\n            content = content.substring(0, index);\n        }\n        if (tag === 'linkcode' || (tag === 'link' && options.link === 'code')) {\n            // Surround the display value in a markdown inline code block\n            display = `\\`${display}\\``;\n        }\n        const renderedLink = options.renderLink?.(content, display) ?? renderLinkDefault(content, display);\n        return renderedLink;\n    }\n    return undefined;\n}\nfunction renderLinkDefault(content, display) {\n    try {\n        URI.parse(content, true);\n        return `[${display}](${content})`;\n    }\n    catch {\n        return content;\n    }\n}\nclass JSDocTextImpl {\n    constructor(lines, range) {\n        this.inlines = lines;\n        this.range = range;\n    }\n    toString() {\n        let text = '';\n        for (let i = 0; i < this.inlines.length; i++) {\n            const inline = this.inlines[i];\n            const next = this.inlines[i + 1];\n            text += inline.toString();\n            if (next && next.range.start.line > inline.range.start.line) {\n                text += '\\n';\n            }\n        }\n        return text;\n    }\n    toMarkdown(options) {\n        let text = '';\n        for (let i = 0; i < this.inlines.length; i++) {\n            const inline = this.inlines[i];\n            const next = this.inlines[i + 1];\n            text += inline.toMarkdown(options);\n            if (next && next.range.start.line > inline.range.start.line) {\n                text += '\\n';\n            }\n        }\n        return text;\n    }\n}\nclass JSDocLineImpl {\n    constructor(text, range) {\n        this.text = text;\n        this.range = range;\n    }\n    toString() {\n        return this.text;\n    }\n    toMarkdown() {\n        return this.text;\n    }\n}\nfunction fillNewlines(text) {\n    if (text.endsWith('\\n')) {\n        return '\\n';\n    }\n    else {\n        return '\\n\\n';\n    }\n}\n//# sourceMappingURL=jsdoc.js.map","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { getDocument } from '../utils/ast-utils.js';\nimport { isJSDoc, parseJSDoc } from './jsdoc.js';\nexport class JSDocDocumentationProvider {\n    constructor(services) {\n        this.indexManager = services.shared.workspace.IndexManager;\n        this.commentProvider = services.documentation.CommentProvider;\n    }\n    getDocumentation(node) {\n        const comment = this.commentProvider.getComment(node);\n        if (comment && isJSDoc(comment)) {\n            const parsedJSDoc = parseJSDoc(comment);\n            return parsedJSDoc.toMarkdown({\n                renderLink: (link, display) => {\n                    return this.documentationLinkRenderer(node, link, display);\n                },\n                renderTag: (tag) => {\n                    return this.documentationTagRenderer(node, tag);\n                }\n            });\n        }\n        return undefined;\n    }\n    documentationLinkRenderer(node, name, display) {\n        const description = this.findNameInLocalSymbols(node, name) ?? this.findNameInGlobalScope(node, name);\n        if (description && description.nameSegment) {\n            const line = description.nameSegment.range.start.line + 1;\n            const character = description.nameSegment.range.start.character + 1;\n            const uri = description.documentUri.with({ fragment: `L${line},${character}` });\n            return `[${display}](${uri.toString()})`;\n        }\n        else {\n            return undefined;\n        }\n    }\n    documentationTagRenderer(_node, _tag) {\n        // Fall back to the default tag rendering\n        return undefined;\n    }\n    findNameInLocalSymbols(node, name) {\n        const document = getDocument(node);\n        const precomputed = document.localSymbols;\n        if (!precomputed) {\n            return undefined;\n        }\n        let currentNode = node;\n        do {\n            const allDescriptions = precomputed.getStream(currentNode);\n            const description = allDescriptions.find(e => e.name === name);\n            if (description) {\n                return description;\n            }\n            currentNode = currentNode.$container;\n        } while (currentNode);\n        return undefined;\n    }\n    findNameInGlobalScope(node, name) {\n        const description = this.indexManager.allElements().find(e => e.name === name);\n        return description;\n    }\n}\n//# sourceMappingURL=documentation-provider.js.map","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { isAstNodeWithComment } from '../serializer/json-serializer.js';\nimport { findCommentNode } from '../utils/cst-utils.js';\nexport class DefaultCommentProvider {\n    constructor(services) {\n        this.grammarConfig = () => services.parser.GrammarConfig;\n    }\n    getComment(node) {\n        if (isAstNodeWithComment(node)) {\n            return node.$comment;\n        }\n        return findCommentNode(node.$cstNode, this.grammarConfig().multilineCommentRules)?.text;\n    }\n}\n//# sourceMappingURL=comment-provider.js.map","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { Deferred, OperationCancelled } from '../utils/promise-utils.js';\nimport { Emitter } from '../utils/event.js';\n/**\n * Default implementation of the async parser which simply wraps the sync parser in a promise.\n *\n * @remarks\n * A real implementation would create worker threads or web workers to offload the parsing work.\n */\nexport class DefaultAsyncParser {\n    constructor(services) {\n        this.syncParser = services.parser.LangiumParser;\n    }\n    parse(text, _cancelToken) {\n        return Promise.resolve(this.syncParser.parse(text));\n    }\n}\nexport class AbstractThreadedAsyncParser {\n    constructor(services) {\n        /**\n         * The thread count determines how many threads are used to parse files in parallel.\n         * The default value is 8. Decreasing this value increases startup performance, but decreases parallel parsing performance.\n         */\n        this.threadCount = 8;\n        /**\n         * The termination delay determines how long the parser waits for a thread to finish after a cancellation request.\n         * The default value is 200(ms).\n         */\n        this.terminationDelay = 200;\n        this.workerPool = [];\n        this.queue = [];\n        this.hydrator = services.serializer.Hydrator;\n    }\n    initializeWorkers() {\n        while (this.workerPool.length < this.threadCount) {\n            const worker = this.createWorker();\n            worker.onReady(() => {\n                if (this.queue.length > 0) {\n                    const deferred = this.queue.shift();\n                    if (deferred) {\n                        worker.lock();\n                        deferred.resolve(worker);\n                    }\n                }\n            });\n            this.workerPool.push(worker);\n        }\n    }\n    async parse(text, cancelToken) {\n        const worker = await this.acquireParserWorker(cancelToken);\n        const deferred = new Deferred();\n        let timeout;\n        // If the cancellation token is requested, we wait for a certain time before terminating the worker.\n        // Since the cancellation token lives longer than the parsing process, we need to dispose the event listener.\n        // Otherwise, we might accidentally terminate the worker after the parsing process has finished.\n        const cancellation = cancelToken.onCancellationRequested(() => {\n            timeout = setTimeout(() => {\n                this.terminateWorker(worker);\n            }, this.terminationDelay);\n        });\n        worker.parse(text).then(result => {\n            const hydrated = this.hydrator.hydrate(result);\n            deferred.resolve(hydrated);\n        }).catch(err => {\n            deferred.reject(err);\n        }).finally(() => {\n            cancellation.dispose();\n            clearTimeout(timeout);\n        });\n        return deferred.promise;\n    }\n    terminateWorker(worker) {\n        worker.terminate();\n        const index = this.workerPool.indexOf(worker);\n        if (index >= 0) {\n            this.workerPool.splice(index, 1);\n        }\n    }\n    async acquireParserWorker(cancelToken) {\n        this.initializeWorkers();\n        for (const worker of this.workerPool) {\n            if (worker.ready) {\n                worker.lock();\n                return worker;\n            }\n        }\n        const deferred = new Deferred();\n        cancelToken.onCancellationRequested(() => {\n            const index = this.queue.indexOf(deferred);\n            if (index >= 0) {\n                this.queue.splice(index, 1);\n            }\n            deferred.reject(OperationCancelled);\n        });\n        this.queue.push(deferred);\n        return deferred.promise;\n    }\n}\nexport class ParserWorker {\n    get ready() {\n        return this._ready;\n    }\n    get onReady() {\n        return this.onReadyEmitter.event;\n    }\n    constructor(sendMessage, onMessage, onError, terminate) {\n        this.onReadyEmitter = new Emitter();\n        this.deferred = new Deferred();\n        this._ready = true;\n        this._parsing = false;\n        this.sendMessage = sendMessage;\n        this._terminate = terminate;\n        onMessage(result => {\n            const parseResult = result;\n            this.deferred.resolve(parseResult);\n            this.unlock();\n        });\n        onError(error => {\n            this.deferred.reject(error);\n            this.unlock();\n        });\n    }\n    terminate() {\n        this.deferred.reject(OperationCancelled);\n        this._terminate();\n    }\n    lock() {\n        this._ready = false;\n    }\n    unlock() {\n        this._parsing = false;\n        this._ready = true;\n        this.onReadyEmitter.fire();\n    }\n    parse(text) {\n        if (this._parsing) {\n            throw new Error('Parser worker is busy');\n        }\n        this._parsing = true;\n        this.deferred = new Deferred();\n        this.sendMessage(text);\n        return this.deferred.promise;\n    }\n}\n//# sourceMappingURL=async-parser.js.map","/******************************************************************************\n * Copyright 2023 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { CancellationToken, CancellationTokenSource } from '../utils/cancellation.js';\nimport { Deferred, isOperationCancelled, startCancelableOperation } from '../utils/promise-utils.js';\nexport class DefaultWorkspaceLock {\n    constructor() {\n        this.previousTokenSource = new CancellationTokenSource();\n        this.writeQueue = [];\n        this.readQueue = [];\n        this.done = true;\n    }\n    write(action) {\n        this.cancelWrite();\n        const tokenSource = startCancelableOperation();\n        this.previousTokenSource = tokenSource;\n        return this.enqueue(this.writeQueue, action, tokenSource.token);\n    }\n    read(action) {\n        return this.enqueue(this.readQueue, action);\n    }\n    enqueue(queue, action, cancellationToken = CancellationToken.None) {\n        const deferred = new Deferred();\n        const entry = {\n            action,\n            deferred,\n            cancellationToken\n        };\n        queue.push(entry);\n        this.performNextOperation();\n        return deferred.promise;\n    }\n    async performNextOperation() {\n        if (!this.done) {\n            return;\n        }\n        const entries = [];\n        if (this.writeQueue.length > 0) {\n            // Just perform the next write action\n            entries.push(this.writeQueue.shift());\n        }\n        else if (this.readQueue.length > 0) {\n            // Empty the read queue and perform all actions in parallel\n            entries.push(...this.readQueue.splice(0, this.readQueue.length));\n        }\n        else {\n            return;\n        }\n        this.done = false;\n        await Promise.all(entries.map(async ({ action, deferred, cancellationToken }) => {\n            try {\n                // Move the execution of the action to the next event loop tick via `Promise.resolve()`\n                const result = await Promise.resolve().then(() => action(cancellationToken));\n                deferred.resolve(result);\n            }\n            catch (err) {\n                if (isOperationCancelled(err)) {\n                    // If the operation was cancelled, we don't want to reject the promise\n                    deferred.resolve(undefined);\n                }\n                else {\n                    deferred.reject(err);\n                }\n            }\n        }));\n        this.done = true;\n        this.performNextOperation();\n    }\n    cancelWrite() {\n        this.previousTokenSource.cancel();\n    }\n}\n//# sourceMappingURL=workspace-lock.js.map","/******************************************************************************\n * Copyright 2024 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { CompositeCstNodeImpl, LeafCstNodeImpl, RootCstNodeImpl } from '../parser/cst-node-builder.js';\nimport { isAbstractElement } from '../languages/generated/ast.js';\nimport { isRootCstNode, isCompositeCstNode, isLeafCstNode, isAstNode, isReference } from '../syntax-tree.js';\nimport { streamAst } from '../utils/ast-utils.js';\nimport { BiMap } from '../utils/collections.js';\nimport { streamCst } from '../utils/cst-utils.js';\nexport class DefaultHydrator {\n    constructor(services) {\n        this.grammarElementIdMap = new BiMap();\n        this.tokenTypeIdMap = new BiMap();\n        this.grammar = services.Grammar;\n        this.lexer = services.parser.Lexer;\n        this.linker = services.references.Linker;\n    }\n    dehydrate(result) {\n        return {\n            lexerErrors: result.lexerErrors,\n            lexerReport: result.lexerReport ? this.dehydrateLexerReport(result.lexerReport) : undefined,\n            // We need to create shallow copies of the errors\n            // The original errors inherit from the `Error` class, which is not transferable across worker threads\n            parserErrors: result.parserErrors.map(e => ({ ...e, message: e.message })),\n            value: this.dehydrateAstNode(result.value, this.createDehyrationContext(result.value))\n        };\n    }\n    dehydrateLexerReport(lexerReport) {\n        // By default, lexer reports are serializable\n        return lexerReport;\n    }\n    createDehyrationContext(node) {\n        const astNodes = new Map();\n        const cstNodes = new Map();\n        for (const astNode of streamAst(node)) {\n            astNodes.set(astNode, {});\n        }\n        if (node.$cstNode) {\n            for (const cstNode of streamCst(node.$cstNode)) {\n                cstNodes.set(cstNode, {});\n            }\n        }\n        return {\n            astNodes,\n            cstNodes\n        };\n    }\n    dehydrateAstNode(node, context) {\n        const obj = context.astNodes.get(node);\n        obj.$type = node.$type;\n        obj.$containerIndex = node.$containerIndex;\n        obj.$containerProperty = node.$containerProperty;\n        if (node.$cstNode !== undefined) {\n            obj.$cstNode = this.dehydrateCstNode(node.$cstNode, context);\n        }\n        for (const [name, value] of Object.entries(node)) {\n            if (name.startsWith('$')) {\n                continue;\n            }\n            if (Array.isArray(value)) {\n                const arr = [];\n                obj[name] = arr;\n                for (const item of value) {\n                    if (isAstNode(item)) {\n                        arr.push(this.dehydrateAstNode(item, context));\n                    }\n                    else if (isReference(item)) {\n                        arr.push(this.dehydrateReference(item, context));\n                    }\n                    else {\n                        arr.push(item);\n                    }\n                }\n            }\n            else if (isAstNode(value)) {\n                obj[name] = this.dehydrateAstNode(value, context);\n            }\n            else if (isReference(value)) {\n                obj[name] = this.dehydrateReference(value, context);\n            }\n            else if (value !== undefined) {\n                obj[name] = value;\n            }\n        }\n        return obj;\n    }\n    dehydrateReference(reference, context) {\n        const obj = {};\n        obj.$refText = reference.$refText;\n        if (reference.$refNode) {\n            obj.$refNode = context.cstNodes.get(reference.$refNode);\n        }\n        return obj;\n    }\n    dehydrateCstNode(node, context) {\n        const cstNode = context.cstNodes.get(node);\n        if (isRootCstNode(node)) {\n            cstNode.fullText = node.fullText;\n        }\n        else {\n            // Note: This returns undefined for hidden nodes (i.e. comments)\n            cstNode.grammarSource = this.getGrammarElementId(node.grammarSource);\n        }\n        cstNode.hidden = node.hidden;\n        cstNode.astNode = context.astNodes.get(node.astNode);\n        if (isCompositeCstNode(node)) {\n            cstNode.content = node.content.map(child => this.dehydrateCstNode(child, context));\n        }\n        else if (isLeafCstNode(node)) {\n            cstNode.tokenType = node.tokenType.name;\n            cstNode.offset = node.offset;\n            cstNode.length = node.length;\n            cstNode.startLine = node.range.start.line;\n            cstNode.startColumn = node.range.start.character;\n            cstNode.endLine = node.range.end.line;\n            cstNode.endColumn = node.range.end.character;\n        }\n        return cstNode;\n    }\n    hydrate(result) {\n        const node = result.value;\n        const context = this.createHydrationContext(node);\n        if ('$cstNode' in node) {\n            this.hydrateCstNode(node.$cstNode, context);\n        }\n        return {\n            lexerErrors: result.lexerErrors,\n            lexerReport: result.lexerReport,\n            parserErrors: result.parserErrors,\n            value: this.hydrateAstNode(node, context)\n        };\n    }\n    createHydrationContext(node) {\n        const astNodes = new Map();\n        const cstNodes = new Map();\n        for (const astNode of streamAst(node)) {\n            astNodes.set(astNode, {});\n        }\n        let root;\n        if (node.$cstNode) {\n            for (const cstNode of streamCst(node.$cstNode)) {\n                let cst;\n                if ('fullText' in cstNode) {\n                    cst = new RootCstNodeImpl(cstNode.fullText);\n                    root = cst;\n                }\n                else if ('content' in cstNode) {\n                    cst = new CompositeCstNodeImpl();\n                }\n                else if ('tokenType' in cstNode) {\n                    cst = this.hydrateCstLeafNode(cstNode);\n                }\n                if (cst) {\n                    cstNodes.set(cstNode, cst);\n                    cst.root = root;\n                }\n            }\n        }\n        return {\n            astNodes,\n            cstNodes\n        };\n    }\n    hydrateAstNode(node, context) {\n        const astNode = context.astNodes.get(node);\n        astNode.$type = node.$type;\n        astNode.$containerIndex = node.$containerIndex;\n        astNode.$containerProperty = node.$containerProperty;\n        if (node.$cstNode) {\n            astNode.$cstNode = context.cstNodes.get(node.$cstNode);\n        }\n        for (const [name, value] of Object.entries(node)) {\n            if (name.startsWith('$')) {\n                continue;\n            }\n            if (Array.isArray(value)) {\n                const arr = [];\n                astNode[name] = arr;\n                for (const item of value) {\n                    if (isAstNode(item)) {\n                        arr.push(this.setParent(this.hydrateAstNode(item, context), astNode));\n                    }\n                    else if (isReference(item)) {\n                        arr.push(this.hydrateReference(item, astNode, name, context));\n                    }\n                    else {\n                        arr.push(item);\n                    }\n                }\n            }\n            else if (isAstNode(value)) {\n                astNode[name] = this.setParent(this.hydrateAstNode(value, context), astNode);\n            }\n            else if (isReference(value)) {\n                astNode[name] = this.hydrateReference(value, astNode, name, context);\n            }\n            else if (value !== undefined) {\n                astNode[name] = value;\n            }\n        }\n        return astNode;\n    }\n    setParent(node, parent) {\n        node.$container = parent;\n        return node;\n    }\n    hydrateReference(reference, node, name, context) {\n        return this.linker.buildReference(node, name, context.cstNodes.get(reference.$refNode), reference.$refText);\n    }\n    hydrateCstNode(cstNode, context, num = 0) {\n        const cstNodeObj = context.cstNodes.get(cstNode);\n        if (typeof cstNode.grammarSource === 'number') {\n            cstNodeObj.grammarSource = this.getGrammarElement(cstNode.grammarSource);\n        }\n        cstNodeObj.astNode = context.astNodes.get(cstNode.astNode);\n        if (isCompositeCstNode(cstNodeObj)) {\n            for (const child of cstNode.content) {\n                const hydrated = this.hydrateCstNode(child, context, num++);\n                cstNodeObj.content.push(hydrated);\n            }\n        }\n        return cstNodeObj;\n    }\n    hydrateCstLeafNode(cstNode) {\n        const tokenType = this.getTokenType(cstNode.tokenType);\n        const offset = cstNode.offset;\n        const length = cstNode.length;\n        const startLine = cstNode.startLine;\n        const startColumn = cstNode.startColumn;\n        const endLine = cstNode.endLine;\n        const endColumn = cstNode.endColumn;\n        const hidden = cstNode.hidden;\n        const node = new LeafCstNodeImpl(offset, length, {\n            start: {\n                line: startLine,\n                character: startColumn\n            },\n            end: {\n                line: endLine,\n                character: endColumn\n            }\n        }, tokenType, hidden);\n        return node;\n    }\n    getTokenType(name) {\n        return this.lexer.definition[name];\n    }\n    getGrammarElementId(node) {\n        if (!node) {\n            return undefined;\n        }\n        if (this.grammarElementIdMap.size === 0) {\n            this.createGrammarElementIdMap();\n        }\n        return this.grammarElementIdMap.get(node);\n    }\n    getGrammarElement(id) {\n        if (this.grammarElementIdMap.size === 0) {\n            this.createGrammarElementIdMap();\n        }\n        const element = this.grammarElementIdMap.getKey(id);\n        return element;\n    }\n    createGrammarElementIdMap() {\n        let id = 0;\n        for (const element of streamAst(this.grammar)) {\n            if (isAbstractElement(element)) {\n                this.grammarElementIdMap.set(element, id++);\n            }\n        }\n    }\n}\n//# sourceMappingURL=hydrator.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n******************************************************************************/\nimport { createGrammarConfig } from './languages/grammar-config.js';\nimport { createCompletionParser } from './parser/completion-parser-builder.js';\nimport { createLangiumParser } from './parser/langium-parser-builder.js';\nimport { DefaultTokenBuilder } from './parser/token-builder.js';\nimport { DefaultValueConverter } from './parser/value-converter.js';\nimport { DefaultLinker } from './references/linker.js';\nimport { DefaultNameProvider } from './references/name-provider.js';\nimport { DefaultReferences } from './references/references.js';\nimport { DefaultScopeComputation } from './references/scope-computation.js';\nimport { DefaultScopeProvider } from './references/scope-provider.js';\nimport { DefaultJsonSerializer } from './serializer/json-serializer.js';\nimport { DefaultServiceRegistry } from './service-registry.js';\nimport { DefaultDocumentValidator } from './validation/document-validator.js';\nimport { ValidationRegistry } from './validation/validation-registry.js';\nimport { DefaultAstNodeDescriptionProvider, DefaultReferenceDescriptionProvider } from './workspace/ast-descriptions.js';\nimport { DefaultAstNodeLocator } from './workspace/ast-node-locator.js';\nimport { DefaultConfigurationProvider } from './workspace/configuration.js';\nimport { DefaultDocumentBuilder } from './workspace/document-builder.js';\nimport { DefaultLangiumDocumentFactory, DefaultLangiumDocuments } from './workspace/documents.js';\nimport { DefaultIndexManager } from './workspace/index-manager.js';\nimport { DefaultWorkspaceManager } from './workspace/workspace-manager.js';\nimport { DefaultLexer, DefaultLexerErrorMessageProvider } from './parser/lexer.js';\nimport { JSDocDocumentationProvider } from './documentation/documentation-provider.js';\nimport { DefaultCommentProvider } from './documentation/comment-provider.js';\nimport { LangiumParserErrorMessageProvider } from './parser/langium-parser.js';\nimport { DefaultAsyncParser } from './parser/async-parser.js';\nimport { DefaultWorkspaceLock } from './workspace/workspace-lock.js';\nimport { DefaultHydrator } from './serializer/hydrator.js';\n/**\n * Creates a dependency injection module configuring the default core services.\n * This is a set of services that are dedicated to a specific language.\n */\nexport function createDefaultCoreModule(context) {\n    return {\n        documentation: {\n            CommentProvider: (services) => new DefaultCommentProvider(services),\n            DocumentationProvider: (services) => new JSDocDocumentationProvider(services)\n        },\n        parser: {\n            AsyncParser: (services) => new DefaultAsyncParser(services),\n            GrammarConfig: (services) => createGrammarConfig(services),\n            LangiumParser: (services) => createLangiumParser(services),\n            CompletionParser: (services) => createCompletionParser(services),\n            ValueConverter: () => new DefaultValueConverter(),\n            TokenBuilder: () => new DefaultTokenBuilder(),\n            Lexer: (services) => new DefaultLexer(services),\n            ParserErrorMessageProvider: () => new LangiumParserErrorMessageProvider(),\n            LexerErrorMessageProvider: () => new DefaultLexerErrorMessageProvider()\n        },\n        workspace: {\n            AstNodeLocator: () => new DefaultAstNodeLocator(),\n            AstNodeDescriptionProvider: (services) => new DefaultAstNodeDescriptionProvider(services),\n            ReferenceDescriptionProvider: (services) => new DefaultReferenceDescriptionProvider(services)\n        },\n        references: {\n            Linker: (services) => new DefaultLinker(services),\n            NameProvider: () => new DefaultNameProvider(),\n            ScopeProvider: (services) => new DefaultScopeProvider(services),\n            ScopeComputation: (services) => new DefaultScopeComputation(services),\n            References: (services) => new DefaultReferences(services)\n        },\n        serializer: {\n            Hydrator: (services) => new DefaultHydrator(services),\n            JsonSerializer: (services) => new DefaultJsonSerializer(services)\n        },\n        validation: {\n            DocumentValidator: (services) => new DefaultDocumentValidator(services),\n            ValidationRegistry: (services) => new ValidationRegistry(services)\n        },\n        shared: () => context.shared\n    };\n}\n/**\n * Creates a dependency injection module configuring the default shared core services.\n * This is the set of services that are shared between multiple languages.\n */\nexport function createDefaultSharedCoreModule(context) {\n    return {\n        ServiceRegistry: (services) => new DefaultServiceRegistry(services),\n        workspace: {\n            LangiumDocuments: (services) => new DefaultLangiumDocuments(services),\n            LangiumDocumentFactory: (services) => new DefaultLangiumDocumentFactory(services),\n            DocumentBuilder: (services) => new DefaultDocumentBuilder(services),\n            IndexManager: (services) => new DefaultIndexManager(services),\n            WorkspaceManager: (services) => new DefaultWorkspaceManager(services),\n            FileSystemProvider: (services) => context.fileSystemProvider(services),\n            WorkspaceLock: () => new DefaultWorkspaceLock(),\n            ConfigurationProvider: (services) => new DefaultConfigurationProvider(services),\n        },\n        profilers: {}\n    };\n}\n//# sourceMappingURL=default-module.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nexport var Module;\n(function (Module) {\n    /**\n     * Merges two dependency injection modules into a new (third) one that is returned.\n     * At that `m1` and `m2` stay unchanged. Therefore, `m1` is deep-copied first,\n     * and m2 is merged onto the copy afterwards.\n     *\n     * Note that the leaf values of `m1` and `m2`, i.e. the service constructor functions,\n     * cannot be copied generically, since they are functions. They are shared by the source and merged modules.\n     *\n     * @returns the merged module being a deep copy of `m1` with `m2` merged onto it.\n     */\n    Module.merge = (m1, m2) => _merge(_merge({}, m1), m2);\n})(Module || (Module = {}));\n/**\n * Given a set of modules, the inject function returns a lazily evaluated injector\n * that injects dependencies into the requested service when it is requested the\n * first time. Subsequent requests will return the same service.\n *\n * In the case of cyclic dependencies, an Error will be thrown. This can be fixed\n * by injecting a provider `() => T` instead of a `T`.\n *\n * Please note that the arguments may be objects or arrays. However, the result will\n * be an object. Using it with for..of will have no effect.\n *\n * @param module1 first Module\n * @param module2 (optional) second Module\n * @param module3 (optional) third Module\n * @param module4 (optional) fourth Module\n * @param module5 (optional) fifth Module\n * @param module6 (optional) sixth Module\n * @param module7 (optional) seventh Module\n * @param module8 (optional) eighth Module\n * @param module9 (optional) ninth Module\n * @returns a new object of type I\n */\nexport function inject(module1, module2, module3, module4, module5, module6, module7, module8, module9) {\n    const module = [module1, module2, module3, module4, module5, module6, module7, module8, module9].reduce(_merge, {});\n    return _inject(module);\n}\nconst isProxy = Symbol('isProxy');\n/**\n * Eagerly load all services in the given dependency injection container. This is sometimes\n * necessary because services can register event listeners in their constructors.\n */\nexport function eagerLoad(item) {\n    if (item && item[isProxy]) {\n        for (const value of Object.values(item)) {\n            eagerLoad(value);\n        }\n    }\n    return item;\n}\n/**\n * Helper function that returns an injector by creating a proxy.\n * Invariant: injector is of type I. If injector is undefined, then T = I.\n */\nfunction _inject(module, injector) {\n    const proxy = new Proxy({}, {\n        deleteProperty: () => false,\n        set: () => {\n            throw new Error('Cannot set property on injected service container');\n        },\n        get: (obj, prop) => {\n            if (prop === isProxy) {\n                return true;\n            }\n            else {\n                return _resolve(obj, prop, module, injector || proxy);\n            }\n        },\n        getOwnPropertyDescriptor: (obj, prop) => (_resolve(obj, prop, module, injector || proxy), Object.getOwnPropertyDescriptor(obj, prop)), // used by for..in\n        has: (_, prop) => prop in module, // used by ..in..\n        ownKeys: () => [...Object.getOwnPropertyNames(module)] // used by for..in\n    });\n    return proxy;\n}\n/**\n * Internally used to tag a requested dependency, directly before calling the factory.\n * This allows us to find cycles during instance creation.\n */\nconst __requested__ = Symbol();\n/**\n * Returns the value `obj[prop]`. If the value does not exist, yet, it is resolved from\n * the module description. The result of service factories is cached. Groups are\n * recursively proxied.\n *\n * @param obj an object holding all group proxies and services\n * @param prop the key of a value within obj\n * @param module an object containing groups and service factories\n * @param injector the first level proxy that provides access to all values\n * @returns the requested value `obj[prop]`\n * @throws Error if a dependency cycle is detected\n */\nfunction _resolve(obj, prop, module, injector) {\n    if (prop in obj) {\n        if (obj[prop] instanceof Error) {\n            throw new Error('Construction failure. Please make sure that your dependencies are constructable. Cause: ' + obj[prop]);\n        }\n        if (obj[prop] === __requested__) {\n            throw new Error('Cycle detected. Please make \"' + String(prop) + '\" lazy. Visit https://langium.org/docs/reference/configuration-services/#resolving-cyclic-dependencies');\n        }\n        return obj[prop];\n    }\n    else if (prop in module) {\n        const value = module[prop];\n        obj[prop] = __requested__;\n        try {\n            obj[prop] = (typeof value === 'function') ? value(injector) : _inject(value, injector);\n        }\n        catch (error) {\n            obj[prop] = error instanceof Error ? error : undefined;\n            throw error;\n        }\n        return obj[prop];\n    }\n    else {\n        return undefined;\n    }\n}\n/**\n * Performs a deep-merge of two modules by writing source entries into the target module.\n *\n * @param target the module which is written\n * @param source the module which is read\n * @returns the target module\n */\nfunction _merge(target, source) {\n    if (source) {\n        for (const [key, sourceValue] of Object.entries(source)) {\n            if (sourceValue !== undefined && sourceValue !== null) {\n                if (typeof sourceValue === 'object') {\n                    const targetValue = target[key];\n                    if (typeof targetValue === 'object' && targetValue !== null) {\n                        // in case both values are real (non-null) objects merge them recursively\n                        target[key] = _merge(targetValue, sourceValue);\n                    }\n                    else {\n                        // in case 'target[key]' is not a non-null object\n                        //  we overwrite any existing value with a deep copy of 'sourceValue'\n                        //  by recursively calling this function with a new 'target' object to be populated\n                        //  that is assigned to 'target[key]' afterwards\n                        target[key] = _merge({}, sourceValue);\n                    }\n                }\n                else {\n                    // in case 'sourceValue' is defined and assigned (non-null) but not an object\n                    //  we assume it to be a service constructor function according to the Module<I> type definition\n                    target[key] = sourceValue;\n                    // note the following for such service constructor functions:\n                    // 'target[key]' will now reference the same function object being referenced by 'source[key]'.\n                    // This is accepted here, since function objects cannot be safely copied in general.\n                }\n            }\n        }\n    }\n    return target;\n}\n//# sourceMappingURL=dependency-injection.js.map","/******************************************************************************\n * This file was generated by langium-cli 4.2.0.\n * DO NOT EDIT MANUALLY!\n ******************************************************************************/\n/* eslint-disable */\nimport * as langium from '../../syntax-tree.js';\nexport const LangiumGrammarTerminals = {\n    ID: /\\^?[_a-zA-Z][\\w_]*/,\n    STRING: /\"(\\\\.|[^\"\\\\])*\"|'(\\\\.|[^'\\\\])*'/,\n    NUMBER: /NaN|-?((\\d*\\.\\d+|\\d+)([Ee][+-]?\\d+)?|Infinity)/,\n    RegexLiteral: /\\/(?![*+?])(?:[^\\r\\n\\[/\\\\]|\\\\.|\\[(?:[^\\r\\n\\]\\\\]|\\\\.)*\\])+\\/[a-z]*/,\n    WS: /\\s+/,\n    ML_COMMENT: /\\/\\*[\\s\\S]*?\\*\\//,\n    SL_COMMENT: /\\/\\/[^\\n\\r]*/,\n};\nexport const AbstractElement = {\n    $type: 'AbstractElement',\n    cardinality: 'cardinality'\n};\nexport function isAbstractElement(item) {\n    return reflection.isInstance(item, AbstractElement.$type);\n}\nexport const AbstractParserRule = {\n    $type: 'AbstractParserRule'\n};\nexport function isAbstractParserRule(item) {\n    return reflection.isInstance(item, AbstractParserRule.$type);\n}\nexport const AbstractRule = {\n    $type: 'AbstractRule'\n};\nexport function isAbstractRule(item) {\n    return reflection.isInstance(item, AbstractRule.$type);\n}\nexport const AbstractType = {\n    $type: 'AbstractType'\n};\nexport function isAbstractType(item) {\n    return reflection.isInstance(item, AbstractType.$type);\n}\nexport const Action = {\n    $type: 'Action',\n    cardinality: 'cardinality',\n    feature: 'feature',\n    inferredType: 'inferredType',\n    operator: 'operator',\n    type: 'type'\n};\nexport function isAction(item) {\n    return reflection.isInstance(item, Action.$type);\n}\nexport const Alternatives = {\n    $type: 'Alternatives',\n    cardinality: 'cardinality',\n    elements: 'elements'\n};\nexport function isAlternatives(item) {\n    return reflection.isInstance(item, Alternatives.$type);\n}\nexport const ArrayLiteral = {\n    $type: 'ArrayLiteral',\n    elements: 'elements'\n};\nexport function isArrayLiteral(item) {\n    return reflection.isInstance(item, ArrayLiteral.$type);\n}\nexport const ArrayType = {\n    $type: 'ArrayType',\n    elementType: 'elementType'\n};\nexport function isArrayType(item) {\n    return reflection.isInstance(item, ArrayType.$type);\n}\nexport const Assignment = {\n    $type: 'Assignment',\n    cardinality: 'cardinality',\n    feature: 'feature',\n    operator: 'operator',\n    predicate: 'predicate',\n    terminal: 'terminal'\n};\nexport function isAssignment(item) {\n    return reflection.isInstance(item, Assignment.$type);\n}\nexport const BooleanLiteral = {\n    $type: 'BooleanLiteral',\n    true: 'true'\n};\nexport function isBooleanLiteral(item) {\n    return reflection.isInstance(item, BooleanLiteral.$type);\n}\nexport const CharacterRange = {\n    $type: 'CharacterRange',\n    cardinality: 'cardinality',\n    left: 'left',\n    lookahead: 'lookahead',\n    parenthesized: 'parenthesized',\n    right: 'right'\n};\nexport function isCharacterRange(item) {\n    return reflection.isInstance(item, CharacterRange.$type);\n}\nexport const Condition = {\n    $type: 'Condition'\n};\nexport function isCondition(item) {\n    return reflection.isInstance(item, Condition.$type);\n}\nexport const Conjunction = {\n    $type: 'Conjunction',\n    left: 'left',\n    right: 'right'\n};\nexport function isConjunction(item) {\n    return reflection.isInstance(item, Conjunction.$type);\n}\nexport const CrossReference = {\n    $type: 'CrossReference',\n    cardinality: 'cardinality',\n    deprecatedSyntax: 'deprecatedSyntax',\n    isMulti: 'isMulti',\n    terminal: 'terminal',\n    type: 'type'\n};\nexport function isCrossReference(item) {\n    return reflection.isInstance(item, CrossReference.$type);\n}\nexport const Disjunction = {\n    $type: 'Disjunction',\n    left: 'left',\n    right: 'right'\n};\nexport function isDisjunction(item) {\n    return reflection.isInstance(item, Disjunction.$type);\n}\nexport const EndOfFile = {\n    $type: 'EndOfFile',\n    cardinality: 'cardinality'\n};\nexport function isEndOfFile(item) {\n    return reflection.isInstance(item, EndOfFile.$type);\n}\nexport const Grammar = {\n    $type: 'Grammar',\n    imports: 'imports',\n    interfaces: 'interfaces',\n    isDeclared: 'isDeclared',\n    name: 'name',\n    rules: 'rules',\n    types: 'types'\n};\nexport function isGrammar(item) {\n    return reflection.isInstance(item, Grammar.$type);\n}\nexport const GrammarImport = {\n    $type: 'GrammarImport',\n    path: 'path'\n};\nexport function isGrammarImport(item) {\n    return reflection.isInstance(item, GrammarImport.$type);\n}\nexport const Group = {\n    $type: 'Group',\n    cardinality: 'cardinality',\n    elements: 'elements',\n    guardCondition: 'guardCondition',\n    predicate: 'predicate'\n};\nexport function isGroup(item) {\n    return reflection.isInstance(item, Group.$type);\n}\nexport const InferredType = {\n    $type: 'InferredType',\n    name: 'name'\n};\nexport function isInferredType(item) {\n    return reflection.isInstance(item, InferredType.$type);\n}\nexport const InfixRule = {\n    $type: 'InfixRule',\n    call: 'call',\n    dataType: 'dataType',\n    inferredType: 'inferredType',\n    name: 'name',\n    operators: 'operators',\n    parameters: 'parameters',\n    returnType: 'returnType'\n};\nexport function isInfixRule(item) {\n    return reflection.isInstance(item, InfixRule.$type);\n}\nexport const InfixRuleOperatorList = {\n    $type: 'InfixRuleOperatorList',\n    associativity: 'associativity',\n    operators: 'operators'\n};\nexport function isInfixRuleOperatorList(item) {\n    return reflection.isInstance(item, InfixRuleOperatorList.$type);\n}\nexport const InfixRuleOperators = {\n    $type: 'InfixRuleOperators',\n    precedences: 'precedences'\n};\nexport function isInfixRuleOperators(item) {\n    return reflection.isInstance(item, InfixRuleOperators.$type);\n}\nexport const Interface = {\n    $type: 'Interface',\n    attributes: 'attributes',\n    name: 'name',\n    superTypes: 'superTypes'\n};\nexport function isInterface(item) {\n    return reflection.isInstance(item, Interface.$type);\n}\nexport const Keyword = {\n    $type: 'Keyword',\n    cardinality: 'cardinality',\n    predicate: 'predicate',\n    value: 'value'\n};\nexport function isKeyword(item) {\n    return reflection.isInstance(item, Keyword.$type);\n}\nexport const NamedArgument = {\n    $type: 'NamedArgument',\n    calledByName: 'calledByName',\n    parameter: 'parameter',\n    value: 'value'\n};\nexport function isNamedArgument(item) {\n    return reflection.isInstance(item, NamedArgument.$type);\n}\nexport const NegatedToken = {\n    $type: 'NegatedToken',\n    cardinality: 'cardinality',\n    lookahead: 'lookahead',\n    parenthesized: 'parenthesized',\n    terminal: 'terminal'\n};\nexport function isNegatedToken(item) {\n    return reflection.isInstance(item, NegatedToken.$type);\n}\nexport const Negation = {\n    $type: 'Negation',\n    value: 'value'\n};\nexport function isNegation(item) {\n    return reflection.isInstance(item, Negation.$type);\n}\nexport const NumberLiteral = {\n    $type: 'NumberLiteral',\n    value: 'value'\n};\nexport function isNumberLiteral(item) {\n    return reflection.isInstance(item, NumberLiteral.$type);\n}\nexport const Parameter = {\n    $type: 'Parameter',\n    name: 'name'\n};\nexport function isParameter(item) {\n    return reflection.isInstance(item, Parameter.$type);\n}\nexport const ParameterReference = {\n    $type: 'ParameterReference',\n    parameter: 'parameter'\n};\nexport function isParameterReference(item) {\n    return reflection.isInstance(item, ParameterReference.$type);\n}\nexport const ParserRule = {\n    $type: 'ParserRule',\n    dataType: 'dataType',\n    definition: 'definition',\n    entry: 'entry',\n    fragment: 'fragment',\n    inferredType: 'inferredType',\n    name: 'name',\n    parameters: 'parameters',\n    returnType: 'returnType'\n};\nexport function isParserRule(item) {\n    return reflection.isInstance(item, ParserRule.$type);\n}\nexport const ReferenceType = {\n    $type: 'ReferenceType',\n    isMulti: 'isMulti',\n    referenceType: 'referenceType'\n};\nexport function isReferenceType(item) {\n    return reflection.isInstance(item, ReferenceType.$type);\n}\nexport const RegexToken = {\n    $type: 'RegexToken',\n    cardinality: 'cardinality',\n    lookahead: 'lookahead',\n    parenthesized: 'parenthesized',\n    regex: 'regex'\n};\nexport function isRegexToken(item) {\n    return reflection.isInstance(item, RegexToken.$type);\n}\nexport const ReturnType = {\n    $type: 'ReturnType',\n    name: 'name'\n};\nexport function isReturnType(item) {\n    return reflection.isInstance(item, ReturnType.$type);\n}\nexport const RuleCall = {\n    $type: 'RuleCall',\n    arguments: 'arguments',\n    cardinality: 'cardinality',\n    predicate: 'predicate',\n    rule: 'rule'\n};\nexport function isRuleCall(item) {\n    return reflection.isInstance(item, RuleCall.$type);\n}\nexport const SimpleType = {\n    $type: 'SimpleType',\n    primitiveType: 'primitiveType',\n    stringType: 'stringType',\n    typeRef: 'typeRef'\n};\nexport function isSimpleType(item) {\n    return reflection.isInstance(item, SimpleType.$type);\n}\nexport const StringLiteral = {\n    $type: 'StringLiteral',\n    value: 'value'\n};\nexport function isStringLiteral(item) {\n    return reflection.isInstance(item, StringLiteral.$type);\n}\nexport const TerminalAlternatives = {\n    $type: 'TerminalAlternatives',\n    cardinality: 'cardinality',\n    elements: 'elements',\n    lookahead: 'lookahead',\n    parenthesized: 'parenthesized'\n};\nexport function isTerminalAlternatives(item) {\n    return reflection.isInstance(item, TerminalAlternatives.$type);\n}\nexport const TerminalElement = {\n    $type: 'TerminalElement',\n    cardinality: 'cardinality',\n    lookahead: 'lookahead',\n    parenthesized: 'parenthesized'\n};\nexport function isTerminalElement(item) {\n    return reflection.isInstance(item, TerminalElement.$type);\n}\nexport const TerminalGroup = {\n    $type: 'TerminalGroup',\n    cardinality: 'cardinality',\n    elements: 'elements',\n    lookahead: 'lookahead',\n    parenthesized: 'parenthesized'\n};\nexport function isTerminalGroup(item) {\n    return reflection.isInstance(item, TerminalGroup.$type);\n}\nexport const TerminalRule = {\n    $type: 'TerminalRule',\n    definition: 'definition',\n    fragment: 'fragment',\n    hidden: 'hidden',\n    name: 'name',\n    type: 'type'\n};\nexport function isTerminalRule(item) {\n    return reflection.isInstance(item, TerminalRule.$type);\n}\nexport const TerminalRuleCall = {\n    $type: 'TerminalRuleCall',\n    cardinality: 'cardinality',\n    lookahead: 'lookahead',\n    parenthesized: 'parenthesized',\n    rule: 'rule'\n};\nexport function isTerminalRuleCall(item) {\n    return reflection.isInstance(item, TerminalRuleCall.$type);\n}\nexport const Type = {\n    $type: 'Type',\n    name: 'name',\n    type: 'type'\n};\nexport function isType(item) {\n    return reflection.isInstance(item, Type.$type);\n}\nexport const TypeAttribute = {\n    $type: 'TypeAttribute',\n    defaultValue: 'defaultValue',\n    isOptional: 'isOptional',\n    name: 'name',\n    type: 'type'\n};\nexport function isTypeAttribute(item) {\n    return reflection.isInstance(item, TypeAttribute.$type);\n}\nexport const TypeDefinition = {\n    $type: 'TypeDefinition'\n};\nexport function isTypeDefinition(item) {\n    return reflection.isInstance(item, TypeDefinition.$type);\n}\nexport const UnionType = {\n    $type: 'UnionType',\n    types: 'types'\n};\nexport function isUnionType(item) {\n    return reflection.isInstance(item, UnionType.$type);\n}\nexport const UnorderedGroup = {\n    $type: 'UnorderedGroup',\n    cardinality: 'cardinality',\n    elements: 'elements'\n};\nexport function isUnorderedGroup(item) {\n    return reflection.isInstance(item, UnorderedGroup.$type);\n}\nexport const UntilToken = {\n    $type: 'UntilToken',\n    cardinality: 'cardinality',\n    lookahead: 'lookahead',\n    parenthesized: 'parenthesized',\n    terminal: 'terminal'\n};\nexport function isUntilToken(item) {\n    return reflection.isInstance(item, UntilToken.$type);\n}\nexport const ValueLiteral = {\n    $type: 'ValueLiteral'\n};\nexport function isValueLiteral(item) {\n    return reflection.isInstance(item, ValueLiteral.$type);\n}\nexport const Wildcard = {\n    $type: 'Wildcard',\n    cardinality: 'cardinality',\n    lookahead: 'lookahead',\n    parenthesized: 'parenthesized'\n};\nexport function isWildcard(item) {\n    return reflection.isInstance(item, Wildcard.$type);\n}\nexport class LangiumGrammarAstReflection extends langium.AbstractAstReflection {\n    constructor() {\n        super(...arguments);\n        this.types = {\n            AbstractElement: {\n                name: AbstractElement.$type,\n                properties: {\n                    cardinality: {\n                        name: AbstractElement.cardinality\n                    }\n                },\n                superTypes: []\n            },\n            AbstractParserRule: {\n                name: AbstractParserRule.$type,\n                properties: {},\n                superTypes: [AbstractRule.$type, AbstractType.$type]\n            },\n            AbstractRule: {\n                name: AbstractRule.$type,\n                properties: {},\n                superTypes: []\n            },\n            AbstractType: {\n                name: AbstractType.$type,\n                properties: {},\n                superTypes: []\n            },\n            Action: {\n                name: Action.$type,\n                properties: {\n                    cardinality: {\n                        name: Action.cardinality\n                    },\n                    feature: {\n                        name: Action.feature\n                    },\n                    inferredType: {\n                        name: Action.inferredType\n                    },\n                    operator: {\n                        name: Action.operator\n                    },\n                    type: {\n                        name: Action.type,\n                        referenceType: AbstractType.$type\n                    }\n                },\n                superTypes: [AbstractElement.$type]\n            },\n            Alternatives: {\n                name: Alternatives.$type,\n                properties: {\n                    cardinality: {\n                        name: Alternatives.cardinality\n                    },\n                    elements: {\n                        name: Alternatives.elements,\n                        defaultValue: []\n                    }\n                },\n                superTypes: [AbstractElement.$type]\n            },\n            ArrayLiteral: {\n                name: ArrayLiteral.$type,\n                properties: {\n                    elements: {\n                        name: ArrayLiteral.elements,\n                        defaultValue: []\n                    }\n                },\n                superTypes: [ValueLiteral.$type]\n            },\n            ArrayType: {\n                name: ArrayType.$type,\n                properties: {\n                    elementType: {\n                        name: ArrayType.elementType\n                    }\n                },\n                superTypes: [TypeDefinition.$type]\n            },\n            Assignment: {\n                name: Assignment.$type,\n                properties: {\n                    cardinality: {\n                        name: Assignment.cardinality\n                    },\n                    feature: {\n                        name: Assignment.feature\n                    },\n                    operator: {\n                        name: Assignment.operator\n                    },\n                    predicate: {\n                        name: Assignment.predicate\n                    },\n                    terminal: {\n                        name: Assignment.terminal\n                    }\n                },\n                superTypes: [AbstractElement.$type]\n            },\n            BooleanLiteral: {\n                name: BooleanLiteral.$type,\n                properties: {\n                    true: {\n                        name: BooleanLiteral.true,\n                        defaultValue: false\n                    }\n                },\n                superTypes: [Condition.$type, ValueLiteral.$type]\n            },\n            CharacterRange: {\n                name: CharacterRange.$type,\n                properties: {\n                    cardinality: {\n                        name: CharacterRange.cardinality\n                    },\n                    left: {\n                        name: CharacterRange.left\n                    },\n                    lookahead: {\n                        name: CharacterRange.lookahead\n                    },\n                    parenthesized: {\n                        name: CharacterRange.parenthesized,\n                        defaultValue: false\n                    },\n                    right: {\n                        name: CharacterRange.right\n                    }\n                },\n                superTypes: [TerminalElement.$type]\n            },\n            Condition: {\n                name: Condition.$type,\n                properties: {},\n                superTypes: []\n            },\n            Conjunction: {\n                name: Conjunction.$type,\n                properties: {\n                    left: {\n                        name: Conjunction.left\n                    },\n                    right: {\n                        name: Conjunction.right\n                    }\n                },\n                superTypes: [Condition.$type]\n            },\n            CrossReference: {\n                name: CrossReference.$type,\n                properties: {\n                    cardinality: {\n                        name: CrossReference.cardinality\n                    },\n                    deprecatedSyntax: {\n                        name: CrossReference.deprecatedSyntax,\n                        defaultValue: false\n                    },\n                    isMulti: {\n                        name: CrossReference.isMulti,\n                        defaultValue: false\n                    },\n                    terminal: {\n                        name: CrossReference.terminal\n                    },\n                    type: {\n                        name: CrossReference.type,\n                        referenceType: AbstractType.$type\n                    }\n                },\n                superTypes: [AbstractElement.$type]\n            },\n            Disjunction: {\n                name: Disjunction.$type,\n                properties: {\n                    left: {\n                        name: Disjunction.left\n                    },\n                    right: {\n                        name: Disjunction.right\n                    }\n                },\n                superTypes: [Condition.$type]\n            },\n            EndOfFile: {\n                name: EndOfFile.$type,\n                properties: {\n                    cardinality: {\n                        name: EndOfFile.cardinality\n                    }\n                },\n                superTypes: [AbstractElement.$type]\n            },\n            Grammar: {\n                name: Grammar.$type,\n                properties: {\n                    imports: {\n                        name: Grammar.imports,\n                        defaultValue: []\n                    },\n                    interfaces: {\n                        name: Grammar.interfaces,\n                        defaultValue: []\n                    },\n                    isDeclared: {\n                        name: Grammar.isDeclared,\n                        defaultValue: false\n                    },\n                    name: {\n                        name: Grammar.name\n                    },\n                    rules: {\n                        name: Grammar.rules,\n                        defaultValue: []\n                    },\n                    types: {\n                        name: Grammar.types,\n                        defaultValue: []\n                    }\n                },\n                superTypes: []\n            },\n            GrammarImport: {\n                name: GrammarImport.$type,\n                properties: {\n                    path: {\n                        name: GrammarImport.path\n                    }\n                },\n                superTypes: []\n            },\n            Group: {\n                name: Group.$type,\n                properties: {\n                    cardinality: {\n                        name: Group.cardinality\n                    },\n                    elements: {\n                        name: Group.elements,\n                        defaultValue: []\n                    },\n                    guardCondition: {\n                        name: Group.guardCondition\n                    },\n                    predicate: {\n                        name: Group.predicate\n                    }\n                },\n                superTypes: [AbstractElement.$type]\n            },\n            InferredType: {\n                name: InferredType.$type,\n                properties: {\n                    name: {\n                        name: InferredType.name\n                    }\n                },\n                superTypes: [AbstractType.$type]\n            },\n            InfixRule: {\n                name: InfixRule.$type,\n                properties: {\n                    call: {\n                        name: InfixRule.call\n                    },\n                    dataType: {\n                        name: InfixRule.dataType\n                    },\n                    inferredType: {\n                        name: InfixRule.inferredType\n                    },\n                    name: {\n                        name: InfixRule.name\n                    },\n                    operators: {\n                        name: InfixRule.operators\n                    },\n                    parameters: {\n                        name: InfixRule.parameters,\n                        defaultValue: []\n                    },\n                    returnType: {\n                        name: InfixRule.returnType,\n                        referenceType: AbstractType.$type\n                    }\n                },\n                superTypes: [AbstractParserRule.$type]\n            },\n            InfixRuleOperatorList: {\n                name: InfixRuleOperatorList.$type,\n                properties: {\n                    associativity: {\n                        name: InfixRuleOperatorList.associativity\n                    },\n                    operators: {\n                        name: InfixRuleOperatorList.operators,\n                        defaultValue: []\n                    }\n                },\n                superTypes: []\n            },\n            InfixRuleOperators: {\n                name: InfixRuleOperators.$type,\n                properties: {\n                    precedences: {\n                        name: InfixRuleOperators.precedences,\n                        defaultValue: []\n                    }\n                },\n                superTypes: []\n            },\n            Interface: {\n                name: Interface.$type,\n                properties: {\n                    attributes: {\n                        name: Interface.attributes,\n                        defaultValue: []\n                    },\n                    name: {\n                        name: Interface.name\n                    },\n                    superTypes: {\n                        name: Interface.superTypes,\n                        defaultValue: [],\n                        referenceType: AbstractType.$type\n                    }\n                },\n                superTypes: [AbstractType.$type]\n            },\n            Keyword: {\n                name: Keyword.$type,\n                properties: {\n                    cardinality: {\n                        name: Keyword.cardinality\n                    },\n                    predicate: {\n                        name: Keyword.predicate\n                    },\n                    value: {\n                        name: Keyword.value\n                    }\n                },\n                superTypes: [AbstractElement.$type]\n            },\n            NamedArgument: {\n                name: NamedArgument.$type,\n                properties: {\n                    calledByName: {\n                        name: NamedArgument.calledByName,\n                        defaultValue: false\n                    },\n                    parameter: {\n                        name: NamedArgument.parameter,\n                        referenceType: Parameter.$type\n                    },\n                    value: {\n                        name: NamedArgument.value\n                    }\n                },\n                superTypes: []\n            },\n            NegatedToken: {\n                name: NegatedToken.$type,\n                properties: {\n                    cardinality: {\n                        name: NegatedToken.cardinality\n                    },\n                    lookahead: {\n                        name: NegatedToken.lookahead\n                    },\n                    parenthesized: {\n                        name: NegatedToken.parenthesized,\n                        defaultValue: false\n                    },\n                    terminal: {\n                        name: NegatedToken.terminal\n                    }\n                },\n                superTypes: [TerminalElement.$type]\n            },\n            Negation: {\n                name: Negation.$type,\n                properties: {\n                    value: {\n                        name: Negation.value\n                    }\n                },\n                superTypes: [Condition.$type]\n            },\n            NumberLiteral: {\n                name: NumberLiteral.$type,\n                properties: {\n                    value: {\n                        name: NumberLiteral.value\n                    }\n                },\n                superTypes: [ValueLiteral.$type]\n            },\n            Parameter: {\n                name: Parameter.$type,\n                properties: {\n                    name: {\n                        name: Parameter.name\n                    }\n                },\n                superTypes: []\n            },\n            ParameterReference: {\n                name: ParameterReference.$type,\n                properties: {\n                    parameter: {\n                        name: ParameterReference.parameter,\n                        referenceType: Parameter.$type\n                    }\n                },\n                superTypes: [Condition.$type]\n            },\n            ParserRule: {\n                name: ParserRule.$type,\n                properties: {\n                    dataType: {\n                        name: ParserRule.dataType\n                    },\n                    definition: {\n                        name: ParserRule.definition\n                    },\n                    entry: {\n                        name: ParserRule.entry,\n                        defaultValue: false\n                    },\n                    fragment: {\n                        name: ParserRule.fragment,\n                        defaultValue: false\n                    },\n                    inferredType: {\n                        name: ParserRule.inferredType\n                    },\n                    name: {\n                        name: ParserRule.name\n                    },\n                    parameters: {\n                        name: ParserRule.parameters,\n                        defaultValue: []\n                    },\n                    returnType: {\n                        name: ParserRule.returnType,\n                        referenceType: AbstractType.$type\n                    }\n                },\n                superTypes: [AbstractParserRule.$type]\n            },\n            ReferenceType: {\n                name: ReferenceType.$type,\n                properties: {\n                    isMulti: {\n                        name: ReferenceType.isMulti,\n                        defaultValue: false\n                    },\n                    referenceType: {\n                        name: ReferenceType.referenceType\n                    }\n                },\n                superTypes: [TypeDefinition.$type]\n            },\n            RegexToken: {\n                name: RegexToken.$type,\n                properties: {\n                    cardinality: {\n                        name: RegexToken.cardinality\n                    },\n                    lookahead: {\n                        name: RegexToken.lookahead\n                    },\n                    parenthesized: {\n                        name: RegexToken.parenthesized,\n                        defaultValue: false\n                    },\n                    regex: {\n                        name: RegexToken.regex\n                    }\n                },\n                superTypes: [TerminalElement.$type]\n            },\n            ReturnType: {\n                name: ReturnType.$type,\n                properties: {\n                    name: {\n                        name: ReturnType.name\n                    }\n                },\n                superTypes: []\n            },\n            RuleCall: {\n                name: RuleCall.$type,\n                properties: {\n                    arguments: {\n                        name: RuleCall.arguments,\n                        defaultValue: []\n                    },\n                    cardinality: {\n                        name: RuleCall.cardinality\n                    },\n                    predicate: {\n                        name: RuleCall.predicate\n                    },\n                    rule: {\n                        name: RuleCall.rule,\n                        referenceType: AbstractRule.$type\n                    }\n                },\n                superTypes: [AbstractElement.$type]\n            },\n            SimpleType: {\n                name: SimpleType.$type,\n                properties: {\n                    primitiveType: {\n                        name: SimpleType.primitiveType\n                    },\n                    stringType: {\n                        name: SimpleType.stringType\n                    },\n                    typeRef: {\n                        name: SimpleType.typeRef,\n                        referenceType: AbstractType.$type\n                    }\n                },\n                superTypes: [TypeDefinition.$type]\n            },\n            StringLiteral: {\n                name: StringLiteral.$type,\n                properties: {\n                    value: {\n                        name: StringLiteral.value\n                    }\n                },\n                superTypes: [ValueLiteral.$type]\n            },\n            TerminalAlternatives: {\n                name: TerminalAlternatives.$type,\n                properties: {\n                    cardinality: {\n                        name: TerminalAlternatives.cardinality\n                    },\n                    elements: {\n                        name: TerminalAlternatives.elements,\n                        defaultValue: []\n                    },\n                    lookahead: {\n                        name: TerminalAlternatives.lookahead\n                    },\n                    parenthesized: {\n                        name: TerminalAlternatives.parenthesized,\n                        defaultValue: false\n                    }\n                },\n                superTypes: [TerminalElement.$type]\n            },\n            TerminalElement: {\n                name: TerminalElement.$type,\n                properties: {\n                    cardinality: {\n                        name: TerminalElement.cardinality\n                    },\n                    lookahead: {\n                        name: TerminalElement.lookahead\n                    },\n                    parenthesized: {\n                        name: TerminalElement.parenthesized,\n                        defaultValue: false\n                    }\n                },\n                superTypes: [AbstractElement.$type]\n            },\n            TerminalGroup: {\n                name: TerminalGroup.$type,\n                properties: {\n                    cardinality: {\n                        name: TerminalGroup.cardinality\n                    },\n                    elements: {\n                        name: TerminalGroup.elements,\n                        defaultValue: []\n                    },\n                    lookahead: {\n                        name: TerminalGroup.lookahead\n                    },\n                    parenthesized: {\n                        name: TerminalGroup.parenthesized,\n                        defaultValue: false\n                    }\n                },\n                superTypes: [TerminalElement.$type]\n            },\n            TerminalRule: {\n                name: TerminalRule.$type,\n                properties: {\n                    definition: {\n                        name: TerminalRule.definition\n                    },\n                    fragment: {\n                        name: TerminalRule.fragment,\n                        defaultValue: false\n                    },\n                    hidden: {\n                        name: TerminalRule.hidden,\n                        defaultValue: false\n                    },\n                    name: {\n                        name: TerminalRule.name\n                    },\n                    type: {\n                        name: TerminalRule.type\n                    }\n                },\n                superTypes: [AbstractRule.$type]\n            },\n            TerminalRuleCall: {\n                name: TerminalRuleCall.$type,\n                properties: {\n                    cardinality: {\n                        name: TerminalRuleCall.cardinality\n                    },\n                    lookahead: {\n                        name: TerminalRuleCall.lookahead\n                    },\n                    parenthesized: {\n                        name: TerminalRuleCall.parenthesized,\n                        defaultValue: false\n                    },\n                    rule: {\n                        name: TerminalRuleCall.rule,\n                        referenceType: TerminalRule.$type\n                    }\n                },\n                superTypes: [TerminalElement.$type]\n            },\n            Type: {\n                name: Type.$type,\n                properties: {\n                    name: {\n                        name: Type.name\n                    },\n                    type: {\n                        name: Type.type\n                    }\n                },\n                superTypes: [AbstractType.$type]\n            },\n            TypeAttribute: {\n                name: TypeAttribute.$type,\n                properties: {\n                    defaultValue: {\n                        name: TypeAttribute.defaultValue\n                    },\n                    isOptional: {\n                        name: TypeAttribute.isOptional,\n                        defaultValue: false\n                    },\n                    name: {\n                        name: TypeAttribute.name\n                    },\n                    type: {\n                        name: TypeAttribute.type\n                    }\n                },\n                superTypes: []\n            },\n            TypeDefinition: {\n                name: TypeDefinition.$type,\n                properties: {},\n                superTypes: []\n            },\n            UnionType: {\n                name: UnionType.$type,\n                properties: {\n                    types: {\n                        name: UnionType.types,\n                        defaultValue: []\n                    }\n                },\n                superTypes: [TypeDefinition.$type]\n            },\n            UnorderedGroup: {\n                name: UnorderedGroup.$type,\n                properties: {\n                    cardinality: {\n                        name: UnorderedGroup.cardinality\n                    },\n                    elements: {\n                        name: UnorderedGroup.elements,\n                        defaultValue: []\n                    }\n                },\n                superTypes: [AbstractElement.$type]\n            },\n            UntilToken: {\n                name: UntilToken.$type,\n                properties: {\n                    cardinality: {\n                        name: UntilToken.cardinality\n                    },\n                    lookahead: {\n                        name: UntilToken.lookahead\n                    },\n                    parenthesized: {\n                        name: UntilToken.parenthesized,\n                        defaultValue: false\n                    },\n                    terminal: {\n                        name: UntilToken.terminal\n                    }\n                },\n                superTypes: [TerminalElement.$type]\n            },\n            ValueLiteral: {\n                name: ValueLiteral.$type,\n                properties: {},\n                superTypes: []\n            },\n            Wildcard: {\n                name: Wildcard.$type,\n                properties: {\n                    cardinality: {\n                        name: Wildcard.cardinality\n                    },\n                    lookahead: {\n                        name: Wildcard.lookahead\n                    },\n                    parenthesized: {\n                        name: Wildcard.parenthesized,\n                        defaultValue: false\n                    }\n                },\n                superTypes: [TerminalElement.$type]\n            }\n        };\n    }\n}\nexport const reflection = new LangiumGrammarAstReflection();\n//# sourceMappingURL=ast.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { Lexer } from 'chevrotain';\nimport { isAbstractParserRule, isKeyword, isTerminalRule } from '../languages/generated/ast.js';\nimport { streamAllContents } from '../utils/ast-utils.js';\nimport { getAllReachableRules, terminalRegex } from '../utils/grammar-utils.js';\nimport { escapeRegExp, isWhitespace, partialMatches } from '../utils/regexp-utils.js';\nimport { stream } from '../utils/stream.js';\nexport class DefaultTokenBuilder {\n    constructor() {\n        /**\n         * The list of diagnostics stored during the lexing process of a single text.\n         */\n        this.diagnostics = [];\n    }\n    buildTokens(grammar, options) {\n        const reachableRules = stream(getAllReachableRules(grammar, false));\n        const terminalTokens = this.buildTerminalTokens(reachableRules);\n        const tokens = this.buildKeywordTokens(reachableRules, terminalTokens, options);\n        // Add all terminals tokens to the end in the order they were defined\n        // Chevrotain documentation recommends to add Whitespace-like tokens at the start\n        // However, assuming the lexer is able to optimize the tokens, it should not matter\n        tokens.push(...terminalTokens);\n        // We don't need to add the EOF token explicitly.\n        // It is automatically available at the end of the token stream.\n        return tokens;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    flushLexingReport(text) {\n        return { diagnostics: this.popDiagnostics() };\n    }\n    popDiagnostics() {\n        const diagnostics = [...this.diagnostics];\n        this.diagnostics = [];\n        return diagnostics;\n    }\n    buildTerminalTokens(rules) {\n        return rules.filter(isTerminalRule).filter(e => !e.fragment)\n            .map(terminal => this.buildTerminalToken(terminal)).toArray();\n    }\n    buildTerminalToken(terminal) {\n        const regex = terminalRegex(terminal);\n        const pattern = this.requiresCustomPattern(regex) ? this.regexPatternFunction(regex) : regex;\n        const tokenType = {\n            name: terminal.name,\n            PATTERN: pattern,\n        };\n        if (typeof pattern === 'function') {\n            tokenType.LINE_BREAKS = true;\n        }\n        if (terminal.hidden) {\n            // Only skip tokens that are able to accept whitespace\n            tokenType.GROUP = isWhitespace(regex) ? Lexer.SKIPPED : 'hidden';\n        }\n        return tokenType;\n    }\n    requiresCustomPattern(regex) {\n        if (regex.flags.includes('u') || regex.flags.includes('s')) {\n            // Unicode and dotall regexes are not supported by Chevrotain.\n            return true;\n        }\n        else {\n            return false;\n        }\n    }\n    regexPatternFunction(regex) {\n        const stickyRegex = new RegExp(regex, regex.flags + 'y');\n        return (text, offset) => {\n            stickyRegex.lastIndex = offset;\n            const execResult = stickyRegex.exec(text);\n            return execResult;\n        };\n    }\n    buildKeywordTokens(rules, terminalTokens, options) {\n        return rules\n            // We filter by parser rules, since keywords in terminal rules get transformed into regex and are not actual tokens\n            .filter(isAbstractParserRule)\n            .flatMap(rule => streamAllContents(rule).filter(isKeyword))\n            .distinct(e => e.value).toArray()\n            // Sort keywords by descending length\n            .sort((a, b) => b.value.length - a.value.length)\n            .map(keyword => this.buildKeywordToken(keyword, terminalTokens, Boolean(options?.caseInsensitive)));\n    }\n    buildKeywordToken(keyword, terminalTokens, caseInsensitive) {\n        const keywordPattern = this.buildKeywordPattern(keyword, caseInsensitive);\n        const tokenType = {\n            name: keyword.value,\n            PATTERN: keywordPattern,\n            LONGER_ALT: this.findLongerAlt(keyword, terminalTokens)\n        };\n        if (typeof keywordPattern === 'function') {\n            tokenType.LINE_BREAKS = true;\n        }\n        return tokenType;\n    }\n    buildKeywordPattern(keyword, caseInsensitive) {\n        return caseInsensitive ?\n            new RegExp(escapeRegExp(keyword.value), 'i') :\n            keyword.value;\n    }\n    findLongerAlt(keyword, terminalTokens) {\n        return terminalTokens.reduce((longerAlts, token) => {\n            const pattern = token?.PATTERN;\n            if (pattern?.source && partialMatches('^' + pattern.source + '$', keyword.value)) {\n                longerAlts.push(token);\n            }\n            return longerAlts;\n        }, []);\n    }\n}\n//# sourceMappingURL=token-builder.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { isCrossReference, isRuleCall } from '../languages/generated/ast.js';\nimport { getCrossReferenceTerminal, getRuleType } from '../utils/grammar-utils.js';\nexport class DefaultValueConverter {\n    convert(input, cstNode) {\n        let feature = cstNode.grammarSource;\n        if (isCrossReference(feature)) {\n            feature = getCrossReferenceTerminal(feature);\n        }\n        if (isRuleCall(feature)) {\n            const rule = feature.rule.ref;\n            if (!rule) {\n                throw new Error('This cst node was not parsed by a rule.');\n            }\n            return this.runConverter(rule, input, cstNode);\n        }\n        return input;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    runConverter(rule, input, cstNode) {\n        switch (rule.name.toUpperCase()) {\n            case 'INT': return ValueConverter.convertInt(input);\n            case 'STRING': return ValueConverter.convertString(input);\n            case 'ID': return ValueConverter.convertID(input);\n        }\n        switch (getRuleType(rule)?.toLowerCase()) {\n            case 'number': return ValueConverter.convertNumber(input);\n            case 'boolean': return ValueConverter.convertBoolean(input);\n            case 'bigint': return ValueConverter.convertBigint(input);\n            case 'date': return ValueConverter.convertDate(input);\n            default: return input;\n        }\n    }\n}\nexport var ValueConverter;\n(function (ValueConverter) {\n    function convertString(input) {\n        let result = '';\n        for (let i = 1; i < input.length - 1; i++) {\n            const c = input.charAt(i);\n            if (c === '\\\\') {\n                const c1 = input.charAt(++i);\n                result += convertEscapeCharacter(c1);\n            }\n            else {\n                result += c;\n            }\n        }\n        return result;\n    }\n    ValueConverter.convertString = convertString;\n    function convertEscapeCharacter(char) {\n        switch (char) {\n            case 'b': return '\\b';\n            case 'f': return '\\f';\n            case 'n': return '\\n';\n            case 'r': return '\\r';\n            case 't': return '\\t';\n            case 'v': return '\\v';\n            case '0': return '\\0';\n            default: return char;\n        }\n    }\n    function convertID(input) {\n        if (input.charAt(0) === '^') {\n            return input.substring(1);\n        }\n        else {\n            return input;\n        }\n    }\n    ValueConverter.convertID = convertID;\n    function convertInt(input) {\n        return parseInt(input);\n    }\n    ValueConverter.convertInt = convertInt;\n    function convertBigint(input) {\n        return BigInt(input);\n    }\n    ValueConverter.convertBigint = convertBigint;\n    function convertDate(input) {\n        return new Date(input);\n    }\n    ValueConverter.convertDate = convertDate;\n    function convertNumber(input) {\n        return Number(input);\n    }\n    ValueConverter.convertNumber = convertNumber;\n    function convertBoolean(input) {\n        return input.toLowerCase() === 'true';\n    }\n    ValueConverter.convertBoolean = convertBoolean;\n})(ValueConverter || (ValueConverter = {}));\n//# sourceMappingURL=value-converter.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nexport function isAstNode(obj) {\n    return typeof obj === 'object' && obj !== null && typeof obj.$type === 'string';\n}\nexport function isReference(obj) {\n    return typeof obj === 'object' && obj !== null && typeof obj.$refText === 'string' && 'ref' in obj;\n}\nexport function isMultiReference(obj) {\n    return typeof obj === 'object' && obj !== null && typeof obj.$refText === 'string' && 'items' in obj;\n}\nexport function isAstNodeDescription(obj) {\n    return typeof obj === 'object' && obj !== null\n        && typeof obj.name === 'string'\n        && typeof obj.type === 'string'\n        && typeof obj.path === 'string';\n}\nexport function isLinkingError(obj) {\n    return typeof obj === 'object' && obj !== null\n        && typeof obj.info === 'object'\n        && typeof obj.message === 'string';\n}\n/**\n * An abstract implementation of the {@link AstReflection} interface.\n * Serves to cache subtype computation results to improve performance throughout different parts of Langium.\n */\nexport class AbstractAstReflection {\n    constructor() {\n        this.subtypes = {};\n        this.allSubtypes = {};\n    }\n    getAllTypes() {\n        return Object.keys(this.types);\n    }\n    getReferenceType(refInfo) {\n        const metaData = this.types[refInfo.container.$type];\n        if (!metaData) {\n            throw new Error(`Type ${refInfo.container.$type || 'undefined'} not found.`);\n        }\n        const referenceType = metaData.properties[refInfo.property]?.referenceType;\n        if (!referenceType) {\n            throw new Error(`Property ${refInfo.property || 'undefined'} of type ${refInfo.container.$type} is not a reference.`);\n        }\n        return referenceType;\n    }\n    getTypeMetaData(type) {\n        const result = this.types[type];\n        if (!result) {\n            return {\n                name: type,\n                properties: {},\n                superTypes: []\n            };\n        }\n        return result;\n    }\n    isInstance(node, type) {\n        return isAstNode(node) && this.isSubtype(node.$type, type);\n    }\n    isSubtype(subtype, supertype) {\n        if (subtype === supertype) {\n            return true;\n        }\n        let nested = this.subtypes[subtype];\n        if (!nested) {\n            nested = this.subtypes[subtype] = {};\n        }\n        const existing = nested[supertype];\n        if (existing !== undefined) {\n            return existing;\n        }\n        else {\n            const metaData = this.types[subtype];\n            const result = metaData ? metaData.superTypes.some(s => this.isSubtype(s, supertype)) : false;\n            nested[supertype] = result;\n            return result;\n        }\n    }\n    getAllSubTypes(type) {\n        const existing = this.allSubtypes[type];\n        if (existing) {\n            return existing;\n        }\n        else {\n            const allTypes = this.getAllTypes();\n            const types = [];\n            for (const possibleSubType of allTypes) {\n                if (this.isSubtype(possibleSubType, type)) {\n                    types.push(possibleSubType);\n                }\n            }\n            this.allSubtypes[type] = types;\n            return types;\n        }\n    }\n}\nexport function isCompositeCstNode(node) {\n    return typeof node === 'object' && node !== null && Array.isArray(node.content);\n}\nexport function isLeafCstNode(node) {\n    return typeof node === 'object' && node !== null && typeof node.tokenType === 'object';\n}\nexport function isRootCstNode(node) {\n    return isCompositeCstNode(node) && typeof node.fullText === 'string';\n}\n//# sourceMappingURL=syntax-tree.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { isAstNode, isMultiReference, isReference } from '../syntax-tree.js';\nimport { DONE_RESULT, StreamImpl, TreeStreamImpl } from './stream.js';\nimport { inRange } from './cst-utils.js';\n/**\n * Link the `$container` and other related properties of every AST node that is directly contained\n * in the given `node`.\n */\nexport function linkContentToContainer(node, options = {}) {\n    for (const [name, value] of Object.entries(node)) {\n        if (!name.startsWith('$')) {\n            if (Array.isArray(value)) {\n                value.forEach((item, index) => {\n                    if (isAstNode(item)) {\n                        item.$container = node;\n                        item.$containerProperty = name;\n                        item.$containerIndex = index;\n                        if (options.deep) {\n                            linkContentToContainer(item, options);\n                        }\n                    }\n                });\n            }\n            else if (isAstNode(value)) {\n                value.$container = node;\n                value.$containerProperty = name;\n                if (options.deep) {\n                    linkContentToContainer(value, options);\n                }\n            }\n        }\n    }\n}\n/**\n * Walk along the hierarchy of containers from the given AST node to the root and return the first\n * node that matches the type predicate. If the start node itself matches, it is returned.\n * If no container matches, `undefined` is returned.\n */\nexport function getContainerOfType(node, typePredicate) {\n    let item = node;\n    while (item) {\n        if (typePredicate(item)) {\n            return item;\n        }\n        item = item.$container;\n    }\n    return undefined;\n}\n/**\n * Walk along the hierarchy of containers from the given AST node to the root and check for existence\n * of a container that matches the given predicate. The start node is included in the checks.\n */\nexport function hasContainerOfType(node, predicate) {\n    let item = node;\n    while (item) {\n        if (predicate(item)) {\n            return true;\n        }\n        item = item.$container;\n    }\n    return false;\n}\n/**\n * Retrieve the document in which the given AST node is contained. A reference to the document is\n * usually held by the root node of the AST.\n *\n * @throws an error if the node is not contained in a document.\n */\nexport function getDocument(node) {\n    const rootNode = findRootNode(node);\n    const result = rootNode.$document;\n    if (!result) {\n        throw new Error('AST node has no document.');\n    }\n    return result;\n}\n/**\n * Returns the root node of the given AST node by following the `$container` references.\n */\nexport function findRootNode(node) {\n    while (node.$container) {\n        node = node.$container;\n    }\n    return node;\n}\n/**\n * Returns all AST nodes that are referenced by the given reference or multi-reference.\n */\nexport function getReferenceNodes(reference) {\n    if (isReference(reference)) {\n        return reference.ref ? [reference.ref] : [];\n    }\n    else if (isMultiReference(reference)) {\n        return reference.items.map(item => item.ref);\n    }\n    return [];\n}\n/**\n * Create a stream of all AST nodes that are directly contained in the given node. This includes\n * single-valued as well as multi-valued (array) properties.\n */\nexport function streamContents(node, options) {\n    if (!node) {\n        throw new Error('Node must be an AstNode.');\n    }\n    const range = options?.range;\n    return new StreamImpl(() => ({\n        keys: Object.keys(node),\n        keyIndex: 0,\n        arrayIndex: 0\n    }), state => {\n        while (state.keyIndex < state.keys.length) {\n            const property = state.keys[state.keyIndex];\n            if (!property.startsWith('$')) {\n                const value = node[property];\n                if (isAstNode(value)) {\n                    state.keyIndex++;\n                    if (isAstNodeInRange(value, range)) {\n                        return { done: false, value };\n                    }\n                }\n                else if (Array.isArray(value)) {\n                    while (state.arrayIndex < value.length) {\n                        const index = state.arrayIndex++;\n                        const element = value[index];\n                        if (isAstNode(element) && isAstNodeInRange(element, range)) {\n                            return { done: false, value: element };\n                        }\n                    }\n                    state.arrayIndex = 0;\n                }\n            }\n            state.keyIndex++;\n        }\n        return DONE_RESULT;\n    });\n}\n/**\n * Create a stream of all AST nodes that are directly and indirectly contained in the given root node.\n * This does not include the root node itself.\n */\nexport function streamAllContents(root, options) {\n    if (!root) {\n        throw new Error('Root node must be an AstNode.');\n    }\n    return new TreeStreamImpl(root, node => streamContents(node, options));\n}\n/**\n * Create a stream of all AST nodes that are directly and indirectly contained in the given root node,\n * including the root node itself.\n */\nexport function streamAst(root, options) {\n    if (!root) {\n        throw new Error('Root node must be an AstNode.');\n    }\n    else if (options?.range && !isAstNodeInRange(root, options.range)) {\n        // Return an empty stream if the root node isn't in range\n        return new TreeStreamImpl(root, () => []);\n    }\n    return new TreeStreamImpl(root, node => streamContents(node, options), { includeRoot: true });\n}\nfunction isAstNodeInRange(astNode, range) {\n    if (!range) {\n        return true;\n    }\n    const nodeRange = astNode.$cstNode?.range;\n    if (!nodeRange) {\n        return false;\n    }\n    return inRange(nodeRange, range);\n}\n/**\n * Create a stream of all cross-references that are held by the given AST node. This includes\n * single-valued as well as multi-valued (array) properties.\n */\nexport function streamReferences(node) {\n    return new StreamImpl(() => ({\n        keys: Object.keys(node),\n        keyIndex: 0,\n        arrayIndex: 0\n    }), state => {\n        while (state.keyIndex < state.keys.length) {\n            const property = state.keys[state.keyIndex];\n            if (!property.startsWith('$')) {\n                const value = node[property];\n                if (isReference(value) || isMultiReference(value)) {\n                    state.keyIndex++;\n                    return { done: false, value: { reference: value, container: node, property } };\n                }\n                else if (Array.isArray(value)) {\n                    while (state.arrayIndex < value.length) {\n                        const index = state.arrayIndex++;\n                        const element = value[index];\n                        if (isReference(element) || isMultiReference(value)) {\n                            return { done: false, value: { reference: element, container: node, property, index } };\n                        }\n                    }\n                    state.arrayIndex = 0;\n                }\n            }\n            state.keyIndex++;\n        }\n        return DONE_RESULT;\n    });\n}\n/**\n * Assigns all mandatory AST properties to the specified node.\n *\n * @param reflection Reflection object used to gather mandatory properties for the node.\n * @param node Specified node is modified in place and properties are directly assigned.\n */\nexport function assignMandatoryProperties(reflection, node) {\n    const typeMetaData = reflection.getTypeMetaData(node.$type);\n    const genericNode = node;\n    for (const property of Object.values(typeMetaData.properties)) {\n        // Only set the value if the property is not already set and if it has a default value\n        if (property.defaultValue !== undefined && genericNode[property.name] === undefined) {\n            genericNode[property.name] = copyDefaultValue(property.defaultValue);\n        }\n    }\n}\nfunction copyDefaultValue(propertyType) {\n    if (Array.isArray(propertyType)) {\n        return [...propertyType.map(copyDefaultValue)];\n    }\n    else {\n        return propertyType;\n    }\n}\n/**\n * Creates a deep copy of the specified AST node.\n * The resulting copy will only contain semantically relevant information, such as the `$type` property and AST properties.\n *\n * @param node The AST node to deeply copy.\n * @param buildReference References are not copied, instead this function is called to rebuild them.\n * @param trace For the sake of tracking copied nodes and their originals a `trace` map can be provided (optional).\n */\nexport function copyAstNode(node, buildReference, trace) {\n    const copy = { $type: node.$type };\n    if (trace) {\n        trace.set(node, copy);\n        trace.set(copy, node);\n    }\n    for (const [name, value] of Object.entries(node)) {\n        if (!name.startsWith('$')) {\n            if (isAstNode(value)) {\n                copy[name] = copyAstNode(value, buildReference, trace);\n            }\n            else if (isReference(value)) {\n                copy[name] = buildReference(copy, name, value.$refNode, value.$refText, value);\n            }\n            else if (Array.isArray(value)) {\n                const copiedArray = [];\n                for (const element of value) {\n                    if (isAstNode(element)) {\n                        copiedArray.push(copyAstNode(element, buildReference, trace));\n                    }\n                    else if (isReference(element)) {\n                        copiedArray.push(buildReference(copy, name, element.$refNode, element.$refText, element));\n                    }\n                    else {\n                        copiedArray.push(element);\n                    }\n                }\n                copy[name] = copiedArray;\n            }\n            else {\n                copy[name] = value;\n            }\n        }\n    }\n    linkContentToContainer(copy, { deep: true });\n    return copy;\n}\n//# sourceMappingURL=ast-utils.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { isCompositeCstNode, isLeafCstNode, isRootCstNode } from '../syntax-tree.js';\nimport { TreeStreamImpl } from './stream.js';\nimport { getContainerOfType } from './ast-utils.js';\nimport { isParserRule } from '../languages/generated/ast.js';\n/**\n * Attempts to find the CST node that belongs to the datatype element that contains the given CST node.\n *\n * @param cstNode The CST node for which to find the datatype node.\n * @returns The CST node corresponding to the datatype element, or the undefined if no such element exists.\n */\nexport function getDatatypeNode(cstNode) {\n    let current = cstNode;\n    let found = false;\n    while (current) {\n        const definingRule = getContainerOfType(current.grammarSource, isParserRule);\n        if (definingRule && definingRule.dataType) {\n            // Go up the chain. This element might be part of a larger datatype rule\n            current = current.container;\n            found = true;\n        }\n        else if (found) {\n            // The last datatype node is the one we are looking for\n            return current;\n        }\n        else {\n            // We haven't found any datatype node yet and we've reached a non-datatype rule\n            return undefined;\n        }\n    }\n    return undefined;\n}\n/**\n * Create a stream of all CST nodes that are directly and indirectly contained in the given root node,\n * including the root node itself.\n */\nexport function streamCst(node) {\n    return new TreeStreamImpl(node, element => {\n        if (isCompositeCstNode(element)) {\n            return element.content;\n        }\n        else {\n            return [];\n        }\n    }, { includeRoot: true });\n}\n/**\n * Create a stream of all leaf nodes that are directly and indirectly contained in the given root node.\n */\nexport function flattenCst(node) {\n    return streamCst(node).filter(isLeafCstNode);\n}\n/**\n * Determines whether the specified cst node is a child of the specified parent node.\n */\nexport function isChildNode(child, parent) {\n    while (child.container) {\n        child = child.container;\n        if (child === parent) {\n            return true;\n        }\n    }\n    return false;\n}\nexport function tokenToRange(token) {\n    // Chevrotain uses 1-based indices everywhere\n    // So we subtract 1 from every value to align with the LSP\n    return {\n        start: {\n            character: token.startColumn - 1,\n            line: token.startLine - 1\n        },\n        end: {\n            character: token.endColumn, // endColumn uses the correct index\n            line: token.endLine - 1\n        }\n    };\n}\nexport function toDocumentSegment(node) {\n    if (!node) {\n        return undefined;\n    }\n    const { offset, end, range } = node;\n    return {\n        range,\n        offset,\n        end,\n        length: end - offset\n    };\n}\nexport var RangeComparison;\n(function (RangeComparison) {\n    RangeComparison[RangeComparison[\"Before\"] = 0] = \"Before\";\n    RangeComparison[RangeComparison[\"After\"] = 1] = \"After\";\n    RangeComparison[RangeComparison[\"OverlapFront\"] = 2] = \"OverlapFront\";\n    RangeComparison[RangeComparison[\"OverlapBack\"] = 3] = \"OverlapBack\";\n    RangeComparison[RangeComparison[\"Inside\"] = 4] = \"Inside\";\n    RangeComparison[RangeComparison[\"Outside\"] = 5] = \"Outside\";\n})(RangeComparison || (RangeComparison = {}));\nexport function compareRange(range, to) {\n    if (range.end.line < to.start.line || (range.end.line === to.start.line && range.end.character <= to.start.character)) {\n        return RangeComparison.Before;\n    }\n    else if (range.start.line > to.end.line || (range.start.line === to.end.line && range.start.character >= to.end.character)) {\n        return RangeComparison.After;\n    }\n    const startInside = range.start.line > to.start.line || (range.start.line === to.start.line && range.start.character >= to.start.character);\n    const endInside = range.end.line < to.end.line || (range.end.line === to.end.line && range.end.character <= to.end.character);\n    if (startInside && endInside) {\n        return RangeComparison.Inside;\n    }\n    else if (startInside) {\n        return RangeComparison.OverlapBack;\n    }\n    else if (endInside) {\n        return RangeComparison.OverlapFront;\n    }\n    else {\n        return RangeComparison.Outside;\n    }\n}\nexport function inRange(range, to) {\n    const comparison = compareRange(range, to);\n    return comparison > RangeComparison.After;\n}\n// The \\p{L} regex matches any unicode letter character, i.e. characters from non-english alphabets\n// Together with \\w it matches any kind of character which can commonly appear in IDs\nexport const DefaultNameRegexp = /^[\\w\\p{L}]$/u;\n/**\n * Performs `findLeafNodeAtOffset` with a minor difference: When encountering a character that matches the `nameRegexp` argument,\n * it will instead return the leaf node at the `offset - 1` position.\n *\n * For LSP services, users expect that the declaration of an element is available if the cursor is directly after the element.\n */\nexport function findDeclarationNodeAtOffset(cstNode, offset, nameRegexp = DefaultNameRegexp) {\n    if (cstNode) {\n        if (offset > 0) {\n            const localOffset = offset - cstNode.offset;\n            const textAtOffset = cstNode.text.charAt(localOffset);\n            if (!nameRegexp.test(textAtOffset)) {\n                offset--;\n            }\n        }\n        return findLeafNodeAtOffset(cstNode, offset);\n    }\n    return undefined;\n}\nexport function findCommentNode(cstNode, commentNames) {\n    if (cstNode) {\n        const previous = getPreviousNode(cstNode, true);\n        if (previous && isCommentNode(previous, commentNames)) {\n            return previous;\n        }\n        if (isRootCstNode(cstNode)) {\n            // Go from the first non-hidden node through all nodes in reverse order\n            // We do this to find the comment node which directly precedes the root node\n            const endIndex = cstNode.content.findIndex(e => !e.hidden);\n            for (let i = endIndex - 1; i >= 0; i--) {\n                const child = cstNode.content[i];\n                if (isCommentNode(child, commentNames)) {\n                    return child;\n                }\n            }\n        }\n    }\n    return undefined;\n}\nexport function isCommentNode(cstNode, commentNames) {\n    return isLeafCstNode(cstNode) && commentNames.includes(cstNode.tokenType.name);\n}\n/**\n * Finds the leaf CST node at the specified 0-based string offset.\n * Note that the given offset will be within the range of the returned leaf node.\n *\n * If the offset does not point to a CST node (but just white space), this method will return `undefined`.\n *\n * @param node The CST node to search through.\n * @param offset The specified offset.\n * @returns The CST node at the specified offset.\n */\nexport function findLeafNodeAtOffset(node, offset) {\n    if (isLeafCstNode(node)) {\n        return node;\n    }\n    else if (isCompositeCstNode(node)) {\n        const searchResult = binarySearch(node, offset, false);\n        if (searchResult) {\n            return findLeafNodeAtOffset(searchResult, offset);\n        }\n    }\n    return undefined;\n}\n/**\n * Finds the leaf CST node at the specified 0-based string offset.\n * If no CST node exists at the specified position, it will return the leaf node before it.\n *\n * If there is no leaf node before the specified offset, this method will return `undefined`.\n *\n * @param node The CST node to search through.\n * @param offset The specified offset.\n * @returns The CST node closest to the specified offset.\n */\nexport function findLeafNodeBeforeOffset(node, offset) {\n    if (isLeafCstNode(node)) {\n        return node;\n    }\n    else if (isCompositeCstNode(node)) {\n        const searchResult = binarySearch(node, offset, true);\n        if (searchResult) {\n            return findLeafNodeBeforeOffset(searchResult, offset);\n        }\n    }\n    return undefined;\n}\nfunction binarySearch(node, offset, closest) {\n    let left = 0;\n    let right = node.content.length - 1;\n    let closestNode = undefined;\n    while (left <= right) {\n        const middle = Math.floor((left + right) / 2);\n        const middleNode = node.content[middle];\n        if (middleNode.offset <= offset && middleNode.end > offset) {\n            // Found an exact match\n            return middleNode;\n        }\n        if (middleNode.end <= offset) {\n            // Update the closest node (less than offset) and move to the right half\n            closestNode = closest ? middleNode : undefined;\n            left = middle + 1;\n        }\n        else {\n            // Move to the left half\n            right = middle - 1;\n        }\n    }\n    return closestNode;\n}\nexport function getPreviousNode(node, hidden = true) {\n    while (node.container) {\n        const parent = node.container;\n        let index = parent.content.indexOf(node);\n        while (index > 0) {\n            index--;\n            const previous = parent.content[index];\n            if (hidden || !previous.hidden) {\n                return previous;\n            }\n        }\n        node = parent;\n    }\n    return undefined;\n}\nexport function getNextNode(node, hidden = true) {\n    while (node.container) {\n        const parent = node.container;\n        let index = parent.content.indexOf(node);\n        const last = parent.content.length - 1;\n        while (index < last) {\n            index++;\n            const next = parent.content[index];\n            if (hidden || !next.hidden) {\n                return next;\n            }\n        }\n        node = parent;\n    }\n    return undefined;\n}\nexport function getStartlineNode(node) {\n    if (node.range.start.character === 0) {\n        return node;\n    }\n    const line = node.range.start.line;\n    let last = node;\n    let index;\n    while (node.container) {\n        const parent = node.container;\n        const selfIndex = index ?? parent.content.indexOf(node);\n        if (selfIndex === 0) {\n            node = parent;\n            index = undefined;\n        }\n        else {\n            index = selfIndex - 1;\n            node = parent.content[index];\n        }\n        if (node.range.start.line !== line) {\n            break;\n        }\n        last = node;\n    }\n    return last;\n}\nexport function getInteriorNodes(start, end) {\n    const commonParent = getCommonParent(start, end);\n    if (!commonParent) {\n        return [];\n    }\n    return commonParent.parent.content.slice(commonParent.a + 1, commonParent.b);\n}\nfunction getCommonParent(a, b) {\n    const aParents = getParentChain(a);\n    const bParents = getParentChain(b);\n    let current;\n    for (let i = 0; i < aParents.length && i < bParents.length; i++) {\n        const aParent = aParents[i];\n        const bParent = bParents[i];\n        if (aParent.parent === bParent.parent) {\n            current = {\n                parent: aParent.parent,\n                a: aParent.index,\n                b: bParent.index\n            };\n        }\n        else {\n            break;\n        }\n    }\n    return current;\n}\nfunction getParentChain(node) {\n    const chain = [];\n    while (node.container) {\n        const parent = node.container;\n        const index = parent.content.indexOf(node);\n        chain.push({\n            parent,\n            index\n        });\n        node = parent;\n    }\n    return chain.reverse();\n}\n//# sourceMappingURL=cst-utils.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nexport class ErrorWithLocation extends Error {\n    constructor(node, message) {\n        super(node ? `${message} at ${node.range.start.line}:${node.range.start.character}` : message);\n    }\n}\nexport function assertUnreachable(_, message = 'Error: Got unexpected value.') {\n    throw new Error(message);\n}\nexport function assertCondition(condition, message = 'Error: Condition is violated.') {\n    if (!condition) {\n        throw new Error(message);\n    }\n}\n//# sourceMappingURL=errors.js.map","/******************************************************************************\n * Copyright 2021-2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { assertUnreachable } from '../utils/errors.js';\nimport * as ast from '../languages/generated/ast.js';\nimport { isCompositeCstNode } from '../syntax-tree.js';\nimport { getContainerOfType, streamAllContents } from './ast-utils.js';\nimport { streamCst } from './cst-utils.js';\nimport { escapeRegExp, isWhitespace } from './regexp-utils.js';\n/**\n * Returns the entry rule of the given grammar, if any. If the grammar file does not contain an entry rule,\n * the result is `undefined`.\n */\nexport function getEntryRule(grammar) {\n    return grammar.rules.find(e => ast.isParserRule(e) && e.entry);\n}\n/**\n * Returns all hidden terminal rules of the given grammar, if any.\n */\nexport function getHiddenRules(grammar) {\n    return grammar.rules.filter(e => ast.isTerminalRule(e) && e.hidden);\n}\n/**\n * Returns all rules that can be reached from the topmost rules of the specified grammar (entry and hidden terminal rules).\n *\n * @param grammar The grammar that contains all rules\n * @param allTerminals Whether or not to include terminals that are referenced only by other terminals\n * @returns A list of referenced parser and terminal rules. If the grammar contains no entry rule,\n *      this function returns all rules of the specified grammar.\n */\nexport function getAllReachableRules(grammar, allTerminals) {\n    const ruleNames = new Set();\n    const entryRule = getEntryRule(grammar);\n    if (!entryRule) {\n        return new Set(grammar.rules);\n    }\n    const topMostRules = [entryRule].concat(getHiddenRules(grammar));\n    for (const rule of topMostRules) {\n        ruleDfs(rule, ruleNames, allTerminals);\n    }\n    const rules = new Set();\n    for (const rule of grammar.rules) {\n        if (ruleNames.has(rule.name) || (ast.isTerminalRule(rule) && rule.hidden)) {\n            rules.add(rule);\n        }\n    }\n    return rules;\n}\nfunction ruleDfs(rule, visitedSet, allTerminals) {\n    visitedSet.add(rule.name);\n    streamAllContents(rule).forEach(node => {\n        if (ast.isRuleCall(node) || (allTerminals && ast.isTerminalRuleCall(node))) {\n            const refRule = node.rule.ref;\n            if (refRule && !visitedSet.has(refRule.name)) {\n                ruleDfs(refRule, visitedSet, allTerminals);\n            }\n        }\n    });\n}\n/**\n * Returns all parser rules which provide types which are used in the grammar as type in cross-references.\n * @param grammar the grammar to investigate\n * @returns the set of parser rules whose contributed types are used as type in cross-references\n */\nexport function getAllRulesUsedForCrossReferences(grammar) {\n    const result = new Set();\n    streamAllContents(grammar).forEach(node => {\n        if (ast.isCrossReference(node)) {\n            // the cross-reference refers directly to a parser rule (without \"returns\", without \"infers\")\n            if (ast.isParserRule(node.type.ref)) {\n                result.add(node.type.ref);\n            }\n            // the cross-reference refers to the explicitly inferred type of a parser rule\n            if (ast.isInferredType(node.type.ref) && ast.isParserRule(node.type.ref.$container)) {\n                result.add(node.type.ref.$container);\n            }\n        }\n    });\n    return result;\n}\n/**\n * Determines the grammar expression used to parse a cross-reference (usually a reference to a terminal rule).\n * A cross-reference can declare this expression explicitly in the form `[Type : Terminal]`, but if `Terminal`\n * is omitted, this function attempts to infer it from the name of the referenced `Type` (using `findNameAssignment`).\n *\n * Returns the grammar expression used to parse the given cross-reference, or `undefined` if it is not declared\n * and cannot be inferred.\n */\nexport function getCrossReferenceTerminal(crossRef) {\n    if (crossRef.terminal) {\n        return crossRef.terminal;\n    }\n    else if (crossRef.type.ref) {\n        const nameAssigment = findNameAssignment(crossRef.type.ref);\n        return nameAssigment?.terminal;\n    }\n    return undefined;\n}\n/**\n * Determines whether the given terminal rule represents a comment. This is true if the rule is marked\n * as `hidden` and it does not match white space. This means every hidden token (i.e. excluded from the AST)\n * that contains visible characters is considered a comment.\n */\nexport function isCommentTerminal(terminalRule) {\n    return terminalRule.hidden && !isWhitespace(terminalRegex(terminalRule));\n}\n/**\n * Find all CST nodes within the given node that contribute to the specified property.\n *\n * @param node A CST node in which to look for property assignments. If this is undefined, the result is an empty array.\n * @param property A property name of the constructed AST node. If this is undefined, the result is an empty array.\n */\nexport function findNodesForProperty(node, property) {\n    if (!node || !property) {\n        return [];\n    }\n    return findNodesForPropertyInternal(node, property, node.astNode, true);\n}\n/**\n * Find a single CST node within the given node that contributes to the specified property.\n *\n * @param node A CST node in which to look for property assignments. If this is undefined, the result is `undefined`.\n * @param property A property name of the constructed AST node. If this is undefined, the result is `undefined`.\n * @param index If no index is specified or the index is less than zero, the first found node is returned. If the\n *        specified index exceeds the number of assignments to the property, the last found node is returned. Otherwise,\n *        the node with the specified index is returned.\n */\nexport function findNodeForProperty(node, property, index) {\n    if (!node || !property) {\n        return undefined;\n    }\n    const nodes = findNodesForPropertyInternal(node, property, node.astNode, true);\n    if (nodes.length === 0) {\n        return undefined;\n    }\n    if (index !== undefined) {\n        index = Math.max(0, Math.min(index, nodes.length - 1));\n    }\n    else {\n        index = 0;\n    }\n    return nodes[index];\n}\nfunction findNodesForPropertyInternal(node, property, element, first) {\n    if (!first) {\n        const nodeFeature = getContainerOfType(node.grammarSource, ast.isAssignment);\n        if (nodeFeature && nodeFeature.feature === property) {\n            return [node];\n        }\n    }\n    if (isCompositeCstNode(node) && node.astNode === element) {\n        return node.content.flatMap(e => findNodesForPropertyInternal(e, property, element, false));\n    }\n    return [];\n}\n/**\n * Find all CST nodes within the given node that correspond to the specified keyword.\n *\n * @param node A CST node in which to look for keywords. If this is undefined, the result is an empty array.\n * @param keyword A keyword as specified in the grammar.\n */\nexport function findNodesForKeyword(node, keyword) {\n    if (!node) {\n        return [];\n    }\n    return findNodesForKeywordInternal(node, keyword, node?.astNode);\n}\n/**\n * Find a single CST node within the given node that corresponds to the specified keyword.\n *\n * @param node A CST node in which to look for keywords. If this is undefined, the result is `undefined`.\n * @param keyword A keyword as specified in the grammar.\n * @param index If no index is specified or the index is less than zero, the first found node is returned. If the\n *        specified index exceeds the number of keyword occurrences, the last found node is returned. Otherwise,\n *        the node with the specified index is returned.\n */\nexport function findNodeForKeyword(node, keyword, index) {\n    if (!node) {\n        return undefined;\n    }\n    const nodes = findNodesForKeywordInternal(node, keyword, node?.astNode);\n    if (nodes.length === 0) {\n        return undefined;\n    }\n    if (index !== undefined) {\n        index = Math.max(0, Math.min(index, nodes.length - 1));\n    }\n    else {\n        index = 0;\n    }\n    return nodes[index];\n}\nexport function findNodesForKeywordInternal(node, keyword, element) {\n    if (node.astNode !== element) {\n        return [];\n    }\n    if (ast.isKeyword(node.grammarSource) && node.grammarSource.value === keyword) {\n        return [node];\n    }\n    const treeIterator = streamCst(node).iterator();\n    let result;\n    const keywordNodes = [];\n    do {\n        result = treeIterator.next();\n        if (!result.done) {\n            const childNode = result.value;\n            if (childNode.astNode === element) {\n                if (ast.isKeyword(childNode.grammarSource) && childNode.grammarSource.value === keyword) {\n                    keywordNodes.push(childNode);\n                }\n            }\n            else {\n                treeIterator.prune();\n            }\n        }\n    } while (!result.done);\n    return keywordNodes;\n}\n/**\n * If the given CST node was parsed in the context of a property assignment, the respective `Assignment` grammar\n * node is returned. If no assignment is found, the result is `undefined`.\n *\n * @param cstNode A CST node for which to find a property assignment.\n */\nexport function findAssignment(cstNode) {\n    const astNode = cstNode.astNode;\n    // Only search until the ast node of the parent cst node is no longer the original ast node\n    // This would make us jump to a preceding rule call, which contains only unrelated assignments\n    while (astNode === cstNode.container?.astNode) {\n        const assignment = getContainerOfType(cstNode.grammarSource, ast.isAssignment);\n        if (assignment) {\n            return assignment;\n        }\n        cstNode = cstNode.container;\n    }\n    return undefined;\n}\n/**\n * Find an assignment to the `name` property for the given grammar type. This requires the `type` to be inferred\n * from a parser rule, and that rule must contain an assignment to the `name` property. In all other cases,\n * this function returns `undefined`.\n */\nexport function findNameAssignment(type) {\n    let startNode = type;\n    if (ast.isInferredType(startNode)) {\n        // for inferred types, the location to start searching for the name-assignment is different\n        if (ast.isAction(startNode.$container)) {\n            // a type which is explicitly inferred by an action: investigate the sibling of the Action node, i.e. start searching at the Action's parent\n            startNode = startNode.$container.$container;\n        }\n        else if (ast.isAbstractParserRule(startNode.$container)) {\n            // investigate the parser rule with the explicitly inferred type\n            startNode = startNode.$container;\n        }\n        else {\n            assertUnreachable(startNode.$container);\n        }\n    }\n    return findNameAssignmentInternal(type, startNode, new Map());\n}\nfunction findNameAssignmentInternal(type, startNode, cache) {\n    // the cache is only required to prevent infinite loops\n    function go(node, refType) {\n        let childAssignment = undefined;\n        const parentAssignment = getContainerOfType(node, ast.isAssignment);\n        // No parent assignment implies unassigned rule call\n        if (!parentAssignment) {\n            childAssignment = findNameAssignmentInternal(refType, refType, cache);\n        }\n        cache.set(type, childAssignment);\n        return childAssignment;\n    }\n    if (cache.has(type)) {\n        return cache.get(type);\n    }\n    cache.set(type, undefined);\n    for (const node of streamAllContents(startNode)) {\n        if (ast.isAssignment(node) && node.feature.toLowerCase() === 'name') {\n            cache.set(type, node);\n            return node;\n        }\n        else if (ast.isRuleCall(node) && ast.isParserRule(node.rule.ref)) {\n            return go(node, node.rule.ref);\n        }\n        else if (ast.isSimpleType(node) && node.typeRef?.ref) {\n            return go(node, node.typeRef.ref);\n        }\n    }\n    return undefined;\n}\nexport function getActionAtElement(element) {\n    const parent = element.$container;\n    if (ast.isGroup(parent)) {\n        const elements = parent.elements;\n        const index = elements.indexOf(element);\n        for (let i = index - 1; i >= 0; i--) {\n            const item = elements[i];\n            if (ast.isAction(item)) {\n                return item;\n            }\n            else {\n                const action = streamAllContents(elements[i]).find(ast.isAction);\n                if (action) {\n                    return action;\n                }\n            }\n        }\n    }\n    if (ast.isAbstractElement(parent)) {\n        return getActionAtElement(parent);\n    }\n    else {\n        return undefined;\n    }\n}\nexport function isOptionalCardinality(cardinality, element) {\n    return cardinality === '?' || cardinality === '*' || (ast.isGroup(element) && Boolean(element.guardCondition));\n}\nexport function isArrayCardinality(cardinality) {\n    return cardinality === '*' || cardinality === '+';\n}\nexport function isArrayOperator(operator) {\n    return operator === '+=';\n}\n/**\n * Determines whether the given parser rule is a _data type rule_, meaning that it has a\n * primitive return type like `number`, `boolean`, etc.\n */\nexport function isDataTypeRule(rule) {\n    return isDataTypeRuleInternal(rule, new Set());\n}\nfunction isDataTypeRuleInternal(rule, visited) {\n    if (visited.has(rule)) {\n        return true;\n    }\n    else {\n        visited.add(rule);\n    }\n    for (const node of streamAllContents(rule)) {\n        if (ast.isRuleCall(node)) {\n            if (!node.rule.ref) {\n                // RuleCall to unresolved rule. Don't assume `rule` is a DataType rule.\n                return false;\n            }\n            if (ast.isParserRule(node.rule.ref) && !isDataTypeRuleInternal(node.rule.ref, visited)) {\n                return false;\n            }\n            if (ast.isInfixRule(node.rule.ref)) {\n                return false;\n            }\n        }\n        else if (ast.isAssignment(node)) {\n            return false;\n        }\n        else if (ast.isAction(node)) {\n            return false;\n        }\n    }\n    return Boolean(rule.definition);\n}\nexport function isDataType(type) {\n    return isDataTypeInternal(type.type, new Set());\n}\nfunction isDataTypeInternal(type, visited) {\n    if (visited.has(type)) {\n        return true;\n    }\n    else {\n        visited.add(type);\n    }\n    if (ast.isArrayType(type)) {\n        return false;\n    }\n    else if (ast.isReferenceType(type)) {\n        return false;\n    }\n    else if (ast.isUnionType(type)) {\n        return type.types.every(e => isDataTypeInternal(e, visited));\n    }\n    else if (ast.isSimpleType(type)) {\n        if (type.primitiveType !== undefined) {\n            return true;\n        }\n        else if (type.stringType !== undefined) {\n            return true;\n        }\n        else if (type.typeRef !== undefined) {\n            const ref = type.typeRef.ref;\n            if (ast.isType(ref)) {\n                return isDataTypeInternal(ref.type, visited);\n            }\n            else {\n                return false;\n            }\n        }\n        else {\n            return false;\n        }\n    }\n    else {\n        return false;\n    }\n}\nexport function getExplicitRuleType(rule) {\n    if (ast.isTerminalRule(rule)) {\n        return undefined;\n    }\n    if (rule.inferredType) {\n        return rule.inferredType.name;\n    }\n    else if (rule.dataType) {\n        return rule.dataType;\n    }\n    else if (rule.returnType) {\n        const refType = rule.returnType.ref;\n        if (refType) {\n            return refType.name;\n        }\n    }\n    return undefined;\n}\nexport function getTypeName(type) {\n    if (ast.isAbstractParserRule(type)) {\n        return ast.isParserRule(type) && isDataTypeRule(type) ? type.name : getExplicitRuleType(type) ?? type.name;\n    }\n    else if (ast.isInterface(type) || ast.isType(type) || ast.isReturnType(type)) {\n        return type.name;\n    }\n    else if (ast.isAction(type)) {\n        const actionType = getActionType(type);\n        if (actionType) {\n            return actionType;\n        }\n    }\n    else if (ast.isInferredType(type)) {\n        return type.name;\n    }\n    throw new Error('Cannot get name of Unknown Type');\n}\nexport function getActionType(action) {\n    if (action.inferredType) {\n        return action.inferredType.name;\n    }\n    else if (action.type?.ref) {\n        return getTypeName(action.type.ref);\n    }\n    return undefined; // not inferring and not referencing a valid type\n}\n/**\n * This function is used at development time (for code generation and the internal type system) to get the type of the AST node produced by the given rule.\n * For data type rules, the name of the rule is returned,\n * e.g. \"INT_value returns number: MY_INT;\" returns \"INT_value\".\n * @param rule the given rule\n * @returns the name of the AST node type of the rule\n */\nexport function getRuleTypeName(rule) {\n    if (ast.isTerminalRule(rule)) {\n        return rule.type?.name ?? 'string';\n    }\n    else {\n        return ast.isParserRule(rule) && isDataTypeRule(rule) ? rule.name : getExplicitRuleType(rule) ?? rule.name;\n    }\n}\n/**\n * This function is used at runtime to get the actual type of the values produced by the given rule at runtime.\n * For data type rules, the name of the declared return type of the rule is returned (if any),\n * e.g. \"INT_value returns number: MY_INT;\" returns \"number\".\n * @param rule the given rule\n * @returns the name of the type of the produced values of the rule at runtime\n */\nexport function getRuleType(rule) {\n    if (ast.isTerminalRule(rule)) {\n        return rule.type?.name ?? 'string';\n    }\n    else {\n        return getExplicitRuleType(rule) ?? rule.name;\n    }\n}\nexport function terminalRegex(terminalRule) {\n    const flags = {\n        s: false,\n        i: false,\n        u: false\n    };\n    const source = abstractElementToRegex(terminalRule.definition, flags);\n    const flagText = Object.entries(flags).filter(([, value]) => value).map(([name]) => name).join('');\n    return new RegExp(source, flagText);\n}\n// Using [\\s\\S]* allows to match everything, compared to . which doesn't match line terminators\nconst WILDCARD = /[\\s\\S]/.source;\nfunction abstractElementToRegex(element, flags) {\n    if (ast.isTerminalAlternatives(element)) {\n        return terminalAlternativesToRegex(element);\n    }\n    else if (ast.isTerminalGroup(element)) {\n        return terminalGroupToRegex(element);\n    }\n    else if (ast.isCharacterRange(element)) {\n        return characterRangeToRegex(element);\n    }\n    else if (ast.isTerminalRuleCall(element)) {\n        const rule = element.rule.ref;\n        if (!rule) {\n            throw new Error('Missing rule reference.');\n        }\n        return withCardinality(abstractElementToRegex(rule.definition), {\n            cardinality: element.cardinality,\n            lookahead: element.lookahead,\n            parenthesized: element.parenthesized\n        });\n    }\n    else if (ast.isNegatedToken(element)) {\n        return negateTokenToRegex(element);\n    }\n    else if (ast.isUntilToken(element)) {\n        return untilTokenToRegex(element);\n    }\n    else if (ast.isRegexToken(element)) {\n        const lastSlash = element.regex.lastIndexOf('/');\n        const source = element.regex.substring(1, lastSlash);\n        const regexFlags = element.regex.substring(lastSlash + 1);\n        if (flags) {\n            flags.i = regexFlags.includes('i');\n            flags.s = regexFlags.includes('s');\n            flags.u = regexFlags.includes('u');\n        }\n        return withCardinality(source, {\n            cardinality: element.cardinality,\n            lookahead: element.lookahead,\n            parenthesized: element.parenthesized,\n            wrap: false\n        });\n    }\n    else if (ast.isWildcard(element)) {\n        return withCardinality(WILDCARD, {\n            cardinality: element.cardinality,\n            lookahead: element.lookahead,\n            parenthesized: element.parenthesized\n        });\n    }\n    else {\n        throw new Error(`Invalid terminal element: ${element?.$type}, ${element?.$cstNode?.text}`);\n    }\n}\nfunction terminalAlternativesToRegex(alternatives) {\n    return withCardinality(alternatives.elements.map(e => abstractElementToRegex(e)).join('|'), {\n        cardinality: alternatives.cardinality,\n        lookahead: alternatives.lookahead,\n        parenthesized: alternatives.parenthesized,\n        wrap: false // wrapping is not required for top level alternatives, and nested alternatives are already parenthesized according to the grammar\n    });\n}\nfunction terminalGroupToRegex(group) {\n    return withCardinality(group.elements.map(e => abstractElementToRegex(e)).join(''), {\n        cardinality: group.cardinality,\n        lookahead: group.lookahead,\n        parenthesized: group.parenthesized,\n        wrap: false // wrapping is not required for top level group, and nested group are already parenthesized according to the grammar\n    });\n}\nfunction untilTokenToRegex(until) {\n    return withCardinality(`${WILDCARD}*?${abstractElementToRegex(until.terminal)}`, {\n        cardinality: until.cardinality,\n        lookahead: until.lookahead,\n        parenthesized: until.parenthesized\n    });\n}\nfunction negateTokenToRegex(negate) {\n    return withCardinality(`(?!${abstractElementToRegex(negate.terminal)})${WILDCARD}*?`, {\n        cardinality: negate.cardinality,\n        lookahead: negate.lookahead,\n        parenthesized: negate.parenthesized\n    });\n}\nfunction characterRangeToRegex(range) {\n    if (range.right) {\n        return withCardinality(`[${keywordToRegex(range.left)}-${keywordToRegex(range.right)}]`, {\n            cardinality: range.cardinality,\n            lookahead: range.lookahead,\n            parenthesized: range.parenthesized,\n            wrap: false\n        });\n    }\n    return withCardinality(keywordToRegex(range.left), {\n        cardinality: range.cardinality,\n        lookahead: range.lookahead,\n        parenthesized: range.parenthesized,\n        wrap: false\n    });\n}\nfunction keywordToRegex(keyword) {\n    return escapeRegExp(keyword.value);\n}\nfunction withCardinality(regex, options) {\n    if (options.parenthesized || options.lookahead || options.wrap !== false) {\n        const groupConfig = options.lookahead ?? (options.parenthesized ? '' : '?:');\n        regex = `(${groupConfig}${regex})`;\n    }\n    if (options.cardinality) {\n        return `${regex}${options.cardinality}`;\n    }\n    return regex;\n}\n//# sourceMappingURL=grammar-utils.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { RegExpParser, BaseRegExpVisitor } from '@chevrotain/regexp-to-ast';\nexport const NEWLINE_REGEXP = /\\r?\\n/gm;\nconst regexpParser = new RegExpParser();\n/**\n * This class is in charge of heuristically identifying start/end tokens of terminals.\n *\n * The way this works is by doing the following:\n * 1. Traverse the regular expression in the \"start state\"\n * 2. Add any encountered sets/single characters to the \"start regexp\"\n * 3. Once we encounter any variable-length content (i.e. with quantifiers such as +/?/*), we enter the \"end state\"\n * 4. In the end state, any sets/single characters are added to an \"end stack\".\n * 5. If we re-encounter any variable-length content we reset the end stack\n * 6. We continue visiting the regex until the end, reseting the end stack and rebuilding it as necessary\n *\n * After traversing a regular expression the `startRegexp/endRegexp` properties allow access to the stored start/end of the terminal\n */\nclass TerminalRegExpVisitor extends BaseRegExpVisitor {\n    constructor() {\n        super(...arguments);\n        this.isStarting = true;\n        this.endRegexpStack = [];\n        this.multiline = false;\n    }\n    get endRegex() {\n        return this.endRegexpStack.join('');\n    }\n    reset(regex) {\n        this.multiline = false;\n        this.regex = regex;\n        this.startRegexp = '';\n        this.isStarting = true;\n        this.endRegexpStack = [];\n    }\n    visitGroup(node) {\n        if (node.quantifier) {\n            this.isStarting = false;\n            this.endRegexpStack = [];\n        }\n    }\n    visitCharacter(node) {\n        const char = String.fromCharCode(node.value);\n        if (!this.multiline && char === '\\n') {\n            this.multiline = true;\n        }\n        if (node.quantifier) {\n            this.isStarting = false;\n            this.endRegexpStack = [];\n        }\n        else {\n            const escapedChar = escapeRegExp(char);\n            this.endRegexpStack.push(escapedChar);\n            if (this.isStarting) {\n                this.startRegexp += escapedChar;\n            }\n        }\n    }\n    visitSet(node) {\n        if (!this.multiline) {\n            const set = this.regex.substring(node.loc.begin, node.loc.end);\n            const regex = new RegExp(set);\n            this.multiline = Boolean('\\n'.match(regex));\n        }\n        if (node.quantifier) {\n            this.isStarting = false;\n            this.endRegexpStack = [];\n        }\n        else {\n            const set = this.regex.substring(node.loc.begin, node.loc.end);\n            this.endRegexpStack.push(set);\n            if (this.isStarting) {\n                this.startRegexp += set;\n            }\n        }\n    }\n    visitChildren(node) {\n        if (node.type === 'Group') {\n            // Ignore children of groups with quantifier (+/*/?)\n            // These groups are unrelated to start/end tokens of terminals\n            const group = node;\n            if (group.quantifier) {\n                return;\n            }\n        }\n        super.visitChildren(node);\n    }\n}\nconst visitor = new TerminalRegExpVisitor();\nexport function getTerminalParts(regexp) {\n    try {\n        if (typeof regexp !== 'string') {\n            regexp = regexp.source;\n        }\n        regexp = `/${regexp}/`;\n        const pattern = regexpParser.pattern(regexp);\n        const parts = [];\n        for (const alternative of pattern.value.value) {\n            visitor.reset(regexp);\n            visitor.visit(alternative);\n            parts.push({\n                start: visitor.startRegexp,\n                end: visitor.endRegex\n            });\n        }\n        return parts;\n    }\n    catch {\n        return [];\n    }\n}\nexport function isMultilineComment(regexp) {\n    try {\n        if (typeof regexp === 'string') {\n            regexp = new RegExp(regexp);\n        }\n        regexp = regexp.toString();\n        visitor.reset(regexp);\n        // Parsing the pattern might fail (since it's user code)\n        visitor.visit(regexpParser.pattern(regexp));\n        return visitor.multiline;\n    }\n    catch {\n        return false;\n    }\n}\n/**\n * A set of all characters that are considered whitespace by the '\\s' RegExp character class.\n * Taken from [MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_expressions/Character_classes).\n */\nexport const whitespaceCharacters = ('\\f\\n\\r\\t\\v\\u0020\\u00a0\\u1680\\u2000\\u2001\\u2002\\u2003\\u2004\\u2005\\u2006\\u2007' +\n    '\\u2008\\u2009\\u200a\\u2028\\u2029\\u202f\\u205f\\u3000\\ufeff').split('');\nexport function isWhitespace(value) {\n    const regexp = typeof value === 'string' ? new RegExp(value) : value;\n    return whitespaceCharacters.some((ws) => regexp.test(ws));\n}\nexport function escapeRegExp(value) {\n    return value.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&');\n}\n/**\n * Determines whether the given input has a partial match with the specified regex.\n * @param regex The regex to partially match against\n * @param input The input string\n * @returns Whether any match exists.\n */\nexport function partialMatches(regex, input) {\n    const partial = partialRegExp(regex);\n    const match = input.match(partial);\n    return !!match && match[0].length > 0;\n}\n/**\n * Builds a partial regex from the input regex. A partial regex is able to match incomplete input strings. E.g.\n * a partial regex constructed from `/ab/` is able to match the string `a` without needing a following `b` character. However it won't match `b` alone.\n * @param regex The input regex to be converted.\n * @returns A partial regex constructed from the input regex.\n */\nexport function partialRegExp(regex) {\n    if (typeof regex === 'string') {\n        regex = new RegExp(regex);\n    }\n    const re = regex, source = regex.source;\n    let i = 0;\n    function process() {\n        let result = '', tmp;\n        function appendRaw(nbChars) {\n            result += source.substr(i, nbChars);\n            i += nbChars;\n        }\n        function appendOptional(nbChars) {\n            result += '(?:' + source.substr(i, nbChars) + '|$)';\n            i += nbChars;\n        }\n        while (i < source.length) {\n            switch (source[i]) {\n                case '\\\\':\n                    switch (source[i + 1]) {\n                        case 'c':\n                            appendOptional(3);\n                            break;\n                        case 'x':\n                            appendOptional(4);\n                            break;\n                        case 'u':\n                            if (re.unicode) {\n                                if (source[i + 2] === '{') {\n                                    appendOptional(source.indexOf('}', i) - i + 1);\n                                }\n                                else {\n                                    appendOptional(6);\n                                }\n                            }\n                            else {\n                                appendOptional(2);\n                            }\n                            break;\n                        case 'p':\n                        case 'P':\n                            if (re.unicode) {\n                                appendOptional(source.indexOf('}', i) - i + 1);\n                            }\n                            else {\n                                appendOptional(2);\n                            }\n                            break;\n                        case 'k':\n                            appendOptional(source.indexOf('>', i) - i + 1);\n                            break;\n                        default:\n                            appendOptional(2);\n                            break;\n                    }\n                    break;\n                case '[':\n                    tmp = /\\[(?:\\\\.|.)*?\\]/g;\n                    tmp.lastIndex = i;\n                    tmp = tmp.exec(source) || [];\n                    appendOptional(tmp[0].length);\n                    break;\n                case '|':\n                case '^':\n                case '$':\n                case '*':\n                case '+':\n                case '?':\n                    appendRaw(1);\n                    break;\n                case '{':\n                    tmp = /\\{\\d+,?\\d*\\}/g;\n                    tmp.lastIndex = i;\n                    tmp = tmp.exec(source);\n                    if (tmp) {\n                        appendRaw(tmp[0].length);\n                    }\n                    else {\n                        appendOptional(1);\n                    }\n                    break;\n                case '(':\n                    if (source[i + 1] === '?') {\n                        switch (source[i + 2]) {\n                            case ':':\n                                result += '(?:';\n                                i += 3;\n                                result += process() + '|$)';\n                                break;\n                            case '=':\n                                result += '(?=';\n                                i += 3;\n                                result += process() + ')';\n                                break;\n                            case '!':\n                                tmp = i;\n                                i += 3;\n                                process();\n                                result += source.substr(tmp, i - tmp);\n                                break;\n                            case '<':\n                                switch (source[i + 3]) {\n                                    case '=':\n                                    case '!':\n                                        tmp = i;\n                                        i += 4;\n                                        process();\n                                        result += source.substr(tmp, i - tmp);\n                                        break;\n                                    default:\n                                        appendRaw(source.indexOf('>', i) - i + 1);\n                                        result += process() + '|$)';\n                                        break;\n                                }\n                                break;\n                        }\n                    }\n                    else {\n                        appendRaw(1);\n                        result += process() + '|$)';\n                    }\n                    break;\n                case ')':\n                    ++i;\n                    return result;\n                default:\n                    appendOptional(1);\n                    break;\n            }\n        }\n        return result;\n    }\n    return new RegExp(process(), regex.flags);\n}\n//# sourceMappingURL=regexp-utils.js.map","/******************************************************************************\n * Copyright 2021 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\n/**\n * The default implementation of `Stream` works with two input functions:\n *  - The first function creates the initial state of an iteration.\n *  - The second function gets the current state as argument and returns an `IteratorResult`.\n */\nexport class StreamImpl {\n    constructor(startFn, nextFn) {\n        this.startFn = startFn;\n        this.nextFn = nextFn;\n    }\n    iterator() {\n        const iterator = {\n            state: this.startFn(),\n            next: () => this.nextFn(iterator.state),\n            [Symbol.iterator]: () => iterator\n        };\n        return iterator;\n    }\n    [Symbol.iterator]() {\n        return this.iterator();\n    }\n    isEmpty() {\n        const iterator = this.iterator();\n        return Boolean(iterator.next().done);\n    }\n    count() {\n        const iterator = this.iterator();\n        let count = 0;\n        let next = iterator.next();\n        while (!next.done) {\n            count++;\n            next = iterator.next();\n        }\n        return count;\n    }\n    toArray() {\n        const result = [];\n        const iterator = this.iterator();\n        let next;\n        do {\n            next = iterator.next();\n            if (next.value !== undefined) {\n                result.push(next.value);\n            }\n        } while (!next.done);\n        return result;\n    }\n    toSet() {\n        return new Set(this);\n    }\n    toMap(keyFn, valueFn) {\n        const entryStream = this.map(element => [\n            keyFn ? keyFn(element) : element,\n            valueFn ? valueFn(element) : element\n        ]);\n        return new Map(entryStream);\n    }\n    toString() {\n        return this.join();\n    }\n    concat(other) {\n        return new StreamImpl(() => ({ first: this.startFn(), firstDone: false, iterator: other[Symbol.iterator]() }), state => {\n            let result;\n            if (!state.firstDone) {\n                do {\n                    result = this.nextFn(state.first);\n                    if (!result.done) {\n                        return result;\n                    }\n                } while (!result.done);\n                state.firstDone = true;\n            }\n            do {\n                result = state.iterator.next();\n                if (!result.done) {\n                    return result;\n                }\n            } while (!result.done);\n            return DONE_RESULT;\n        });\n    }\n    join(separator = ',') {\n        const iterator = this.iterator();\n        let value = '';\n        let result;\n        let addSeparator = false;\n        do {\n            result = iterator.next();\n            if (!result.done) {\n                if (addSeparator) {\n                    value += separator;\n                }\n                value += toString(result.value);\n            }\n            addSeparator = true;\n        } while (!result.done);\n        return value;\n    }\n    indexOf(searchElement, fromIndex = 0) {\n        const iterator = this.iterator();\n        let index = 0;\n        let next = iterator.next();\n        while (!next.done) {\n            if (index >= fromIndex && next.value === searchElement) {\n                return index;\n            }\n            next = iterator.next();\n            index++;\n        }\n        return -1;\n    }\n    every(predicate) {\n        const iterator = this.iterator();\n        let next = iterator.next();\n        while (!next.done) {\n            if (!predicate(next.value)) {\n                return false;\n            }\n            next = iterator.next();\n        }\n        return true;\n    }\n    some(predicate) {\n        const iterator = this.iterator();\n        let next = iterator.next();\n        while (!next.done) {\n            if (predicate(next.value)) {\n                return true;\n            }\n            next = iterator.next();\n        }\n        return false;\n    }\n    forEach(callbackfn) {\n        const iterator = this.iterator();\n        let index = 0;\n        let next = iterator.next();\n        while (!next.done) {\n            callbackfn(next.value, index);\n            next = iterator.next();\n            index++;\n        }\n    }\n    map(callbackfn) {\n        return new StreamImpl(this.startFn, (state) => {\n            const { done, value } = this.nextFn(state);\n            if (done) {\n                return DONE_RESULT;\n            }\n            else {\n                return { done: false, value: callbackfn(value) };\n            }\n        });\n    }\n    filter(predicate) {\n        return new StreamImpl(this.startFn, state => {\n            let result;\n            do {\n                result = this.nextFn(state);\n                if (!result.done && predicate(result.value)) {\n                    return result;\n                }\n            } while (!result.done);\n            return DONE_RESULT;\n        });\n    }\n    nonNullable() {\n        return this.filter(e => e !== undefined && e !== null);\n    }\n    reduce(callbackfn, initialValue) {\n        const iterator = this.iterator();\n        let previousValue = initialValue;\n        let next = iterator.next();\n        while (!next.done) {\n            if (previousValue === undefined) {\n                previousValue = next.value;\n            }\n            else {\n                previousValue = callbackfn(previousValue, next.value);\n            }\n            next = iterator.next();\n        }\n        return previousValue;\n    }\n    reduceRight(callbackfn, initialValue) {\n        return this.recursiveReduce(this.iterator(), callbackfn, initialValue);\n    }\n    recursiveReduce(iterator, callbackfn, initialValue) {\n        const next = iterator.next();\n        if (next.done) {\n            return initialValue;\n        }\n        const previousValue = this.recursiveReduce(iterator, callbackfn, initialValue);\n        if (previousValue === undefined) {\n            return next.value;\n        }\n        return callbackfn(previousValue, next.value);\n    }\n    find(predicate) {\n        const iterator = this.iterator();\n        let next = iterator.next();\n        while (!next.done) {\n            if (predicate(next.value)) {\n                return next.value;\n            }\n            next = iterator.next();\n        }\n        return undefined;\n    }\n    findIndex(predicate) {\n        const iterator = this.iterator();\n        let index = 0;\n        let next = iterator.next();\n        while (!next.done) {\n            if (predicate(next.value)) {\n                return index;\n            }\n            next = iterator.next();\n            index++;\n        }\n        return -1;\n    }\n    includes(searchElement) {\n        const iterator = this.iterator();\n        let next = iterator.next();\n        while (!next.done) {\n            if (next.value === searchElement) {\n                return true;\n            }\n            next = iterator.next();\n        }\n        return false;\n    }\n    flatMap(callbackfn) {\n        return new StreamImpl(() => ({ this: this.startFn() }), (state) => {\n            do {\n                if (state.iterator) {\n                    const next = state.iterator.next();\n                    if (next.done) {\n                        state.iterator = undefined;\n                    }\n                    else {\n                        return next;\n                    }\n                }\n                const { done, value } = this.nextFn(state.this);\n                if (!done) {\n                    const mapped = callbackfn(value);\n                    if (isIterable(mapped)) {\n                        state.iterator = mapped[Symbol.iterator]();\n                    }\n                    else {\n                        return { done: false, value: mapped };\n                    }\n                }\n            } while (state.iterator);\n            return DONE_RESULT;\n        });\n    }\n    flat(depth) {\n        if (depth === undefined) {\n            depth = 1;\n        }\n        if (depth <= 0) {\n            return this;\n        }\n        const stream = depth > 1 ? this.flat(depth - 1) : this;\n        return new StreamImpl(() => ({ this: stream.startFn() }), (state) => {\n            do {\n                if (state.iterator) {\n                    const next = state.iterator.next();\n                    if (next.done) {\n                        state.iterator = undefined;\n                    }\n                    else {\n                        return next;\n                    }\n                }\n                const { done, value } = stream.nextFn(state.this);\n                if (!done) {\n                    if (isIterable(value)) {\n                        state.iterator = value[Symbol.iterator]();\n                    }\n                    else {\n                        return { done: false, value: value };\n                    }\n                }\n            } while (state.iterator);\n            return DONE_RESULT;\n        });\n    }\n    head() {\n        const iterator = this.iterator();\n        const result = iterator.next();\n        if (result.done) {\n            return undefined;\n        }\n        return result.value;\n    }\n    tail(skipCount = 1) {\n        return new StreamImpl(() => {\n            const state = this.startFn();\n            for (let i = 0; i < skipCount; i++) {\n                const next = this.nextFn(state);\n                if (next.done) {\n                    return state;\n                }\n            }\n            return state;\n        }, this.nextFn);\n    }\n    limit(maxSize) {\n        return new StreamImpl(() => ({ size: 0, state: this.startFn() }), state => {\n            state.size++;\n            if (state.size > maxSize) {\n                return DONE_RESULT;\n            }\n            return this.nextFn(state.state);\n        });\n    }\n    distinct(by) {\n        return new StreamImpl(() => ({ set: new Set(), internalState: this.startFn() }), state => {\n            let result;\n            do {\n                result = this.nextFn(state.internalState);\n                if (!result.done) {\n                    const value = by ? by(result.value) : result.value;\n                    if (!state.set.has(value)) {\n                        state.set.add(value);\n                        return result;\n                    }\n                }\n            } while (!result.done);\n            return DONE_RESULT;\n        });\n    }\n    exclude(other, key) {\n        const otherKeySet = new Set();\n        for (const item of other) {\n            const value = key ? key(item) : item;\n            otherKeySet.add(value);\n        }\n        return this.filter(e => {\n            const ownKey = key ? key(e) : e;\n            return !otherKeySet.has(ownKey);\n        });\n    }\n}\nfunction toString(item) {\n    if (typeof item === 'string') {\n        return item;\n    }\n    if (typeof item === 'undefined') {\n        return 'undefined';\n    }\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    if (typeof item.toString === 'function') {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        return item.toString();\n    }\n    return Object.prototype.toString.call(item);\n}\nfunction isIterable(obj) {\n    return !!obj && typeof obj[Symbol.iterator] === 'function';\n}\n/**\n * An empty stream of any type.\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nexport const EMPTY_STREAM = new StreamImpl(() => undefined, () => DONE_RESULT);\n/**\n * Use this `IteratorResult` when implementing a `StreamImpl` to indicate that there are no more elements in the stream.\n */\nexport const DONE_RESULT = Object.freeze({ done: true, value: undefined });\n/**\n * Create a stream from one or more iterables or array-likes.\n */\nexport function stream(...collections) {\n    if (collections.length === 1) {\n        const collection = collections[0];\n        if (collection instanceof StreamImpl) {\n            return collection;\n        }\n        if (isIterable(collection)) {\n            return new StreamImpl(() => collection[Symbol.iterator](), (iterator) => iterator.next());\n        }\n        if (typeof collection.length === 'number') {\n            return new StreamImpl(() => ({ index: 0 }), (state) => {\n                if (state.index < collection.length) {\n                    return { done: false, value: collection[state.index++] };\n                }\n                else {\n                    return DONE_RESULT;\n                }\n            });\n        }\n    }\n    if (collections.length > 1) {\n        return new StreamImpl(() => ({ collIndex: 0, arrIndex: 0 }), (state) => {\n            do {\n                if (state.iterator) {\n                    const next = state.iterator.next();\n                    if (!next.done) {\n                        return next;\n                    }\n                    state.iterator = undefined;\n                }\n                if (state.array) {\n                    if (state.arrIndex < state.array.length) {\n                        return { done: false, value: state.array[state.arrIndex++] };\n                    }\n                    state.array = undefined;\n                    state.arrIndex = 0;\n                }\n                if (state.collIndex < collections.length) {\n                    const collection = collections[state.collIndex++];\n                    if (isIterable(collection)) {\n                        state.iterator = collection[Symbol.iterator]();\n                    }\n                    else if (collection && typeof collection.length === 'number') {\n                        state.array = collection;\n                    }\n                }\n            } while (state.iterator || state.array || state.collIndex < collections.length);\n            return DONE_RESULT;\n        });\n    }\n    return EMPTY_STREAM;\n}\n/**\n * The default implementation of `TreeStream` takes a root element and a function that computes the\n * children of its argument. Whether the root node included in the stream is controlled with the\n * `includeRoot` option, which defaults to `false`.\n */\nexport class TreeStreamImpl extends StreamImpl {\n    constructor(root, children, options) {\n        super(() => ({\n            iterators: options?.includeRoot ? [[root][Symbol.iterator]()] : [children(root)[Symbol.iterator]()],\n            pruned: false\n        }), state => {\n            if (state.pruned) {\n                state.iterators.pop();\n                state.pruned = false;\n            }\n            while (state.iterators.length > 0) {\n                const iterator = state.iterators[state.iterators.length - 1];\n                const next = iterator.next();\n                if (next.done) {\n                    state.iterators.pop();\n                }\n                else {\n                    state.iterators.push(children(next.value)[Symbol.iterator]());\n                    return next;\n                }\n            }\n            return DONE_RESULT;\n        });\n    }\n    iterator() {\n        const iterator = {\n            state: this.startFn(),\n            next: () => this.nextFn(iterator.state),\n            prune: () => {\n                iterator.state.pruned = true;\n            },\n            [Symbol.iterator]: () => iterator\n        };\n        return iterator;\n    }\n}\n/**\n * A set of utility functions that reduce a stream to a single value.\n */\nexport var Reduction;\n(function (Reduction) {\n    /**\n     * Compute the sum of a number stream.\n     */\n    function sum(stream) {\n        return stream.reduce((a, b) => a + b, 0);\n    }\n    Reduction.sum = sum;\n    /**\n     * Compute the product of a number stream.\n     */\n    function product(stream) {\n        return stream.reduce((a, b) => a * b, 0);\n    }\n    Reduction.product = product;\n    /**\n     * Compute the minimum of a number stream. Returns `undefined` if the stream is empty.\n     */\n    function min(stream) {\n        return stream.reduce((a, b) => Math.min(a, b));\n    }\n    Reduction.min = min;\n    /**\n     * Compute the maximum of a number stream. Returns `undefined` if the stream is empty.\n     */\n    function max(stream) {\n        return stream.reduce((a, b) => Math.max(a, b));\n    }\n    Reduction.max = max;\n})(Reduction || (Reduction = {}));\n//# sourceMappingURL=stream.js.map","/******************************************************************************\n * Copyright 2022 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nexport class EmptyFileSystemProvider {\n    stat(_uri) {\n        throw new Error('No file system is available.');\n    }\n    statSync(_uri) {\n        throw new Error('No file system is available.');\n    }\n    async exists() {\n        return false;\n    }\n    existsSync() {\n        return false;\n    }\n    readBinary() {\n        throw new Error('No file system is available.');\n    }\n    readBinarySync() {\n        throw new Error('No file system is available.');\n    }\n    readFile() {\n        throw new Error('No file system is available.');\n    }\n    readFileSync() {\n        throw new Error('No file system is available.');\n    }\n    async readDirectory() {\n        return [];\n    }\n    readDirectorySync() {\n        return [];\n    }\n}\nexport const EmptyFileSystem = {\n    fileSystemProvider: () => new EmptyFileSystemProvider()\n};\n//# sourceMappingURL=file-system-provider.js.map","import isSymbol from './isSymbol.js';\n\n/**\n * The base implementation of methods like `_.max` and `_.min` which accepts a\n * `comparator` to determine the extremum value.\n *\n * @private\n * @param {Array} array The array to iterate over.\n * @param {Function} iteratee The iteratee invoked per iteration.\n * @param {Function} comparator The comparator used to compare values.\n * @returns {*} Returns the extremum value.\n */\nfunction baseExtremum(array, iteratee, comparator) {\n  var index = -1,\n      length = array.length;\n\n  while (++index < length) {\n    var value = array[index],\n        current = iteratee(value);\n\n    if (current != null && (computed === undefined\n          ? (current === current && !isSymbol(current))\n          : comparator(current, computed)\n        )) {\n      var computed = current,\n          result = value;\n    }\n  }\n  return result;\n}\n\nexport default baseExtremum;\n","/**\n * The base implementation of `_.lt` which doesn't coerce arguments.\n *\n * @private\n * @param {*} value The value to compare.\n * @param {*} other The other value to compare.\n * @returns {boolean} Returns `true` if `value` is less than `other`,\n *  else `false`.\n */\nfunction baseLt(value, other) {\n  return value < other;\n}\n\nexport default baseLt;\n","import baseEach from './_baseEach.js';\nimport isArrayLike from './isArrayLike.js';\n\n/**\n * The base implementation of `_.map` without support for iteratee shorthands.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns the new mapped array.\n */\nfunction baseMap(collection, iteratee) {\n  var index = -1,\n      result = isArrayLike(collection) ? Array(collection.length) : [];\n\n  baseEach(collection, function(value, key, collection) {\n    result[++index] = iteratee(value, key, collection);\n  });\n  return result;\n}\n\nexport default baseMap;\n","import assignValue from './_assignValue.js';\nimport castPath from './_castPath.js';\nimport isIndex from './_isIndex.js';\nimport isObject from './isObject.js';\nimport toKey from './_toKey.js';\n\n/**\n * The base implementation of `_.set`.\n *\n * @private\n * @param {Object} object The object to modify.\n * @param {Array|string} path The path of the property to set.\n * @param {*} value The value to set.\n * @param {Function} [customizer] The function to customize path creation.\n * @returns {Object} Returns `object`.\n */\nfunction baseSet(object, path, value, customizer) {\n  if (!isObject(object)) {\n    return object;\n  }\n  path = castPath(path, object);\n\n  var index = -1,\n      length = path.length,\n      lastIndex = length - 1,\n      nested = object;\n\n  while (nested != null && ++index < length) {\n    var key = toKey(path[index]),\n        newValue = value;\n\n    if (key === '__proto__' || key === 'constructor' || key === 'prototype') {\n      return object;\n    }\n\n    if (index != lastIndex) {\n      var objValue = nested[key];\n      newValue = customizer ? customizer(objValue, key, nested) : undefined;\n      if (newValue === undefined) {\n        newValue = isObject(objValue)\n          ? objValue\n          : (isIndex(path[index + 1]) ? [] : {});\n      }\n    }\n    assignValue(nested, key, newValue);\n    nested = nested[key];\n  }\n  return object;\n}\n\nexport default baseSet;\n","import baseGet from './_baseGet.js';\nimport baseSet from './_baseSet.js';\nimport castPath from './_castPath.js';\n\n/**\n * The base implementation of  `_.pickBy` without support for iteratee shorthands.\n *\n * @private\n * @param {Object} object The source object.\n * @param {string[]} paths The property paths to pick.\n * @param {Function} predicate The function invoked per property.\n * @returns {Object} Returns the new object.\n */\nfunction basePickBy(object, paths, predicate) {\n  var index = -1,\n      length = paths.length,\n      result = {};\n\n  while (++index < length) {\n    var path = paths[index],\n        value = baseGet(object, path);\n\n    if (predicate(value, path)) {\n      baseSet(result, castPath(path, object), value);\n    }\n  }\n  return result;\n}\n\nexport default basePickBy;\n","import baseClone from './_baseClone.js';\n\n/** Used to compose bitmasks for cloning. */\nvar CLONE_SYMBOLS_FLAG = 4;\n\n/**\n * Creates a shallow clone of `value`.\n *\n * **Note:** This method is loosely based on the\n * [structured clone algorithm](https://mdn.io/Structured_clone_algorithm)\n * and supports cloning arrays, array buffers, booleans, date objects, maps,\n * numbers, `Object` objects, regexes, sets, strings, symbols, and typed\n * arrays. The own enumerable properties of `arguments` objects are cloned\n * as plain objects. An empty object is returned for uncloneable values such\n * as error objects, functions, DOM nodes, and WeakMaps.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to clone.\n * @returns {*} Returns the cloned value.\n * @see _.cloneDeep\n * @example\n *\n * var objects = [{ 'a': 1 }, { 'b': 2 }];\n *\n * var shallow = _.clone(objects);\n * console.log(shallow[0] === objects[0]);\n * // => true\n */\nfunction clone(value) {\n  return baseClone(value, CLONE_SYMBOLS_FLAG);\n}\n\nexport default clone;\n","import baseRest from './_baseRest.js';\nimport eq from './eq.js';\nimport isIterateeCall from './_isIterateeCall.js';\nimport keysIn from './keysIn.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Assigns own and inherited enumerable string keyed properties of source\n * objects to the destination object for all destination properties that\n * resolve to `undefined`. Source objects are applied from left to right.\n * Once a property is set, additional values of the same property are ignored.\n *\n * **Note:** This method mutates `object`.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The destination object.\n * @param {...Object} [sources] The source objects.\n * @returns {Object} Returns `object`.\n * @see _.defaultsDeep\n * @example\n *\n * _.defaults({ 'a': 1 }, { 'b': 2 }, { 'a': 3 });\n * // => { 'a': 1, 'b': 2 }\n */\nvar defaults = baseRest(function(object, sources) {\n  object = Object(object);\n\n  var index = -1;\n  var length = sources.length;\n  var guard = length > 2 ? sources[2] : undefined;\n\n  if (guard && isIterateeCall(sources[0], sources[1], guard)) {\n    length = 1;\n  }\n\n  while (++index < length) {\n    var source = sources[index];\n    var props = keysIn(source);\n    var propsIndex = -1;\n    var propsLength = props.length;\n\n    while (++propsIndex < propsLength) {\n      var key = props[propsIndex];\n      var value = object[key];\n\n      if (value === undefined ||\n          (eq(value, objectProto[key]) && !hasOwnProperty.call(object, key))) {\n        object[key] = source[key];\n      }\n    }\n  }\n\n  return object;\n});\n\nexport default defaults;\n","import baseIteratee from './_baseIteratee.js';\nimport isArrayLike from './isArrayLike.js';\nimport keys from './keys.js';\n\n/**\n * Creates a `_.find` or `_.findLast` function.\n *\n * @private\n * @param {Function} findIndexFunc The function to find the collection index.\n * @returns {Function} Returns the new find function.\n */\nfunction createFind(findIndexFunc) {\n  return function(collection, predicate, fromIndex) {\n    var iterable = Object(collection);\n    if (!isArrayLike(collection)) {\n      var iteratee = baseIteratee(predicate, 3);\n      collection = keys(collection);\n      predicate = function(key) { return iteratee(iterable[key], key, iterable); };\n    }\n    var index = findIndexFunc(collection, predicate, fromIndex);\n    return index > -1 ? iterable[iteratee ? collection[index] : index] : undefined;\n  };\n}\n\nexport default createFind;\n","import baseFindIndex from './_baseFindIndex.js';\nimport baseIteratee from './_baseIteratee.js';\nimport toInteger from './toInteger.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * This method is like `_.find` except that it returns the index of the first\n * element `predicate` returns truthy for instead of the element itself.\n *\n * @static\n * @memberOf _\n * @since 1.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param {number} [fromIndex=0] The index to search from.\n * @returns {number} Returns the index of the found element, else `-1`.\n * @example\n *\n * var users = [\n *   { 'user': 'barney',  'active': false },\n *   { 'user': 'fred',    'active': false },\n *   { 'user': 'pebbles', 'active': true }\n * ];\n *\n * _.findIndex(users, function(o) { return o.user == 'barney'; });\n * // => 0\n *\n * // The `_.matches` iteratee shorthand.\n * _.findIndex(users, { 'user': 'fred', 'active': false });\n * // => 1\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.findIndex(users, ['active', false]);\n * // => 0\n *\n * // The `_.property` iteratee shorthand.\n * _.findIndex(users, 'active');\n * // => 2\n */\nfunction findIndex(array, predicate, fromIndex) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return -1;\n  }\n  var index = fromIndex == null ? 0 : toInteger(fromIndex);\n  if (index < 0) {\n    index = nativeMax(length + index, 0);\n  }\n  return baseFindIndex(array, baseIteratee(predicate, 3), index);\n}\n\nexport default findIndex;\n","import createFind from './_createFind.js';\nimport findIndex from './findIndex.js';\n\n/**\n * Iterates over elements of `collection`, returning the first element\n * `predicate` returns truthy for. The predicate is invoked with three\n * arguments: (value, index|key, collection).\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to inspect.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param {number} [fromIndex=0] The index to search from.\n * @returns {*} Returns the matched element, else `undefined`.\n * @example\n *\n * var users = [\n *   { 'user': 'barney',  'age': 36, 'active': true },\n *   { 'user': 'fred',    'age': 40, 'active': false },\n *   { 'user': 'pebbles', 'age': 1,  'active': true }\n * ];\n *\n * _.find(users, function(o) { return o.age < 40; });\n * // => object for 'barney'\n *\n * // The `_.matches` iteratee shorthand.\n * _.find(users, { 'age': 1, 'active': true });\n * // => object for 'pebbles'\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.find(users, ['active', false]);\n * // => object for 'fred'\n *\n * // The `_.property` iteratee shorthand.\n * _.find(users, 'active');\n * // => object for 'barney'\n */\nvar find = createFind(findIndex);\n\nexport default find;\n","import baseFlatten from './_baseFlatten.js';\nimport map from './map.js';\n\n/**\n * Creates a flattened array of values by running each element in `collection`\n * thru `iteratee` and flattening the mapped results. The iteratee is invoked\n * with three arguments: (value, index|key, collection).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The function invoked per iteration.\n * @returns {Array} Returns the new flattened array.\n * @example\n *\n * function duplicate(n) {\n *   return [n, n];\n * }\n *\n * _.flatMap([1, 2], duplicate);\n * // => [1, 1, 2, 2]\n */\nfunction flatMap(collection, iteratee) {\n  return baseFlatten(map(collection, iteratee), 1);\n}\n\nexport default flatMap;\n","import baseFlatten from './_baseFlatten.js';\n\n/**\n * Flattens `array` a single level deep.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to flatten.\n * @returns {Array} Returns the new flattened array.\n * @example\n *\n * _.flatten([1, [2, [3, [4]], 5]]);\n * // => [1, 2, [3, [4]], 5]\n */\nfunction flatten(array) {\n  var length = array == null ? 0 : array.length;\n  return length ? baseFlatten(array, 1) : [];\n}\n\nexport default flatten;\n","/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * The base implementation of `_.has` without support for deep paths.\n *\n * @private\n * @param {Object} [object] The object to query.\n * @param {Array|string} key The key to check.\n * @returns {boolean} Returns `true` if `key` exists, else `false`.\n */\nfunction baseHas(object, key) {\n  return object != null && hasOwnProperty.call(object, key);\n}\n\nexport default baseHas;\n","import baseHas from './_baseHas.js';\nimport hasPath from './_hasPath.js';\n\n/**\n * Checks if `path` is a direct property of `object`.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The object to query.\n * @param {Array|string} path The path to check.\n * @returns {boolean} Returns `true` if `path` exists, else `false`.\n * @example\n *\n * var object = { 'a': { 'b': 2 } };\n * var other = _.create({ 'a': _.create({ 'b': 2 }) });\n *\n * _.has(object, 'a');\n * // => true\n *\n * _.has(object, 'a.b');\n * // => true\n *\n * _.has(object, ['a', 'b']);\n * // => true\n *\n * _.has(other, 'a');\n * // => false\n */\nfunction has(object, path) {\n  return object != null && hasPath(object, path, baseHas);\n}\n\nexport default has;\n","import baseGetTag from './_baseGetTag.js';\nimport isArray from './isArray.js';\nimport isObjectLike from './isObjectLike.js';\n\n/** `Object#toString` result references. */\nvar stringTag = '[object String]';\n\n/**\n * Checks if `value` is classified as a `String` primitive or object.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a string, else `false`.\n * @example\n *\n * _.isString('abc');\n * // => true\n *\n * _.isString(1);\n * // => false\n */\nfunction isString(value) {\n  return typeof value == 'string' ||\n    (!isArray(value) && isObjectLike(value) && baseGetTag(value) == stringTag);\n}\n\nexport default isString;\n","/**\n * Gets the last element of `array`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to query.\n * @returns {*} Returns the last element of `array`.\n * @example\n *\n * _.last([1, 2, 3]);\n * // => 3\n */\nfunction last(array) {\n  var length = array == null ? 0 : array.length;\n  return length ? array[length - 1] : undefined;\n}\n\nexport default last;\n","import arrayMap from './_arrayMap.js';\nimport baseIteratee from './_baseIteratee.js';\nimport baseMap from './_baseMap.js';\nimport isArray from './isArray.js';\n\n/**\n * Creates an array of values by running each element in `collection` thru\n * `iteratee`. The iteratee is invoked with three arguments:\n * (value, index|key, collection).\n *\n * Many lodash methods are guarded to work as iteratees for methods like\n * `_.every`, `_.filter`, `_.map`, `_.mapValues`, `_.reject`, and `_.some`.\n *\n * The guarded methods are:\n * `ary`, `chunk`, `curry`, `curryRight`, `drop`, `dropRight`, `every`,\n * `fill`, `invert`, `parseInt`, `random`, `range`, `rangeRight`, `repeat`,\n * `sampleSize`, `slice`, `some`, `sortBy`, `split`, `take`, `takeRight`,\n * `template`, `trim`, `trimEnd`, `trimStart`, and `words`\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The function invoked per iteration.\n * @returns {Array} Returns the new mapped array.\n * @example\n *\n * function square(n) {\n *   return n * n;\n * }\n *\n * _.map([4, 8], square);\n * // => [16, 64]\n *\n * _.map({ 'a': 4, 'b': 8 }, square);\n * // => [16, 64] (iteration order is not guaranteed)\n *\n * var users = [\n *   { 'user': 'barney' },\n *   { 'user': 'fred' }\n * ];\n *\n * // The `_.property` iteratee shorthand.\n * _.map(users, 'user');\n * // => ['barney', 'fred']\n */\nfunction map(collection, iteratee) {\n  var func = isArray(collection) ? arrayMap : baseMap;\n  return func(collection, baseIteratee(iteratee, 3));\n}\n\nexport default map;\n","import baseExtremum from './_baseExtremum.js';\nimport baseLt from './_baseLt.js';\nimport identity from './identity.js';\n\n/**\n * Computes the minimum value of `array`. If `array` is empty or falsey,\n * `undefined` is returned.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Math\n * @param {Array} array The array to iterate over.\n * @returns {*} Returns the minimum value.\n * @example\n *\n * _.min([4, 2, 8, 6]);\n * // => 2\n *\n * _.min([]);\n * // => undefined\n */\nfunction min(array) {\n  return (array && array.length)\n    ? baseExtremum(array, identity, baseLt)\n    : undefined;\n}\n\nexport default min;\n","/** Used to match a single whitespace character. */\nvar reWhitespace = /\\s/;\n\n/**\n * Used by `_.trim` and `_.trimEnd` to get the index of the last non-whitespace\n * character of `string`.\n *\n * @private\n * @param {string} string The string to inspect.\n * @returns {number} Returns the index of the last non-whitespace character.\n */\nfunction trimmedEndIndex(string) {\n  var index = string.length;\n\n  while (index-- && reWhitespace.test(string.charAt(index))) {}\n  return index;\n}\n\nexport default trimmedEndIndex;\n","import trimmedEndIndex from './_trimmedEndIndex.js';\n\n/** Used to match leading whitespace. */\nvar reTrimStart = /^\\s+/;\n\n/**\n * The base implementation of `_.trim`.\n *\n * @private\n * @param {string} string The string to trim.\n * @returns {string} Returns the trimmed string.\n */\nfunction baseTrim(string) {\n  return string\n    ? string.slice(0, trimmedEndIndex(string) + 1).replace(reTrimStart, '')\n    : string;\n}\n\nexport default baseTrim;\n","import baseTrim from './_baseTrim.js';\nimport isObject from './isObject.js';\nimport isSymbol from './isSymbol.js';\n\n/** Used as references for various `Number` constants. */\nvar NAN = 0 / 0;\n\n/** Used to detect bad signed hexadecimal string values. */\nvar reIsBadHex = /^[-+]0x[0-9a-f]+$/i;\n\n/** Used to detect binary string values. */\nvar reIsBinary = /^0b[01]+$/i;\n\n/** Used to detect octal string values. */\nvar reIsOctal = /^0o[0-7]+$/i;\n\n/** Built-in method references without a dependency on `root`. */\nvar freeParseInt = parseInt;\n\n/**\n * Converts `value` to a number.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to process.\n * @returns {number} Returns the number.\n * @example\n *\n * _.toNumber(3.2);\n * // => 3.2\n *\n * _.toNumber(Number.MIN_VALUE);\n * // => 5e-324\n *\n * _.toNumber(Infinity);\n * // => Infinity\n *\n * _.toNumber('3.2');\n * // => 3.2\n */\nfunction toNumber(value) {\n  if (typeof value == 'number') {\n    return value;\n  }\n  if (isSymbol(value)) {\n    return NAN;\n  }\n  if (isObject(value)) {\n    var other = typeof value.valueOf == 'function' ? value.valueOf() : value;\n    value = isObject(other) ? (other + '') : other;\n  }\n  if (typeof value != 'string') {\n    return value === 0 ? value : +value;\n  }\n  value = baseTrim(value);\n  var isBinary = reIsBinary.test(value);\n  return (isBinary || reIsOctal.test(value))\n    ? freeParseInt(value.slice(2), isBinary ? 2 : 8)\n    : (reIsBadHex.test(value) ? NAN : +value);\n}\n\nexport default toNumber;\n","import toNumber from './toNumber.js';\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0,\n    MAX_INTEGER = 1.7976931348623157e+308;\n\n/**\n * Converts `value` to a finite number.\n *\n * @static\n * @memberOf _\n * @since 4.12.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {number} Returns the converted number.\n * @example\n *\n * _.toFinite(3.2);\n * // => 3.2\n *\n * _.toFinite(Number.MIN_VALUE);\n * // => 5e-324\n *\n * _.toFinite(Infinity);\n * // => 1.7976931348623157e+308\n *\n * _.toFinite('3.2');\n * // => 3.2\n */\nfunction toFinite(value) {\n  if (!value) {\n    return value === 0 ? value : 0;\n  }\n  value = toNumber(value);\n  if (value === INFINITY || value === -INFINITY) {\n    var sign = (value < 0 ? -1 : 1);\n    return sign * MAX_INTEGER;\n  }\n  return value === value ? value : 0;\n}\n\nexport default toFinite;\n","import toFinite from './toFinite.js';\n\n/**\n * Converts `value` to an integer.\n *\n * **Note:** This method is loosely based on\n * [`ToInteger`](http://www.ecma-international.org/ecma-262/7.0/#sec-tointeger).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {number} Returns the converted integer.\n * @example\n *\n * _.toInteger(3.2);\n * // => 3\n *\n * _.toInteger(Number.MIN_VALUE);\n * // => 0\n *\n * _.toInteger(Infinity);\n * // => 1.7976931348623157e+308\n *\n * _.toInteger('3.2');\n * // => 3\n */\nfunction toInteger(value) {\n  var result = toFinite(value),\n      remainder = result % 1;\n\n  return result === result ? (remainder ? result - remainder : result) : 0;\n}\n\nexport default toInteger;\n","// shim for using process in browser\nvar process = module.exports = {};\n\n// cached from whatever global is present so that test runners that stub it\n// don't break things.  But we need to wrap it in a try catch in case it is\n// wrapped in strict mode code which doesn't define any globals.  It's inside a\n// function because try/catches deoptimize in certain engines.\n\nvar cachedSetTimeout;\nvar cachedClearTimeout;\n\nfunction defaultSetTimout() {\n    throw new Error('setTimeout has not been defined');\n}\nfunction defaultClearTimeout () {\n    throw new Error('clearTimeout has not been defined');\n}\n(function () {\n    try {\n        if (typeof setTimeout === 'function') {\n            cachedSetTimeout = setTimeout;\n        } else {\n            cachedSetTimeout = defaultSetTimout;\n        }\n    } catch (e) {\n        cachedSetTimeout = defaultSetTimout;\n    }\n    try {\n        if (typeof clearTimeout === 'function') {\n            cachedClearTimeout = clearTimeout;\n        } else {\n            cachedClearTimeout = defaultClearTimeout;\n        }\n    } catch (e) {\n        cachedClearTimeout = defaultClearTimeout;\n    }\n} ())\nfunction runTimeout(fun) {\n    if (cachedSetTimeout === setTimeout) {\n        //normal enviroments in sane situations\n        return setTimeout(fun, 0);\n    }\n    // if setTimeout wasn't available but was latter defined\n    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {\n        cachedSetTimeout = setTimeout;\n        return setTimeout(fun, 0);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedSetTimeout(fun, 0);\n    } catch(e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally\n            return cachedSetTimeout.call(null, fun, 0);\n        } catch(e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error\n            return cachedSetTimeout.call(this, fun, 0);\n        }\n    }\n\n\n}\nfunction runClearTimeout(marker) {\n    if (cachedClearTimeout === clearTimeout) {\n        //normal enviroments in sane situations\n        return clearTimeout(marker);\n    }\n    // if clearTimeout wasn't available but was latter defined\n    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {\n        cachedClearTimeout = clearTimeout;\n        return clearTimeout(marker);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedClearTimeout(marker);\n    } catch (e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally\n            return cachedClearTimeout.call(null, marker);\n        } catch (e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.\n            // Some versions of I.E. have different rules for clearTimeout vs setTimeout\n            return cachedClearTimeout.call(this, marker);\n        }\n    }\n\n\n\n}\nvar queue = [];\nvar draining = false;\nvar currentQueue;\nvar queueIndex = -1;\n\nfunction cleanUpNextTick() {\n    if (!draining || !currentQueue) {\n        return;\n    }\n    draining = false;\n    if (currentQueue.length) {\n        queue = currentQueue.concat(queue);\n    } else {\n        queueIndex = -1;\n    }\n    if (queue.length) {\n        drainQueue();\n    }\n}\n\nfunction drainQueue() {\n    if (draining) {\n        return;\n    }\n    var timeout = runTimeout(cleanUpNextTick);\n    draining = true;\n\n    var len = queue.length;\n    while(len) {\n        currentQueue = queue;\n        queue = [];\n        while (++queueIndex < len) {\n            if (currentQueue) {\n                currentQueue[queueIndex].run();\n            }\n        }\n        queueIndex = -1;\n        len = queue.length;\n    }\n    currentQueue = null;\n    draining = false;\n    runClearTimeout(timeout);\n}\n\nprocess.nextTick = function (fun) {\n    var args = new Array(arguments.length - 1);\n    if (arguments.length > 1) {\n        for (var i = 1; i < arguments.length; i++) {\n            args[i - 1] = arguments[i];\n        }\n    }\n    queue.push(new Item(fun, args));\n    if (queue.length === 1 && !draining) {\n        runTimeout(drainQueue);\n    }\n};\n\n// v8 likes predictible objects\nfunction Item(fun, array) {\n    this.fun = fun;\n    this.array = array;\n}\nItem.prototype.run = function () {\n    this.fun.apply(null, this.array);\n};\nprocess.title = 'browser';\nprocess.browser = true;\nprocess.env = {};\nprocess.argv = [];\nprocess.version = ''; // empty string to avoid regexp issues\nprocess.versions = {};\n\nfunction noop() {}\n\nprocess.on = noop;\nprocess.addListener = noop;\nprocess.once = noop;\nprocess.off = noop;\nprocess.removeListener = noop;\nprocess.removeAllListeners = noop;\nprocess.emit = noop;\nprocess.prependListener = noop;\nprocess.prependOnceListener = noop;\n\nprocess.listeners = function (name) { return [] }\n\nprocess.binding = function (name) {\n    throw new Error('process.binding is not supported');\n};\n\nprocess.cwd = function () { return '/' };\nprocess.chdir = function (dir) {\n    throw new Error('process.chdir is not supported');\n};\nprocess.umask = function() { return 0; };\n","/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ----------------------------------------------------------------------------------------- */\n'use strict';\n\nmodule.exports = require('./lib/browser/main');","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.createProtocolConnection = void 0;\nconst browser_1 = require(\"vscode-jsonrpc/browser\");\n__exportStar(require(\"vscode-jsonrpc/browser\"), exports);\n__exportStar(require(\"../common/api\"), exports);\nfunction createProtocolConnection(reader, writer, logger, options) {\n    return (0, browser_1.createMessageConnection)(reader, writer, logger, options);\n}\nexports.createProtocolConnection = createProtocolConnection;\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.LSPErrorCodes = exports.createProtocolConnection = void 0;\n__exportStar(require(\"vscode-jsonrpc\"), exports);\n__exportStar(require(\"vscode-languageserver-types\"), exports);\n__exportStar(require(\"./messages\"), exports);\n__exportStar(require(\"./protocol\"), exports);\nvar connection_1 = require(\"./connection\");\nObject.defineProperty(exports, \"createProtocolConnection\", { enumerable: true, get: function () { return connection_1.createProtocolConnection; } });\nvar LSPErrorCodes;\n(function (LSPErrorCodes) {\n    /**\n    * This is the start range of LSP reserved error codes.\n    * It doesn't denote a real error code.\n    *\n    * @since 3.16.0\n    */\n    LSPErrorCodes.lspReservedErrorRangeStart = -32899;\n    /**\n     * A request failed but it was syntactically correct, e.g the\n     * method name was known and the parameters were valid. The error\n     * message should contain human readable information about why\n     * the request failed.\n     *\n     * @since 3.17.0\n     */\n    LSPErrorCodes.RequestFailed = -32803;\n    /**\n     * The server cancelled the request. This error code should\n     * only be used for requests that explicitly support being\n     * server cancellable.\n     *\n     * @since 3.17.0\n     */\n    LSPErrorCodes.ServerCancelled = -32802;\n    /**\n     * The server detected that the content of a document got\n     * modified outside normal conditions. A server should\n     * NOT send this error code if it detects a content change\n     * in it unprocessed messages. The result even computed\n     * on an older state might still be useful for the client.\n     *\n     * If a client decides that a result is not of any use anymore\n     * the client should cancel the request.\n     */\n    LSPErrorCodes.ContentModified = -32801;\n    /**\n     * The client has canceled a request and a server as detected\n     * the cancel.\n     */\n    LSPErrorCodes.RequestCancelled = -32800;\n    /**\n    * This is the end range of LSP reserved error codes.\n    * It doesn't denote a real error code.\n    *\n    * @since 3.16.0\n    */\n    LSPErrorCodes.lspReservedErrorRangeEnd = -32800;\n})(LSPErrorCodes || (exports.LSPErrorCodes = LSPErrorCodes = {}));\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.createProtocolConnection = void 0;\nconst vscode_jsonrpc_1 = require(\"vscode-jsonrpc\");\nfunction createProtocolConnection(input, output, logger, options) {\n    if (vscode_jsonrpc_1.ConnectionStrategy.is(options)) {\n        options = { connectionStrategy: options };\n    }\n    return (0, vscode_jsonrpc_1.createMessageConnection)(input, output, logger, options);\n}\nexports.createProtocolConnection = createProtocolConnection;\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ProtocolNotificationType = exports.ProtocolNotificationType0 = exports.ProtocolRequestType = exports.ProtocolRequestType0 = exports.RegistrationType = exports.MessageDirection = void 0;\nconst vscode_jsonrpc_1 = require(\"vscode-jsonrpc\");\nvar MessageDirection;\n(function (MessageDirection) {\n    MessageDirection[\"clientToServer\"] = \"clientToServer\";\n    MessageDirection[\"serverToClient\"] = \"serverToClient\";\n    MessageDirection[\"both\"] = \"both\";\n})(MessageDirection || (exports.MessageDirection = MessageDirection = {}));\nclass RegistrationType {\n    constructor(method) {\n        this.method = method;\n    }\n}\nexports.RegistrationType = RegistrationType;\nclass ProtocolRequestType0 extends vscode_jsonrpc_1.RequestType0 {\n    constructor(method) {\n        super(method);\n    }\n}\nexports.ProtocolRequestType0 = ProtocolRequestType0;\nclass ProtocolRequestType extends vscode_jsonrpc_1.RequestType {\n    constructor(method) {\n        super(method, vscode_jsonrpc_1.ParameterStructures.byName);\n    }\n}\nexports.ProtocolRequestType = ProtocolRequestType;\nclass ProtocolNotificationType0 extends vscode_jsonrpc_1.NotificationType0 {\n    constructor(method) {\n        super(method);\n    }\n}\nexports.ProtocolNotificationType0 = ProtocolNotificationType0;\nclass ProtocolNotificationType extends vscode_jsonrpc_1.NotificationType {\n    constructor(method) {\n        super(method, vscode_jsonrpc_1.ParameterStructures.byName);\n    }\n}\nexports.ProtocolNotificationType = ProtocolNotificationType;\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) TypeFox, Microsoft and others. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.CallHierarchyOutgoingCallsRequest = exports.CallHierarchyIncomingCallsRequest = exports.CallHierarchyPrepareRequest = void 0;\nconst messages_1 = require(\"./messages\");\n/**\n * A request to result a `CallHierarchyItem` in a document at a given position.\n * Can be used as an input to an incoming or outgoing call hierarchy.\n *\n * @since 3.16.0\n */\nvar CallHierarchyPrepareRequest;\n(function (CallHierarchyPrepareRequest) {\n    CallHierarchyPrepareRequest.method = 'textDocument/prepareCallHierarchy';\n    CallHierarchyPrepareRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    CallHierarchyPrepareRequest.type = new messages_1.ProtocolRequestType(CallHierarchyPrepareRequest.method);\n})(CallHierarchyPrepareRequest || (exports.CallHierarchyPrepareRequest = CallHierarchyPrepareRequest = {}));\n/**\n * A request to resolve the incoming calls for a given `CallHierarchyItem`.\n *\n * @since 3.16.0\n */\nvar CallHierarchyIncomingCallsRequest;\n(function (CallHierarchyIncomingCallsRequest) {\n    CallHierarchyIncomingCallsRequest.method = 'callHierarchy/incomingCalls';\n    CallHierarchyIncomingCallsRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    CallHierarchyIncomingCallsRequest.type = new messages_1.ProtocolRequestType(CallHierarchyIncomingCallsRequest.method);\n})(CallHierarchyIncomingCallsRequest || (exports.CallHierarchyIncomingCallsRequest = CallHierarchyIncomingCallsRequest = {}));\n/**\n * A request to resolve the outgoing calls for a given `CallHierarchyItem`.\n *\n * @since 3.16.0\n */\nvar CallHierarchyOutgoingCallsRequest;\n(function (CallHierarchyOutgoingCallsRequest) {\n    CallHierarchyOutgoingCallsRequest.method = 'callHierarchy/outgoingCalls';\n    CallHierarchyOutgoingCallsRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    CallHierarchyOutgoingCallsRequest.type = new messages_1.ProtocolRequestType(CallHierarchyOutgoingCallsRequest.method);\n})(CallHierarchyOutgoingCallsRequest || (exports.CallHierarchyOutgoingCallsRequest = CallHierarchyOutgoingCallsRequest = {}));\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ColorPresentationRequest = exports.DocumentColorRequest = void 0;\nconst messages_1 = require(\"./messages\");\n/**\n * A request to list all color symbols found in a given text document. The request's\n * parameter is of type {@link DocumentColorParams} the\n * response is of type {@link ColorInformation ColorInformation[]} or a Thenable\n * that resolves to such.\n */\nvar DocumentColorRequest;\n(function (DocumentColorRequest) {\n    DocumentColorRequest.method = 'textDocument/documentColor';\n    DocumentColorRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    DocumentColorRequest.type = new messages_1.ProtocolRequestType(DocumentColorRequest.method);\n})(DocumentColorRequest || (exports.DocumentColorRequest = DocumentColorRequest = {}));\n/**\n * A request to list all presentation for a color. The request's\n * parameter is of type {@link ColorPresentationParams} the\n * response is of type {@link ColorInformation ColorInformation[]} or a Thenable\n * that resolves to such.\n */\nvar ColorPresentationRequest;\n(function (ColorPresentationRequest) {\n    ColorPresentationRequest.method = 'textDocument/colorPresentation';\n    ColorPresentationRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    ColorPresentationRequest.type = new messages_1.ProtocolRequestType(ColorPresentationRequest.method);\n})(ColorPresentationRequest || (exports.ColorPresentationRequest = ColorPresentationRequest = {}));\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ConfigurationRequest = void 0;\nconst messages_1 = require(\"./messages\");\n//---- Get Configuration request ----\n/**\n * The 'workspace/configuration' request is sent from the server to the client to fetch a certain\n * configuration setting.\n *\n * This pull model replaces the old push model were the client signaled configuration change via an\n * event. If the server still needs to react to configuration changes (since the server caches the\n * result of `workspace/configuration` requests) the server should register for an empty configuration\n * change event and empty the cache if such an event is received.\n */\nvar ConfigurationRequest;\n(function (ConfigurationRequest) {\n    ConfigurationRequest.method = 'workspace/configuration';\n    ConfigurationRequest.messageDirection = messages_1.MessageDirection.serverToClient;\n    ConfigurationRequest.type = new messages_1.ProtocolRequestType(ConfigurationRequest.method);\n})(ConfigurationRequest || (exports.ConfigurationRequest = ConfigurationRequest = {}));\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.DeclarationRequest = void 0;\nconst messages_1 = require(\"./messages\");\n// @ts-ignore: to avoid inlining LocationLink as dynamic import\nlet __noDynamicImport;\n/**\n * A request to resolve the type definition locations of a symbol at a given text\n * document position. The request's parameter is of type {@link TextDocumentPositionParams}\n * the response is of type {@link Declaration} or a typed array of {@link DeclarationLink}\n * or a Thenable that resolves to such.\n */\nvar DeclarationRequest;\n(function (DeclarationRequest) {\n    DeclarationRequest.method = 'textDocument/declaration';\n    DeclarationRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    DeclarationRequest.type = new messages_1.ProtocolRequestType(DeclarationRequest.method);\n})(DeclarationRequest || (exports.DeclarationRequest = DeclarationRequest = {}));\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.DiagnosticRefreshRequest = exports.WorkspaceDiagnosticRequest = exports.DocumentDiagnosticRequest = exports.DocumentDiagnosticReportKind = exports.DiagnosticServerCancellationData = void 0;\nconst vscode_jsonrpc_1 = require(\"vscode-jsonrpc\");\nconst Is = require(\"./utils/is\");\nconst messages_1 = require(\"./messages\");\n/**\n * @since 3.17.0\n */\nvar DiagnosticServerCancellationData;\n(function (DiagnosticServerCancellationData) {\n    function is(value) {\n        const candidate = value;\n        return candidate && Is.boolean(candidate.retriggerRequest);\n    }\n    DiagnosticServerCancellationData.is = is;\n})(DiagnosticServerCancellationData || (exports.DiagnosticServerCancellationData = DiagnosticServerCancellationData = {}));\n/**\n * The document diagnostic report kinds.\n *\n * @since 3.17.0\n */\nvar DocumentDiagnosticReportKind;\n(function (DocumentDiagnosticReportKind) {\n    /**\n     * A diagnostic report with a full\n     * set of problems.\n     */\n    DocumentDiagnosticReportKind.Full = 'full';\n    /**\n     * A report indicating that the last\n     * returned report is still accurate.\n     */\n    DocumentDiagnosticReportKind.Unchanged = 'unchanged';\n})(DocumentDiagnosticReportKind || (exports.DocumentDiagnosticReportKind = DocumentDiagnosticReportKind = {}));\n/**\n * The document diagnostic request definition.\n *\n * @since 3.17.0\n */\nvar DocumentDiagnosticRequest;\n(function (DocumentDiagnosticRequest) {\n    DocumentDiagnosticRequest.method = 'textDocument/diagnostic';\n    DocumentDiagnosticRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    DocumentDiagnosticRequest.type = new messages_1.ProtocolRequestType(DocumentDiagnosticRequest.method);\n    DocumentDiagnosticRequest.partialResult = new vscode_jsonrpc_1.ProgressType();\n})(DocumentDiagnosticRequest || (exports.DocumentDiagnosticRequest = DocumentDiagnosticRequest = {}));\n/**\n * The workspace diagnostic request definition.\n *\n * @since 3.17.0\n */\nvar WorkspaceDiagnosticRequest;\n(function (WorkspaceDiagnosticRequest) {\n    WorkspaceDiagnosticRequest.method = 'workspace/diagnostic';\n    WorkspaceDiagnosticRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    WorkspaceDiagnosticRequest.type = new messages_1.ProtocolRequestType(WorkspaceDiagnosticRequest.method);\n    WorkspaceDiagnosticRequest.partialResult = new vscode_jsonrpc_1.ProgressType();\n})(WorkspaceDiagnosticRequest || (exports.WorkspaceDiagnosticRequest = WorkspaceDiagnosticRequest = {}));\n/**\n * The diagnostic refresh request definition.\n *\n * @since 3.17.0\n */\nvar DiagnosticRefreshRequest;\n(function (DiagnosticRefreshRequest) {\n    DiagnosticRefreshRequest.method = `workspace/diagnostic/refresh`;\n    DiagnosticRefreshRequest.messageDirection = messages_1.MessageDirection.serverToClient;\n    DiagnosticRefreshRequest.type = new messages_1.ProtocolRequestType0(DiagnosticRefreshRequest.method);\n})(DiagnosticRefreshRequest || (exports.DiagnosticRefreshRequest = DiagnosticRefreshRequest = {}));\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.WillDeleteFilesRequest = exports.DidDeleteFilesNotification = exports.DidRenameFilesNotification = exports.WillRenameFilesRequest = exports.DidCreateFilesNotification = exports.WillCreateFilesRequest = exports.FileOperationPatternKind = void 0;\nconst messages_1 = require(\"./messages\");\n/**\n * A pattern kind describing if a glob pattern matches a file a folder or\n * both.\n *\n * @since 3.16.0\n */\nvar FileOperationPatternKind;\n(function (FileOperationPatternKind) {\n    /**\n     * The pattern matches a file only.\n     */\n    FileOperationPatternKind.file = 'file';\n    /**\n     * The pattern matches a folder only.\n     */\n    FileOperationPatternKind.folder = 'folder';\n})(FileOperationPatternKind || (exports.FileOperationPatternKind = FileOperationPatternKind = {}));\n/**\n * The will create files request is sent from the client to the server before files are actually\n * created as long as the creation is triggered from within the client.\n *\n * The request can return a `WorkspaceEdit` which will be applied to workspace before the\n * files are created. Hence the `WorkspaceEdit` can not manipulate the content of the file\n * to be created.\n *\n * @since 3.16.0\n */\nvar WillCreateFilesRequest;\n(function (WillCreateFilesRequest) {\n    WillCreateFilesRequest.method = 'workspace/willCreateFiles';\n    WillCreateFilesRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    WillCreateFilesRequest.type = new messages_1.ProtocolRequestType(WillCreateFilesRequest.method);\n})(WillCreateFilesRequest || (exports.WillCreateFilesRequest = WillCreateFilesRequest = {}));\n/**\n * The did create files notification is sent from the client to the server when\n * files were created from within the client.\n *\n * @since 3.16.0\n */\nvar DidCreateFilesNotification;\n(function (DidCreateFilesNotification) {\n    DidCreateFilesNotification.method = 'workspace/didCreateFiles';\n    DidCreateFilesNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    DidCreateFilesNotification.type = new messages_1.ProtocolNotificationType(DidCreateFilesNotification.method);\n})(DidCreateFilesNotification || (exports.DidCreateFilesNotification = DidCreateFilesNotification = {}));\n/**\n * The will rename files request is sent from the client to the server before files are actually\n * renamed as long as the rename is triggered from within the client.\n *\n * @since 3.16.0\n */\nvar WillRenameFilesRequest;\n(function (WillRenameFilesRequest) {\n    WillRenameFilesRequest.method = 'workspace/willRenameFiles';\n    WillRenameFilesRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    WillRenameFilesRequest.type = new messages_1.ProtocolRequestType(WillRenameFilesRequest.method);\n})(WillRenameFilesRequest || (exports.WillRenameFilesRequest = WillRenameFilesRequest = {}));\n/**\n * The did rename files notification is sent from the client to the server when\n * files were renamed from within the client.\n *\n * @since 3.16.0\n */\nvar DidRenameFilesNotification;\n(function (DidRenameFilesNotification) {\n    DidRenameFilesNotification.method = 'workspace/didRenameFiles';\n    DidRenameFilesNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    DidRenameFilesNotification.type = new messages_1.ProtocolNotificationType(DidRenameFilesNotification.method);\n})(DidRenameFilesNotification || (exports.DidRenameFilesNotification = DidRenameFilesNotification = {}));\n/**\n * The will delete files request is sent from the client to the server before files are actually\n * deleted as long as the deletion is triggered from within the client.\n *\n * @since 3.16.0\n */\nvar DidDeleteFilesNotification;\n(function (DidDeleteFilesNotification) {\n    DidDeleteFilesNotification.method = 'workspace/didDeleteFiles';\n    DidDeleteFilesNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    DidDeleteFilesNotification.type = new messages_1.ProtocolNotificationType(DidDeleteFilesNotification.method);\n})(DidDeleteFilesNotification || (exports.DidDeleteFilesNotification = DidDeleteFilesNotification = {}));\n/**\n * The did delete files notification is sent from the client to the server when\n * files were deleted from within the client.\n *\n * @since 3.16.0\n */\nvar WillDeleteFilesRequest;\n(function (WillDeleteFilesRequest) {\n    WillDeleteFilesRequest.method = 'workspace/willDeleteFiles';\n    WillDeleteFilesRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    WillDeleteFilesRequest.type = new messages_1.ProtocolRequestType(WillDeleteFilesRequest.method);\n})(WillDeleteFilesRequest || (exports.WillDeleteFilesRequest = WillDeleteFilesRequest = {}));\n","\"use strict\";\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.FoldingRangeRefreshRequest = exports.FoldingRangeRequest = void 0;\nconst messages_1 = require(\"./messages\");\n/**\n * A request to provide folding ranges in a document. The request's\n * parameter is of type {@link FoldingRangeParams}, the\n * response is of type {@link FoldingRangeList} or a Thenable\n * that resolves to such.\n */\nvar FoldingRangeRequest;\n(function (FoldingRangeRequest) {\n    FoldingRangeRequest.method = 'textDocument/foldingRange';\n    FoldingRangeRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    FoldingRangeRequest.type = new messages_1.ProtocolRequestType(FoldingRangeRequest.method);\n})(FoldingRangeRequest || (exports.FoldingRangeRequest = FoldingRangeRequest = {}));\n/**\n * @since 3.18.0\n * @proposed\n */\nvar FoldingRangeRefreshRequest;\n(function (FoldingRangeRefreshRequest) {\n    FoldingRangeRefreshRequest.method = `workspace/foldingRange/refresh`;\n    FoldingRangeRefreshRequest.messageDirection = messages_1.MessageDirection.serverToClient;\n    FoldingRangeRefreshRequest.type = new messages_1.ProtocolRequestType0(FoldingRangeRefreshRequest.method);\n})(FoldingRangeRefreshRequest || (exports.FoldingRangeRefreshRequest = FoldingRangeRefreshRequest = {}));\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ImplementationRequest = void 0;\nconst messages_1 = require(\"./messages\");\n// @ts-ignore: to avoid inlining LocationLink as dynamic import\nlet __noDynamicImport;\n/**\n * A request to resolve the implementation locations of a symbol at a given text\n * document position. The request's parameter is of type {@link TextDocumentPositionParams}\n * the response is of type {@link Definition} or a Thenable that resolves to such.\n */\nvar ImplementationRequest;\n(function (ImplementationRequest) {\n    ImplementationRequest.method = 'textDocument/implementation';\n    ImplementationRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    ImplementationRequest.type = new messages_1.ProtocolRequestType(ImplementationRequest.method);\n})(ImplementationRequest || (exports.ImplementationRequest = ImplementationRequest = {}));\n","\"use strict\";\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.InlayHintRefreshRequest = exports.InlayHintResolveRequest = exports.InlayHintRequest = void 0;\nconst messages_1 = require(\"./messages\");\n/**\n * A request to provide inlay hints in a document. The request's parameter is of\n * type {@link InlayHintsParams}, the response is of type\n * {@link InlayHint InlayHint[]} or a Thenable that resolves to such.\n *\n * @since 3.17.0\n */\nvar InlayHintRequest;\n(function (InlayHintRequest) {\n    InlayHintRequest.method = 'textDocument/inlayHint';\n    InlayHintRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    InlayHintRequest.type = new messages_1.ProtocolRequestType(InlayHintRequest.method);\n})(InlayHintRequest || (exports.InlayHintRequest = InlayHintRequest = {}));\n/**\n * A request to resolve additional properties for an inlay hint.\n * The request's parameter is of type {@link InlayHint}, the response is\n * of type {@link InlayHint} or a Thenable that resolves to such.\n *\n * @since 3.17.0\n */\nvar InlayHintResolveRequest;\n(function (InlayHintResolveRequest) {\n    InlayHintResolveRequest.method = 'inlayHint/resolve';\n    InlayHintResolveRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    InlayHintResolveRequest.type = new messages_1.ProtocolRequestType(InlayHintResolveRequest.method);\n})(InlayHintResolveRequest || (exports.InlayHintResolveRequest = InlayHintResolveRequest = {}));\n/**\n * @since 3.17.0\n */\nvar InlayHintRefreshRequest;\n(function (InlayHintRefreshRequest) {\n    InlayHintRefreshRequest.method = `workspace/inlayHint/refresh`;\n    InlayHintRefreshRequest.messageDirection = messages_1.MessageDirection.serverToClient;\n    InlayHintRefreshRequest.type = new messages_1.ProtocolRequestType0(InlayHintRefreshRequest.method);\n})(InlayHintRefreshRequest || (exports.InlayHintRefreshRequest = InlayHintRefreshRequest = {}));\n","\"use strict\";\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.InlineCompletionRequest = void 0;\nconst messages_1 = require(\"./messages\");\n/**\n * A request to provide inline completions in a document. The request's parameter is of\n * type {@link InlineCompletionParams}, the response is of type\n * {@link InlineCompletion InlineCompletion[]} or a Thenable that resolves to such.\n *\n * @since 3.18.0\n * @proposed\n */\nvar InlineCompletionRequest;\n(function (InlineCompletionRequest) {\n    InlineCompletionRequest.method = 'textDocument/inlineCompletion';\n    InlineCompletionRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    InlineCompletionRequest.type = new messages_1.ProtocolRequestType(InlineCompletionRequest.method);\n})(InlineCompletionRequest || (exports.InlineCompletionRequest = InlineCompletionRequest = {}));\n","\"use strict\";\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.InlineValueRefreshRequest = exports.InlineValueRequest = void 0;\nconst messages_1 = require(\"./messages\");\n/**\n * A request to provide inline values in a document. The request's parameter is of\n * type {@link InlineValueParams}, the response is of type\n * {@link InlineValue InlineValue[]} or a Thenable that resolves to such.\n *\n * @since 3.17.0\n */\nvar InlineValueRequest;\n(function (InlineValueRequest) {\n    InlineValueRequest.method = 'textDocument/inlineValue';\n    InlineValueRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    InlineValueRequest.type = new messages_1.ProtocolRequestType(InlineValueRequest.method);\n})(InlineValueRequest || (exports.InlineValueRequest = InlineValueRequest = {}));\n/**\n * @since 3.17.0\n */\nvar InlineValueRefreshRequest;\n(function (InlineValueRefreshRequest) {\n    InlineValueRefreshRequest.method = `workspace/inlineValue/refresh`;\n    InlineValueRefreshRequest.messageDirection = messages_1.MessageDirection.serverToClient;\n    InlineValueRefreshRequest.type = new messages_1.ProtocolRequestType0(InlineValueRefreshRequest.method);\n})(InlineValueRefreshRequest || (exports.InlineValueRefreshRequest = InlineValueRefreshRequest = {}));\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.WorkspaceSymbolRequest = exports.CodeActionResolveRequest = exports.CodeActionRequest = exports.DocumentSymbolRequest = exports.DocumentHighlightRequest = exports.ReferencesRequest = exports.DefinitionRequest = exports.SignatureHelpRequest = exports.SignatureHelpTriggerKind = exports.HoverRequest = exports.CompletionResolveRequest = exports.CompletionRequest = exports.CompletionTriggerKind = exports.PublishDiagnosticsNotification = exports.WatchKind = exports.RelativePattern = exports.FileChangeType = exports.DidChangeWatchedFilesNotification = exports.WillSaveTextDocumentWaitUntilRequest = exports.WillSaveTextDocumentNotification = exports.TextDocumentSaveReason = exports.DidSaveTextDocumentNotification = exports.DidCloseTextDocumentNotification = exports.DidChangeTextDocumentNotification = exports.TextDocumentContentChangeEvent = exports.DidOpenTextDocumentNotification = exports.TextDocumentSyncKind = exports.TelemetryEventNotification = exports.LogMessageNotification = exports.ShowMessageRequest = exports.ShowMessageNotification = exports.MessageType = exports.DidChangeConfigurationNotification = exports.ExitNotification = exports.ShutdownRequest = exports.InitializedNotification = exports.InitializeErrorCodes = exports.InitializeRequest = exports.WorkDoneProgressOptions = exports.TextDocumentRegistrationOptions = exports.StaticRegistrationOptions = exports.PositionEncodingKind = exports.FailureHandlingKind = exports.ResourceOperationKind = exports.UnregistrationRequest = exports.RegistrationRequest = exports.DocumentSelector = exports.NotebookCellTextDocumentFilter = exports.NotebookDocumentFilter = exports.TextDocumentFilter = void 0;\nexports.MonikerRequest = exports.MonikerKind = exports.UniquenessLevel = exports.WillDeleteFilesRequest = exports.DidDeleteFilesNotification = exports.WillRenameFilesRequest = exports.DidRenameFilesNotification = exports.WillCreateFilesRequest = exports.DidCreateFilesNotification = exports.FileOperationPatternKind = exports.LinkedEditingRangeRequest = exports.ShowDocumentRequest = exports.SemanticTokensRegistrationType = exports.SemanticTokensRefreshRequest = exports.SemanticTokensRangeRequest = exports.SemanticTokensDeltaRequest = exports.SemanticTokensRequest = exports.TokenFormat = exports.CallHierarchyPrepareRequest = exports.CallHierarchyOutgoingCallsRequest = exports.CallHierarchyIncomingCallsRequest = exports.WorkDoneProgressCancelNotification = exports.WorkDoneProgressCreateRequest = exports.WorkDoneProgress = exports.SelectionRangeRequest = exports.DeclarationRequest = exports.FoldingRangeRefreshRequest = exports.FoldingRangeRequest = exports.ColorPresentationRequest = exports.DocumentColorRequest = exports.ConfigurationRequest = exports.DidChangeWorkspaceFoldersNotification = exports.WorkspaceFoldersRequest = exports.TypeDefinitionRequest = exports.ImplementationRequest = exports.ApplyWorkspaceEditRequest = exports.ExecuteCommandRequest = exports.PrepareRenameRequest = exports.RenameRequest = exports.PrepareSupportDefaultBehavior = exports.DocumentOnTypeFormattingRequest = exports.DocumentRangesFormattingRequest = exports.DocumentRangeFormattingRequest = exports.DocumentFormattingRequest = exports.DocumentLinkResolveRequest = exports.DocumentLinkRequest = exports.CodeLensRefreshRequest = exports.CodeLensResolveRequest = exports.CodeLensRequest = exports.WorkspaceSymbolResolveRequest = void 0;\nexports.InlineCompletionRequest = exports.DidCloseNotebookDocumentNotification = exports.DidSaveNotebookDocumentNotification = exports.DidChangeNotebookDocumentNotification = exports.NotebookCellArrayChange = exports.DidOpenNotebookDocumentNotification = exports.NotebookDocumentSyncRegistrationType = exports.NotebookDocument = exports.NotebookCell = exports.ExecutionSummary = exports.NotebookCellKind = exports.DiagnosticRefreshRequest = exports.WorkspaceDiagnosticRequest = exports.DocumentDiagnosticRequest = exports.DocumentDiagnosticReportKind = exports.DiagnosticServerCancellationData = exports.InlayHintRefreshRequest = exports.InlayHintResolveRequest = exports.InlayHintRequest = exports.InlineValueRefreshRequest = exports.InlineValueRequest = exports.TypeHierarchySupertypesRequest = exports.TypeHierarchySubtypesRequest = exports.TypeHierarchyPrepareRequest = void 0;\nconst messages_1 = require(\"./messages\");\nconst vscode_languageserver_types_1 = require(\"vscode-languageserver-types\");\nconst Is = require(\"./utils/is\");\nconst protocol_implementation_1 = require(\"./protocol.implementation\");\nObject.defineProperty(exports, \"ImplementationRequest\", { enumerable: true, get: function () { return protocol_implementation_1.ImplementationRequest; } });\nconst protocol_typeDefinition_1 = require(\"./protocol.typeDefinition\");\nObject.defineProperty(exports, \"TypeDefinitionRequest\", { enumerable: true, get: function () { return protocol_typeDefinition_1.TypeDefinitionRequest; } });\nconst protocol_workspaceFolder_1 = require(\"./protocol.workspaceFolder\");\nObject.defineProperty(exports, \"WorkspaceFoldersRequest\", { enumerable: true, get: function () { return protocol_workspaceFolder_1.WorkspaceFoldersRequest; } });\nObject.defineProperty(exports, \"DidChangeWorkspaceFoldersNotification\", { enumerable: true, get: function () { return protocol_workspaceFolder_1.DidChangeWorkspaceFoldersNotification; } });\nconst protocol_configuration_1 = require(\"./protocol.configuration\");\nObject.defineProperty(exports, \"ConfigurationRequest\", { enumerable: true, get: function () { return protocol_configuration_1.ConfigurationRequest; } });\nconst protocol_colorProvider_1 = require(\"./protocol.colorProvider\");\nObject.defineProperty(exports, \"DocumentColorRequest\", { enumerable: true, get: function () { return protocol_colorProvider_1.DocumentColorRequest; } });\nObject.defineProperty(exports, \"ColorPresentationRequest\", { enumerable: true, get: function () { return protocol_colorProvider_1.ColorPresentationRequest; } });\nconst protocol_foldingRange_1 = require(\"./protocol.foldingRange\");\nObject.defineProperty(exports, \"FoldingRangeRequest\", { enumerable: true, get: function () { return protocol_foldingRange_1.FoldingRangeRequest; } });\nObject.defineProperty(exports, \"FoldingRangeRefreshRequest\", { enumerable: true, get: function () { return protocol_foldingRange_1.FoldingRangeRefreshRequest; } });\nconst protocol_declaration_1 = require(\"./protocol.declaration\");\nObject.defineProperty(exports, \"DeclarationRequest\", { enumerable: true, get: function () { return protocol_declaration_1.DeclarationRequest; } });\nconst protocol_selectionRange_1 = require(\"./protocol.selectionRange\");\nObject.defineProperty(exports, \"SelectionRangeRequest\", { enumerable: true, get: function () { return protocol_selectionRange_1.SelectionRangeRequest; } });\nconst protocol_progress_1 = require(\"./protocol.progress\");\nObject.defineProperty(exports, \"WorkDoneProgress\", { enumerable: true, get: function () { return protocol_progress_1.WorkDoneProgress; } });\nObject.defineProperty(exports, \"WorkDoneProgressCreateRequest\", { enumerable: true, get: function () { return protocol_progress_1.WorkDoneProgressCreateRequest; } });\nObject.defineProperty(exports, \"WorkDoneProgressCancelNotification\", { enumerable: true, get: function () { return protocol_progress_1.WorkDoneProgressCancelNotification; } });\nconst protocol_callHierarchy_1 = require(\"./protocol.callHierarchy\");\nObject.defineProperty(exports, \"CallHierarchyIncomingCallsRequest\", { enumerable: true, get: function () { return protocol_callHierarchy_1.CallHierarchyIncomingCallsRequest; } });\nObject.defineProperty(exports, \"CallHierarchyOutgoingCallsRequest\", { enumerable: true, get: function () { return protocol_callHierarchy_1.CallHierarchyOutgoingCallsRequest; } });\nObject.defineProperty(exports, \"CallHierarchyPrepareRequest\", { enumerable: true, get: function () { return protocol_callHierarchy_1.CallHierarchyPrepareRequest; } });\nconst protocol_semanticTokens_1 = require(\"./protocol.semanticTokens\");\nObject.defineProperty(exports, \"TokenFormat\", { enumerable: true, get: function () { return protocol_semanticTokens_1.TokenFormat; } });\nObject.defineProperty(exports, \"SemanticTokensRequest\", { enumerable: true, get: function () { return protocol_semanticTokens_1.SemanticTokensRequest; } });\nObject.defineProperty(exports, \"SemanticTokensDeltaRequest\", { enumerable: true, get: function () { return protocol_semanticTokens_1.SemanticTokensDeltaRequest; } });\nObject.defineProperty(exports, \"SemanticTokensRangeRequest\", { enumerable: true, get: function () { return protocol_semanticTokens_1.SemanticTokensRangeRequest; } });\nObject.defineProperty(exports, \"SemanticTokensRefreshRequest\", { enumerable: true, get: function () { return protocol_semanticTokens_1.SemanticTokensRefreshRequest; } });\nObject.defineProperty(exports, \"SemanticTokensRegistrationType\", { enumerable: true, get: function () { return protocol_semanticTokens_1.SemanticTokensRegistrationType; } });\nconst protocol_showDocument_1 = require(\"./protocol.showDocument\");\nObject.defineProperty(exports, \"ShowDocumentRequest\", { enumerable: true, get: function () { return protocol_showDocument_1.ShowDocumentRequest; } });\nconst protocol_linkedEditingRange_1 = require(\"./protocol.linkedEditingRange\");\nObject.defineProperty(exports, \"LinkedEditingRangeRequest\", { enumerable: true, get: function () { return protocol_linkedEditingRange_1.LinkedEditingRangeRequest; } });\nconst protocol_fileOperations_1 = require(\"./protocol.fileOperations\");\nObject.defineProperty(exports, \"FileOperationPatternKind\", { enumerable: true, get: function () { return protocol_fileOperations_1.FileOperationPatternKind; } });\nObject.defineProperty(exports, \"DidCreateFilesNotification\", { enumerable: true, get: function () { return protocol_fileOperations_1.DidCreateFilesNotification; } });\nObject.defineProperty(exports, \"WillCreateFilesRequest\", { enumerable: true, get: function () { return protocol_fileOperations_1.WillCreateFilesRequest; } });\nObject.defineProperty(exports, \"DidRenameFilesNotification\", { enumerable: true, get: function () { return protocol_fileOperations_1.DidRenameFilesNotification; } });\nObject.defineProperty(exports, \"WillRenameFilesRequest\", { enumerable: true, get: function () { return protocol_fileOperations_1.WillRenameFilesRequest; } });\nObject.defineProperty(exports, \"DidDeleteFilesNotification\", { enumerable: true, get: function () { return protocol_fileOperations_1.DidDeleteFilesNotification; } });\nObject.defineProperty(exports, \"WillDeleteFilesRequest\", { enumerable: true, get: function () { return protocol_fileOperations_1.WillDeleteFilesRequest; } });\nconst protocol_moniker_1 = require(\"./protocol.moniker\");\nObject.defineProperty(exports, \"UniquenessLevel\", { enumerable: true, get: function () { return protocol_moniker_1.UniquenessLevel; } });\nObject.defineProperty(exports, \"MonikerKind\", { enumerable: true, get: function () { return protocol_moniker_1.MonikerKind; } });\nObject.defineProperty(exports, \"MonikerRequest\", { enumerable: true, get: function () { return protocol_moniker_1.MonikerRequest; } });\nconst protocol_typeHierarchy_1 = require(\"./protocol.typeHierarchy\");\nObject.defineProperty(exports, \"TypeHierarchyPrepareRequest\", { enumerable: true, get: function () { return protocol_typeHierarchy_1.TypeHierarchyPrepareRequest; } });\nObject.defineProperty(exports, \"TypeHierarchySubtypesRequest\", { enumerable: true, get: function () { return protocol_typeHierarchy_1.TypeHierarchySubtypesRequest; } });\nObject.defineProperty(exports, \"TypeHierarchySupertypesRequest\", { enumerable: true, get: function () { return protocol_typeHierarchy_1.TypeHierarchySupertypesRequest; } });\nconst protocol_inlineValue_1 = require(\"./protocol.inlineValue\");\nObject.defineProperty(exports, \"InlineValueRequest\", { enumerable: true, get: function () { return protocol_inlineValue_1.InlineValueRequest; } });\nObject.defineProperty(exports, \"InlineValueRefreshRequest\", { enumerable: true, get: function () { return protocol_inlineValue_1.InlineValueRefreshRequest; } });\nconst protocol_inlayHint_1 = require(\"./protocol.inlayHint\");\nObject.defineProperty(exports, \"InlayHintRequest\", { enumerable: true, get: function () { return protocol_inlayHint_1.InlayHintRequest; } });\nObject.defineProperty(exports, \"InlayHintResolveRequest\", { enumerable: true, get: function () { return protocol_inlayHint_1.InlayHintResolveRequest; } });\nObject.defineProperty(exports, \"InlayHintRefreshRequest\", { enumerable: true, get: function () { return protocol_inlayHint_1.InlayHintRefreshRequest; } });\nconst protocol_diagnostic_1 = require(\"./protocol.diagnostic\");\nObject.defineProperty(exports, \"DiagnosticServerCancellationData\", { enumerable: true, get: function () { return protocol_diagnostic_1.DiagnosticServerCancellationData; } });\nObject.defineProperty(exports, \"DocumentDiagnosticReportKind\", { enumerable: true, get: function () { return protocol_diagnostic_1.DocumentDiagnosticReportKind; } });\nObject.defineProperty(exports, \"DocumentDiagnosticRequest\", { enumerable: true, get: function () { return protocol_diagnostic_1.DocumentDiagnosticRequest; } });\nObject.defineProperty(exports, \"WorkspaceDiagnosticRequest\", { enumerable: true, get: function () { return protocol_diagnostic_1.WorkspaceDiagnosticRequest; } });\nObject.defineProperty(exports, \"DiagnosticRefreshRequest\", { enumerable: true, get: function () { return protocol_diagnostic_1.DiagnosticRefreshRequest; } });\nconst protocol_notebook_1 = require(\"./protocol.notebook\");\nObject.defineProperty(exports, \"NotebookCellKind\", { enumerable: true, get: function () { return protocol_notebook_1.NotebookCellKind; } });\nObject.defineProperty(exports, \"ExecutionSummary\", { enumerable: true, get: function () { return protocol_notebook_1.ExecutionSummary; } });\nObject.defineProperty(exports, \"NotebookCell\", { enumerable: true, get: function () { return protocol_notebook_1.NotebookCell; } });\nObject.defineProperty(exports, \"NotebookDocument\", { enumerable: true, get: function () { return protocol_notebook_1.NotebookDocument; } });\nObject.defineProperty(exports, \"NotebookDocumentSyncRegistrationType\", { enumerable: true, get: function () { return protocol_notebook_1.NotebookDocumentSyncRegistrationType; } });\nObject.defineProperty(exports, \"DidOpenNotebookDocumentNotification\", { enumerable: true, get: function () { return protocol_notebook_1.DidOpenNotebookDocumentNotification; } });\nObject.defineProperty(exports, \"NotebookCellArrayChange\", { enumerable: true, get: function () { return protocol_notebook_1.NotebookCellArrayChange; } });\nObject.defineProperty(exports, \"DidChangeNotebookDocumentNotification\", { enumerable: true, get: function () { return protocol_notebook_1.DidChangeNotebookDocumentNotification; } });\nObject.defineProperty(exports, \"DidSaveNotebookDocumentNotification\", { enumerable: true, get: function () { return protocol_notebook_1.DidSaveNotebookDocumentNotification; } });\nObject.defineProperty(exports, \"DidCloseNotebookDocumentNotification\", { enumerable: true, get: function () { return protocol_notebook_1.DidCloseNotebookDocumentNotification; } });\nconst protocol_inlineCompletion_1 = require(\"./protocol.inlineCompletion\");\nObject.defineProperty(exports, \"InlineCompletionRequest\", { enumerable: true, get: function () { return protocol_inlineCompletion_1.InlineCompletionRequest; } });\n// @ts-ignore: to avoid inlining LocationLink as dynamic import\nlet __noDynamicImport;\n/**\n * The TextDocumentFilter namespace provides helper functions to work with\n * {@link TextDocumentFilter} literals.\n *\n * @since 3.17.0\n */\nvar TextDocumentFilter;\n(function (TextDocumentFilter) {\n    function is(value) {\n        const candidate = value;\n        return Is.string(candidate) || (Is.string(candidate.language) || Is.string(candidate.scheme) || Is.string(candidate.pattern));\n    }\n    TextDocumentFilter.is = is;\n})(TextDocumentFilter || (exports.TextDocumentFilter = TextDocumentFilter = {}));\n/**\n * The NotebookDocumentFilter namespace provides helper functions to work with\n * {@link NotebookDocumentFilter} literals.\n *\n * @since 3.17.0\n */\nvar NotebookDocumentFilter;\n(function (NotebookDocumentFilter) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && (Is.string(candidate.notebookType) || Is.string(candidate.scheme) || Is.string(candidate.pattern));\n    }\n    NotebookDocumentFilter.is = is;\n})(NotebookDocumentFilter || (exports.NotebookDocumentFilter = NotebookDocumentFilter = {}));\n/**\n * The NotebookCellTextDocumentFilter namespace provides helper functions to work with\n * {@link NotebookCellTextDocumentFilter} literals.\n *\n * @since 3.17.0\n */\nvar NotebookCellTextDocumentFilter;\n(function (NotebookCellTextDocumentFilter) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate)\n            && (Is.string(candidate.notebook) || NotebookDocumentFilter.is(candidate.notebook))\n            && (candidate.language === undefined || Is.string(candidate.language));\n    }\n    NotebookCellTextDocumentFilter.is = is;\n})(NotebookCellTextDocumentFilter || (exports.NotebookCellTextDocumentFilter = NotebookCellTextDocumentFilter = {}));\n/**\n * The DocumentSelector namespace provides helper functions to work with\n * {@link DocumentSelector}s.\n */\nvar DocumentSelector;\n(function (DocumentSelector) {\n    function is(value) {\n        if (!Array.isArray(value)) {\n            return false;\n        }\n        for (let elem of value) {\n            if (!Is.string(elem) && !TextDocumentFilter.is(elem) && !NotebookCellTextDocumentFilter.is(elem)) {\n                return false;\n            }\n        }\n        return true;\n    }\n    DocumentSelector.is = is;\n})(DocumentSelector || (exports.DocumentSelector = DocumentSelector = {}));\n/**\n * The `client/registerCapability` request is sent from the server to the client to register a new capability\n * handler on the client side.\n */\nvar RegistrationRequest;\n(function (RegistrationRequest) {\n    RegistrationRequest.method = 'client/registerCapability';\n    RegistrationRequest.messageDirection = messages_1.MessageDirection.serverToClient;\n    RegistrationRequest.type = new messages_1.ProtocolRequestType(RegistrationRequest.method);\n})(RegistrationRequest || (exports.RegistrationRequest = RegistrationRequest = {}));\n/**\n * The `client/unregisterCapability` request is sent from the server to the client to unregister a previously registered capability\n * handler on the client side.\n */\nvar UnregistrationRequest;\n(function (UnregistrationRequest) {\n    UnregistrationRequest.method = 'client/unregisterCapability';\n    UnregistrationRequest.messageDirection = messages_1.MessageDirection.serverToClient;\n    UnregistrationRequest.type = new messages_1.ProtocolRequestType(UnregistrationRequest.method);\n})(UnregistrationRequest || (exports.UnregistrationRequest = UnregistrationRequest = {}));\nvar ResourceOperationKind;\n(function (ResourceOperationKind) {\n    /**\n     * Supports creating new files and folders.\n     */\n    ResourceOperationKind.Create = 'create';\n    /**\n     * Supports renaming existing files and folders.\n     */\n    ResourceOperationKind.Rename = 'rename';\n    /**\n     * Supports deleting existing files and folders.\n     */\n    ResourceOperationKind.Delete = 'delete';\n})(ResourceOperationKind || (exports.ResourceOperationKind = ResourceOperationKind = {}));\nvar FailureHandlingKind;\n(function (FailureHandlingKind) {\n    /**\n     * Applying the workspace change is simply aborted if one of the changes provided\n     * fails. All operations executed before the failing operation stay executed.\n     */\n    FailureHandlingKind.Abort = 'abort';\n    /**\n     * All operations are executed transactional. That means they either all\n     * succeed or no changes at all are applied to the workspace.\n     */\n    FailureHandlingKind.Transactional = 'transactional';\n    /**\n     * If the workspace edit contains only textual file changes they are executed transactional.\n     * If resource changes (create, rename or delete file) are part of the change the failure\n     * handling strategy is abort.\n     */\n    FailureHandlingKind.TextOnlyTransactional = 'textOnlyTransactional';\n    /**\n     * The client tries to undo the operations already executed. But there is no\n     * guarantee that this is succeeding.\n     */\n    FailureHandlingKind.Undo = 'undo';\n})(FailureHandlingKind || (exports.FailureHandlingKind = FailureHandlingKind = {}));\n/**\n * A set of predefined position encoding kinds.\n *\n * @since 3.17.0\n */\nvar PositionEncodingKind;\n(function (PositionEncodingKind) {\n    /**\n     * Character offsets count UTF-8 code units (e.g. bytes).\n     */\n    PositionEncodingKind.UTF8 = 'utf-8';\n    /**\n     * Character offsets count UTF-16 code units.\n     *\n     * This is the default and must always be supported\n     * by servers\n     */\n    PositionEncodingKind.UTF16 = 'utf-16';\n    /**\n     * Character offsets count UTF-32 code units.\n     *\n     * Implementation note: these are the same as Unicode codepoints,\n     * so this `PositionEncodingKind` may also be used for an\n     * encoding-agnostic representation of character offsets.\n     */\n    PositionEncodingKind.UTF32 = 'utf-32';\n})(PositionEncodingKind || (exports.PositionEncodingKind = PositionEncodingKind = {}));\n/**\n * The StaticRegistrationOptions namespace provides helper functions to work with\n * {@link StaticRegistrationOptions} literals.\n */\nvar StaticRegistrationOptions;\n(function (StaticRegistrationOptions) {\n    function hasId(value) {\n        const candidate = value;\n        return candidate && Is.string(candidate.id) && candidate.id.length > 0;\n    }\n    StaticRegistrationOptions.hasId = hasId;\n})(StaticRegistrationOptions || (exports.StaticRegistrationOptions = StaticRegistrationOptions = {}));\n/**\n * The TextDocumentRegistrationOptions namespace provides helper functions to work with\n * {@link TextDocumentRegistrationOptions} literals.\n */\nvar TextDocumentRegistrationOptions;\n(function (TextDocumentRegistrationOptions) {\n    function is(value) {\n        const candidate = value;\n        return candidate && (candidate.documentSelector === null || DocumentSelector.is(candidate.documentSelector));\n    }\n    TextDocumentRegistrationOptions.is = is;\n})(TextDocumentRegistrationOptions || (exports.TextDocumentRegistrationOptions = TextDocumentRegistrationOptions = {}));\n/**\n * The WorkDoneProgressOptions namespace provides helper functions to work with\n * {@link WorkDoneProgressOptions} literals.\n */\nvar WorkDoneProgressOptions;\n(function (WorkDoneProgressOptions) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && (candidate.workDoneProgress === undefined || Is.boolean(candidate.workDoneProgress));\n    }\n    WorkDoneProgressOptions.is = is;\n    function hasWorkDoneProgress(value) {\n        const candidate = value;\n        return candidate && Is.boolean(candidate.workDoneProgress);\n    }\n    WorkDoneProgressOptions.hasWorkDoneProgress = hasWorkDoneProgress;\n})(WorkDoneProgressOptions || (exports.WorkDoneProgressOptions = WorkDoneProgressOptions = {}));\n/**\n * The initialize request is sent from the client to the server.\n * It is sent once as the request after starting up the server.\n * The requests parameter is of type {@link InitializeParams}\n * the response if of type {@link InitializeResult} of a Thenable that\n * resolves to such.\n */\nvar InitializeRequest;\n(function (InitializeRequest) {\n    InitializeRequest.method = 'initialize';\n    InitializeRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    InitializeRequest.type = new messages_1.ProtocolRequestType(InitializeRequest.method);\n})(InitializeRequest || (exports.InitializeRequest = InitializeRequest = {}));\n/**\n * Known error codes for an `InitializeErrorCodes`;\n */\nvar InitializeErrorCodes;\n(function (InitializeErrorCodes) {\n    /**\n     * If the protocol version provided by the client can't be handled by the server.\n     *\n     * @deprecated This initialize error got replaced by client capabilities. There is\n     * no version handshake in version 3.0x\n     */\n    InitializeErrorCodes.unknownProtocolVersion = 1;\n})(InitializeErrorCodes || (exports.InitializeErrorCodes = InitializeErrorCodes = {}));\n/**\n * The initialized notification is sent from the client to the\n * server after the client is fully initialized and the server\n * is allowed to send requests from the server to the client.\n */\nvar InitializedNotification;\n(function (InitializedNotification) {\n    InitializedNotification.method = 'initialized';\n    InitializedNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    InitializedNotification.type = new messages_1.ProtocolNotificationType(InitializedNotification.method);\n})(InitializedNotification || (exports.InitializedNotification = InitializedNotification = {}));\n//---- Shutdown Method ----\n/**\n * A shutdown request is sent from the client to the server.\n * It is sent once when the client decides to shutdown the\n * server. The only notification that is sent after a shutdown request\n * is the exit event.\n */\nvar ShutdownRequest;\n(function (ShutdownRequest) {\n    ShutdownRequest.method = 'shutdown';\n    ShutdownRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    ShutdownRequest.type = new messages_1.ProtocolRequestType0(ShutdownRequest.method);\n})(ShutdownRequest || (exports.ShutdownRequest = ShutdownRequest = {}));\n//---- Exit Notification ----\n/**\n * The exit event is sent from the client to the server to\n * ask the server to exit its process.\n */\nvar ExitNotification;\n(function (ExitNotification) {\n    ExitNotification.method = 'exit';\n    ExitNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    ExitNotification.type = new messages_1.ProtocolNotificationType0(ExitNotification.method);\n})(ExitNotification || (exports.ExitNotification = ExitNotification = {}));\n/**\n * The configuration change notification is sent from the client to the server\n * when the client's configuration has changed. The notification contains\n * the changed configuration as defined by the language client.\n */\nvar DidChangeConfigurationNotification;\n(function (DidChangeConfigurationNotification) {\n    DidChangeConfigurationNotification.method = 'workspace/didChangeConfiguration';\n    DidChangeConfigurationNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    DidChangeConfigurationNotification.type = new messages_1.ProtocolNotificationType(DidChangeConfigurationNotification.method);\n})(DidChangeConfigurationNotification || (exports.DidChangeConfigurationNotification = DidChangeConfigurationNotification = {}));\n//---- Message show and log notifications ----\n/**\n * The message type\n */\nvar MessageType;\n(function (MessageType) {\n    /**\n     * An error message.\n     */\n    MessageType.Error = 1;\n    /**\n     * A warning message.\n     */\n    MessageType.Warning = 2;\n    /**\n     * An information message.\n     */\n    MessageType.Info = 3;\n    /**\n     * A log message.\n     */\n    MessageType.Log = 4;\n    /**\n     * A debug message.\n     *\n     * @since 3.18.0\n     */\n    MessageType.Debug = 5;\n})(MessageType || (exports.MessageType = MessageType = {}));\n/**\n * The show message notification is sent from a server to a client to ask\n * the client to display a particular message in the user interface.\n */\nvar ShowMessageNotification;\n(function (ShowMessageNotification) {\n    ShowMessageNotification.method = 'window/showMessage';\n    ShowMessageNotification.messageDirection = messages_1.MessageDirection.serverToClient;\n    ShowMessageNotification.type = new messages_1.ProtocolNotificationType(ShowMessageNotification.method);\n})(ShowMessageNotification || (exports.ShowMessageNotification = ShowMessageNotification = {}));\n/**\n * The show message request is sent from the server to the client to show a message\n * and a set of options actions to the user.\n */\nvar ShowMessageRequest;\n(function (ShowMessageRequest) {\n    ShowMessageRequest.method = 'window/showMessageRequest';\n    ShowMessageRequest.messageDirection = messages_1.MessageDirection.serverToClient;\n    ShowMessageRequest.type = new messages_1.ProtocolRequestType(ShowMessageRequest.method);\n})(ShowMessageRequest || (exports.ShowMessageRequest = ShowMessageRequest = {}));\n/**\n * The log message notification is sent from the server to the client to ask\n * the client to log a particular message.\n */\nvar LogMessageNotification;\n(function (LogMessageNotification) {\n    LogMessageNotification.method = 'window/logMessage';\n    LogMessageNotification.messageDirection = messages_1.MessageDirection.serverToClient;\n    LogMessageNotification.type = new messages_1.ProtocolNotificationType(LogMessageNotification.method);\n})(LogMessageNotification || (exports.LogMessageNotification = LogMessageNotification = {}));\n//---- Telemetry notification\n/**\n * The telemetry event notification is sent from the server to the client to ask\n * the client to log telemetry data.\n */\nvar TelemetryEventNotification;\n(function (TelemetryEventNotification) {\n    TelemetryEventNotification.method = 'telemetry/event';\n    TelemetryEventNotification.messageDirection = messages_1.MessageDirection.serverToClient;\n    TelemetryEventNotification.type = new messages_1.ProtocolNotificationType(TelemetryEventNotification.method);\n})(TelemetryEventNotification || (exports.TelemetryEventNotification = TelemetryEventNotification = {}));\n/**\n * Defines how the host (editor) should sync\n * document changes to the language server.\n */\nvar TextDocumentSyncKind;\n(function (TextDocumentSyncKind) {\n    /**\n     * Documents should not be synced at all.\n     */\n    TextDocumentSyncKind.None = 0;\n    /**\n     * Documents are synced by always sending the full content\n     * of the document.\n     */\n    TextDocumentSyncKind.Full = 1;\n    /**\n     * Documents are synced by sending the full content on open.\n     * After that only incremental updates to the document are\n     * send.\n     */\n    TextDocumentSyncKind.Incremental = 2;\n})(TextDocumentSyncKind || (exports.TextDocumentSyncKind = TextDocumentSyncKind = {}));\n/**\n * The document open notification is sent from the client to the server to signal\n * newly opened text documents. The document's truth is now managed by the client\n * and the server must not try to read the document's truth using the document's\n * uri. Open in this sense means it is managed by the client. It doesn't necessarily\n * mean that its content is presented in an editor. An open notification must not\n * be sent more than once without a corresponding close notification send before.\n * This means open and close notification must be balanced and the max open count\n * is one.\n */\nvar DidOpenTextDocumentNotification;\n(function (DidOpenTextDocumentNotification) {\n    DidOpenTextDocumentNotification.method = 'textDocument/didOpen';\n    DidOpenTextDocumentNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    DidOpenTextDocumentNotification.type = new messages_1.ProtocolNotificationType(DidOpenTextDocumentNotification.method);\n})(DidOpenTextDocumentNotification || (exports.DidOpenTextDocumentNotification = DidOpenTextDocumentNotification = {}));\nvar TextDocumentContentChangeEvent;\n(function (TextDocumentContentChangeEvent) {\n    /**\n     * Checks whether the information describes a delta event.\n     */\n    function isIncremental(event) {\n        let candidate = event;\n        return candidate !== undefined && candidate !== null &&\n            typeof candidate.text === 'string' && candidate.range !== undefined &&\n            (candidate.rangeLength === undefined || typeof candidate.rangeLength === 'number');\n    }\n    TextDocumentContentChangeEvent.isIncremental = isIncremental;\n    /**\n     * Checks whether the information describes a full replacement event.\n     */\n    function isFull(event) {\n        let candidate = event;\n        return candidate !== undefined && candidate !== null &&\n            typeof candidate.text === 'string' && candidate.range === undefined && candidate.rangeLength === undefined;\n    }\n    TextDocumentContentChangeEvent.isFull = isFull;\n})(TextDocumentContentChangeEvent || (exports.TextDocumentContentChangeEvent = TextDocumentContentChangeEvent = {}));\n/**\n * The document change notification is sent from the client to the server to signal\n * changes to a text document.\n */\nvar DidChangeTextDocumentNotification;\n(function (DidChangeTextDocumentNotification) {\n    DidChangeTextDocumentNotification.method = 'textDocument/didChange';\n    DidChangeTextDocumentNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    DidChangeTextDocumentNotification.type = new messages_1.ProtocolNotificationType(DidChangeTextDocumentNotification.method);\n})(DidChangeTextDocumentNotification || (exports.DidChangeTextDocumentNotification = DidChangeTextDocumentNotification = {}));\n/**\n * The document close notification is sent from the client to the server when\n * the document got closed in the client. The document's truth now exists where\n * the document's uri points to (e.g. if the document's uri is a file uri the\n * truth now exists on disk). As with the open notification the close notification\n * is about managing the document's content. Receiving a close notification\n * doesn't mean that the document was open in an editor before. A close\n * notification requires a previous open notification to be sent.\n */\nvar DidCloseTextDocumentNotification;\n(function (DidCloseTextDocumentNotification) {\n    DidCloseTextDocumentNotification.method = 'textDocument/didClose';\n    DidCloseTextDocumentNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    DidCloseTextDocumentNotification.type = new messages_1.ProtocolNotificationType(DidCloseTextDocumentNotification.method);\n})(DidCloseTextDocumentNotification || (exports.DidCloseTextDocumentNotification = DidCloseTextDocumentNotification = {}));\n/**\n * The document save notification is sent from the client to the server when\n * the document got saved in the client.\n */\nvar DidSaveTextDocumentNotification;\n(function (DidSaveTextDocumentNotification) {\n    DidSaveTextDocumentNotification.method = 'textDocument/didSave';\n    DidSaveTextDocumentNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    DidSaveTextDocumentNotification.type = new messages_1.ProtocolNotificationType(DidSaveTextDocumentNotification.method);\n})(DidSaveTextDocumentNotification || (exports.DidSaveTextDocumentNotification = DidSaveTextDocumentNotification = {}));\n/**\n * Represents reasons why a text document is saved.\n */\nvar TextDocumentSaveReason;\n(function (TextDocumentSaveReason) {\n    /**\n     * Manually triggered, e.g. by the user pressing save, by starting debugging,\n     * or by an API call.\n     */\n    TextDocumentSaveReason.Manual = 1;\n    /**\n     * Automatic after a delay.\n     */\n    TextDocumentSaveReason.AfterDelay = 2;\n    /**\n     * When the editor lost focus.\n     */\n    TextDocumentSaveReason.FocusOut = 3;\n})(TextDocumentSaveReason || (exports.TextDocumentSaveReason = TextDocumentSaveReason = {}));\n/**\n * A document will save notification is sent from the client to the server before\n * the document is actually saved.\n */\nvar WillSaveTextDocumentNotification;\n(function (WillSaveTextDocumentNotification) {\n    WillSaveTextDocumentNotification.method = 'textDocument/willSave';\n    WillSaveTextDocumentNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    WillSaveTextDocumentNotification.type = new messages_1.ProtocolNotificationType(WillSaveTextDocumentNotification.method);\n})(WillSaveTextDocumentNotification || (exports.WillSaveTextDocumentNotification = WillSaveTextDocumentNotification = {}));\n/**\n * A document will save request is sent from the client to the server before\n * the document is actually saved. The request can return an array of TextEdits\n * which will be applied to the text document before it is saved. Please note that\n * clients might drop results if computing the text edits took too long or if a\n * server constantly fails on this request. This is done to keep the save fast and\n * reliable.\n */\nvar WillSaveTextDocumentWaitUntilRequest;\n(function (WillSaveTextDocumentWaitUntilRequest) {\n    WillSaveTextDocumentWaitUntilRequest.method = 'textDocument/willSaveWaitUntil';\n    WillSaveTextDocumentWaitUntilRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    WillSaveTextDocumentWaitUntilRequest.type = new messages_1.ProtocolRequestType(WillSaveTextDocumentWaitUntilRequest.method);\n})(WillSaveTextDocumentWaitUntilRequest || (exports.WillSaveTextDocumentWaitUntilRequest = WillSaveTextDocumentWaitUntilRequest = {}));\n/**\n * The watched files notification is sent from the client to the server when\n * the client detects changes to file watched by the language client.\n */\nvar DidChangeWatchedFilesNotification;\n(function (DidChangeWatchedFilesNotification) {\n    DidChangeWatchedFilesNotification.method = 'workspace/didChangeWatchedFiles';\n    DidChangeWatchedFilesNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    DidChangeWatchedFilesNotification.type = new messages_1.ProtocolNotificationType(DidChangeWatchedFilesNotification.method);\n})(DidChangeWatchedFilesNotification || (exports.DidChangeWatchedFilesNotification = DidChangeWatchedFilesNotification = {}));\n/**\n * The file event type\n */\nvar FileChangeType;\n(function (FileChangeType) {\n    /**\n     * The file got created.\n     */\n    FileChangeType.Created = 1;\n    /**\n     * The file got changed.\n     */\n    FileChangeType.Changed = 2;\n    /**\n     * The file got deleted.\n     */\n    FileChangeType.Deleted = 3;\n})(FileChangeType || (exports.FileChangeType = FileChangeType = {}));\nvar RelativePattern;\n(function (RelativePattern) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && (vscode_languageserver_types_1.URI.is(candidate.baseUri) || vscode_languageserver_types_1.WorkspaceFolder.is(candidate.baseUri)) && Is.string(candidate.pattern);\n    }\n    RelativePattern.is = is;\n})(RelativePattern || (exports.RelativePattern = RelativePattern = {}));\nvar WatchKind;\n(function (WatchKind) {\n    /**\n     * Interested in create events.\n     */\n    WatchKind.Create = 1;\n    /**\n     * Interested in change events\n     */\n    WatchKind.Change = 2;\n    /**\n     * Interested in delete events\n     */\n    WatchKind.Delete = 4;\n})(WatchKind || (exports.WatchKind = WatchKind = {}));\n/**\n * Diagnostics notification are sent from the server to the client to signal\n * results of validation runs.\n */\nvar PublishDiagnosticsNotification;\n(function (PublishDiagnosticsNotification) {\n    PublishDiagnosticsNotification.method = 'textDocument/publishDiagnostics';\n    PublishDiagnosticsNotification.messageDirection = messages_1.MessageDirection.serverToClient;\n    PublishDiagnosticsNotification.type = new messages_1.ProtocolNotificationType(PublishDiagnosticsNotification.method);\n})(PublishDiagnosticsNotification || (exports.PublishDiagnosticsNotification = PublishDiagnosticsNotification = {}));\n/**\n * How a completion was triggered\n */\nvar CompletionTriggerKind;\n(function (CompletionTriggerKind) {\n    /**\n     * Completion was triggered by typing an identifier (24x7 code\n     * complete), manual invocation (e.g Ctrl+Space) or via API.\n     */\n    CompletionTriggerKind.Invoked = 1;\n    /**\n     * Completion was triggered by a trigger character specified by\n     * the `triggerCharacters` properties of the `CompletionRegistrationOptions`.\n     */\n    CompletionTriggerKind.TriggerCharacter = 2;\n    /**\n     * Completion was re-triggered as current completion list is incomplete\n     */\n    CompletionTriggerKind.TriggerForIncompleteCompletions = 3;\n})(CompletionTriggerKind || (exports.CompletionTriggerKind = CompletionTriggerKind = {}));\n/**\n * Request to request completion at a given text document position. The request's\n * parameter is of type {@link TextDocumentPosition} the response\n * is of type {@link CompletionItem CompletionItem[]} or {@link CompletionList}\n * or a Thenable that resolves to such.\n *\n * The request can delay the computation of the {@link CompletionItem.detail `detail`}\n * and {@link CompletionItem.documentation `documentation`} properties to the `completionItem/resolve`\n * request. However, properties that are needed for the initial sorting and filtering, like `sortText`,\n * `filterText`, `insertText`, and `textEdit`, must not be changed during resolve.\n */\nvar CompletionRequest;\n(function (CompletionRequest) {\n    CompletionRequest.method = 'textDocument/completion';\n    CompletionRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    CompletionRequest.type = new messages_1.ProtocolRequestType(CompletionRequest.method);\n})(CompletionRequest || (exports.CompletionRequest = CompletionRequest = {}));\n/**\n * Request to resolve additional information for a given completion item.The request's\n * parameter is of type {@link CompletionItem} the response\n * is of type {@link CompletionItem} or a Thenable that resolves to such.\n */\nvar CompletionResolveRequest;\n(function (CompletionResolveRequest) {\n    CompletionResolveRequest.method = 'completionItem/resolve';\n    CompletionResolveRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    CompletionResolveRequest.type = new messages_1.ProtocolRequestType(CompletionResolveRequest.method);\n})(CompletionResolveRequest || (exports.CompletionResolveRequest = CompletionResolveRequest = {}));\n/**\n * Request to request hover information at a given text document position. The request's\n * parameter is of type {@link TextDocumentPosition} the response is of\n * type {@link Hover} or a Thenable that resolves to such.\n */\nvar HoverRequest;\n(function (HoverRequest) {\n    HoverRequest.method = 'textDocument/hover';\n    HoverRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    HoverRequest.type = new messages_1.ProtocolRequestType(HoverRequest.method);\n})(HoverRequest || (exports.HoverRequest = HoverRequest = {}));\n/**\n * How a signature help was triggered.\n *\n * @since 3.15.0\n */\nvar SignatureHelpTriggerKind;\n(function (SignatureHelpTriggerKind) {\n    /**\n     * Signature help was invoked manually by the user or by a command.\n     */\n    SignatureHelpTriggerKind.Invoked = 1;\n    /**\n     * Signature help was triggered by a trigger character.\n     */\n    SignatureHelpTriggerKind.TriggerCharacter = 2;\n    /**\n     * Signature help was triggered by the cursor moving or by the document content changing.\n     */\n    SignatureHelpTriggerKind.ContentChange = 3;\n})(SignatureHelpTriggerKind || (exports.SignatureHelpTriggerKind = SignatureHelpTriggerKind = {}));\nvar SignatureHelpRequest;\n(function (SignatureHelpRequest) {\n    SignatureHelpRequest.method = 'textDocument/signatureHelp';\n    SignatureHelpRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    SignatureHelpRequest.type = new messages_1.ProtocolRequestType(SignatureHelpRequest.method);\n})(SignatureHelpRequest || (exports.SignatureHelpRequest = SignatureHelpRequest = {}));\n/**\n * A request to resolve the definition location of a symbol at a given text\n * document position. The request's parameter is of type {@link TextDocumentPosition}\n * the response is of either type {@link Definition} or a typed array of\n * {@link DefinitionLink} or a Thenable that resolves to such.\n */\nvar DefinitionRequest;\n(function (DefinitionRequest) {\n    DefinitionRequest.method = 'textDocument/definition';\n    DefinitionRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    DefinitionRequest.type = new messages_1.ProtocolRequestType(DefinitionRequest.method);\n})(DefinitionRequest || (exports.DefinitionRequest = DefinitionRequest = {}));\n/**\n * A request to resolve project-wide references for the symbol denoted\n * by the given text document position. The request's parameter is of\n * type {@link ReferenceParams} the response is of type\n * {@link Location Location[]} or a Thenable that resolves to such.\n */\nvar ReferencesRequest;\n(function (ReferencesRequest) {\n    ReferencesRequest.method = 'textDocument/references';\n    ReferencesRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    ReferencesRequest.type = new messages_1.ProtocolRequestType(ReferencesRequest.method);\n})(ReferencesRequest || (exports.ReferencesRequest = ReferencesRequest = {}));\n/**\n * Request to resolve a {@link DocumentHighlight} for a given\n * text document position. The request's parameter is of type {@link TextDocumentPosition}\n * the request response is an array of type {@link DocumentHighlight}\n * or a Thenable that resolves to such.\n */\nvar DocumentHighlightRequest;\n(function (DocumentHighlightRequest) {\n    DocumentHighlightRequest.method = 'textDocument/documentHighlight';\n    DocumentHighlightRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    DocumentHighlightRequest.type = new messages_1.ProtocolRequestType(DocumentHighlightRequest.method);\n})(DocumentHighlightRequest || (exports.DocumentHighlightRequest = DocumentHighlightRequest = {}));\n/**\n * A request to list all symbols found in a given text document. The request's\n * parameter is of type {@link TextDocumentIdentifier} the\n * response is of type {@link SymbolInformation SymbolInformation[]} or a Thenable\n * that resolves to such.\n */\nvar DocumentSymbolRequest;\n(function (DocumentSymbolRequest) {\n    DocumentSymbolRequest.method = 'textDocument/documentSymbol';\n    DocumentSymbolRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    DocumentSymbolRequest.type = new messages_1.ProtocolRequestType(DocumentSymbolRequest.method);\n})(DocumentSymbolRequest || (exports.DocumentSymbolRequest = DocumentSymbolRequest = {}));\n/**\n * A request to provide commands for the given text document and range.\n */\nvar CodeActionRequest;\n(function (CodeActionRequest) {\n    CodeActionRequest.method = 'textDocument/codeAction';\n    CodeActionRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    CodeActionRequest.type = new messages_1.ProtocolRequestType(CodeActionRequest.method);\n})(CodeActionRequest || (exports.CodeActionRequest = CodeActionRequest = {}));\n/**\n * Request to resolve additional information for a given code action.The request's\n * parameter is of type {@link CodeAction} the response\n * is of type {@link CodeAction} or a Thenable that resolves to such.\n */\nvar CodeActionResolveRequest;\n(function (CodeActionResolveRequest) {\n    CodeActionResolveRequest.method = 'codeAction/resolve';\n    CodeActionResolveRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    CodeActionResolveRequest.type = new messages_1.ProtocolRequestType(CodeActionResolveRequest.method);\n})(CodeActionResolveRequest || (exports.CodeActionResolveRequest = CodeActionResolveRequest = {}));\n/**\n * A request to list project-wide symbols matching the query string given\n * by the {@link WorkspaceSymbolParams}. The response is\n * of type {@link SymbolInformation SymbolInformation[]} or a Thenable that\n * resolves to such.\n *\n * @since 3.17.0 - support for WorkspaceSymbol in the returned data. Clients\n *  need to advertise support for WorkspaceSymbols via the client capability\n *  `workspace.symbol.resolveSupport`.\n *\n */\nvar WorkspaceSymbolRequest;\n(function (WorkspaceSymbolRequest) {\n    WorkspaceSymbolRequest.method = 'workspace/symbol';\n    WorkspaceSymbolRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    WorkspaceSymbolRequest.type = new messages_1.ProtocolRequestType(WorkspaceSymbolRequest.method);\n})(WorkspaceSymbolRequest || (exports.WorkspaceSymbolRequest = WorkspaceSymbolRequest = {}));\n/**\n * A request to resolve the range inside the workspace\n * symbol's location.\n *\n * @since 3.17.0\n */\nvar WorkspaceSymbolResolveRequest;\n(function (WorkspaceSymbolResolveRequest) {\n    WorkspaceSymbolResolveRequest.method = 'workspaceSymbol/resolve';\n    WorkspaceSymbolResolveRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    WorkspaceSymbolResolveRequest.type = new messages_1.ProtocolRequestType(WorkspaceSymbolResolveRequest.method);\n})(WorkspaceSymbolResolveRequest || (exports.WorkspaceSymbolResolveRequest = WorkspaceSymbolResolveRequest = {}));\n/**\n * A request to provide code lens for the given text document.\n */\nvar CodeLensRequest;\n(function (CodeLensRequest) {\n    CodeLensRequest.method = 'textDocument/codeLens';\n    CodeLensRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    CodeLensRequest.type = new messages_1.ProtocolRequestType(CodeLensRequest.method);\n})(CodeLensRequest || (exports.CodeLensRequest = CodeLensRequest = {}));\n/**\n * A request to resolve a command for a given code lens.\n */\nvar CodeLensResolveRequest;\n(function (CodeLensResolveRequest) {\n    CodeLensResolveRequest.method = 'codeLens/resolve';\n    CodeLensResolveRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    CodeLensResolveRequest.type = new messages_1.ProtocolRequestType(CodeLensResolveRequest.method);\n})(CodeLensResolveRequest || (exports.CodeLensResolveRequest = CodeLensResolveRequest = {}));\n/**\n * A request to refresh all code actions\n *\n * @since 3.16.0\n */\nvar CodeLensRefreshRequest;\n(function (CodeLensRefreshRequest) {\n    CodeLensRefreshRequest.method = `workspace/codeLens/refresh`;\n    CodeLensRefreshRequest.messageDirection = messages_1.MessageDirection.serverToClient;\n    CodeLensRefreshRequest.type = new messages_1.ProtocolRequestType0(CodeLensRefreshRequest.method);\n})(CodeLensRefreshRequest || (exports.CodeLensRefreshRequest = CodeLensRefreshRequest = {}));\n/**\n * A request to provide document links\n */\nvar DocumentLinkRequest;\n(function (DocumentLinkRequest) {\n    DocumentLinkRequest.method = 'textDocument/documentLink';\n    DocumentLinkRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    DocumentLinkRequest.type = new messages_1.ProtocolRequestType(DocumentLinkRequest.method);\n})(DocumentLinkRequest || (exports.DocumentLinkRequest = DocumentLinkRequest = {}));\n/**\n * Request to resolve additional information for a given document link. The request's\n * parameter is of type {@link DocumentLink} the response\n * is of type {@link DocumentLink} or a Thenable that resolves to such.\n */\nvar DocumentLinkResolveRequest;\n(function (DocumentLinkResolveRequest) {\n    DocumentLinkResolveRequest.method = 'documentLink/resolve';\n    DocumentLinkResolveRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    DocumentLinkResolveRequest.type = new messages_1.ProtocolRequestType(DocumentLinkResolveRequest.method);\n})(DocumentLinkResolveRequest || (exports.DocumentLinkResolveRequest = DocumentLinkResolveRequest = {}));\n/**\n * A request to format a whole document.\n */\nvar DocumentFormattingRequest;\n(function (DocumentFormattingRequest) {\n    DocumentFormattingRequest.method = 'textDocument/formatting';\n    DocumentFormattingRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    DocumentFormattingRequest.type = new messages_1.ProtocolRequestType(DocumentFormattingRequest.method);\n})(DocumentFormattingRequest || (exports.DocumentFormattingRequest = DocumentFormattingRequest = {}));\n/**\n * A request to format a range in a document.\n */\nvar DocumentRangeFormattingRequest;\n(function (DocumentRangeFormattingRequest) {\n    DocumentRangeFormattingRequest.method = 'textDocument/rangeFormatting';\n    DocumentRangeFormattingRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    DocumentRangeFormattingRequest.type = new messages_1.ProtocolRequestType(DocumentRangeFormattingRequest.method);\n})(DocumentRangeFormattingRequest || (exports.DocumentRangeFormattingRequest = DocumentRangeFormattingRequest = {}));\n/**\n * A request to format ranges in a document.\n *\n * @since 3.18.0\n * @proposed\n */\nvar DocumentRangesFormattingRequest;\n(function (DocumentRangesFormattingRequest) {\n    DocumentRangesFormattingRequest.method = 'textDocument/rangesFormatting';\n    DocumentRangesFormattingRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    DocumentRangesFormattingRequest.type = new messages_1.ProtocolRequestType(DocumentRangesFormattingRequest.method);\n})(DocumentRangesFormattingRequest || (exports.DocumentRangesFormattingRequest = DocumentRangesFormattingRequest = {}));\n/**\n * A request to format a document on type.\n */\nvar DocumentOnTypeFormattingRequest;\n(function (DocumentOnTypeFormattingRequest) {\n    DocumentOnTypeFormattingRequest.method = 'textDocument/onTypeFormatting';\n    DocumentOnTypeFormattingRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    DocumentOnTypeFormattingRequest.type = new messages_1.ProtocolRequestType(DocumentOnTypeFormattingRequest.method);\n})(DocumentOnTypeFormattingRequest || (exports.DocumentOnTypeFormattingRequest = DocumentOnTypeFormattingRequest = {}));\n//---- Rename ----------------------------------------------\nvar PrepareSupportDefaultBehavior;\n(function (PrepareSupportDefaultBehavior) {\n    /**\n     * The client's default behavior is to select the identifier\n     * according the to language's syntax rule.\n     */\n    PrepareSupportDefaultBehavior.Identifier = 1;\n})(PrepareSupportDefaultBehavior || (exports.PrepareSupportDefaultBehavior = PrepareSupportDefaultBehavior = {}));\n/**\n * A request to rename a symbol.\n */\nvar RenameRequest;\n(function (RenameRequest) {\n    RenameRequest.method = 'textDocument/rename';\n    RenameRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    RenameRequest.type = new messages_1.ProtocolRequestType(RenameRequest.method);\n})(RenameRequest || (exports.RenameRequest = RenameRequest = {}));\n/**\n * A request to test and perform the setup necessary for a rename.\n *\n * @since 3.16 - support for default behavior\n */\nvar PrepareRenameRequest;\n(function (PrepareRenameRequest) {\n    PrepareRenameRequest.method = 'textDocument/prepareRename';\n    PrepareRenameRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    PrepareRenameRequest.type = new messages_1.ProtocolRequestType(PrepareRenameRequest.method);\n})(PrepareRenameRequest || (exports.PrepareRenameRequest = PrepareRenameRequest = {}));\n/**\n * A request send from the client to the server to execute a command. The request might return\n * a workspace edit which the client will apply to the workspace.\n */\nvar ExecuteCommandRequest;\n(function (ExecuteCommandRequest) {\n    ExecuteCommandRequest.method = 'workspace/executeCommand';\n    ExecuteCommandRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    ExecuteCommandRequest.type = new messages_1.ProtocolRequestType(ExecuteCommandRequest.method);\n})(ExecuteCommandRequest || (exports.ExecuteCommandRequest = ExecuteCommandRequest = {}));\n/**\n * A request sent from the server to the client to modified certain resources.\n */\nvar ApplyWorkspaceEditRequest;\n(function (ApplyWorkspaceEditRequest) {\n    ApplyWorkspaceEditRequest.method = 'workspace/applyEdit';\n    ApplyWorkspaceEditRequest.messageDirection = messages_1.MessageDirection.serverToClient;\n    ApplyWorkspaceEditRequest.type = new messages_1.ProtocolRequestType('workspace/applyEdit');\n})(ApplyWorkspaceEditRequest || (exports.ApplyWorkspaceEditRequest = ApplyWorkspaceEditRequest = {}));\n","\"use strict\";\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.LinkedEditingRangeRequest = void 0;\nconst messages_1 = require(\"./messages\");\n/**\n * A request to provide ranges that can be edited together.\n *\n * @since 3.16.0\n */\nvar LinkedEditingRangeRequest;\n(function (LinkedEditingRangeRequest) {\n    LinkedEditingRangeRequest.method = 'textDocument/linkedEditingRange';\n    LinkedEditingRangeRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    LinkedEditingRangeRequest.type = new messages_1.ProtocolRequestType(LinkedEditingRangeRequest.method);\n})(LinkedEditingRangeRequest || (exports.LinkedEditingRangeRequest = LinkedEditingRangeRequest = {}));\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.MonikerRequest = exports.MonikerKind = exports.UniquenessLevel = void 0;\nconst messages_1 = require(\"./messages\");\n/**\n * Moniker uniqueness level to define scope of the moniker.\n *\n * @since 3.16.0\n */\nvar UniquenessLevel;\n(function (UniquenessLevel) {\n    /**\n     * The moniker is only unique inside a document\n     */\n    UniquenessLevel.document = 'document';\n    /**\n     * The moniker is unique inside a project for which a dump got created\n     */\n    UniquenessLevel.project = 'project';\n    /**\n     * The moniker is unique inside the group to which a project belongs\n     */\n    UniquenessLevel.group = 'group';\n    /**\n     * The moniker is unique inside the moniker scheme.\n     */\n    UniquenessLevel.scheme = 'scheme';\n    /**\n     * The moniker is globally unique\n     */\n    UniquenessLevel.global = 'global';\n})(UniquenessLevel || (exports.UniquenessLevel = UniquenessLevel = {}));\n/**\n * The moniker kind.\n *\n * @since 3.16.0\n */\nvar MonikerKind;\n(function (MonikerKind) {\n    /**\n     * The moniker represent a symbol that is imported into a project\n     */\n    MonikerKind.$import = 'import';\n    /**\n     * The moniker represents a symbol that is exported from a project\n     */\n    MonikerKind.$export = 'export';\n    /**\n     * The moniker represents a symbol that is local to a project (e.g. a local\n     * variable of a function, a class not visible outside the project, ...)\n     */\n    MonikerKind.local = 'local';\n})(MonikerKind || (exports.MonikerKind = MonikerKind = {}));\n/**\n * A request to get the moniker of a symbol at a given text document position.\n * The request parameter is of type {@link TextDocumentPositionParams}.\n * The response is of type {@link Moniker Moniker[]} or `null`.\n */\nvar MonikerRequest;\n(function (MonikerRequest) {\n    MonikerRequest.method = 'textDocument/moniker';\n    MonikerRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    MonikerRequest.type = new messages_1.ProtocolRequestType(MonikerRequest.method);\n})(MonikerRequest || (exports.MonikerRequest = MonikerRequest = {}));\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.DidCloseNotebookDocumentNotification = exports.DidSaveNotebookDocumentNotification = exports.DidChangeNotebookDocumentNotification = exports.NotebookCellArrayChange = exports.DidOpenNotebookDocumentNotification = exports.NotebookDocumentSyncRegistrationType = exports.NotebookDocument = exports.NotebookCell = exports.ExecutionSummary = exports.NotebookCellKind = void 0;\nconst vscode_languageserver_types_1 = require(\"vscode-languageserver-types\");\nconst Is = require(\"./utils/is\");\nconst messages_1 = require(\"./messages\");\n/**\n * A notebook cell kind.\n *\n * @since 3.17.0\n */\nvar NotebookCellKind;\n(function (NotebookCellKind) {\n    /**\n     * A markup-cell is formatted source that is used for display.\n     */\n    NotebookCellKind.Markup = 1;\n    /**\n     * A code-cell is source code.\n     */\n    NotebookCellKind.Code = 2;\n    function is(value) {\n        return value === 1 || value === 2;\n    }\n    NotebookCellKind.is = is;\n})(NotebookCellKind || (exports.NotebookCellKind = NotebookCellKind = {}));\nvar ExecutionSummary;\n(function (ExecutionSummary) {\n    function create(executionOrder, success) {\n        const result = { executionOrder };\n        if (success === true || success === false) {\n            result.success = success;\n        }\n        return result;\n    }\n    ExecutionSummary.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && vscode_languageserver_types_1.uinteger.is(candidate.executionOrder) && (candidate.success === undefined || Is.boolean(candidate.success));\n    }\n    ExecutionSummary.is = is;\n    function equals(one, other) {\n        if (one === other) {\n            return true;\n        }\n        if (one === null || one === undefined || other === null || other === undefined) {\n            return false;\n        }\n        return one.executionOrder === other.executionOrder && one.success === other.success;\n    }\n    ExecutionSummary.equals = equals;\n})(ExecutionSummary || (exports.ExecutionSummary = ExecutionSummary = {}));\nvar NotebookCell;\n(function (NotebookCell) {\n    function create(kind, document) {\n        return { kind, document };\n    }\n    NotebookCell.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && NotebookCellKind.is(candidate.kind) && vscode_languageserver_types_1.DocumentUri.is(candidate.document) &&\n            (candidate.metadata === undefined || Is.objectLiteral(candidate.metadata));\n    }\n    NotebookCell.is = is;\n    function diff(one, two) {\n        const result = new Set();\n        if (one.document !== two.document) {\n            result.add('document');\n        }\n        if (one.kind !== two.kind) {\n            result.add('kind');\n        }\n        if (one.executionSummary !== two.executionSummary) {\n            result.add('executionSummary');\n        }\n        if ((one.metadata !== undefined || two.metadata !== undefined) && !equalsMetadata(one.metadata, two.metadata)) {\n            result.add('metadata');\n        }\n        if ((one.executionSummary !== undefined || two.executionSummary !== undefined) && !ExecutionSummary.equals(one.executionSummary, two.executionSummary)) {\n            result.add('executionSummary');\n        }\n        return result;\n    }\n    NotebookCell.diff = diff;\n    function equalsMetadata(one, other) {\n        if (one === other) {\n            return true;\n        }\n        if (one === null || one === undefined || other === null || other === undefined) {\n            return false;\n        }\n        if (typeof one !== typeof other) {\n            return false;\n        }\n        if (typeof one !== 'object') {\n            return false;\n        }\n        const oneArray = Array.isArray(one);\n        const otherArray = Array.isArray(other);\n        if (oneArray !== otherArray) {\n            return false;\n        }\n        if (oneArray && otherArray) {\n            if (one.length !== other.length) {\n                return false;\n            }\n            for (let i = 0; i < one.length; i++) {\n                if (!equalsMetadata(one[i], other[i])) {\n                    return false;\n                }\n            }\n        }\n        if (Is.objectLiteral(one) && Is.objectLiteral(other)) {\n            const oneKeys = Object.keys(one);\n            const otherKeys = Object.keys(other);\n            if (oneKeys.length !== otherKeys.length) {\n                return false;\n            }\n            oneKeys.sort();\n            otherKeys.sort();\n            if (!equalsMetadata(oneKeys, otherKeys)) {\n                return false;\n            }\n            for (let i = 0; i < oneKeys.length; i++) {\n                const prop = oneKeys[i];\n                if (!equalsMetadata(one[prop], other[prop])) {\n                    return false;\n                }\n            }\n        }\n        return true;\n    }\n})(NotebookCell || (exports.NotebookCell = NotebookCell = {}));\nvar NotebookDocument;\n(function (NotebookDocument) {\n    function create(uri, notebookType, version, cells) {\n        return { uri, notebookType, version, cells };\n    }\n    NotebookDocument.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.string(candidate.uri) && vscode_languageserver_types_1.integer.is(candidate.version) && Is.typedArray(candidate.cells, NotebookCell.is);\n    }\n    NotebookDocument.is = is;\n})(NotebookDocument || (exports.NotebookDocument = NotebookDocument = {}));\nvar NotebookDocumentSyncRegistrationType;\n(function (NotebookDocumentSyncRegistrationType) {\n    NotebookDocumentSyncRegistrationType.method = 'notebookDocument/sync';\n    NotebookDocumentSyncRegistrationType.messageDirection = messages_1.MessageDirection.clientToServer;\n    NotebookDocumentSyncRegistrationType.type = new messages_1.RegistrationType(NotebookDocumentSyncRegistrationType.method);\n})(NotebookDocumentSyncRegistrationType || (exports.NotebookDocumentSyncRegistrationType = NotebookDocumentSyncRegistrationType = {}));\n/**\n * A notification sent when a notebook opens.\n *\n * @since 3.17.0\n */\nvar DidOpenNotebookDocumentNotification;\n(function (DidOpenNotebookDocumentNotification) {\n    DidOpenNotebookDocumentNotification.method = 'notebookDocument/didOpen';\n    DidOpenNotebookDocumentNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    DidOpenNotebookDocumentNotification.type = new messages_1.ProtocolNotificationType(DidOpenNotebookDocumentNotification.method);\n    DidOpenNotebookDocumentNotification.registrationMethod = NotebookDocumentSyncRegistrationType.method;\n})(DidOpenNotebookDocumentNotification || (exports.DidOpenNotebookDocumentNotification = DidOpenNotebookDocumentNotification = {}));\nvar NotebookCellArrayChange;\n(function (NotebookCellArrayChange) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && vscode_languageserver_types_1.uinteger.is(candidate.start) && vscode_languageserver_types_1.uinteger.is(candidate.deleteCount) && (candidate.cells === undefined || Is.typedArray(candidate.cells, NotebookCell.is));\n    }\n    NotebookCellArrayChange.is = is;\n    function create(start, deleteCount, cells) {\n        const result = { start, deleteCount };\n        if (cells !== undefined) {\n            result.cells = cells;\n        }\n        return result;\n    }\n    NotebookCellArrayChange.create = create;\n})(NotebookCellArrayChange || (exports.NotebookCellArrayChange = NotebookCellArrayChange = {}));\nvar DidChangeNotebookDocumentNotification;\n(function (DidChangeNotebookDocumentNotification) {\n    DidChangeNotebookDocumentNotification.method = 'notebookDocument/didChange';\n    DidChangeNotebookDocumentNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    DidChangeNotebookDocumentNotification.type = new messages_1.ProtocolNotificationType(DidChangeNotebookDocumentNotification.method);\n    DidChangeNotebookDocumentNotification.registrationMethod = NotebookDocumentSyncRegistrationType.method;\n})(DidChangeNotebookDocumentNotification || (exports.DidChangeNotebookDocumentNotification = DidChangeNotebookDocumentNotification = {}));\n/**\n * A notification sent when a notebook document is saved.\n *\n * @since 3.17.0\n */\nvar DidSaveNotebookDocumentNotification;\n(function (DidSaveNotebookDocumentNotification) {\n    DidSaveNotebookDocumentNotification.method = 'notebookDocument/didSave';\n    DidSaveNotebookDocumentNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    DidSaveNotebookDocumentNotification.type = new messages_1.ProtocolNotificationType(DidSaveNotebookDocumentNotification.method);\n    DidSaveNotebookDocumentNotification.registrationMethod = NotebookDocumentSyncRegistrationType.method;\n})(DidSaveNotebookDocumentNotification || (exports.DidSaveNotebookDocumentNotification = DidSaveNotebookDocumentNotification = {}));\n/**\n * A notification sent when a notebook closes.\n *\n * @since 3.17.0\n */\nvar DidCloseNotebookDocumentNotification;\n(function (DidCloseNotebookDocumentNotification) {\n    DidCloseNotebookDocumentNotification.method = 'notebookDocument/didClose';\n    DidCloseNotebookDocumentNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    DidCloseNotebookDocumentNotification.type = new messages_1.ProtocolNotificationType(DidCloseNotebookDocumentNotification.method);\n    DidCloseNotebookDocumentNotification.registrationMethod = NotebookDocumentSyncRegistrationType.method;\n})(DidCloseNotebookDocumentNotification || (exports.DidCloseNotebookDocumentNotification = DidCloseNotebookDocumentNotification = {}));\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.WorkDoneProgressCancelNotification = exports.WorkDoneProgressCreateRequest = exports.WorkDoneProgress = void 0;\nconst vscode_jsonrpc_1 = require(\"vscode-jsonrpc\");\nconst messages_1 = require(\"./messages\");\nvar WorkDoneProgress;\n(function (WorkDoneProgress) {\n    WorkDoneProgress.type = new vscode_jsonrpc_1.ProgressType();\n    function is(value) {\n        return value === WorkDoneProgress.type;\n    }\n    WorkDoneProgress.is = is;\n})(WorkDoneProgress || (exports.WorkDoneProgress = WorkDoneProgress = {}));\n/**\n * The `window/workDoneProgress/create` request is sent from the server to the client to initiate progress\n * reporting from the server.\n */\nvar WorkDoneProgressCreateRequest;\n(function (WorkDoneProgressCreateRequest) {\n    WorkDoneProgressCreateRequest.method = 'window/workDoneProgress/create';\n    WorkDoneProgressCreateRequest.messageDirection = messages_1.MessageDirection.serverToClient;\n    WorkDoneProgressCreateRequest.type = new messages_1.ProtocolRequestType(WorkDoneProgressCreateRequest.method);\n})(WorkDoneProgressCreateRequest || (exports.WorkDoneProgressCreateRequest = WorkDoneProgressCreateRequest = {}));\n/**\n * The `window/workDoneProgress/cancel` notification is sent from  the client to the server to cancel a progress\n * initiated on the server side.\n */\nvar WorkDoneProgressCancelNotification;\n(function (WorkDoneProgressCancelNotification) {\n    WorkDoneProgressCancelNotification.method = 'window/workDoneProgress/cancel';\n    WorkDoneProgressCancelNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    WorkDoneProgressCancelNotification.type = new messages_1.ProtocolNotificationType(WorkDoneProgressCancelNotification.method);\n})(WorkDoneProgressCancelNotification || (exports.WorkDoneProgressCancelNotification = WorkDoneProgressCancelNotification = {}));\n","\"use strict\";\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.SelectionRangeRequest = void 0;\nconst messages_1 = require(\"./messages\");\n/**\n * A request to provide selection ranges in a document. The request's\n * parameter is of type {@link SelectionRangeParams}, the\n * response is of type {@link SelectionRange SelectionRange[]} or a Thenable\n * that resolves to such.\n */\nvar SelectionRangeRequest;\n(function (SelectionRangeRequest) {\n    SelectionRangeRequest.method = 'textDocument/selectionRange';\n    SelectionRangeRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    SelectionRangeRequest.type = new messages_1.ProtocolRequestType(SelectionRangeRequest.method);\n})(SelectionRangeRequest || (exports.SelectionRangeRequest = SelectionRangeRequest = {}));\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.SemanticTokensRefreshRequest = exports.SemanticTokensRangeRequest = exports.SemanticTokensDeltaRequest = exports.SemanticTokensRequest = exports.SemanticTokensRegistrationType = exports.TokenFormat = void 0;\nconst messages_1 = require(\"./messages\");\n//------- 'textDocument/semanticTokens' -----\nvar TokenFormat;\n(function (TokenFormat) {\n    TokenFormat.Relative = 'relative';\n})(TokenFormat || (exports.TokenFormat = TokenFormat = {}));\nvar SemanticTokensRegistrationType;\n(function (SemanticTokensRegistrationType) {\n    SemanticTokensRegistrationType.method = 'textDocument/semanticTokens';\n    SemanticTokensRegistrationType.type = new messages_1.RegistrationType(SemanticTokensRegistrationType.method);\n})(SemanticTokensRegistrationType || (exports.SemanticTokensRegistrationType = SemanticTokensRegistrationType = {}));\n/**\n * @since 3.16.0\n */\nvar SemanticTokensRequest;\n(function (SemanticTokensRequest) {\n    SemanticTokensRequest.method = 'textDocument/semanticTokens/full';\n    SemanticTokensRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    SemanticTokensRequest.type = new messages_1.ProtocolRequestType(SemanticTokensRequest.method);\n    SemanticTokensRequest.registrationMethod = SemanticTokensRegistrationType.method;\n})(SemanticTokensRequest || (exports.SemanticTokensRequest = SemanticTokensRequest = {}));\n/**\n * @since 3.16.0\n */\nvar SemanticTokensDeltaRequest;\n(function (SemanticTokensDeltaRequest) {\n    SemanticTokensDeltaRequest.method = 'textDocument/semanticTokens/full/delta';\n    SemanticTokensDeltaRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    SemanticTokensDeltaRequest.type = new messages_1.ProtocolRequestType(SemanticTokensDeltaRequest.method);\n    SemanticTokensDeltaRequest.registrationMethod = SemanticTokensRegistrationType.method;\n})(SemanticTokensDeltaRequest || (exports.SemanticTokensDeltaRequest = SemanticTokensDeltaRequest = {}));\n/**\n * @since 3.16.0\n */\nvar SemanticTokensRangeRequest;\n(function (SemanticTokensRangeRequest) {\n    SemanticTokensRangeRequest.method = 'textDocument/semanticTokens/range';\n    SemanticTokensRangeRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    SemanticTokensRangeRequest.type = new messages_1.ProtocolRequestType(SemanticTokensRangeRequest.method);\n    SemanticTokensRangeRequest.registrationMethod = SemanticTokensRegistrationType.method;\n})(SemanticTokensRangeRequest || (exports.SemanticTokensRangeRequest = SemanticTokensRangeRequest = {}));\n/**\n * @since 3.16.0\n */\nvar SemanticTokensRefreshRequest;\n(function (SemanticTokensRefreshRequest) {\n    SemanticTokensRefreshRequest.method = `workspace/semanticTokens/refresh`;\n    SemanticTokensRefreshRequest.messageDirection = messages_1.MessageDirection.serverToClient;\n    SemanticTokensRefreshRequest.type = new messages_1.ProtocolRequestType0(SemanticTokensRefreshRequest.method);\n})(SemanticTokensRefreshRequest || (exports.SemanticTokensRefreshRequest = SemanticTokensRefreshRequest = {}));\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ShowDocumentRequest = void 0;\nconst messages_1 = require(\"./messages\");\n/**\n * A request to show a document. This request might open an\n * external program depending on the value of the URI to open.\n * For example a request to open `https://code.visualstudio.com/`\n * will very likely open the URI in a WEB browser.\n *\n * @since 3.16.0\n*/\nvar ShowDocumentRequest;\n(function (ShowDocumentRequest) {\n    ShowDocumentRequest.method = 'window/showDocument';\n    ShowDocumentRequest.messageDirection = messages_1.MessageDirection.serverToClient;\n    ShowDocumentRequest.type = new messages_1.ProtocolRequestType(ShowDocumentRequest.method);\n})(ShowDocumentRequest || (exports.ShowDocumentRequest = ShowDocumentRequest = {}));\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.TypeDefinitionRequest = void 0;\nconst messages_1 = require(\"./messages\");\n// @ts-ignore: to avoid inlining LocatioLink as dynamic import\nlet __noDynamicImport;\n/**\n * A request to resolve the type definition locations of a symbol at a given text\n * document position. The request's parameter is of type {@link TextDocumentPositionParams}\n * the response is of type {@link Definition} or a Thenable that resolves to such.\n */\nvar TypeDefinitionRequest;\n(function (TypeDefinitionRequest) {\n    TypeDefinitionRequest.method = 'textDocument/typeDefinition';\n    TypeDefinitionRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    TypeDefinitionRequest.type = new messages_1.ProtocolRequestType(TypeDefinitionRequest.method);\n})(TypeDefinitionRequest || (exports.TypeDefinitionRequest = TypeDefinitionRequest = {}));\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) TypeFox, Microsoft and others. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.TypeHierarchySubtypesRequest = exports.TypeHierarchySupertypesRequest = exports.TypeHierarchyPrepareRequest = void 0;\nconst messages_1 = require(\"./messages\");\n/**\n * A request to result a `TypeHierarchyItem` in a document at a given position.\n * Can be used as an input to a subtypes or supertypes type hierarchy.\n *\n * @since 3.17.0\n */\nvar TypeHierarchyPrepareRequest;\n(function (TypeHierarchyPrepareRequest) {\n    TypeHierarchyPrepareRequest.method = 'textDocument/prepareTypeHierarchy';\n    TypeHierarchyPrepareRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    TypeHierarchyPrepareRequest.type = new messages_1.ProtocolRequestType(TypeHierarchyPrepareRequest.method);\n})(TypeHierarchyPrepareRequest || (exports.TypeHierarchyPrepareRequest = TypeHierarchyPrepareRequest = {}));\n/**\n * A request to resolve the supertypes for a given `TypeHierarchyItem`.\n *\n * @since 3.17.0\n */\nvar TypeHierarchySupertypesRequest;\n(function (TypeHierarchySupertypesRequest) {\n    TypeHierarchySupertypesRequest.method = 'typeHierarchy/supertypes';\n    TypeHierarchySupertypesRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    TypeHierarchySupertypesRequest.type = new messages_1.ProtocolRequestType(TypeHierarchySupertypesRequest.method);\n})(TypeHierarchySupertypesRequest || (exports.TypeHierarchySupertypesRequest = TypeHierarchySupertypesRequest = {}));\n/**\n * A request to resolve the subtypes for a given `TypeHierarchyItem`.\n *\n * @since 3.17.0\n */\nvar TypeHierarchySubtypesRequest;\n(function (TypeHierarchySubtypesRequest) {\n    TypeHierarchySubtypesRequest.method = 'typeHierarchy/subtypes';\n    TypeHierarchySubtypesRequest.messageDirection = messages_1.MessageDirection.clientToServer;\n    TypeHierarchySubtypesRequest.type = new messages_1.ProtocolRequestType(TypeHierarchySubtypesRequest.method);\n})(TypeHierarchySubtypesRequest || (exports.TypeHierarchySubtypesRequest = TypeHierarchySubtypesRequest = {}));\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.DidChangeWorkspaceFoldersNotification = exports.WorkspaceFoldersRequest = void 0;\nconst messages_1 = require(\"./messages\");\n/**\n * The `workspace/workspaceFolders` is sent from the server to the client to fetch the open workspace folders.\n */\nvar WorkspaceFoldersRequest;\n(function (WorkspaceFoldersRequest) {\n    WorkspaceFoldersRequest.method = 'workspace/workspaceFolders';\n    WorkspaceFoldersRequest.messageDirection = messages_1.MessageDirection.serverToClient;\n    WorkspaceFoldersRequest.type = new messages_1.ProtocolRequestType0(WorkspaceFoldersRequest.method);\n})(WorkspaceFoldersRequest || (exports.WorkspaceFoldersRequest = WorkspaceFoldersRequest = {}));\n/**\n * The `workspace/didChangeWorkspaceFolders` notification is sent from the client to the server when the workspace\n * folder configuration changes.\n */\nvar DidChangeWorkspaceFoldersNotification;\n(function (DidChangeWorkspaceFoldersNotification) {\n    DidChangeWorkspaceFoldersNotification.method = 'workspace/didChangeWorkspaceFolders';\n    DidChangeWorkspaceFoldersNotification.messageDirection = messages_1.MessageDirection.clientToServer;\n    DidChangeWorkspaceFoldersNotification.type = new messages_1.ProtocolNotificationType(DidChangeWorkspaceFoldersNotification.method);\n})(DidChangeWorkspaceFoldersNotification || (exports.DidChangeWorkspaceFoldersNotification = DidChangeWorkspaceFoldersNotification = {}));\n","/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\n'use strict';\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.objectLiteral = exports.typedArray = exports.stringArray = exports.array = exports.func = exports.error = exports.number = exports.string = exports.boolean = void 0;\nfunction boolean(value) {\n    return value === true || value === false;\n}\nexports.boolean = boolean;\nfunction string(value) {\n    return typeof value === 'string' || value instanceof String;\n}\nexports.string = string;\nfunction number(value) {\n    return typeof value === 'number' || value instanceof Number;\n}\nexports.number = number;\nfunction error(value) {\n    return value instanceof Error;\n}\nexports.error = error;\nfunction func(value) {\n    return typeof value === 'function';\n}\nexports.func = func;\nfunction array(value) {\n    return Array.isArray(value);\n}\nexports.array = array;\nfunction stringArray(value) {\n    return array(value) && value.every(elem => string(elem));\n}\nexports.stringArray = stringArray;\nfunction typedArray(value, check) {\n    return Array.isArray(value) && value.every(check);\n}\nexports.typedArray = typedArray;\nfunction objectLiteral(value) {\n    // Strictly speaking class instances pass this check as well. Since the LSP\n    // doesn't use classes we ignore this for now. If we do we need to add something\n    // like this: `Object.getPrototypeOf(Object.getPrototypeOf(x)) === null`\n    return value !== null && typeof value === 'object';\n}\nexports.objectLiteral = objectLiteral;\n","/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\n'use strict';\nexport var DocumentUri;\n(function (DocumentUri) {\n    function is(value) {\n        return typeof value === 'string';\n    }\n    DocumentUri.is = is;\n})(DocumentUri || (DocumentUri = {}));\nexport var URI;\n(function (URI) {\n    function is(value) {\n        return typeof value === 'string';\n    }\n    URI.is = is;\n})(URI || (URI = {}));\nexport var integer;\n(function (integer) {\n    integer.MIN_VALUE = -2147483648;\n    integer.MAX_VALUE = 2147483647;\n    function is(value) {\n        return typeof value === 'number' && integer.MIN_VALUE <= value && value <= integer.MAX_VALUE;\n    }\n    integer.is = is;\n})(integer || (integer = {}));\nexport var uinteger;\n(function (uinteger) {\n    uinteger.MIN_VALUE = 0;\n    uinteger.MAX_VALUE = 2147483647;\n    function is(value) {\n        return typeof value === 'number' && uinteger.MIN_VALUE <= value && value <= uinteger.MAX_VALUE;\n    }\n    uinteger.is = is;\n})(uinteger || (uinteger = {}));\n/**\n * The Position namespace provides helper functions to work with\n * {@link Position} literals.\n */\nexport var Position;\n(function (Position) {\n    /**\n     * Creates a new Position literal from the given line and character.\n     * @param line The position's line.\n     * @param character The position's character.\n     */\n    function create(line, character) {\n        if (line === Number.MAX_VALUE) {\n            line = uinteger.MAX_VALUE;\n        }\n        if (character === Number.MAX_VALUE) {\n            character = uinteger.MAX_VALUE;\n        }\n        return { line, character };\n    }\n    Position.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Position} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Is.uinteger(candidate.line) && Is.uinteger(candidate.character);\n    }\n    Position.is = is;\n})(Position || (Position = {}));\n/**\n * The Range namespace provides helper functions to work with\n * {@link Range} literals.\n */\nexport var Range;\n(function (Range) {\n    function create(one, two, three, four) {\n        if (Is.uinteger(one) && Is.uinteger(two) && Is.uinteger(three) && Is.uinteger(four)) {\n            return { start: Position.create(one, two), end: Position.create(three, four) };\n        }\n        else if (Position.is(one) && Position.is(two)) {\n            return { start: one, end: two };\n        }\n        else {\n            throw new Error(`Range#create called with invalid arguments[${one}, ${two}, ${three}, ${four}]`);\n        }\n    }\n    Range.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Range} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Position.is(candidate.start) && Position.is(candidate.end);\n    }\n    Range.is = is;\n})(Range || (Range = {}));\n/**\n * The Location namespace provides helper functions to work with\n * {@link Location} literals.\n */\nexport var Location;\n(function (Location) {\n    /**\n     * Creates a Location literal.\n     * @param uri The location's uri.\n     * @param range The location's range.\n     */\n    function create(uri, range) {\n        return { uri, range };\n    }\n    Location.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Location} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.range) && (Is.string(candidate.uri) || Is.undefined(candidate.uri));\n    }\n    Location.is = is;\n})(Location || (Location = {}));\n/**\n * The LocationLink namespace provides helper functions to work with\n * {@link LocationLink} literals.\n */\nexport var LocationLink;\n(function (LocationLink) {\n    /**\n     * Creates a LocationLink literal.\n     * @param targetUri The definition's uri.\n     * @param targetRange The full range of the definition.\n     * @param targetSelectionRange The span of the symbol definition at the target.\n     * @param originSelectionRange The span of the symbol being defined in the originating source file.\n     */\n    function create(targetUri, targetRange, targetSelectionRange, originSelectionRange) {\n        return { targetUri, targetRange, targetSelectionRange, originSelectionRange };\n    }\n    LocationLink.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link LocationLink} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.targetRange) && Is.string(candidate.targetUri)\n            && Range.is(candidate.targetSelectionRange)\n            && (Range.is(candidate.originSelectionRange) || Is.undefined(candidate.originSelectionRange));\n    }\n    LocationLink.is = is;\n})(LocationLink || (LocationLink = {}));\n/**\n * The Color namespace provides helper functions to work with\n * {@link Color} literals.\n */\nexport var Color;\n(function (Color) {\n    /**\n     * Creates a new Color literal.\n     */\n    function create(red, green, blue, alpha) {\n        return {\n            red,\n            green,\n            blue,\n            alpha,\n        };\n    }\n    Color.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Color} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.numberRange(candidate.red, 0, 1)\n            && Is.numberRange(candidate.green, 0, 1)\n            && Is.numberRange(candidate.blue, 0, 1)\n            && Is.numberRange(candidate.alpha, 0, 1);\n    }\n    Color.is = is;\n})(Color || (Color = {}));\n/**\n * The ColorInformation namespace provides helper functions to work with\n * {@link ColorInformation} literals.\n */\nexport var ColorInformation;\n(function (ColorInformation) {\n    /**\n     * Creates a new ColorInformation literal.\n     */\n    function create(range, color) {\n        return {\n            range,\n            color,\n        };\n    }\n    ColorInformation.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link ColorInformation} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.range) && Color.is(candidate.color);\n    }\n    ColorInformation.is = is;\n})(ColorInformation || (ColorInformation = {}));\n/**\n * The Color namespace provides helper functions to work with\n * {@link ColorPresentation} literals.\n */\nexport var ColorPresentation;\n(function (ColorPresentation) {\n    /**\n     * Creates a new ColorInformation literal.\n     */\n    function create(label, textEdit, additionalTextEdits) {\n        return {\n            label,\n            textEdit,\n            additionalTextEdits,\n        };\n    }\n    ColorPresentation.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link ColorInformation} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.string(candidate.label)\n            && (Is.undefined(candidate.textEdit) || TextEdit.is(candidate))\n            && (Is.undefined(candidate.additionalTextEdits) || Is.typedArray(candidate.additionalTextEdits, TextEdit.is));\n    }\n    ColorPresentation.is = is;\n})(ColorPresentation || (ColorPresentation = {}));\n/**\n * A set of predefined range kinds.\n */\nexport var FoldingRangeKind;\n(function (FoldingRangeKind) {\n    /**\n     * Folding range for a comment\n     */\n    FoldingRangeKind.Comment = 'comment';\n    /**\n     * Folding range for an import or include\n     */\n    FoldingRangeKind.Imports = 'imports';\n    /**\n     * Folding range for a region (e.g. `#region`)\n     */\n    FoldingRangeKind.Region = 'region';\n})(FoldingRangeKind || (FoldingRangeKind = {}));\n/**\n * The folding range namespace provides helper functions to work with\n * {@link FoldingRange} literals.\n */\nexport var FoldingRange;\n(function (FoldingRange) {\n    /**\n     * Creates a new FoldingRange literal.\n     */\n    function create(startLine, endLine, startCharacter, endCharacter, kind, collapsedText) {\n        const result = {\n            startLine,\n            endLine\n        };\n        if (Is.defined(startCharacter)) {\n            result.startCharacter = startCharacter;\n        }\n        if (Is.defined(endCharacter)) {\n            result.endCharacter = endCharacter;\n        }\n        if (Is.defined(kind)) {\n            result.kind = kind;\n        }\n        if (Is.defined(collapsedText)) {\n            result.collapsedText = collapsedText;\n        }\n        return result;\n    }\n    FoldingRange.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link FoldingRange} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.uinteger(candidate.startLine) && Is.uinteger(candidate.startLine)\n            && (Is.undefined(candidate.startCharacter) || Is.uinteger(candidate.startCharacter))\n            && (Is.undefined(candidate.endCharacter) || Is.uinteger(candidate.endCharacter))\n            && (Is.undefined(candidate.kind) || Is.string(candidate.kind));\n    }\n    FoldingRange.is = is;\n})(FoldingRange || (FoldingRange = {}));\n/**\n * The DiagnosticRelatedInformation namespace provides helper functions to work with\n * {@link DiagnosticRelatedInformation} literals.\n */\nexport var DiagnosticRelatedInformation;\n(function (DiagnosticRelatedInformation) {\n    /**\n     * Creates a new DiagnosticRelatedInformation literal.\n     */\n    function create(location, message) {\n        return {\n            location,\n            message\n        };\n    }\n    DiagnosticRelatedInformation.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link DiagnosticRelatedInformation} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Location.is(candidate.location) && Is.string(candidate.message);\n    }\n    DiagnosticRelatedInformation.is = is;\n})(DiagnosticRelatedInformation || (DiagnosticRelatedInformation = {}));\n/**\n * The diagnostic's severity.\n */\nexport var DiagnosticSeverity;\n(function (DiagnosticSeverity) {\n    /**\n     * Reports an error.\n     */\n    DiagnosticSeverity.Error = 1;\n    /**\n     * Reports a warning.\n     */\n    DiagnosticSeverity.Warning = 2;\n    /**\n     * Reports an information.\n     */\n    DiagnosticSeverity.Information = 3;\n    /**\n     * Reports a hint.\n     */\n    DiagnosticSeverity.Hint = 4;\n})(DiagnosticSeverity || (DiagnosticSeverity = {}));\n/**\n * The diagnostic tags.\n *\n * @since 3.15.0\n */\nexport var DiagnosticTag;\n(function (DiagnosticTag) {\n    /**\n     * Unused or unnecessary code.\n     *\n     * Clients are allowed to render diagnostics with this tag faded out instead of having\n     * an error squiggle.\n     */\n    DiagnosticTag.Unnecessary = 1;\n    /**\n     * Deprecated or obsolete code.\n     *\n     * Clients are allowed to rendered diagnostics with this tag strike through.\n     */\n    DiagnosticTag.Deprecated = 2;\n})(DiagnosticTag || (DiagnosticTag = {}));\n/**\n * The CodeDescription namespace provides functions to deal with descriptions for diagnostic codes.\n *\n * @since 3.16.0\n */\nexport var CodeDescription;\n(function (CodeDescription) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.string(candidate.href);\n    }\n    CodeDescription.is = is;\n})(CodeDescription || (CodeDescription = {}));\n/**\n * The Diagnostic namespace provides helper functions to work with\n * {@link Diagnostic} literals.\n */\nexport var Diagnostic;\n(function (Diagnostic) {\n    /**\n     * Creates a new Diagnostic literal.\n     */\n    function create(range, message, severity, code, source, relatedInformation) {\n        let result = { range, message };\n        if (Is.defined(severity)) {\n            result.severity = severity;\n        }\n        if (Is.defined(code)) {\n            result.code = code;\n        }\n        if (Is.defined(source)) {\n            result.source = source;\n        }\n        if (Is.defined(relatedInformation)) {\n            result.relatedInformation = relatedInformation;\n        }\n        return result;\n    }\n    Diagnostic.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Diagnostic} interface.\n     */\n    function is(value) {\n        var _a;\n        let candidate = value;\n        return Is.defined(candidate)\n            && Range.is(candidate.range)\n            && Is.string(candidate.message)\n            && (Is.number(candidate.severity) || Is.undefined(candidate.severity))\n            && (Is.integer(candidate.code) || Is.string(candidate.code) || Is.undefined(candidate.code))\n            && (Is.undefined(candidate.codeDescription) || (Is.string((_a = candidate.codeDescription) === null || _a === void 0 ? void 0 : _a.href)))\n            && (Is.string(candidate.source) || Is.undefined(candidate.source))\n            && (Is.undefined(candidate.relatedInformation) || Is.typedArray(candidate.relatedInformation, DiagnosticRelatedInformation.is));\n    }\n    Diagnostic.is = is;\n})(Diagnostic || (Diagnostic = {}));\n/**\n * The Command namespace provides helper functions to work with\n * {@link Command} literals.\n */\nexport var Command;\n(function (Command) {\n    /**\n     * Creates a new Command literal.\n     */\n    function create(title, command, ...args) {\n        let result = { title, command };\n        if (Is.defined(args) && args.length > 0) {\n            result.arguments = args;\n        }\n        return result;\n    }\n    Command.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Command} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.title) && Is.string(candidate.command);\n    }\n    Command.is = is;\n})(Command || (Command = {}));\n/**\n * The TextEdit namespace provides helper function to create replace,\n * insert and delete edits more easily.\n */\nexport var TextEdit;\n(function (TextEdit) {\n    /**\n     * Creates a replace text edit.\n     * @param range The range of text to be replaced.\n     * @param newText The new text.\n     */\n    function replace(range, newText) {\n        return { range, newText };\n    }\n    TextEdit.replace = replace;\n    /**\n     * Creates an insert text edit.\n     * @param position The position to insert the text at.\n     * @param newText The text to be inserted.\n     */\n    function insert(position, newText) {\n        return { range: { start: position, end: position }, newText };\n    }\n    TextEdit.insert = insert;\n    /**\n     * Creates a delete text edit.\n     * @param range The range of text to be deleted.\n     */\n    function del(range) {\n        return { range, newText: '' };\n    }\n    TextEdit.del = del;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate)\n            && Is.string(candidate.newText)\n            && Range.is(candidate.range);\n    }\n    TextEdit.is = is;\n})(TextEdit || (TextEdit = {}));\nexport var ChangeAnnotation;\n(function (ChangeAnnotation) {\n    function create(label, needsConfirmation, description) {\n        const result = { label };\n        if (needsConfirmation !== undefined) {\n            result.needsConfirmation = needsConfirmation;\n        }\n        if (description !== undefined) {\n            result.description = description;\n        }\n        return result;\n    }\n    ChangeAnnotation.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.string(candidate.label) &&\n            (Is.boolean(candidate.needsConfirmation) || candidate.needsConfirmation === undefined) &&\n            (Is.string(candidate.description) || candidate.description === undefined);\n    }\n    ChangeAnnotation.is = is;\n})(ChangeAnnotation || (ChangeAnnotation = {}));\nexport var ChangeAnnotationIdentifier;\n(function (ChangeAnnotationIdentifier) {\n    function is(value) {\n        const candidate = value;\n        return Is.string(candidate);\n    }\n    ChangeAnnotationIdentifier.is = is;\n})(ChangeAnnotationIdentifier || (ChangeAnnotationIdentifier = {}));\nexport var AnnotatedTextEdit;\n(function (AnnotatedTextEdit) {\n    /**\n     * Creates an annotated replace text edit.\n     *\n     * @param range The range of text to be replaced.\n     * @param newText The new text.\n     * @param annotation The annotation.\n     */\n    function replace(range, newText, annotation) {\n        return { range, newText, annotationId: annotation };\n    }\n    AnnotatedTextEdit.replace = replace;\n    /**\n     * Creates an annotated insert text edit.\n     *\n     * @param position The position to insert the text at.\n     * @param newText The text to be inserted.\n     * @param annotation The annotation.\n     */\n    function insert(position, newText, annotation) {\n        return { range: { start: position, end: position }, newText, annotationId: annotation };\n    }\n    AnnotatedTextEdit.insert = insert;\n    /**\n     * Creates an annotated delete text edit.\n     *\n     * @param range The range of text to be deleted.\n     * @param annotation The annotation.\n     */\n    function del(range, annotation) {\n        return { range, newText: '', annotationId: annotation };\n    }\n    AnnotatedTextEdit.del = del;\n    function is(value) {\n        const candidate = value;\n        return TextEdit.is(candidate) && (ChangeAnnotation.is(candidate.annotationId) || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    AnnotatedTextEdit.is = is;\n})(AnnotatedTextEdit || (AnnotatedTextEdit = {}));\n/**\n * The TextDocumentEdit namespace provides helper function to create\n * an edit that manipulates a text document.\n */\nexport var TextDocumentEdit;\n(function (TextDocumentEdit) {\n    /**\n     * Creates a new `TextDocumentEdit`\n     */\n    function create(textDocument, edits) {\n        return { textDocument, edits };\n    }\n    TextDocumentEdit.create = create;\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate)\n            && OptionalVersionedTextDocumentIdentifier.is(candidate.textDocument)\n            && Array.isArray(candidate.edits);\n    }\n    TextDocumentEdit.is = is;\n})(TextDocumentEdit || (TextDocumentEdit = {}));\nexport var CreateFile;\n(function (CreateFile) {\n    function create(uri, options, annotation) {\n        let result = {\n            kind: 'create',\n            uri\n        };\n        if (options !== undefined && (options.overwrite !== undefined || options.ignoreIfExists !== undefined)) {\n            result.options = options;\n        }\n        if (annotation !== undefined) {\n            result.annotationId = annotation;\n        }\n        return result;\n    }\n    CreateFile.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && candidate.kind === 'create' && Is.string(candidate.uri) && (candidate.options === undefined ||\n            ((candidate.options.overwrite === undefined || Is.boolean(candidate.options.overwrite)) && (candidate.options.ignoreIfExists === undefined || Is.boolean(candidate.options.ignoreIfExists)))) && (candidate.annotationId === undefined || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    CreateFile.is = is;\n})(CreateFile || (CreateFile = {}));\nexport var RenameFile;\n(function (RenameFile) {\n    function create(oldUri, newUri, options, annotation) {\n        let result = {\n            kind: 'rename',\n            oldUri,\n            newUri\n        };\n        if (options !== undefined && (options.overwrite !== undefined || options.ignoreIfExists !== undefined)) {\n            result.options = options;\n        }\n        if (annotation !== undefined) {\n            result.annotationId = annotation;\n        }\n        return result;\n    }\n    RenameFile.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && candidate.kind === 'rename' && Is.string(candidate.oldUri) && Is.string(candidate.newUri) && (candidate.options === undefined ||\n            ((candidate.options.overwrite === undefined || Is.boolean(candidate.options.overwrite)) && (candidate.options.ignoreIfExists === undefined || Is.boolean(candidate.options.ignoreIfExists)))) && (candidate.annotationId === undefined || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    RenameFile.is = is;\n})(RenameFile || (RenameFile = {}));\nexport var DeleteFile;\n(function (DeleteFile) {\n    function create(uri, options, annotation) {\n        let result = {\n            kind: 'delete',\n            uri\n        };\n        if (options !== undefined && (options.recursive !== undefined || options.ignoreIfNotExists !== undefined)) {\n            result.options = options;\n        }\n        if (annotation !== undefined) {\n            result.annotationId = annotation;\n        }\n        return result;\n    }\n    DeleteFile.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && candidate.kind === 'delete' && Is.string(candidate.uri) && (candidate.options === undefined ||\n            ((candidate.options.recursive === undefined || Is.boolean(candidate.options.recursive)) && (candidate.options.ignoreIfNotExists === undefined || Is.boolean(candidate.options.ignoreIfNotExists)))) && (candidate.annotationId === undefined || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    DeleteFile.is = is;\n})(DeleteFile || (DeleteFile = {}));\nexport var WorkspaceEdit;\n(function (WorkspaceEdit) {\n    function is(value) {\n        let candidate = value;\n        return candidate &&\n            (candidate.changes !== undefined || candidate.documentChanges !== undefined) &&\n            (candidate.documentChanges === undefined || candidate.documentChanges.every((change) => {\n                if (Is.string(change.kind)) {\n                    return CreateFile.is(change) || RenameFile.is(change) || DeleteFile.is(change);\n                }\n                else {\n                    return TextDocumentEdit.is(change);\n                }\n            }));\n    }\n    WorkspaceEdit.is = is;\n})(WorkspaceEdit || (WorkspaceEdit = {}));\nclass TextEditChangeImpl {\n    constructor(edits, changeAnnotations) {\n        this.edits = edits;\n        this.changeAnnotations = changeAnnotations;\n    }\n    insert(position, newText, annotation) {\n        let edit;\n        let id;\n        if (annotation === undefined) {\n            edit = TextEdit.insert(position, newText);\n        }\n        else if (ChangeAnnotationIdentifier.is(annotation)) {\n            id = annotation;\n            edit = AnnotatedTextEdit.insert(position, newText, annotation);\n        }\n        else {\n            this.assertChangeAnnotations(this.changeAnnotations);\n            id = this.changeAnnotations.manage(annotation);\n            edit = AnnotatedTextEdit.insert(position, newText, id);\n        }\n        this.edits.push(edit);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    replace(range, newText, annotation) {\n        let edit;\n        let id;\n        if (annotation === undefined) {\n            edit = TextEdit.replace(range, newText);\n        }\n        else if (ChangeAnnotationIdentifier.is(annotation)) {\n            id = annotation;\n            edit = AnnotatedTextEdit.replace(range, newText, annotation);\n        }\n        else {\n            this.assertChangeAnnotations(this.changeAnnotations);\n            id = this.changeAnnotations.manage(annotation);\n            edit = AnnotatedTextEdit.replace(range, newText, id);\n        }\n        this.edits.push(edit);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    delete(range, annotation) {\n        let edit;\n        let id;\n        if (annotation === undefined) {\n            edit = TextEdit.del(range);\n        }\n        else if (ChangeAnnotationIdentifier.is(annotation)) {\n            id = annotation;\n            edit = AnnotatedTextEdit.del(range, annotation);\n        }\n        else {\n            this.assertChangeAnnotations(this.changeAnnotations);\n            id = this.changeAnnotations.manage(annotation);\n            edit = AnnotatedTextEdit.del(range, id);\n        }\n        this.edits.push(edit);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    add(edit) {\n        this.edits.push(edit);\n    }\n    all() {\n        return this.edits;\n    }\n    clear() {\n        this.edits.splice(0, this.edits.length);\n    }\n    assertChangeAnnotations(value) {\n        if (value === undefined) {\n            throw new Error(`Text edit change is not configured to manage change annotations.`);\n        }\n    }\n}\n/**\n * A helper class\n */\nclass ChangeAnnotations {\n    constructor(annotations) {\n        this._annotations = annotations === undefined ? Object.create(null) : annotations;\n        this._counter = 0;\n        this._size = 0;\n    }\n    all() {\n        return this._annotations;\n    }\n    get size() {\n        return this._size;\n    }\n    manage(idOrAnnotation, annotation) {\n        let id;\n        if (ChangeAnnotationIdentifier.is(idOrAnnotation)) {\n            id = idOrAnnotation;\n        }\n        else {\n            id = this.nextId();\n            annotation = idOrAnnotation;\n        }\n        if (this._annotations[id] !== undefined) {\n            throw new Error(`Id ${id} is already in use.`);\n        }\n        if (annotation === undefined) {\n            throw new Error(`No annotation provided for id ${id}`);\n        }\n        this._annotations[id] = annotation;\n        this._size++;\n        return id;\n    }\n    nextId() {\n        this._counter++;\n        return this._counter.toString();\n    }\n}\n/**\n * A workspace change helps constructing changes to a workspace.\n */\nexport class WorkspaceChange {\n    constructor(workspaceEdit) {\n        this._textEditChanges = Object.create(null);\n        if (workspaceEdit !== undefined) {\n            this._workspaceEdit = workspaceEdit;\n            if (workspaceEdit.documentChanges) {\n                this._changeAnnotations = new ChangeAnnotations(workspaceEdit.changeAnnotations);\n                workspaceEdit.changeAnnotations = this._changeAnnotations.all();\n                workspaceEdit.documentChanges.forEach((change) => {\n                    if (TextDocumentEdit.is(change)) {\n                        const textEditChange = new TextEditChangeImpl(change.edits, this._changeAnnotations);\n                        this._textEditChanges[change.textDocument.uri] = textEditChange;\n                    }\n                });\n            }\n            else if (workspaceEdit.changes) {\n                Object.keys(workspaceEdit.changes).forEach((key) => {\n                    const textEditChange = new TextEditChangeImpl(workspaceEdit.changes[key]);\n                    this._textEditChanges[key] = textEditChange;\n                });\n            }\n        }\n        else {\n            this._workspaceEdit = {};\n        }\n    }\n    /**\n     * Returns the underlying {@link WorkspaceEdit} literal\n     * use to be returned from a workspace edit operation like rename.\n     */\n    get edit() {\n        this.initDocumentChanges();\n        if (this._changeAnnotations !== undefined) {\n            if (this._changeAnnotations.size === 0) {\n                this._workspaceEdit.changeAnnotations = undefined;\n            }\n            else {\n                this._workspaceEdit.changeAnnotations = this._changeAnnotations.all();\n            }\n        }\n        return this._workspaceEdit;\n    }\n    getTextEditChange(key) {\n        if (OptionalVersionedTextDocumentIdentifier.is(key)) {\n            this.initDocumentChanges();\n            if (this._workspaceEdit.documentChanges === undefined) {\n                throw new Error('Workspace edit is not configured for document changes.');\n            }\n            const textDocument = { uri: key.uri, version: key.version };\n            let result = this._textEditChanges[textDocument.uri];\n            if (!result) {\n                const edits = [];\n                const textDocumentEdit = {\n                    textDocument,\n                    edits\n                };\n                this._workspaceEdit.documentChanges.push(textDocumentEdit);\n                result = new TextEditChangeImpl(edits, this._changeAnnotations);\n                this._textEditChanges[textDocument.uri] = result;\n            }\n            return result;\n        }\n        else {\n            this.initChanges();\n            if (this._workspaceEdit.changes === undefined) {\n                throw new Error('Workspace edit is not configured for normal text edit changes.');\n            }\n            let result = this._textEditChanges[key];\n            if (!result) {\n                let edits = [];\n                this._workspaceEdit.changes[key] = edits;\n                result = new TextEditChangeImpl(edits);\n                this._textEditChanges[key] = result;\n            }\n            return result;\n        }\n    }\n    initDocumentChanges() {\n        if (this._workspaceEdit.documentChanges === undefined && this._workspaceEdit.changes === undefined) {\n            this._changeAnnotations = new ChangeAnnotations();\n            this._workspaceEdit.documentChanges = [];\n            this._workspaceEdit.changeAnnotations = this._changeAnnotations.all();\n        }\n    }\n    initChanges() {\n        if (this._workspaceEdit.documentChanges === undefined && this._workspaceEdit.changes === undefined) {\n            this._workspaceEdit.changes = Object.create(null);\n        }\n    }\n    createFile(uri, optionsOrAnnotation, options) {\n        this.initDocumentChanges();\n        if (this._workspaceEdit.documentChanges === undefined) {\n            throw new Error('Workspace edit is not configured for document changes.');\n        }\n        let annotation;\n        if (ChangeAnnotation.is(optionsOrAnnotation) || ChangeAnnotationIdentifier.is(optionsOrAnnotation)) {\n            annotation = optionsOrAnnotation;\n        }\n        else {\n            options = optionsOrAnnotation;\n        }\n        let operation;\n        let id;\n        if (annotation === undefined) {\n            operation = CreateFile.create(uri, options);\n        }\n        else {\n            id = ChangeAnnotationIdentifier.is(annotation) ? annotation : this._changeAnnotations.manage(annotation);\n            operation = CreateFile.create(uri, options, id);\n        }\n        this._workspaceEdit.documentChanges.push(operation);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    renameFile(oldUri, newUri, optionsOrAnnotation, options) {\n        this.initDocumentChanges();\n        if (this._workspaceEdit.documentChanges === undefined) {\n            throw new Error('Workspace edit is not configured for document changes.');\n        }\n        let annotation;\n        if (ChangeAnnotation.is(optionsOrAnnotation) || ChangeAnnotationIdentifier.is(optionsOrAnnotation)) {\n            annotation = optionsOrAnnotation;\n        }\n        else {\n            options = optionsOrAnnotation;\n        }\n        let operation;\n        let id;\n        if (annotation === undefined) {\n            operation = RenameFile.create(oldUri, newUri, options);\n        }\n        else {\n            id = ChangeAnnotationIdentifier.is(annotation) ? annotation : this._changeAnnotations.manage(annotation);\n            operation = RenameFile.create(oldUri, newUri, options, id);\n        }\n        this._workspaceEdit.documentChanges.push(operation);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    deleteFile(uri, optionsOrAnnotation, options) {\n        this.initDocumentChanges();\n        if (this._workspaceEdit.documentChanges === undefined) {\n            throw new Error('Workspace edit is not configured for document changes.');\n        }\n        let annotation;\n        if (ChangeAnnotation.is(optionsOrAnnotation) || ChangeAnnotationIdentifier.is(optionsOrAnnotation)) {\n            annotation = optionsOrAnnotation;\n        }\n        else {\n            options = optionsOrAnnotation;\n        }\n        let operation;\n        let id;\n        if (annotation === undefined) {\n            operation = DeleteFile.create(uri, options);\n        }\n        else {\n            id = ChangeAnnotationIdentifier.is(annotation) ? annotation : this._changeAnnotations.manage(annotation);\n            operation = DeleteFile.create(uri, options, id);\n        }\n        this._workspaceEdit.documentChanges.push(operation);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n}\n/**\n * The TextDocumentIdentifier namespace provides helper functions to work with\n * {@link TextDocumentIdentifier} literals.\n */\nexport var TextDocumentIdentifier;\n(function (TextDocumentIdentifier) {\n    /**\n     * Creates a new TextDocumentIdentifier literal.\n     * @param uri The document's uri.\n     */\n    function create(uri) {\n        return { uri };\n    }\n    TextDocumentIdentifier.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link TextDocumentIdentifier} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri);\n    }\n    TextDocumentIdentifier.is = is;\n})(TextDocumentIdentifier || (TextDocumentIdentifier = {}));\n/**\n * The VersionedTextDocumentIdentifier namespace provides helper functions to work with\n * {@link VersionedTextDocumentIdentifier} literals.\n */\nexport var VersionedTextDocumentIdentifier;\n(function (VersionedTextDocumentIdentifier) {\n    /**\n     * Creates a new VersionedTextDocumentIdentifier literal.\n     * @param uri The document's uri.\n     * @param version The document's version.\n     */\n    function create(uri, version) {\n        return { uri, version };\n    }\n    VersionedTextDocumentIdentifier.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link VersionedTextDocumentIdentifier} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && Is.integer(candidate.version);\n    }\n    VersionedTextDocumentIdentifier.is = is;\n})(VersionedTextDocumentIdentifier || (VersionedTextDocumentIdentifier = {}));\n/**\n * The OptionalVersionedTextDocumentIdentifier namespace provides helper functions to work with\n * {@link OptionalVersionedTextDocumentIdentifier} literals.\n */\nexport var OptionalVersionedTextDocumentIdentifier;\n(function (OptionalVersionedTextDocumentIdentifier) {\n    /**\n     * Creates a new OptionalVersionedTextDocumentIdentifier literal.\n     * @param uri The document's uri.\n     * @param version The document's version.\n     */\n    function create(uri, version) {\n        return { uri, version };\n    }\n    OptionalVersionedTextDocumentIdentifier.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link OptionalVersionedTextDocumentIdentifier} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && (candidate.version === null || Is.integer(candidate.version));\n    }\n    OptionalVersionedTextDocumentIdentifier.is = is;\n})(OptionalVersionedTextDocumentIdentifier || (OptionalVersionedTextDocumentIdentifier = {}));\n/**\n * The TextDocumentItem namespace provides helper functions to work with\n * {@link TextDocumentItem} literals.\n */\nexport var TextDocumentItem;\n(function (TextDocumentItem) {\n    /**\n     * Creates a new TextDocumentItem literal.\n     * @param uri The document's uri.\n     * @param languageId The document's language identifier.\n     * @param version The document's version number.\n     * @param text The document's text.\n     */\n    function create(uri, languageId, version, text) {\n        return { uri, languageId, version, text };\n    }\n    TextDocumentItem.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link TextDocumentItem} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && Is.string(candidate.languageId) && Is.integer(candidate.version) && Is.string(candidate.text);\n    }\n    TextDocumentItem.is = is;\n})(TextDocumentItem || (TextDocumentItem = {}));\n/**\n * Describes the content type that a client supports in various\n * result literals like `Hover`, `ParameterInfo` or `CompletionItem`.\n *\n * Please note that `MarkupKinds` must not start with a `$`. This kinds\n * are reserved for internal usage.\n */\nexport var MarkupKind;\n(function (MarkupKind) {\n    /**\n     * Plain text is supported as a content format\n     */\n    MarkupKind.PlainText = 'plaintext';\n    /**\n     * Markdown is supported as a content format\n     */\n    MarkupKind.Markdown = 'markdown';\n    /**\n     * Checks whether the given value is a value of the {@link MarkupKind} type.\n     */\n    function is(value) {\n        const candidate = value;\n        return candidate === MarkupKind.PlainText || candidate === MarkupKind.Markdown;\n    }\n    MarkupKind.is = is;\n})(MarkupKind || (MarkupKind = {}));\nexport var MarkupContent;\n(function (MarkupContent) {\n    /**\n     * Checks whether the given value conforms to the {@link MarkupContent} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(value) && MarkupKind.is(candidate.kind) && Is.string(candidate.value);\n    }\n    MarkupContent.is = is;\n})(MarkupContent || (MarkupContent = {}));\n/**\n * The kind of a completion entry.\n */\nexport var CompletionItemKind;\n(function (CompletionItemKind) {\n    CompletionItemKind.Text = 1;\n    CompletionItemKind.Method = 2;\n    CompletionItemKind.Function = 3;\n    CompletionItemKind.Constructor = 4;\n    CompletionItemKind.Field = 5;\n    CompletionItemKind.Variable = 6;\n    CompletionItemKind.Class = 7;\n    CompletionItemKind.Interface = 8;\n    CompletionItemKind.Module = 9;\n    CompletionItemKind.Property = 10;\n    CompletionItemKind.Unit = 11;\n    CompletionItemKind.Value = 12;\n    CompletionItemKind.Enum = 13;\n    CompletionItemKind.Keyword = 14;\n    CompletionItemKind.Snippet = 15;\n    CompletionItemKind.Color = 16;\n    CompletionItemKind.File = 17;\n    CompletionItemKind.Reference = 18;\n    CompletionItemKind.Folder = 19;\n    CompletionItemKind.EnumMember = 20;\n    CompletionItemKind.Constant = 21;\n    CompletionItemKind.Struct = 22;\n    CompletionItemKind.Event = 23;\n    CompletionItemKind.Operator = 24;\n    CompletionItemKind.TypeParameter = 25;\n})(CompletionItemKind || (CompletionItemKind = {}));\n/**\n * Defines whether the insert text in a completion item should be interpreted as\n * plain text or a snippet.\n */\nexport var InsertTextFormat;\n(function (InsertTextFormat) {\n    /**\n     * The primary text to be inserted is treated as a plain string.\n     */\n    InsertTextFormat.PlainText = 1;\n    /**\n     * The primary text to be inserted is treated as a snippet.\n     *\n     * A snippet can define tab stops and placeholders with `$1`, `$2`\n     * and `${3:foo}`. `$0` defines the final tab stop, it defaults to\n     * the end of the snippet. Placeholders with equal identifiers are linked,\n     * that is typing in one will update others too.\n     *\n     * See also: https://microsoft.github.io/language-server-protocol/specifications/specification-current/#snippet_syntax\n     */\n    InsertTextFormat.Snippet = 2;\n})(InsertTextFormat || (InsertTextFormat = {}));\n/**\n * Completion item tags are extra annotations that tweak the rendering of a completion\n * item.\n *\n * @since 3.15.0\n */\nexport var CompletionItemTag;\n(function (CompletionItemTag) {\n    /**\n     * Render a completion as obsolete, usually using a strike-out.\n     */\n    CompletionItemTag.Deprecated = 1;\n})(CompletionItemTag || (CompletionItemTag = {}));\n/**\n * The InsertReplaceEdit namespace provides functions to deal with insert / replace edits.\n *\n * @since 3.16.0\n */\nexport var InsertReplaceEdit;\n(function (InsertReplaceEdit) {\n    /**\n     * Creates a new insert / replace edit\n     */\n    function create(newText, insert, replace) {\n        return { newText, insert, replace };\n    }\n    InsertReplaceEdit.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link InsertReplaceEdit} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return candidate && Is.string(candidate.newText) && Range.is(candidate.insert) && Range.is(candidate.replace);\n    }\n    InsertReplaceEdit.is = is;\n})(InsertReplaceEdit || (InsertReplaceEdit = {}));\n/**\n * How whitespace and indentation is handled during completion\n * item insertion.\n *\n * @since 3.16.0\n */\nexport var InsertTextMode;\n(function (InsertTextMode) {\n    /**\n     * The insertion or replace strings is taken as it is. If the\n     * value is multi line the lines below the cursor will be\n     * inserted using the indentation defined in the string value.\n     * The client will not apply any kind of adjustments to the\n     * string.\n     */\n    InsertTextMode.asIs = 1;\n    /**\n     * The editor adjusts leading whitespace of new lines so that\n     * they match the indentation up to the cursor of the line for\n     * which the item is accepted.\n     *\n     * Consider a line like this: <2tabs><cursor><3tabs>foo. Accepting a\n     * multi line completion item is indented using 2 tabs and all\n     * following lines inserted will be indented using 2 tabs as well.\n     */\n    InsertTextMode.adjustIndentation = 2;\n})(InsertTextMode || (InsertTextMode = {}));\nexport var CompletionItemLabelDetails;\n(function (CompletionItemLabelDetails) {\n    function is(value) {\n        const candidate = value;\n        return candidate && (Is.string(candidate.detail) || candidate.detail === undefined) &&\n            (Is.string(candidate.description) || candidate.description === undefined);\n    }\n    CompletionItemLabelDetails.is = is;\n})(CompletionItemLabelDetails || (CompletionItemLabelDetails = {}));\n/**\n * The CompletionItem namespace provides functions to deal with\n * completion items.\n */\nexport var CompletionItem;\n(function (CompletionItem) {\n    /**\n     * Create a completion item and seed it with a label.\n     * @param label The completion item's label\n     */\n    function create(label) {\n        return { label };\n    }\n    CompletionItem.create = create;\n})(CompletionItem || (CompletionItem = {}));\n/**\n * The CompletionList namespace provides functions to deal with\n * completion lists.\n */\nexport var CompletionList;\n(function (CompletionList) {\n    /**\n     * Creates a new completion list.\n     *\n     * @param items The completion items.\n     * @param isIncomplete The list is not complete.\n     */\n    function create(items, isIncomplete) {\n        return { items: items ? items : [], isIncomplete: !!isIncomplete };\n    }\n    CompletionList.create = create;\n})(CompletionList || (CompletionList = {}));\nexport var MarkedString;\n(function (MarkedString) {\n    /**\n     * Creates a marked string from plain text.\n     *\n     * @param plainText The plain text.\n     */\n    function fromPlainText(plainText) {\n        return plainText.replace(/[\\\\`*_{}[\\]()#+\\-.!]/g, '\\\\$&'); // escape markdown syntax tokens: http://daringfireball.net/projects/markdown/syntax#backslash\n    }\n    MarkedString.fromPlainText = fromPlainText;\n    /**\n     * Checks whether the given value conforms to the {@link MarkedString} type.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.string(candidate) || (Is.objectLiteral(candidate) && Is.string(candidate.language) && Is.string(candidate.value));\n    }\n    MarkedString.is = is;\n})(MarkedString || (MarkedString = {}));\nexport var Hover;\n(function (Hover) {\n    /**\n     * Checks whether the given value conforms to the {@link Hover} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return !!candidate && Is.objectLiteral(candidate) && (MarkupContent.is(candidate.contents) ||\n            MarkedString.is(candidate.contents) ||\n            Is.typedArray(candidate.contents, MarkedString.is)) && (value.range === undefined || Range.is(value.range));\n    }\n    Hover.is = is;\n})(Hover || (Hover = {}));\n/**\n * The ParameterInformation namespace provides helper functions to work with\n * {@link ParameterInformation} literals.\n */\nexport var ParameterInformation;\n(function (ParameterInformation) {\n    /**\n     * Creates a new parameter information literal.\n     *\n     * @param label A label string.\n     * @param documentation A doc string.\n     */\n    function create(label, documentation) {\n        return documentation ? { label, documentation } : { label };\n    }\n    ParameterInformation.create = create;\n})(ParameterInformation || (ParameterInformation = {}));\n/**\n * The SignatureInformation namespace provides helper functions to work with\n * {@link SignatureInformation} literals.\n */\nexport var SignatureInformation;\n(function (SignatureInformation) {\n    function create(label, documentation, ...parameters) {\n        let result = { label };\n        if (Is.defined(documentation)) {\n            result.documentation = documentation;\n        }\n        if (Is.defined(parameters)) {\n            result.parameters = parameters;\n        }\n        else {\n            result.parameters = [];\n        }\n        return result;\n    }\n    SignatureInformation.create = create;\n})(SignatureInformation || (SignatureInformation = {}));\n/**\n * A document highlight kind.\n */\nexport var DocumentHighlightKind;\n(function (DocumentHighlightKind) {\n    /**\n     * A textual occurrence.\n     */\n    DocumentHighlightKind.Text = 1;\n    /**\n     * Read-access of a symbol, like reading a variable.\n     */\n    DocumentHighlightKind.Read = 2;\n    /**\n     * Write-access of a symbol, like writing to a variable.\n     */\n    DocumentHighlightKind.Write = 3;\n})(DocumentHighlightKind || (DocumentHighlightKind = {}));\n/**\n * DocumentHighlight namespace to provide helper functions to work with\n * {@link DocumentHighlight} literals.\n */\nexport var DocumentHighlight;\n(function (DocumentHighlight) {\n    /**\n     * Create a DocumentHighlight object.\n     * @param range The range the highlight applies to.\n     * @param kind The highlight kind\n     */\n    function create(range, kind) {\n        let result = { range };\n        if (Is.number(kind)) {\n            result.kind = kind;\n        }\n        return result;\n    }\n    DocumentHighlight.create = create;\n})(DocumentHighlight || (DocumentHighlight = {}));\n/**\n * A symbol kind.\n */\nexport var SymbolKind;\n(function (SymbolKind) {\n    SymbolKind.File = 1;\n    SymbolKind.Module = 2;\n    SymbolKind.Namespace = 3;\n    SymbolKind.Package = 4;\n    SymbolKind.Class = 5;\n    SymbolKind.Method = 6;\n    SymbolKind.Property = 7;\n    SymbolKind.Field = 8;\n    SymbolKind.Constructor = 9;\n    SymbolKind.Enum = 10;\n    SymbolKind.Interface = 11;\n    SymbolKind.Function = 12;\n    SymbolKind.Variable = 13;\n    SymbolKind.Constant = 14;\n    SymbolKind.String = 15;\n    SymbolKind.Number = 16;\n    SymbolKind.Boolean = 17;\n    SymbolKind.Array = 18;\n    SymbolKind.Object = 19;\n    SymbolKind.Key = 20;\n    SymbolKind.Null = 21;\n    SymbolKind.EnumMember = 22;\n    SymbolKind.Struct = 23;\n    SymbolKind.Event = 24;\n    SymbolKind.Operator = 25;\n    SymbolKind.TypeParameter = 26;\n})(SymbolKind || (SymbolKind = {}));\n/**\n * Symbol tags are extra annotations that tweak the rendering of a symbol.\n *\n * @since 3.16\n */\nexport var SymbolTag;\n(function (SymbolTag) {\n    /**\n     * Render a symbol as obsolete, usually using a strike-out.\n     */\n    SymbolTag.Deprecated = 1;\n})(SymbolTag || (SymbolTag = {}));\nexport var SymbolInformation;\n(function (SymbolInformation) {\n    /**\n     * Creates a new symbol information literal.\n     *\n     * @param name The name of the symbol.\n     * @param kind The kind of the symbol.\n     * @param range The range of the location of the symbol.\n     * @param uri The resource of the location of symbol.\n     * @param containerName The name of the symbol containing the symbol.\n     */\n    function create(name, kind, range, uri, containerName) {\n        let result = {\n            name,\n            kind,\n            location: { uri, range }\n        };\n        if (containerName) {\n            result.containerName = containerName;\n        }\n        return result;\n    }\n    SymbolInformation.create = create;\n})(SymbolInformation || (SymbolInformation = {}));\nexport var WorkspaceSymbol;\n(function (WorkspaceSymbol) {\n    /**\n     * Create a new workspace symbol.\n     *\n     * @param name The name of the symbol.\n     * @param kind The kind of the symbol.\n     * @param uri The resource of the location of the symbol.\n     * @param range An options range of the location.\n     * @returns A WorkspaceSymbol.\n     */\n    function create(name, kind, uri, range) {\n        return range !== undefined\n            ? { name, kind, location: { uri, range } }\n            : { name, kind, location: { uri } };\n    }\n    WorkspaceSymbol.create = create;\n})(WorkspaceSymbol || (WorkspaceSymbol = {}));\nexport var DocumentSymbol;\n(function (DocumentSymbol) {\n    /**\n     * Creates a new symbol information literal.\n     *\n     * @param name The name of the symbol.\n     * @param detail The detail of the symbol.\n     * @param kind The kind of the symbol.\n     * @param range The range of the symbol.\n     * @param selectionRange The selectionRange of the symbol.\n     * @param children Children of the symbol.\n     */\n    function create(name, detail, kind, range, selectionRange, children) {\n        let result = {\n            name,\n            detail,\n            kind,\n            range,\n            selectionRange\n        };\n        if (children !== undefined) {\n            result.children = children;\n        }\n        return result;\n    }\n    DocumentSymbol.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link DocumentSymbol} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return candidate &&\n            Is.string(candidate.name) && Is.number(candidate.kind) &&\n            Range.is(candidate.range) && Range.is(candidate.selectionRange) &&\n            (candidate.detail === undefined || Is.string(candidate.detail)) &&\n            (candidate.deprecated === undefined || Is.boolean(candidate.deprecated)) &&\n            (candidate.children === undefined || Array.isArray(candidate.children)) &&\n            (candidate.tags === undefined || Array.isArray(candidate.tags));\n    }\n    DocumentSymbol.is = is;\n})(DocumentSymbol || (DocumentSymbol = {}));\n/**\n * A set of predefined code action kinds\n */\nexport var CodeActionKind;\n(function (CodeActionKind) {\n    /**\n     * Empty kind.\n     */\n    CodeActionKind.Empty = '';\n    /**\n     * Base kind for quickfix actions: 'quickfix'\n     */\n    CodeActionKind.QuickFix = 'quickfix';\n    /**\n     * Base kind for refactoring actions: 'refactor'\n     */\n    CodeActionKind.Refactor = 'refactor';\n    /**\n     * Base kind for refactoring extraction actions: 'refactor.extract'\n     *\n     * Example extract actions:\n     *\n     * - Extract method\n     * - Extract function\n     * - Extract variable\n     * - Extract interface from class\n     * - ...\n     */\n    CodeActionKind.RefactorExtract = 'refactor.extract';\n    /**\n     * Base kind for refactoring inline actions: 'refactor.inline'\n     *\n     * Example inline actions:\n     *\n     * - Inline function\n     * - Inline variable\n     * - Inline constant\n     * - ...\n     */\n    CodeActionKind.RefactorInline = 'refactor.inline';\n    /**\n     * Base kind for refactoring rewrite actions: 'refactor.rewrite'\n     *\n     * Example rewrite actions:\n     *\n     * - Convert JavaScript function to class\n     * - Add or remove parameter\n     * - Encapsulate field\n     * - Make method static\n     * - Move method to base class\n     * - ...\n     */\n    CodeActionKind.RefactorRewrite = 'refactor.rewrite';\n    /**\n     * Base kind for source actions: `source`\n     *\n     * Source code actions apply to the entire file.\n     */\n    CodeActionKind.Source = 'source';\n    /**\n     * Base kind for an organize imports source action: `source.organizeImports`\n     */\n    CodeActionKind.SourceOrganizeImports = 'source.organizeImports';\n    /**\n     * Base kind for auto-fix source actions: `source.fixAll`.\n     *\n     * Fix all actions automatically fix errors that have a clear fix that do not require user input.\n     * They should not suppress errors or perform unsafe fixes such as generating new types or classes.\n     *\n     * @since 3.15.0\n     */\n    CodeActionKind.SourceFixAll = 'source.fixAll';\n})(CodeActionKind || (CodeActionKind = {}));\n/**\n * The reason why code actions were requested.\n *\n * @since 3.17.0\n */\nexport var CodeActionTriggerKind;\n(function (CodeActionTriggerKind) {\n    /**\n     * Code actions were explicitly requested by the user or by an extension.\n     */\n    CodeActionTriggerKind.Invoked = 1;\n    /**\n     * Code actions were requested automatically.\n     *\n     * This typically happens when current selection in a file changes, but can\n     * also be triggered when file content changes.\n     */\n    CodeActionTriggerKind.Automatic = 2;\n})(CodeActionTriggerKind || (CodeActionTriggerKind = {}));\n/**\n * The CodeActionContext namespace provides helper functions to work with\n * {@link CodeActionContext} literals.\n */\nexport var CodeActionContext;\n(function (CodeActionContext) {\n    /**\n     * Creates a new CodeActionContext literal.\n     */\n    function create(diagnostics, only, triggerKind) {\n        let result = { diagnostics };\n        if (only !== undefined && only !== null) {\n            result.only = only;\n        }\n        if (triggerKind !== undefined && triggerKind !== null) {\n            result.triggerKind = triggerKind;\n        }\n        return result;\n    }\n    CodeActionContext.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link CodeActionContext} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.typedArray(candidate.diagnostics, Diagnostic.is)\n            && (candidate.only === undefined || Is.typedArray(candidate.only, Is.string))\n            && (candidate.triggerKind === undefined || candidate.triggerKind === CodeActionTriggerKind.Invoked || candidate.triggerKind === CodeActionTriggerKind.Automatic);\n    }\n    CodeActionContext.is = is;\n})(CodeActionContext || (CodeActionContext = {}));\nexport var CodeAction;\n(function (CodeAction) {\n    function create(title, kindOrCommandOrEdit, kind) {\n        let result = { title };\n        let checkKind = true;\n        if (typeof kindOrCommandOrEdit === 'string') {\n            checkKind = false;\n            result.kind = kindOrCommandOrEdit;\n        }\n        else if (Command.is(kindOrCommandOrEdit)) {\n            result.command = kindOrCommandOrEdit;\n        }\n        else {\n            result.edit = kindOrCommandOrEdit;\n        }\n        if (checkKind && kind !== undefined) {\n            result.kind = kind;\n        }\n        return result;\n    }\n    CodeAction.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && Is.string(candidate.title) &&\n            (candidate.diagnostics === undefined || Is.typedArray(candidate.diagnostics, Diagnostic.is)) &&\n            (candidate.kind === undefined || Is.string(candidate.kind)) &&\n            (candidate.edit !== undefined || candidate.command !== undefined) &&\n            (candidate.command === undefined || Command.is(candidate.command)) &&\n            (candidate.isPreferred === undefined || Is.boolean(candidate.isPreferred)) &&\n            (candidate.edit === undefined || WorkspaceEdit.is(candidate.edit));\n    }\n    CodeAction.is = is;\n})(CodeAction || (CodeAction = {}));\n/**\n * The CodeLens namespace provides helper functions to work with\n * {@link CodeLens} literals.\n */\nexport var CodeLens;\n(function (CodeLens) {\n    /**\n     * Creates a new CodeLens literal.\n     */\n    function create(range, data) {\n        let result = { range };\n        if (Is.defined(data)) {\n            result.data = data;\n        }\n        return result;\n    }\n    CodeLens.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link CodeLens} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Range.is(candidate.range) && (Is.undefined(candidate.command) || Command.is(candidate.command));\n    }\n    CodeLens.is = is;\n})(CodeLens || (CodeLens = {}));\n/**\n * The FormattingOptions namespace provides helper functions to work with\n * {@link FormattingOptions} literals.\n */\nexport var FormattingOptions;\n(function (FormattingOptions) {\n    /**\n     * Creates a new FormattingOptions literal.\n     */\n    function create(tabSize, insertSpaces) {\n        return { tabSize, insertSpaces };\n    }\n    FormattingOptions.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link FormattingOptions} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.uinteger(candidate.tabSize) && Is.boolean(candidate.insertSpaces);\n    }\n    FormattingOptions.is = is;\n})(FormattingOptions || (FormattingOptions = {}));\n/**\n * The DocumentLink namespace provides helper functions to work with\n * {@link DocumentLink} literals.\n */\nexport var DocumentLink;\n(function (DocumentLink) {\n    /**\n     * Creates a new DocumentLink literal.\n     */\n    function create(range, target, data) {\n        return { range, target, data };\n    }\n    DocumentLink.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link DocumentLink} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Range.is(candidate.range) && (Is.undefined(candidate.target) || Is.string(candidate.target));\n    }\n    DocumentLink.is = is;\n})(DocumentLink || (DocumentLink = {}));\n/**\n * The SelectionRange namespace provides helper function to work with\n * SelectionRange literals.\n */\nexport var SelectionRange;\n(function (SelectionRange) {\n    /**\n     * Creates a new SelectionRange\n     * @param range the range.\n     * @param parent an optional parent.\n     */\n    function create(range, parent) {\n        return { range, parent };\n    }\n    SelectionRange.create = create;\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.range) && (candidate.parent === undefined || SelectionRange.is(candidate.parent));\n    }\n    SelectionRange.is = is;\n})(SelectionRange || (SelectionRange = {}));\n/**\n * A set of predefined token types. This set is not fixed\n * an clients can specify additional token types via the\n * corresponding client capabilities.\n *\n * @since 3.16.0\n */\nexport var SemanticTokenTypes;\n(function (SemanticTokenTypes) {\n    SemanticTokenTypes[\"namespace\"] = \"namespace\";\n    /**\n     * Represents a generic type. Acts as a fallback for types which can't be mapped to\n     * a specific type like class or enum.\n     */\n    SemanticTokenTypes[\"type\"] = \"type\";\n    SemanticTokenTypes[\"class\"] = \"class\";\n    SemanticTokenTypes[\"enum\"] = \"enum\";\n    SemanticTokenTypes[\"interface\"] = \"interface\";\n    SemanticTokenTypes[\"struct\"] = \"struct\";\n    SemanticTokenTypes[\"typeParameter\"] = \"typeParameter\";\n    SemanticTokenTypes[\"parameter\"] = \"parameter\";\n    SemanticTokenTypes[\"variable\"] = \"variable\";\n    SemanticTokenTypes[\"property\"] = \"property\";\n    SemanticTokenTypes[\"enumMember\"] = \"enumMember\";\n    SemanticTokenTypes[\"event\"] = \"event\";\n    SemanticTokenTypes[\"function\"] = \"function\";\n    SemanticTokenTypes[\"method\"] = \"method\";\n    SemanticTokenTypes[\"macro\"] = \"macro\";\n    SemanticTokenTypes[\"keyword\"] = \"keyword\";\n    SemanticTokenTypes[\"modifier\"] = \"modifier\";\n    SemanticTokenTypes[\"comment\"] = \"comment\";\n    SemanticTokenTypes[\"string\"] = \"string\";\n    SemanticTokenTypes[\"number\"] = \"number\";\n    SemanticTokenTypes[\"regexp\"] = \"regexp\";\n    SemanticTokenTypes[\"operator\"] = \"operator\";\n    /**\n     * @since 3.17.0\n     */\n    SemanticTokenTypes[\"decorator\"] = \"decorator\";\n})(SemanticTokenTypes || (SemanticTokenTypes = {}));\n/**\n * A set of predefined token modifiers. This set is not fixed\n * an clients can specify additional token types via the\n * corresponding client capabilities.\n *\n * @since 3.16.0\n */\nexport var SemanticTokenModifiers;\n(function (SemanticTokenModifiers) {\n    SemanticTokenModifiers[\"declaration\"] = \"declaration\";\n    SemanticTokenModifiers[\"definition\"] = \"definition\";\n    SemanticTokenModifiers[\"readonly\"] = \"readonly\";\n    SemanticTokenModifiers[\"static\"] = \"static\";\n    SemanticTokenModifiers[\"deprecated\"] = \"deprecated\";\n    SemanticTokenModifiers[\"abstract\"] = \"abstract\";\n    SemanticTokenModifiers[\"async\"] = \"async\";\n    SemanticTokenModifiers[\"modification\"] = \"modification\";\n    SemanticTokenModifiers[\"documentation\"] = \"documentation\";\n    SemanticTokenModifiers[\"defaultLibrary\"] = \"defaultLibrary\";\n})(SemanticTokenModifiers || (SemanticTokenModifiers = {}));\n/**\n * @since 3.16.0\n */\nexport var SemanticTokens;\n(function (SemanticTokens) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && (candidate.resultId === undefined || typeof candidate.resultId === 'string') &&\n            Array.isArray(candidate.data) && (candidate.data.length === 0 || typeof candidate.data[0] === 'number');\n    }\n    SemanticTokens.is = is;\n})(SemanticTokens || (SemanticTokens = {}));\n/**\n * The InlineValueText namespace provides functions to deal with InlineValueTexts.\n *\n * @since 3.17.0\n */\nexport var InlineValueText;\n(function (InlineValueText) {\n    /**\n     * Creates a new InlineValueText literal.\n     */\n    function create(range, text) {\n        return { range, text };\n    }\n    InlineValueText.create = create;\n    function is(value) {\n        const candidate = value;\n        return candidate !== undefined && candidate !== null && Range.is(candidate.range) && Is.string(candidate.text);\n    }\n    InlineValueText.is = is;\n})(InlineValueText || (InlineValueText = {}));\n/**\n * The InlineValueVariableLookup namespace provides functions to deal with InlineValueVariableLookups.\n *\n * @since 3.17.0\n */\nexport var InlineValueVariableLookup;\n(function (InlineValueVariableLookup) {\n    /**\n     * Creates a new InlineValueText literal.\n     */\n    function create(range, variableName, caseSensitiveLookup) {\n        return { range, variableName, caseSensitiveLookup };\n    }\n    InlineValueVariableLookup.create = create;\n    function is(value) {\n        const candidate = value;\n        return candidate !== undefined && candidate !== null && Range.is(candidate.range) && Is.boolean(candidate.caseSensitiveLookup)\n            && (Is.string(candidate.variableName) || candidate.variableName === undefined);\n    }\n    InlineValueVariableLookup.is = is;\n})(InlineValueVariableLookup || (InlineValueVariableLookup = {}));\n/**\n * The InlineValueEvaluatableExpression namespace provides functions to deal with InlineValueEvaluatableExpression.\n *\n * @since 3.17.0\n */\nexport var InlineValueEvaluatableExpression;\n(function (InlineValueEvaluatableExpression) {\n    /**\n     * Creates a new InlineValueEvaluatableExpression literal.\n     */\n    function create(range, expression) {\n        return { range, expression };\n    }\n    InlineValueEvaluatableExpression.create = create;\n    function is(value) {\n        const candidate = value;\n        return candidate !== undefined && candidate !== null && Range.is(candidate.range)\n            && (Is.string(candidate.expression) || candidate.expression === undefined);\n    }\n    InlineValueEvaluatableExpression.is = is;\n})(InlineValueEvaluatableExpression || (InlineValueEvaluatableExpression = {}));\n/**\n * The InlineValueContext namespace provides helper functions to work with\n * {@link InlineValueContext} literals.\n *\n * @since 3.17.0\n */\nexport var InlineValueContext;\n(function (InlineValueContext) {\n    /**\n     * Creates a new InlineValueContext literal.\n     */\n    function create(frameId, stoppedLocation) {\n        return { frameId, stoppedLocation };\n    }\n    InlineValueContext.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link InlineValueContext} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.defined(candidate) && Range.is(value.stoppedLocation);\n    }\n    InlineValueContext.is = is;\n})(InlineValueContext || (InlineValueContext = {}));\n/**\n * Inlay hint kinds.\n *\n * @since 3.17.0\n */\nexport var InlayHintKind;\n(function (InlayHintKind) {\n    /**\n     * An inlay hint that for a type annotation.\n     */\n    InlayHintKind.Type = 1;\n    /**\n     * An inlay hint that is for a parameter.\n     */\n    InlayHintKind.Parameter = 2;\n    function is(value) {\n        return value === 1 || value === 2;\n    }\n    InlayHintKind.is = is;\n})(InlayHintKind || (InlayHintKind = {}));\nexport var InlayHintLabelPart;\n(function (InlayHintLabelPart) {\n    function create(value) {\n        return { value };\n    }\n    InlayHintLabelPart.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate)\n            && (candidate.tooltip === undefined || Is.string(candidate.tooltip) || MarkupContent.is(candidate.tooltip))\n            && (candidate.location === undefined || Location.is(candidate.location))\n            && (candidate.command === undefined || Command.is(candidate.command));\n    }\n    InlayHintLabelPart.is = is;\n})(InlayHintLabelPart || (InlayHintLabelPart = {}));\nexport var InlayHint;\n(function (InlayHint) {\n    function create(position, label, kind) {\n        const result = { position, label };\n        if (kind !== undefined) {\n            result.kind = kind;\n        }\n        return result;\n    }\n    InlayHint.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Position.is(candidate.position)\n            && (Is.string(candidate.label) || Is.typedArray(candidate.label, InlayHintLabelPart.is))\n            && (candidate.kind === undefined || InlayHintKind.is(candidate.kind))\n            && (candidate.textEdits === undefined) || Is.typedArray(candidate.textEdits, TextEdit.is)\n            && (candidate.tooltip === undefined || Is.string(candidate.tooltip) || MarkupContent.is(candidate.tooltip))\n            && (candidate.paddingLeft === undefined || Is.boolean(candidate.paddingLeft))\n            && (candidate.paddingRight === undefined || Is.boolean(candidate.paddingRight));\n    }\n    InlayHint.is = is;\n})(InlayHint || (InlayHint = {}));\nexport var StringValue;\n(function (StringValue) {\n    function createSnippet(value) {\n        return { kind: 'snippet', value };\n    }\n    StringValue.createSnippet = createSnippet;\n})(StringValue || (StringValue = {}));\nexport var InlineCompletionItem;\n(function (InlineCompletionItem) {\n    function create(insertText, filterText, range, command) {\n        return { insertText, filterText, range, command };\n    }\n    InlineCompletionItem.create = create;\n})(InlineCompletionItem || (InlineCompletionItem = {}));\nexport var InlineCompletionList;\n(function (InlineCompletionList) {\n    function create(items) {\n        return { items };\n    }\n    InlineCompletionList.create = create;\n})(InlineCompletionList || (InlineCompletionList = {}));\n/**\n * Describes how an {@link InlineCompletionItemProvider inline completion provider} was triggered.\n *\n * @since 3.18.0\n * @proposed\n */\nexport var InlineCompletionTriggerKind;\n(function (InlineCompletionTriggerKind) {\n    /**\n     * Completion was triggered explicitly by a user gesture.\n     */\n    InlineCompletionTriggerKind.Invoked = 0;\n    /**\n     * Completion was triggered automatically while editing.\n     */\n    InlineCompletionTriggerKind.Automatic = 1;\n})(InlineCompletionTriggerKind || (InlineCompletionTriggerKind = {}));\nexport var SelectedCompletionInfo;\n(function (SelectedCompletionInfo) {\n    function create(range, text) {\n        return { range, text };\n    }\n    SelectedCompletionInfo.create = create;\n})(SelectedCompletionInfo || (SelectedCompletionInfo = {}));\nexport var InlineCompletionContext;\n(function (InlineCompletionContext) {\n    function create(triggerKind, selectedCompletionInfo) {\n        return { triggerKind, selectedCompletionInfo };\n    }\n    InlineCompletionContext.create = create;\n})(InlineCompletionContext || (InlineCompletionContext = {}));\nexport var WorkspaceFolder;\n(function (WorkspaceFolder) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && URI.is(candidate.uri) && Is.string(candidate.name);\n    }\n    WorkspaceFolder.is = is;\n})(WorkspaceFolder || (WorkspaceFolder = {}));\nexport const EOL = ['\\n', '\\r\\n', '\\r'];\n/**\n * @deprecated Use the text document from the new vscode-languageserver-textdocument package.\n */\nexport var TextDocument;\n(function (TextDocument) {\n    /**\n     * Creates a new ITextDocument literal from the given uri and content.\n     * @param uri The document's uri.\n     * @param languageId The document's language Id.\n     * @param version The document's version.\n     * @param content The document's content.\n     */\n    function create(uri, languageId, version, content) {\n        return new FullTextDocument(uri, languageId, version, content);\n    }\n    TextDocument.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link ITextDocument} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && (Is.undefined(candidate.languageId) || Is.string(candidate.languageId)) && Is.uinteger(candidate.lineCount)\n            && Is.func(candidate.getText) && Is.func(candidate.positionAt) && Is.func(candidate.offsetAt) ? true : false;\n    }\n    TextDocument.is = is;\n    function applyEdits(document, edits) {\n        let text = document.getText();\n        let sortedEdits = mergeSort(edits, (a, b) => {\n            let diff = a.range.start.line - b.range.start.line;\n            if (diff === 0) {\n                return a.range.start.character - b.range.start.character;\n            }\n            return diff;\n        });\n        let lastModifiedOffset = text.length;\n        for (let i = sortedEdits.length - 1; i >= 0; i--) {\n            let e = sortedEdits[i];\n            let startOffset = document.offsetAt(e.range.start);\n            let endOffset = document.offsetAt(e.range.end);\n            if (endOffset <= lastModifiedOffset) {\n                text = text.substring(0, startOffset) + e.newText + text.substring(endOffset, text.length);\n            }\n            else {\n                throw new Error('Overlapping edit');\n            }\n            lastModifiedOffset = startOffset;\n        }\n        return text;\n    }\n    TextDocument.applyEdits = applyEdits;\n    function mergeSort(data, compare) {\n        if (data.length <= 1) {\n            // sorted\n            return data;\n        }\n        const p = (data.length / 2) | 0;\n        const left = data.slice(0, p);\n        const right = data.slice(p);\n        mergeSort(left, compare);\n        mergeSort(right, compare);\n        let leftIdx = 0;\n        let rightIdx = 0;\n        let i = 0;\n        while (leftIdx < left.length && rightIdx < right.length) {\n            let ret = compare(left[leftIdx], right[rightIdx]);\n            if (ret <= 0) {\n                // smaller_equal -> take left to preserve order\n                data[i++] = left[leftIdx++];\n            }\n            else {\n                // greater -> take right\n                data[i++] = right[rightIdx++];\n            }\n        }\n        while (leftIdx < left.length) {\n            data[i++] = left[leftIdx++];\n        }\n        while (rightIdx < right.length) {\n            data[i++] = right[rightIdx++];\n        }\n        return data;\n    }\n})(TextDocument || (TextDocument = {}));\n/**\n * @deprecated Use the text document from the new vscode-languageserver-textdocument package.\n */\nclass FullTextDocument {\n    constructor(uri, languageId, version, content) {\n        this._uri = uri;\n        this._languageId = languageId;\n        this._version = version;\n        this._content = content;\n        this._lineOffsets = undefined;\n    }\n    get uri() {\n        return this._uri;\n    }\n    get languageId() {\n        return this._languageId;\n    }\n    get version() {\n        return this._version;\n    }\n    getText(range) {\n        if (range) {\n            let start = this.offsetAt(range.start);\n            let end = this.offsetAt(range.end);\n            return this._content.substring(start, end);\n        }\n        return this._content;\n    }\n    update(event, version) {\n        this._content = event.text;\n        this._version = version;\n        this._lineOffsets = undefined;\n    }\n    getLineOffsets() {\n        if (this._lineOffsets === undefined) {\n            let lineOffsets = [];\n            let text = this._content;\n            let isLineStart = true;\n            for (let i = 0; i < text.length; i++) {\n                if (isLineStart) {\n                    lineOffsets.push(i);\n                    isLineStart = false;\n                }\n                let ch = text.charAt(i);\n                isLineStart = (ch === '\\r' || ch === '\\n');\n                if (ch === '\\r' && i + 1 < text.length && text.charAt(i + 1) === '\\n') {\n                    i++;\n                }\n            }\n            if (isLineStart && text.length > 0) {\n                lineOffsets.push(text.length);\n            }\n            this._lineOffsets = lineOffsets;\n        }\n        return this._lineOffsets;\n    }\n    positionAt(offset) {\n        offset = Math.max(Math.min(offset, this._content.length), 0);\n        let lineOffsets = this.getLineOffsets();\n        let low = 0, high = lineOffsets.length;\n        if (high === 0) {\n            return Position.create(0, offset);\n        }\n        while (low < high) {\n            let mid = Math.floor((low + high) / 2);\n            if (lineOffsets[mid] > offset) {\n                high = mid;\n            }\n            else {\n                low = mid + 1;\n            }\n        }\n        // low is the least x for which the line offset is larger than the current offset\n        // or array.length if no line offset is larger than the current offset\n        let line = low - 1;\n        return Position.create(line, offset - lineOffsets[line]);\n    }\n    offsetAt(position) {\n        let lineOffsets = this.getLineOffsets();\n        if (position.line >= lineOffsets.length) {\n            return this._content.length;\n        }\n        else if (position.line < 0) {\n            return 0;\n        }\n        let lineOffset = lineOffsets[position.line];\n        let nextLineOffset = (position.line + 1 < lineOffsets.length) ? lineOffsets[position.line + 1] : this._content.length;\n        return Math.max(Math.min(lineOffset + position.character, nextLineOffset), lineOffset);\n    }\n    get lineCount() {\n        return this.getLineOffsets().length;\n    }\n}\nvar Is;\n(function (Is) {\n    const toString = Object.prototype.toString;\n    function defined(value) {\n        return typeof value !== 'undefined';\n    }\n    Is.defined = defined;\n    function undefined(value) {\n        return typeof value === 'undefined';\n    }\n    Is.undefined = undefined;\n    function boolean(value) {\n        return value === true || value === false;\n    }\n    Is.boolean = boolean;\n    function string(value) {\n        return toString.call(value) === '[object String]';\n    }\n    Is.string = string;\n    function number(value) {\n        return toString.call(value) === '[object Number]';\n    }\n    Is.number = number;\n    function numberRange(value, min, max) {\n        return toString.call(value) === '[object Number]' && min <= value && value <= max;\n    }\n    Is.numberRange = numberRange;\n    function integer(value) {\n        return toString.call(value) === '[object Number]' && -2147483648 <= value && value <= 2147483647;\n    }\n    Is.integer = integer;\n    function uinteger(value) {\n        return toString.call(value) === '[object Number]' && 0 <= value && value <= 2147483647;\n    }\n    Is.uinteger = uinteger;\n    function func(value) {\n        return toString.call(value) === '[object Function]';\n    }\n    Is.func = func;\n    function objectLiteral(value) {\n        // Strictly speaking class instances pass this check as well. Since the LSP\n        // doesn't use classes we ignore this for now. If we do we need to add something\n        // like this: `Object.getPrototypeOf(Object.getPrototypeOf(x)) === null`\n        return value !== null && typeof value === 'object';\n    }\n    Is.objectLiteral = objectLiteral;\n    function typedArray(value, check) {\n        return Array.isArray(value) && value.every(check);\n    }\n    Is.typedArray = typedArray;\n})(Is || (Is = {}));\n","var LIB;(()=>{\"use strict\";var t={975:t=>{function e(t){if(\"string\"!=typeof t)throw new TypeError(\"Path must be a string. Received \"+JSON.stringify(t))}function r(t,e){for(var r,n=\"\",i=0,o=-1,s=0,h=0;h<=t.length;++h){if(h<t.length)r=t.charCodeAt(h);else{if(47===r)break;r=47}if(47===r){if(o===h-1||1===s);else if(o!==h-1&&2===s){if(n.length<2||2!==i||46!==n.charCodeAt(n.length-1)||46!==n.charCodeAt(n.length-2))if(n.length>2){var a=n.lastIndexOf(\"/\");if(a!==n.length-1){-1===a?(n=\"\",i=0):i=(n=n.slice(0,a)).length-1-n.lastIndexOf(\"/\"),o=h,s=0;continue}}else if(2===n.length||1===n.length){n=\"\",i=0,o=h,s=0;continue}e&&(n.length>0?n+=\"/..\":n=\"..\",i=2)}else n.length>0?n+=\"/\"+t.slice(o+1,h):n=t.slice(o+1,h),i=h-o-1;o=h,s=0}else 46===r&&-1!==s?++s:s=-1}return n}var n={resolve:function(){for(var t,n=\"\",i=!1,o=arguments.length-1;o>=-1&&!i;o--){var s;o>=0?s=arguments[o]:(void 0===t&&(t=process.cwd()),s=t),e(s),0!==s.length&&(n=s+\"/\"+n,i=47===s.charCodeAt(0))}return n=r(n,!i),i?n.length>0?\"/\"+n:\"/\":n.length>0?n:\".\"},normalize:function(t){if(e(t),0===t.length)return\".\";var n=47===t.charCodeAt(0),i=47===t.charCodeAt(t.length-1);return 0!==(t=r(t,!n)).length||n||(t=\".\"),t.length>0&&i&&(t+=\"/\"),n?\"/\"+t:t},isAbsolute:function(t){return e(t),t.length>0&&47===t.charCodeAt(0)},join:function(){if(0===arguments.length)return\".\";for(var t,r=0;r<arguments.length;++r){var i=arguments[r];e(i),i.length>0&&(void 0===t?t=i:t+=\"/\"+i)}return void 0===t?\".\":n.normalize(t)},relative:function(t,r){if(e(t),e(r),t===r)return\"\";if((t=n.resolve(t))===(r=n.resolve(r)))return\"\";for(var i=1;i<t.length&&47===t.charCodeAt(i);++i);for(var o=t.length,s=o-i,h=1;h<r.length&&47===r.charCodeAt(h);++h);for(var a=r.length-h,c=s<a?s:a,f=-1,u=0;u<=c;++u){if(u===c){if(a>c){if(47===r.charCodeAt(h+u))return r.slice(h+u+1);if(0===u)return r.slice(h+u)}else s>c&&(47===t.charCodeAt(i+u)?f=u:0===u&&(f=0));break}var l=t.charCodeAt(i+u);if(l!==r.charCodeAt(h+u))break;47===l&&(f=u)}var g=\"\";for(u=i+f+1;u<=o;++u)u!==o&&47!==t.charCodeAt(u)||(0===g.length?g+=\"..\":g+=\"/..\");return g.length>0?g+r.slice(h+f):(h+=f,47===r.charCodeAt(h)&&++h,r.slice(h))},_makeLong:function(t){return t},dirname:function(t){if(e(t),0===t.length)return\".\";for(var r=t.charCodeAt(0),n=47===r,i=-1,o=!0,s=t.length-1;s>=1;--s)if(47===(r=t.charCodeAt(s))){if(!o){i=s;break}}else o=!1;return-1===i?n?\"/\":\".\":n&&1===i?\"//\":t.slice(0,i)},basename:function(t,r){if(void 0!==r&&\"string\"!=typeof r)throw new TypeError('\"ext\" argument must be a string');e(t);var n,i=0,o=-1,s=!0;if(void 0!==r&&r.length>0&&r.length<=t.length){if(r.length===t.length&&r===t)return\"\";var h=r.length-1,a=-1;for(n=t.length-1;n>=0;--n){var c=t.charCodeAt(n);if(47===c){if(!s){i=n+1;break}}else-1===a&&(s=!1,a=n+1),h>=0&&(c===r.charCodeAt(h)?-1==--h&&(o=n):(h=-1,o=a))}return i===o?o=a:-1===o&&(o=t.length),t.slice(i,o)}for(n=t.length-1;n>=0;--n)if(47===t.charCodeAt(n)){if(!s){i=n+1;break}}else-1===o&&(s=!1,o=n+1);return-1===o?\"\":t.slice(i,o)},extname:function(t){e(t);for(var r=-1,n=0,i=-1,o=!0,s=0,h=t.length-1;h>=0;--h){var a=t.charCodeAt(h);if(47!==a)-1===i&&(o=!1,i=h+1),46===a?-1===r?r=h:1!==s&&(s=1):-1!==r&&(s=-1);else if(!o){n=h+1;break}}return-1===r||-1===i||0===s||1===s&&r===i-1&&r===n+1?\"\":t.slice(r,i)},format:function(t){if(null===t||\"object\"!=typeof t)throw new TypeError('The \"pathObject\" argument must be of type Object. Received type '+typeof t);return function(t,e){var r=e.dir||e.root,n=e.base||(e.name||\"\")+(e.ext||\"\");return r?r===e.root?r+n:r+\"/\"+n:n}(0,t)},parse:function(t){e(t);var r={root:\"\",dir:\"\",base:\"\",ext:\"\",name:\"\"};if(0===t.length)return r;var n,i=t.charCodeAt(0),o=47===i;o?(r.root=\"/\",n=1):n=0;for(var s=-1,h=0,a=-1,c=!0,f=t.length-1,u=0;f>=n;--f)if(47!==(i=t.charCodeAt(f)))-1===a&&(c=!1,a=f+1),46===i?-1===s?s=f:1!==u&&(u=1):-1!==s&&(u=-1);else if(!c){h=f+1;break}return-1===s||-1===a||0===u||1===u&&s===a-1&&s===h+1?-1!==a&&(r.base=r.name=0===h&&o?t.slice(1,a):t.slice(h,a)):(0===h&&o?(r.name=t.slice(1,s),r.base=t.slice(1,a)):(r.name=t.slice(h,s),r.base=t.slice(h,a)),r.ext=t.slice(s,a)),h>0?r.dir=t.slice(0,h-1):o&&(r.dir=\"/\"),r},sep:\"/\",delimiter:\":\",win32:null,posix:null};n.posix=n,t.exports=n}},e={};function r(n){var i=e[n];if(void 0!==i)return i.exports;var o=e[n]={exports:{}};return t[n](o,o.exports,r),o.exports}r.d=(t,e)=>{for(var n in e)r.o(e,n)&&!r.o(t,n)&&Object.defineProperty(t,n,{enumerable:!0,get:e[n]})},r.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),r.r=t=>{\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(t,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(t,\"__esModule\",{value:!0})};var n={};let i;if(r.r(n),r.d(n,{URI:()=>l,Utils:()=>I}),\"object\"==typeof process)i=\"win32\"===process.platform;else if(\"object\"==typeof navigator){let t=navigator.userAgent;i=t.indexOf(\"Windows\")>=0}const o=/^\\w[\\w\\d+.-]*$/,s=/^\\//,h=/^\\/\\//;function a(t,e){if(!t.scheme&&e)throw new Error(`[UriError]: Scheme is missing: {scheme: \"\", authority: \"${t.authority}\", path: \"${t.path}\", query: \"${t.query}\", fragment: \"${t.fragment}\"}`);if(t.scheme&&!o.test(t.scheme))throw new Error(\"[UriError]: Scheme contains illegal characters.\");if(t.path)if(t.authority){if(!s.test(t.path))throw new Error('[UriError]: If a URI contains an authority component, then the path component must either be empty or begin with a slash (\"/\") character')}else if(h.test(t.path))throw new Error('[UriError]: If a URI does not contain an authority component, then the path cannot begin with two slash characters (\"//\")')}const c=\"\",f=\"/\",u=/^(([^:/?#]+?):)?(\\/\\/([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?/;class l{static isUri(t){return t instanceof l||!!t&&\"string\"==typeof t.authority&&\"string\"==typeof t.fragment&&\"string\"==typeof t.path&&\"string\"==typeof t.query&&\"string\"==typeof t.scheme&&\"string\"==typeof t.fsPath&&\"function\"==typeof t.with&&\"function\"==typeof t.toString}scheme;authority;path;query;fragment;constructor(t,e,r,n,i,o=!1){\"object\"==typeof t?(this.scheme=t.scheme||c,this.authority=t.authority||c,this.path=t.path||c,this.query=t.query||c,this.fragment=t.fragment||c):(this.scheme=function(t,e){return t||e?t:\"file\"}(t,o),this.authority=e||c,this.path=function(t,e){switch(t){case\"https\":case\"http\":case\"file\":e?e[0]!==f&&(e=f+e):e=f}return e}(this.scheme,r||c),this.query=n||c,this.fragment=i||c,a(this,o))}get fsPath(){return v(this,!1)}with(t){if(!t)return this;let{scheme:e,authority:r,path:n,query:i,fragment:o}=t;return void 0===e?e=this.scheme:null===e&&(e=c),void 0===r?r=this.authority:null===r&&(r=c),void 0===n?n=this.path:null===n&&(n=c),void 0===i?i=this.query:null===i&&(i=c),void 0===o?o=this.fragment:null===o&&(o=c),e===this.scheme&&r===this.authority&&n===this.path&&i===this.query&&o===this.fragment?this:new d(e,r,n,i,o)}static parse(t,e=!1){const r=u.exec(t);return r?new d(r[2]||c,w(r[4]||c),w(r[5]||c),w(r[7]||c),w(r[9]||c),e):new d(c,c,c,c,c)}static file(t){let e=c;if(i&&(t=t.replace(/\\\\/g,f)),t[0]===f&&t[1]===f){const r=t.indexOf(f,2);-1===r?(e=t.substring(2),t=f):(e=t.substring(2,r),t=t.substring(r)||f)}return new d(\"file\",e,t,c,c)}static from(t){const e=new d(t.scheme,t.authority,t.path,t.query,t.fragment);return a(e,!0),e}toString(t=!1){return b(this,t)}toJSON(){return this}static revive(t){if(t){if(t instanceof l)return t;{const e=new d(t);return e._formatted=t.external,e._fsPath=t._sep===g?t.fsPath:null,e}}return t}}const g=i?1:void 0;class d extends l{_formatted=null;_fsPath=null;get fsPath(){return this._fsPath||(this._fsPath=v(this,!1)),this._fsPath}toString(t=!1){return t?b(this,!0):(this._formatted||(this._formatted=b(this,!1)),this._formatted)}toJSON(){const t={$mid:1};return this._fsPath&&(t.fsPath=this._fsPath,t._sep=g),this._formatted&&(t.external=this._formatted),this.path&&(t.path=this.path),this.scheme&&(t.scheme=this.scheme),this.authority&&(t.authority=this.authority),this.query&&(t.query=this.query),this.fragment&&(t.fragment=this.fragment),t}}const p={58:\"%3A\",47:\"%2F\",63:\"%3F\",35:\"%23\",91:\"%5B\",93:\"%5D\",64:\"%40\",33:\"%21\",36:\"%24\",38:\"%26\",39:\"%27\",40:\"%28\",41:\"%29\",42:\"%2A\",43:\"%2B\",44:\"%2C\",59:\"%3B\",61:\"%3D\",32:\"%20\"};function m(t,e,r){let n,i=-1;for(let o=0;o<t.length;o++){const s=t.charCodeAt(o);if(s>=97&&s<=122||s>=65&&s<=90||s>=48&&s<=57||45===s||46===s||95===s||126===s||e&&47===s||r&&91===s||r&&93===s||r&&58===s)-1!==i&&(n+=encodeURIComponent(t.substring(i,o)),i=-1),void 0!==n&&(n+=t.charAt(o));else{void 0===n&&(n=t.substr(0,o));const e=p[s];void 0!==e?(-1!==i&&(n+=encodeURIComponent(t.substring(i,o)),i=-1),n+=e):-1===i&&(i=o)}}return-1!==i&&(n+=encodeURIComponent(t.substring(i))),void 0!==n?n:t}function y(t){let e;for(let r=0;r<t.length;r++){const n=t.charCodeAt(r);35===n||63===n?(void 0===e&&(e=t.substr(0,r)),e+=p[n]):void 0!==e&&(e+=t[r])}return void 0!==e?e:t}function v(t,e){let r;return r=t.authority&&t.path.length>1&&\"file\"===t.scheme?`//${t.authority}${t.path}`:47===t.path.charCodeAt(0)&&(t.path.charCodeAt(1)>=65&&t.path.charCodeAt(1)<=90||t.path.charCodeAt(1)>=97&&t.path.charCodeAt(1)<=122)&&58===t.path.charCodeAt(2)?e?t.path.substr(1):t.path[1].toLowerCase()+t.path.substr(2):t.path,i&&(r=r.replace(/\\//g,\"\\\\\")),r}function b(t,e){const r=e?y:m;let n=\"\",{scheme:i,authority:o,path:s,query:h,fragment:a}=t;if(i&&(n+=i,n+=\":\"),(o||\"file\"===i)&&(n+=f,n+=f),o){let t=o.indexOf(\"@\");if(-1!==t){const e=o.substr(0,t);o=o.substr(t+1),t=e.lastIndexOf(\":\"),-1===t?n+=r(e,!1,!1):(n+=r(e.substr(0,t),!1,!1),n+=\":\",n+=r(e.substr(t+1),!1,!0)),n+=\"@\"}o=o.toLowerCase(),t=o.lastIndexOf(\":\"),-1===t?n+=r(o,!1,!0):(n+=r(o.substr(0,t),!1,!0),n+=o.substr(t))}if(s){if(s.length>=3&&47===s.charCodeAt(0)&&58===s.charCodeAt(2)){const t=s.charCodeAt(1);t>=65&&t<=90&&(s=`/${String.fromCharCode(t+32)}:${s.substr(3)}`)}else if(s.length>=2&&58===s.charCodeAt(1)){const t=s.charCodeAt(0);t>=65&&t<=90&&(s=`${String.fromCharCode(t+32)}:${s.substr(2)}`)}n+=r(s,!0,!1)}return h&&(n+=\"?\",n+=r(h,!1,!1)),a&&(n+=\"#\",n+=e?a:m(a,!1,!1)),n}function C(t){try{return decodeURIComponent(t)}catch{return t.length>3?t.substr(0,3)+C(t.substr(3)):t}}const A=/(%[0-9A-Za-z][0-9A-Za-z])+/g;function w(t){return t.match(A)?t.replace(A,(t=>C(t))):t}var x=r(975);const P=x.posix||x,_=\"/\";var I;!function(t){t.joinPath=function(t,...e){return t.with({path:P.join(t.path,...e)})},t.resolvePath=function(t,...e){let r=t.path,n=!1;r[0]!==_&&(r=_+r,n=!0);let i=P.resolve(r,...e);return n&&i[0]===_&&!t.authority&&(i=i.substring(1)),t.with({path:i})},t.dirname=function(t){if(0===t.path.length||t.path===_)return t;let e=P.dirname(t.path);return 1===e.length&&46===e.charCodeAt(0)&&(e=\"\"),t.with({path:e})},t.basename=function(t){return P.basename(t.path)},t.extname=function(t){return P.extname(t.path)}}(I||(I={})),LIB=n})();export const{URI,Utils}=LIB;\n//# sourceMappingURL=index.mjs.map"],"names":[],"sourceRoot":""}